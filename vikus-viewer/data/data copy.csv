keywords,year,id,_title,_authors,_abstract,_origin_path,_display_path_to_pdf,_path_to_pdf,_fulltext
None,2021,https-www-ijcai-org-proceedings-2021-0001-pdf,Distance Polymatrix Coordination Games,"Alessandro Aloisio, Michele Flammini, Bojana Kodric, Cosimo Vinci",None,https://www.ijcai.org/proceedings/2021/0001.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0001-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0001-pdf.pdf,"distance polymatrix coordination games
alessandro aloisio1 2   michele flammini1   bojana kodric1 and cosimo vinci1
1gran sasso science institute  l aquila  italy
2university of l aquila  italy
 alessandro aloisio  michele flammini  bojana kodric  cosimo vinci @gssi it
abstract
in polymatrix coordination games  each player x is
a node of a graph and must select an action in her
strategy set  nodes are playing separate bimatrix
games with their neighbors in the graph  namely 
the utility of x is given by the preference she has for
her action plus  for each neighbor y  a payoff which
strictly depends on the mutual actions played by x
and y 
we propose the new class of distance polymatrix
coordination games  properly generalizing polyma-
trix coordination games  in which the overall utility
of player x further depends on the payoffs arising
from mutual actions of players v  z that are the end-
points of edges at any distance h < d from x  for a
fixed threshold value d ≤ n  in particular  the over-
all utility of player x is the sum of all the above
payoffs  where each payoff is proportionally dis-
counted by a factor depending on the distance h of
the corresponding edge 
under the above framework  which is a natural gen-
eralization that is well-suited for capturing positive
community interactions  we study the social ineffi-
ciency of equilibria resorting to standard measures
of price of anarchy and price of stability  namely 
we provide suitable upper and lower bounds for
the aforementioned quantities  both for bounded-
degree and general graphs 
1
introduction
polymatrix games  yanovskaya  1968  are a well-known uni-
versal framework for modeling multi-agent games  which
takes into account only pairwise interactions and thus allows
a succinct representation  despite the constraint of consid-
ering only pairwise interactions  its formulation is general
enough to capture a number of settings  both of theoretical
and practical interest  in polymatrix games each player plays
a separate bimatrix game with every other player  in the re-
stricted version named polymatrix coordination games  rahn
and sch¨afer  2015   an outcome of a bimatrix game gives the
same payoff w x y  σx  σy  to the two players x and y in-
volved in it  moreover  every player gets also an additional
payoff px σx  that only depends on the strategy she chooses 
in this paper  we generalize polymatrix coordination
games  by allowing players to receive further payoff from the
interactions they are not personally involved in  the idea
here is that each player benefits not only from good rela-
tions with her immediate neighbors  but also from the pos-
itive environment stemming from good relations between her
immediate neighbors and their respective immediate neigh-
bors  a further generalization of this thought brings us to
a model in which the utility is computed as the sum of the
payoffs from the whole connected component of the inter-
action graph  up to a certain maximal distance d  where d
is a parameter of the model  furthermore  it seems reason-
able to discount the amount of payoff received from non-
neighboring edges by a factor between zero and one  and to
make such factors decrease with the distance of the corre-
sponding edge/interaction  in other words  an agent x gets
also the payoff αh 1 · w v z  σv  σz  for every edge  v  z 
at distance h < d from x  where αh 1 is the relative dis-
count factor  we call the arising model  that generalizes poly-
matrix coordination games  distance polymatrix coordination
games 
distance polymatrix coordination games are able to cap-
ture many types of interactions in the real world  in fact 
several kinds of positive community effects easily fall within
their scope  for instance  members of a scientific community
obviously benefit from successful collaborations with their
colleagues  while at the same time having personal prefer-
ences of what they would like to work on   however  any
individual also benefits  albeit to a smaller degree  when his
close colleagues have successful collaborations that he is not
personally a part of  this is quite obvious when thinking
about the student–advisor relationship  but also noticeable for
researchers working at the same university or institution  a
further example comes from politics  where a person who be-
longs to a party profits not only from her direct contacts  but
also from the contacts of her contacts  etc  at the same time  it
is also common that the benefit obtained by relations at sec-
ond or higher distance level generate less payoff  which is
taken into account by our discount factors 
in the setting described above  we will be focusing on the
efficiency of the system  our reference point for stability will
be k-strong nash equilibria  which are action profiles from
which no group of up to k agents can simultaneously deviate
such that all of them profit from the deviation  such a defini-
proceedings of the thirtieth    ijcai-21 
3
 tion also includes the standard notion of nash equilibria for
k = 1  however  we will see that only for k ≥ 2 the ineffi-
ciency can be suitably bounded  this fact is not a real draw-
back  as some degree of communication between the agents
is to be expected in real-world scenarios  and especially in
the ones modeled by means of these games  which assume a
positive coordination effect among close agents  our analysis
provides bounds which depend on k and on the discounting
factors for the part of the utility of the agents coming from
non-first-hand interactions 
1 1
related work
polymatrix games were introduced several decades ago
 yanovskaya  1968  and have been thoroughly studied since 
both in some classical works  howson  1972  eaves  1973 
howson and rosenthal  1974  miller and zucker  1991  and
also more recently with a special focus on equilibria  rahn
and sch¨afer  2015  cai et al   2016  deligkas et al   2017 
deligkas et al   2020  
polymatrix coordination games  rahn and sch¨afer  2015  
in which the bimatrix games have symmetrical payoffs and
players have individual preferences  are the basis of our
model  indeed  they are encompassed by our model by setting
d = 1  polymatrix coordination games are in turn an exten-
sion of a previously introduced model that did not include
individual preferences  cai and daskalakis  2011  
our model is also related to the so-called social context
games  ashlagi et al   2008   where the players  utilities are
computed from the payoffs based on the underlying neighbor-
hood graph and an aggregation function  we consider more
than just the neighborhood of an agent  and we account the
player s preference only for her own utility 
related to our work are also  symmetric  additively separa-
ble hedonic games  dr eze and greenberg  1980  and hyper-
graph hedonic games  aloisio et al   2020   where the players
are embedded in a weighted graph and the utility is computed
as the sum of the edges or hyperedges towards members of the
same coalition  the difference from our model  however  is
that in hedonic games in general every coalition is a feasible
choice for every player  there are no individual preferences 
and the weights in each bimatrix are all equal to either 0 or to
a fixed value w 
another model related to our work is the group activity se-
lection problem  darmann et al   2012  darmann and lang 
2017  bil o et al   2019   standing between polymatrix coordi-
nation games and hedonic games  also here  in each bimatrix
all the weights are either 0 or a fixed value w  but there are
also individual preferences that depend on the chosen activity 
a generalization of polymatrix coordination games to hy-
pergraphs is called synchronization games  simon and wo-
jtczak  2017   for which the existence and computability of
pure and strong nash equilibria have been studied  without
investigating the degradation of social welfare 
some negative results for our problem can be inherited
from additively separable hedonic games  for instance  com-
puting a nash stable outcome is pls-complete  gairing and
savani  2010   while computing an optimal outcome and de-
termining the existence of a core stable  strict core stable 
nash stable  or individually stable outcome are all np-hard
problems  aziz et al   2011   it has also been proven that
finding a pure nash equilibrium in a polymatrix coordination
game is pls-complete  cai and daskalakis  2011  
the idea of obtaining utility from non-neighboring players
has been explored recently for a variant of hedonic games 
called distance hedonic games  that are not additively sepa-
rable  since the coalition size also plays a role in determining
the payoffs  flammini et al   2020   they generalize frac-
tional hedonic games  aziz et al   2019  elkind et al   2020 
monaco et al   2020  carosi et al   2019  bil o et al   2018 
similarly as our model does with polymatrix games 
1 2
our contribution
we study the inefficiency of k-stable nash equilibria of d-
distance polymatrix coordination games and provide suitable
bounds on both the price of anarchy and the price of sta-
bility  to the best of our knowledge  there are no previous
results of this kind in the literature that would apply to our
model  in section 3  we give upper and lower bounds for
bounded-degree graphs  with the gap being reasonably small 
and in section 4  a tight bound on the price of anarchy for
general graphs  finally  in section 5  we show that in general
graphs the price of stability is asymptotically equal to the
price of anarchy  meaning that the ineffieciency of k-strong
equilibria is fully characterized  the related proof technique
is in our opinion of independent interest and a valuable con-
tribution in itself  as it provides a general approach that can
potentially be used in other contexts 
we remark that our results apply also to the subclass of the
classical polymatrix coordination games  for which in turn we
get the first upper and lower bounds on the price of anarchy
for bounded-degree graphs  and the first asymptotically tight
lower bound on the price of stability for general graphs 
our results are summarized in table 1  due to space con-
straints  some of the proofs are only sketched  while all the
details are deferred to the full version 
bounded-degree
general
poak lb 
poak ub 
�
h∈ d  αh∆ ∆−1 h−1
�
h∈ d  αh ∆−1 ⌊h/2⌋
2 �
h∈ d  αh∆ ∆ − 1 h−1
 2 α2· n−2  · n−1 
k−1
posk ub 
posk lb 
↓
←
↓
2n−3   α2 n−2  n−3/2 
 1 α2 k
table 1  summary of our results  where ub and lb stands for upper
and lower bound  respectively  furthermore  ∆ denotes the maximal
vertex degree in the bounded-degree case and αh  h ∈  d   is the
discounting factor for edges at distance h − 1  the arrows denote
that a result follows from an adjacent result in the table 
2
model and definitions
distance polymatrix coordination games 
given an in-
teger d ≥ 1  a d-distance polymatrix coordination game
g =  g   σx x∈v    we e∈e   px x∈v    αh h∈ d  
proceedings of the thirtieth    ijcai-21 
4
 is a tuple defined as follows 
• g =  v  e  is an undirected graph  where v is the set
of players and e the set of edges between players 
• for any x ∈ v   σx is a finite set of strategies of player x 
a strategy profile σ =  σ1          σn  is a configuration in
which each player x ∈ v plays strategy σx ∈ σx 
• for any edge  v  z  ∈ e  let w v z    σv × σz →
r≥0 be the weight function that assigns  to each pair of
strategies σv  σz played respectively by v and z  a weight
w v z  σv  σz  ≥ 0 
• for any x ∈ v   let px   σx → r≥0 be the player-
preference function that assigns  to each strategy profile
σx played by player x  a non-negative real value px σx  
called player-preference 
• let  αh h∈ d  be the distance-factors sequence of the
game  that is a non-negative sequence of real parame-
ters  called distance-factors  such that 1 = α1 ≥ α2 ≥
      ≥ αd ≥ 0 
in what follows  for the sake of brevity  given any strategy
profile σ  we will often denote w v z  σv  σz  and px σx 
simply as w v z  σ  and px σ   respectively 
for any h ∈  d   let eh x  be the set of edges  v  z  such
that the minimum distance between x and one of the players
v and z is exactly h − 1  then  for any x ∈ v   the utility
function ux   ×x∈v σx → r of player x  for any strategy
profile σ is defined as
ux σ   = px σ   
�
h∈ d 
αh
�
e∈eh x 
we σ  
remark 1  we observe that  if d = 1  we obtain the classical
polymatrix coordination games  where the overall utility of
player x only depends on payoffs we σ  for e for which x is
an endpoint  instead  if d > 1  the overall utility of player x
further depends on the discounted payoffs αh 1 · w v z  σ 
arising by mutual actions of players v  z that are the endpoints
of edges at any distance h < d from x 
given a strategy profile σ  the social welfare of σ is de-
fined as sw σ  = �
x∈v ux σ   a social optimum of game
g is a strategy profile σ∗ that maximizes the social welfare 
we denote by opt g  = sw σ∗  the corresponding value 
k-strong nash equilibrium 
given two strategy profiles
σ =  σ1          σn  and σ∗ =  σ∗
1          σ∗
n   and a subset
z ⊆ v   let σ
z→ σ∗ be the strategy profile σ′ =  σ′
1          σ′
n 
such that σ′
x = σ∗
x if x ∈ z  and σ′
x = σx otherwise  given
k ≥ 1  a strategy profile σ is a k-strong nash equilibrium of
g if  for any strategy profile σ∗ and any z ⊆ v such that
|z| ≤ k  there exists x ∈ z such that ux σ  ≥ ux σ
z→ σ∗  
informally  σ is a k-strong nash equilibrium if  for any coali-
tion of at most k players deviating  there exists at least one
player in the coalition that has no benefit  we denote the  pos-
sibly empty  set of k-strong nash equilibria of g by nek g  
k-strong price of anarchy  poa  and price of stability
 pos  
the k-strong price of anarchy of a game g is de-
fined as poak g   = maxσ∈nek g 
opt g 
sw σ    i e   it is the
1
2
3
4
5
6
7
8
0
0
1
0
1
1
1
figure 1  the underlying graph of the d-distance polymatrix coordi-
nation game from example 1 for n = 8  where the weight function
has already been evaluated  in particular  the nodes playing strategy
s are depicted as squares  and the ones playing s∗ as hexagons 
worst-case ratio between the optimal social welfare and the
social welfare of a k-strong nash equilibrium  the k-strong
price of stability of game g is defined as posk g   =
minσ∈nek g 
opt g 
sw σ    i e   it is the best-case ratio between the
optimal social welfare and the social welfare of a k-strong
nash equilibrium  clearly  posk g  ≤ poak g   whereas
both quantities are not defined if nek g  = ∅ 
example 1  consider a d-distance polymatrix coordination
game with n = 8 players whose underlying graph is a star
 shown in figure 1 for n = 8   let σx =  s  s∗  for every
x ∈  n   w x y  σ  = 1 iff σx = σy = s∗ and 0 otherwise 
furthermore  let p1 σ  = 1 iff σ1 = s and 0 otherwise  while
all other player-preference functions are constant and equal
to zero  then  the strategy profile in which all players play s∗
is a k-strong nash equilibrium for any k  the utility of player
1 for this strategy profile is n − 1  while for all other players
it is 1 for d = 1 and 1    n − 2 α2 for d ≥ 2 
3
k-strong poa of bounded-degree graphs
in this section we compute upper and lower bounds on the
k-strong price of anarchy of bounded-degree graphs  more
formally  a game g is ∆-bounded-degree if the degree of each
node/player x ∈ v in graph g is at most ∆ 
remark 2  for k = 1  d ≥ 1  and ∆ = 1  there exists
a simple ∆-bounded-degree d-distance polymatrix coordina-
tion game g such that poak g  = ∞  rahn and sch¨afer 
2015   for sake of completeness  we present this example in
the full version  thus  as it is not possible to bound the k-
strong poa for k = 1  not even for bounded-degree graphs
and not even when ∆ = 1  in the rest of the paper we will
only focus on the estimation of the k-strong poa for k ≥ 2 
furthermore  if ∆ = 1  w l o g  we can assume that the graph
consists of 2 agents and an edge between them  this special
case is encompassed by section 4  so here we will assume
that ∆ ≥ 2 
theorem 1  for any integer k ≥ 2 and any ∆-bounded-
degree d-distance polymatrix coordination game g having a
distance-factors sequence  αh h∈ d   it holds that
poak g  ≤ 2
�
h∈ d 
αh · ∆ ·  ∆ − 1 h−1 
 1 
remark 3  from eq   1   notice that the k-strong price of an-
archy of ∆-bounded-degree d-distance polymatrix coordina-
tion games  as a function of d  grows at most as o  ∆−1 d  
proceedings of the thirtieth    ijcai-21 
5
 before proving the theorem  we provide a lemma that gives
an upper bound on the social welfare of any strategy profile 
lemma 1  for any strategy profile σ  it holds that sw σ  ≤
�
x∈v px σ    2 �
h∈ d  αh ·  ∆ − 1 h−1 · �
e∈e we σ  
proof  for any e ∈ e and h ∈  d   let nh e   = | x ∈ v
 
e ∈ eh x  |  i e   nh e  denotes how many players x ∈ v
have distance equal to h − 1 from e  we can see that
�
x∈v
�
e∈eh i 
we σ  =
�
e∈e
nh e  · we σ  
 2 
furthermore  the number of players having distance h − 1 to
an edge e =  v  z  is at most equal to the number of simple
paths starting from either v or z and having length h−1  this
number is upper bounded by 2 ·  ∆ − 1 h−1  therefore 
nh e  ≤ 2 ·  ∆ − 1 h−1 
 3 
by using  2  and  3   we get
sw σ  =
�
x∈v
px σ   
�
h∈ d 
αh
�
x∈v
�
e∈eh x 
we σ 
=
�
x∈v
px σ   
�
h∈ d 
αh
�
e∈e
nh e  · we σ 
=
�
x∈v
px σ   
�
e∈e
�
h∈ d 
αh · nh e  · we σ 
≤
�
x∈v
px σ   
�
e∈e
�
h∈ d 
αh · 2 ·  ∆ − 1 h−1we σ 
=
�
x∈v
px σ    2
�
h∈ d 
αh ·  ∆ − 1 h−1 �
e∈e
we σ  
thus showing the claim 
proof of theorem 1  fix k ≥ 2  let σ and σ∗ be a worst-
case k-strong nash equilibrium and a social optimum of g 
respectively  as k ≥ 2  σ is in particular also a 2-strong
nash equilibrium  thus  for any edge e ∈ e  we know that
there exists a player ve ∈ e  such that
uve σ  ≥ uve σ
e→ σ∗  ≥ pve σ∗    we σ∗  
 4 
for any e ∈ e  let ze denote the player in e \  ve   as σ is
also a 1-strong nash equilibrium  we have that
uze σ  ≥ uze σ
 ze 
→ σ∗  ≥ pze σ∗  
 5 
by using  4  and  5   we get
�
e∈e
 uve σ    uze σ  
≥
�
e∈e
 pve σ∗    pze σ∗    we σ∗  
≥
�
e∈e
we σ∗   
�
x∈v
px σ∗ 
≥
�
�2
�
h∈ d 
αh ·  ∆ − 1 h−1
�
�
−1
· sw σ∗ 
 6 
where  6  comes from lemma 1  furthermore  we get
�
e∈e
 uve σ    uze σ   ≤
�
x∈v
∆·ux σ  = ∆·sw σ    7 
since  in the left-hand part of  7   the utility of each player
is counted at most ∆ times 
by putting together  6  and
 7   we get sw σ  ≥ ∆−1 · �
e∈e  uve σ    uze σ   ≥
∆−1 ·
�
2 �
h∈ d  αh ·  ∆ − 1 h−1�−1
· sw σ∗   this shows
the claim  since we get poak g  = sw σ∗ 
sw σ  ≤ 2 �
h∈ d  αh ·
∆ ·  ∆ − 1 h−1 
in the following theorem we provide a lower bound on
the k-strong price of anarchy  relying on a nice construction
from graph theory 
theorem 2  for any k ≥ 2  ∆ ≥ 2  d ≥ 1  and any distance-
factors sequence  αh h∈ d   there exists a ∆-bounded-degree
d-distance polymatrix coordination game g such that
poak g  ≥
�
h∈ d  αh · ∆ ·  ∆ − 1 h−1
�
h∈ d  αh ∆ − 1 ⌊h/2⌋
 
 8 
remark 4  notice that  if all the distance-factors are not
lower than a constant c > 0  from eq   8  we can conclude
that the k-strong price of anarchy of ∆-bounded-degree d-
distance polymatrix coordination games  as a function of d 
can grow as ω  ∆ − 1 d/2   the formal proof of this remark
is deferred to the full version  
proof of theorem 2  fix k ≥ 2  ∆ ≥ 2  d ≥ 1  and a
distance-factors sequence  αh h∈ d   by  sachs  1963   there
exists an undirected graph g =  v  e  such that g is ∆-
regular  i e   every node in v has degree ∆   and the girth1
of g is at least max 2d   1  k   1   let g be a ∆-bounded-
degree d-distance polymatrix coordination game such that 
 i  g is its underlying graph   ii   αh h∈ d  is its distance-
factors sequence   iii  each player x has two strategies  s and
s∗   iv  for every edge e =  v  z  ∈ e and strategy profile
σ  we σ  = 1 if both v and z play s∗ in σ  and 0 otherwise 
 v  for every x ∈ v   px σ  = �
h∈ d  αh ∆ − 1 ⌊h/2⌋ if x
plays s in σ  otherwise px σ  = 0  let σ and σ∗ be the
strategy profiles in which all players play strategy s and s∗ 
respectively  we present two technical lemmas  which use the
above defined properties of graph g 
lemma 2  σ is a k-strong nash equilibrium 
proof sketch  we prove the claim by assuming that σ is not
a k-strong nash equilibrium  i e   there exists a coalition z
with |z| ≤ k such that all the players of z get a benefit when
deviating simultaneously to their strategy in σ∗  as there
exists no simple cycle with ≤ k edges in g  we have that
the subgraph g′ induced by z is a forest  we consider an
arbitrary tree t of g′ and we fix a root r of t  then  we
consider a player y corresponding to one of the deepest leaves
of rooted tree t  and we assume w l o g  that t is a complete
tree of height d whose root has ∆ children and each other
non-leaf node has ∆−1 children  see figure 2 for a clarifying
proceedings of the thirtieth    ijcai-21 
6
 y
r
t ′
figure 2  the utility of a leaf node y in t  with root r  for ∆ = 4
and d = 4  here  t ′ denotes a perfect 3-ary tree of height 4 
example   finally  we show that player y does not get any
benefit from the deviation  thus reaching a contradiction 
lemma 3  ux σ∗  = �
h∈ d  αh · ∆ ·  ∆ − 1 h−1 for any
x ∈ v  
proof sketch  as graph g is ∆-regular and the girth of g is at
least 2d 1  we necessarily have that |eh x | = ∆ ∆−1 h−1
for every h ∈  d   to show the above equality  we observe that
the subgraph of g made of all the edges at distance at most
d − 1 from x  i e   all the edges in ∪h∈ d eh x   is a perfect
tree of depth d rooted in x such that each non-leaf node has
degree ∆ 
by using the above equality  for every x ∈ v it holds that
ux σ∗  = �
h∈ d  αh|eh x | = �
h∈ d  αh∆ ∆ − 1 h−1 
from lemma 2 and 3  we get poak g  ≥
�
x∈v ux σ∗ 
�
x∈v ux σ  ≥
�
h∈ d  αh·∆· ∆−1 h−1
�
h∈ d  αh ∆−1 ⌊h/2⌋  
4
k-strong poa of general graphs
in this section  we provide tight bounds on the k-strong price
of anarchy when there is no particular assumption on the un-
derlying graph of the considered game  such bounds depend
on k  on the number of players n  and on the value α2 of the
distance-factors sequence 
theorem 3  for any integer k ≥ 2 and any d-distance poly-
matrix coordination game g having a distance-factors se-
quence  αh h∈ d   we have poak g  ≤  2 α2· n−2  · n−1 
k−1
 
before proving the theorem  we provide a lemma that  sim-
ilarly to lemma 1  gives an upper bound on the social welfare
of any strategy profile 
lemma 4  for any strategy profile σ  it holds that sw σ  ≤
�
x∈v px σ     2   α2 ·  n − 2   · �
e∈e we σ  
proof sketch  we define nh e  as in the proof of lemma 1 
and know that eq   2  holds 
furthermore  one can eas-
ily show that  for any e ∈ e  |n1 e | = 2  and therefore
�d
h=2 nh e  = �d
h=1 nh e  − n1 e  ≤ n − n1 e  = n − 2 
from here  by using eq   2   and the fact that α1 = 1 and
α2 ≥ αh for any h ∈  d  \  1   we get the claim 
proof of theorem 3  fix k ≥ 2  let σ and σ∗ be a worst-
case k-strong nash equilibrium and a social optimum of g 
respectively  as σ is a k-strong nash equilibrium  we have
that  for any z ⊆ v with |z| = k  there exists a player
1the length of a shortest cycle contained in the graph
z1 z  ∈ z such that uz1 z  σ  ≥ uz1 z  σ
z→ σ∗   fur-
thermore  there also exists a player z2 z  ∈ z 2   = z\ z1 
such that uz2 z  σ  ≥ uz2 z  σ
z 2 
→ σ∗   if we proceed it-
eratively  we have that  for any i ∈  k   there exists a player
zi z  ∈ z i   = z \  z1 z           zi−1 z   such that
uzi z  σ  ≥ uzi z  σ
z i 
→ σ∗  
 9 
before continuing the proof  we present two technical lem-
mas below 
lemma 5 
�n−1
k−1
�
· sw σ  = �
z⊆v
|z|=k
�
i∈ k  uzi z  σ  
lemma 6  it holds that
�
z⊆v
|z|=k
�
i∈ k 
uzx z  σ
z x 
→ σ∗ 
≥
�n − 1
k − 1
� �
x∈v
px σ∗   
�n − 2
k − 2
� �
e∈e
we σ∗  
proof of theorem 3  cont    by putting together the auxiliary
lemmas  we get
�n − 1
k − 1
�
· sw σ  =
�
z⊆v  |z|=k
�
i∈ k 
uzi z  σ 
 10 
≥
�
z⊆v  |z|=k
�
i∈ k 
uzi z  σ
z i 
→ σ∗ 
 11 
≥
�n − 1
k − 1
� �
x∈v
px σ∗   
�n − 2
k − 2
� �
e∈e
we σ∗ 
 12 
≥
�n − 2
k − 2
� ��
x∈v
px σ∗   
�
e∈e
we σ∗ 
�
≥
�n − 2
k − 2
�
·  2   α2 ·  n − 2  −1 · sw σ∗  
 13 
where  10    11    12   and  13   follow by lemma 5  eq   9  
lemma 6  and lemma 4  respectively  by exploiting  13   we
get poak g  ≤  
n−1
k−1 · 2 α2· n−2  
 
n−2
k−2 
=
 2 α2· n−2  · n−1 
k−1
 
thus showing the claim 
in the following theorem  we provide a tight lower bound 
theorem 4  for any k ≥ 2  d ≥ 1  n ≥ 2  and any distance-
factors sequence  αh h∈ d   there is a d-distance polymatrix
coordination game g with poak g  ≥  2 α2· n−2  · n−1 
k−1
 
proof sketch  fix d ≥ 1  k ≥ 2  n ≥ 2  and a distance-factors
sequence  αh h∈ d   let g be the d-distance polymatrix co-
ordination game of example 1  having n players   αh h∈ d 
as distance-factors sequence  and defined as follows   i  the
underlying graph g is a star in which all the players x ≥ 2
are only connected to player 1   ii  each player can play two
strategies s  s∗ only   iii  we σ  = 1 if all the players in e
play strategy s∗ under strategy profile σ  and we σ  = 0 oth-
erwise   iv  p1 σ  = k − 1 if player 1 plays strategy s under
proceedings of the thirtieth    ijcai-21 
7
 strategy profile σ  and p1 σ  = 0 otherwise   v  px σ  = 0
for any strategy profile σ and x ≥ 2  let σ and σ∗ be the
strategy profiles in which all players play strategy s and s∗ 
respectively  we can show that σ is a k-strong nash equilib-
rium and that poak g  ≥ sw σ∗ 
sw σ  =  2 α2· n−2  · n−1 
k−1
 
5
the k-strong pos of general graphs
in this section we show that there exists a d-distance poly-
matrix coordination game g such that posk g  is asymptoti-
cally equal to the upper bound on poak shown in theorem 3 
thus we completely characterize the inefficiency of d-distance
polymatrix coordination games for general graphs 
the modus operandi that we use to create the lower bound
for posk is to start from the lower bound instance on poak
provided in the proof of theorem 4  in which the optimal
outcome is a k-strong nash equilibrium  and to suitably trans-
form it in such a way that all the outcomes with social welfare
close to the optimum  which we call set of almost optimal out-
comes  cannot be stable  this is accomplished by inserting a
cycle of improvement steps involving these solutions  that ba-
sically do not influence the social welfare 
this technique is of independent interest  as it provides a
general approach that can be potentially used in other con-
texts  thus  we believe it is a valuable contribution in itself 
theorem 5  for any n ≥ 6  there exists a d-distance
polymatrix coordination game g such that posk g 
=
2n−3   α2 n−2  n−3/2 
 1 α2 k
 
proof  let g be defined as follows  the underlying graph g
has n nodes and 2n − 3 edges  where
e =   1  h    2  ℓ    h ∈  2          n   ℓ ∈  3          n  
 see figure 3   and σx =  1  2  3  for any x ∈  n   i e  
each player can play the same three strategies  we call bot-
tom layer  medium layer  and top layer the strategy profile in
which every player plays strategy 3  2  and 1  respectively 
we also shortly refer to strategies 3  2  and 1 by bottom 
medium  and top  respectively 
we now define for each layer the player-preference and
weight functions  where each entry that is not mentioned  we
assume to be null  at the bottom layer p1 3  = p2 3  =
 1   α2  1   ϵ  
at the medium layer  w 1 2  2  2  =
w 1 h  2  2  = w 2 h  2  2  =
1 ϵ
k   where 3 ≤ h ≤ n 
at the top layer p1 1  = p2 1  =
1
k  w 1 h  1  1  =
w 2 h  1  1  =
1 ϵ
k   where 3 ≤ h ≤ n  non-null edges
between the layers are w 1 2  1  2  =
2ϵ
k   w 1 h  1  2  =
w 1 h  2  1  = w 2 h  1  2  = w 2 h  2  1  =
1 ϵ
k   where
3 ≤ h ≤ n 
1
2
3
4
5
6
7
figure 3  graph g from the proof of theorem 5 for n = 7 
player 1
player 2
top
medium
top
1
k 
1
k
1 2ϵ
k  
2ϵ
k
medium
0 
1
k
1 ϵ
k  
1 ϵ
k
table 2  the part of the utility of player 1 and 2 coming from the
player-preference and the weight w 1 2  σ  for σ1  σ2 ∈  1  2   no
strategy profile is stable  as always at least one player can improve
her utility by deviating 
lemma 7  the bottom layer is a k-strong equilibrium with
social welfare 2 1   α2  1   ϵ  
lemma 8  all the k-strong equilibria have the same social
welfare 2 1   α2  1   ϵ  
proof sketch  if there exists an equilibrium where both play-
ers 1 and 2 are at the bottom  then the social welfare is
2 1   α2  1   ϵ   and we do not investigate further  if one of
the players 1 and 2 is not at the bottom  then all the players
will move to medium or top  starting from the ones different
from 1 and 2  finally  if both are not at the bottom  then at
least one of the players 1 and 2 will always move  this is
so  because each of them gets a constant utility from the re-
maining players  so they move just according to their bimatrix
game  whose values are reported in table 2 
the following lemma concludes the theorem 
lemma 9  the ratio between the optimum social wel-
fare and the social welfare given by one of the k-strong
nash stable strategy profiles  e g   the bottom layer  is
2n−3   α2 n−2  n−3/2 
 1 α2 k
  giving the posk g  
6
conclusion
in this work  we have introduced the class of d-distance poly-
matrix coordination games  and studied their performance
 by means of the k-strong price of anarchy and stability  
some open problems left by our work are that of closing
the gap between the upper and lower bound on the strong
price of anarchy for bounded-degree graphs  and provid-
ing better bounds on the strong price of stability specifically
for the case of bounded-degree graphs  another interesting
research direction is extending the idea of obtaining utili-
ties from non-neighboring players  as in  flammini et al  
2020  and our work  to other graphical games  kearns  2007 
bil o et al   2010   and then studying the social performance
of their equilibria in general graphs or specific topologies 
acknowledgements
this work has been partially supported by the italian miur
prin 2017 project algadimar  algorithms  games  and
digital markets  
proceedings of the thirtieth    ijcai-21 
8
 references
 aloisio et al   2020  alessandro aloisio  michele flam-
mini  and cosimo vinci  the impact of selfishness in hy-
pergraph hedonic games 
in proc  34th conf  artificial
intelligence  aaai   pages 1766–1773  2020 
 ashlagi et al   2008  itai ashlagi  piotr krysta  and moshe
tennenholtz 
social context games 
in proc  4th intl 
workshop internet   network economics  wine   pages
675–683  2008 
 aziz et al   2011  haris aziz  felix brandt  and hans georg
seedig  optimal partitions in additively separable hedonic
games  in proc  22nd intl  joint conf  artif  intell   ijcai  
pages 43–48  2011 
 aziz et al   2019  haris aziz  florian brandl  felix brandt 
paul harrenstein  martin olsen  and dominik peters  frac-
tional hedonic games  acm trans  economics and com-
put   7 2  6 1–6 29  2019 
 bil o et al   2010  vittorio bil o  angelo fanelli  michele
flammini  and luca moscardelli  when ignorance helps 
graphical multicast cost sharing games  theoret  comput 
sci   411 3  660–671  2010 
 bil o et al   2018  vittorio bil o  angelo fanelli  michele
flammini  gianpiero monaco  and luca moscardelli 
nash stable outcomes in fractional hedonic games  ex-
istence  efficiency and computation  j  artif  intell  res  
62 315–371  2018 
 bil o et al   2019  vittorio bil o  angelo fanelli  michele
flammini  gianpiero monaco  and luca moscardelli  op-
timality and nash stability in additive separable general-
ized group activity selection problems  in proc  28th intl 
joint conf  artif  intell   ijcai   pages 102–108  2019 
 cai and daskalakis  2011  yang
cai
and
constantinos
daskalakis  on minmax theorems for multiplayer games 
in proc  22nd symp  discr  algorithms  soda   pages
217–234  2011 
 cai et al   2016  yang cai  ozan candogan  constantinos
daskalakis  and christos h  papadimitriou 
zero-sum
polymatrix games  a generalization of minmax  math 
oper  res   41 2  648–655  2016 
 carosi et al   2019  raffaello carosi  gianpiero monaco 
and luca moscardelli  local core stability in simple sym-
metric fractional hedonic games 
in proc  18th conf 
autonomous agents and multi-agent systems  aamas  
pages 574–582  2019 
 darmann and lang  2017  andreas darmann and j erˆome
lang 
group activity selection problems 
in trends in
computational social choice  pages 385–410  2017 
 darmann et al   2012  andreas darmann 
edith elkind 
sascha kurz  j erˆome lang  joachim schauer  and ger-
hard j  woeginger  group activity selection problem  in
proc  8th intl  workshop internet   network economics
 wine   volume 7695  pages 156–169  2012 
 deligkas et al   2017  argyrios deligkas  john fearnley 
rahul savani  and paul g  spirakis  computing approx-
imate nash equilibria in polymatrix games  algorithmica 
77 2  487–514  2017 
 deligkas et al   2020  argyrios deligkas  john fearnley 
and rahul savani  tree polymatrix games are ppad-hard 
in proc  47th intl  coll  autom  lang  program   icalp  
pages 38 1–38 14  2020 
 dr eze and greenberg  1980  jacquese h  dr eze and joseph
greenberg  hedonic coalitions  optimality and stability 
econometrica  48 4  987–1003  1980 
 eaves  1973  b  curtis eaves 
polymatrix games with
joint constraints  siam journal on applied mathematics 
24 3  418–423  1973 
 elkind et al   2020  edith elkind 
angelo fanelli 
and
michele flammini  price of pareto optimality in hedonic
games  artif  intell   288 103357  2020 
 flammini et al   2020  michele flammini  bojana kodric 
martin olsen  and giovanna varricchio  distance hedo-
nic games  in proc  19th conf  autonomous agents and
multi-agent systems  aamas   pages 1846–1848  2020 
 gairing and savani  2010  martin gairing and rahul sa-
vani  computing stable outcomes in hedonic games  in
proc  3rd intl  symp  algorithmic game theory  sagt  
pages 174–185  2010 
 howson and rosenthal  1974  joseph howson and robert
rosenthal 
bayesian equilibria of finite two-person
games with incomplete information 
management sci  
21 3  313–315  1974 
 howson  1972  joseph howson  equilibria of polymatrix
games  management sci   18 5-part-1  312–318  1972 
 kearns  2007  michael kearns 
graphical games  page
159–180  cambridge university press  2007 
 miller and zucker  1991  douglas
miller
and
steven
zucker  copositive-plus lemke algorithm solves polyma-
trix games  oper  res  lett   10 5  285–290  1991 
 monaco et al   2020  gianpiero monaco  luca moscardelli 
and yllka velaj  stable outcomes in modified fractional
hedonic games  auton  agents multi agent syst   34 1  4 
2020 
 rahn and sch¨afer  2015  mona rahn and guido sch¨afer 
efficient equilibria in polymatrix coordination games  in
proc  40th intl  symp  math  foundations of computer sci-
ence  mfcs   pages 529–541  2015 
 sachs  1963  horst sachs  regular graphs with given girth
and restricted circuits  journal of the london mathemati-
cal society  1 1  423–429  1963 
 simon and wojtczak  2017  sunil simon and dominik wo-
jtczak  synchronisation games on hypergraphs  in proc 
26th intl  joint conf  artif  intell   ijcai   pages 402–408 
2017 
 yanovskaya  1968  elena b  yanovskaya 
equilibrium
points in polymatrix games 
lithuanian mathematical
journal  8 2  381–384  1968 
proceedings of the thirtieth    ijcai-21 
9
 "
None,2021,https-www-ijcai-org-proceedings-2021-0002-pdf,Diversity in Kemeny Rank Aggregation: A Parameterized Approach,"Emmanuel Arrighi, Henning Fernau, Daniel Lokshtanov, Mateus de Oliveira Oliveira, Petra Wolf",None,https://www.ijcai.org/proceedings/2021/0002.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0002-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0002-pdf.pdf,"diversity in kemeny rank aggregation 
a parameterized approach
emmanuel arrighi1   henning fernau2   daniel lokshtanov3
mateus de oliveira oliveira1   petra wolf 2
1university of bergen  norway
2university of trier  germany
3university of california santa barbara  ca  usa
 emmanuel arrighi  mateus oliveira @uib no   fernau  wolfp @informatik uni-trier de 
 daniello @ucsb edu
abstract
in its most traditional setting  the main concern of
optimization theory is the search for optimal solu-
tions for instances of a given computational prob-
lem  a recent trend of research in artificial intelli-
gence  called solution diversity  has focused on the
development of notions of optimality that may be
more appropriate in settings where subjectivity is
essential  the idea is instead of aiming at the devel-
opment of algorithms that output a single optimal
solution  the goal is to investigate algorithms out-
putting a small set of sufficiently good solutions that
are sufficiently diverse from one another  this way 
the user has the opportunity to choose the solution
being most appropriate to the context at hand  it
also displays the richness of the solution space 
when combined with techniques from parameter-
ized complexity theory  the paradigm of diversity
of solutions offers a powerful algorithmic frame-
work to address problems of practical relevance  in
this work  we investigate the impact of this com-
bination in the field of kemeny rank aggregation 
a well-studied class of problems lying in the inter-
section of order theory and social choice theory and
also in the field of order theory itself  in particular 
we show that the kemeny rank aggregation prob-
lem is fixed-parameter tractable with respect to nat-
ural parameters providing natural formalizations of
the notions of diversity and of the notion of a suffi-
ciently good solution  our main results work both
when considering the traditional setting of aggre-
gation over linearly ordered votes  and in the more
general setting where votes are partially ordered 
1
introduction
traditionally  in optimization theory  when given an instance
of a computational problem  one is interested in computing
some optimal solution for the instance in question  for cer-
tain problems of practical relevance  this framework may not
be satisfactory because it precludes the user from the pos-
sibility of choosing among optimal solutions in case more
than one exists  or from choosing a slightly less optimal solu-
tion that may be a better fit for the intended application  due
to subjective factors  a recent upcoming trend of research
in artificial intelligence  called diversity of solutions  petit
and trapp  2019  baste et al   2020  ingmar et al   2020 
baste et al   2019  fomin et al   2020   has focused on the
development of notions of optimality that may be more ap-
propriate in settings where subjectivity is essential  the idea
is that instead of aiming at the development of algorithms that
output a single optimal solution  the goal is to investigate al-
gorithms that output a small set of sufficiently good solutions
that are sufficiently diverse from one another  in this way  the
user has the opportunity to choose the solution that is most
appropriate to the context at hand  the intuition is that the
criteria employed by the user to decide what an appropriate
solution is may be subjective  and therefore  impractical or
even impossible to be formalized at the level of the problem
specification  examples of such criteria are aesthetic  eco-
nomic  political  or environmental criteria  another motiva-
tion comes from the problem of finding several good commit-
tees such that each committee member is not overloaded with
commitments  as described in  bredereck et al   2020   again 
some diversity could be helpful 
one source of difficulty when trying to develop efficient
algorithms for diverse variants of computational problems is
the fact that these problems may be computationally hard 
in particular  many interesting computational problems that
are suitable for being studied from the perspective of diver-
sity of solutions are already np-hard in the usual variant in
which one asks for a single solution  additionally  it may be
the case that even problems that are polynomial-time solvable
in the single-solution version become np-hard when consid-
ering diverse sets of solutions  one way to circumvent this
difficulty is to combine the framework of diversity of solu-
tions with the framework of fixed-parameter tractability the-
ory  downey and fellows  1999   a central notion in this
framework is the one of fixed-parameter tractability  an al-
gorithm for a given computational problem is said to be fixed-
parameter tractable with respect to parameters k1          kr if it
runs in time f k1          kr  · no 1   where n is the size of the
input and f is a computable function that depends only on the
parameters  the intuition is that if the range of the parameters
proceedings of the thirtieth    ijcai-21 
10
 is small on instances of practical relevance  then even if the
function f grows relatively fast  the algorithm can be consid-
ered to be fast enough for practical purposes 
when studying a given computational problem from the
point of view of solution diversity  it is crucial to have in
hands a notion of distance between solutions for that prob-
lem  the diversity of a set of solutions s is then defined as the
sum of distances between pairs of solutions in s  we denote
this measure by d  intuitively  diversity is a global measure
for how representative a set of solutions is among the space
of solutions  three natural parameters can be used to quan-
tify how good a diverse set of solutions is  the number r of
solutions in the set  the maximum distance δ between the cost
of a solution in the set and the cost of an optimal solution  we
call this parameter the solution imperfection of the set   and
the minimum required distance s between any two solutions
in the set  this last parameter is also known in the literature
as the scatteredness of s  galle  1989  
in this work  we investigate the impact of the notions of di-
versity of solutions and of fixed parameter tractability theory
in the context of social choice theory  in particular  we focus
on the framework of preference list aggregation introduced by
kemeny in the late fifties  kemeny  1959   intuitively  prefer-
ence lists are a formalism used in social choice theory to cap-
ture information about choice in applications involving the
selection of candidates  products  etc  by a group of voters 
the task is then to find a ranking of the candidates that maxi-
mizes the overall satisfaction among the voters  this problem
is commonly referred to in modern terminology as the ke-
meny rank aggregation  kra  problem  in its most general
setting  the ranking cast by each voter is a partial order on the
set of candidates  the distance measure we use to define our
diverse version for kra is the kendall-tau distance which is
widely used in the context of preference aggregation  its pop-
ularity is underlined by articles describing these issues for the
interested public audience  see  farkas and timotity  2019  
our main result is a multi-parametric algorithm for di-
verse kra over partially ordered votes that runs in time
f w  r  δ  s  · d · n · log n2 · m   where n is the number of
candidates  m is the number of votes  r  δ  s and d are the pa-
rameters discussed above  and w is the unanimity width of
the votes  that is to say  the pathwidth of the cocomparabil-
ity graph of the unanimity order of the input votes  corol-
lary 11   intuitively  this width measure is a quantification of
the amount of disagreement between votes  note that path-
width and treewidth coincide for the class of cocomparability
graphs  habib and m¨ohring  1994  
on the path towards obtaining our results for kemeny
rank aggregation  we also make contributions to problems
of independent interest arising in the theory of cocompara-
bility graphs 
first  by leveraging on classic results from
 habib and m¨ohring  1994   we show that the problem of
constructing a ρ-consistent path decomposition of approxi-
mately minimum width for the cocomparability graph gρ of
a given partial-order ρ is fixed-parameter tractable with re-
spect to the pathwidth of gρ  while it was known that the
pathwidth and the ρ-consistent pathwidth of gρ are always
the same  arrighi et al   2020   and fixed-parameter tractable
algorithms for computing path decompositions of approxi-
mately minimum width exists due to structural properties of
cocomparability graphs  bouchitt e et al   2004   the problem
of computing such a decomposition satisfying the additional
ρ-consistent requirement was open  arrighi et al   2020  
second  we note that the notion of kendall-tau distance
between partial orders  formally defined in section 3   which
is used to define our notion of diversity  can be applied
equally well in the more general context of the comple-
tion of an ordering problem  co   a problem of funda-
mental importance in order theory that unifies several prob-
lems of relevance for artificial intelligence  such as kra 
one-sided crossing minimization  an important sub-
routine used in the search for good hierarchical representa-
tions of graphs   and grouping by swapping  a relevant
problem in the field of memory management   wong and
reingold  1991   for a matter of generality  we first develop a
f w  r  δ  s ·d·n·log n2·m  time algorithm for diverse co
 theorem 10  and then obtain our main result for diverse
kra as a corollary  in the more general context of co  the
parameter w is the width of the cocomparability graph of the
partial order given at the input 
finally  building on recent advances in the theory of ck-
free graphs  chudnovsky et al   2020  we establish an up-
per bound for the pathwidth of a cocomparability graph in
terms of the number of edges of the graph  as a by-product
of this result  we obtain the first algorithm running in time
o∗ 2o 
√
k    theorem 12  for the positive completion of an
ordering problem  pco   a special case of co which still
generalizes kra and other important combinatorial prob-
lems  previous to our work  the best algorithm for this prob-
lem parameterized by cost had asymptotic time complexity
o∗ ko 
√
k   = o∗ 2
√
k log k   we remove the log-factor in
the exponent  according to thm  18 in  arrighi et al   2020 
this is optimal under eth  exponential time hypothesis  
2
preliminaries
if n is a positive integer   n  =  1          n  denotes the dis-
crete interval of the first n positive integers  and  n 0 =
 n  ∪  0   n denotes the non-negative integers 
let c be a set  a partial order over c is a reflexive  anti-
symmetric and transitive binary relation ρ ⊆ c × c  we say
that ρ is a linear order if additionally  for each  x  y  ∈ c×c 
either  x  y  ∈ ρ or  y  x  ∈ ρ  the comparability relation
sc ρ  of ρ is the symmetric closure of ρ  i e    x  y  ∈ sc ρ 
iff  x  y  ∈ ρ or  y  x  ∈ ρ  for instance  sc ρ  = c × c iff
ρ is a linear order  if ρ ⊆ c ×c is a partial order  then <ρ de-
notes the corresponding strict order  which is irreflexive and
transitive  linear orders over c can be given by bijections
π    |c|  → c  hence  <π  or ≤π  is used to denote the
corresponding strict  or partial  linear order  given a binary
relation α  we denote by tc α  the transitive closure of α 
definition 1  cocomparability graph  f1    given a partial
order ρ ⊆ c × c  we let gρ ˙=  c  c × c \ sc ρ   be the
cocomparability graph of ρ 
given an undirected graph g =  v  e  and a vertex v ∈ v  
we let n v  ˙=  u | u ∈ v   v  u  ∈ e  be the neighborhood
of v  a path decomposition of a graph g =  v  e  is a se-
proceedings of the thirtieth    ijcai-21 
11
 quence p =  b1  b2          bl  of subsets of v   such that the
following conditions are satisfied 
• �
1≤i≤l bi = v  
• for each edge  u  v  ∈ e  there is an i ∈  l  such that
u  v ∈ bi 
• for each i  j  k ∈  l  with i < j < k  bi
� bk ⊆ bj 
for each position p ∈  2          l   for each vertex v ∈ bp \
bp−1  we say that bp introduces v  v is introduced by bp 
and for each vertex v ∈ bp−1 \ bp  we say that bp forgets v
 v is forgotten by bp   for a position p ∈  1          l   we write
intro p   resp  forg p   for the set of all vertices introduced
 resp  forgotten  by bp  and we let lp = �
1≤i≤p forg p  be
the set of vertices that have been forgotten up to position p 
the width of p is defined as w p  = maxi∈ l  |bi| − 1  the
pathwidth  pw g   of g is the minimum width of a path de-
composition of g 
the pathwidth of the cocomparability graph of a partial or-
der may be regarded as a measure of how close the order is
from being a linear order  the cocomparability graph of a
linear order τ on n elements is the graph with n vertices and
no edges  this graph has pathwidth 0  on the other hand  if τ
is a partial order where all n elements are unrelated  then the
cocomparability graph of τ is the n-clique  which has path-
width n − 1  the highest possible pathwidth in an n-vertex
graph  
3
the kemeny rank aggregation problem
let c be a finite set  which in this paper will denote a set of
candidates  or alternatives  a partial vote over c is a partial
order over c  the kt-distance between two partial votes π1
and π2  denoted by kt-dist π1  π2   is the number of pairs of
candidates that are ordered differently in the two partial votes 
kt-dist π1  π2  = |  c  c′  ∈ c×c | c <π1 c′∧c′ <π2 c |  
observe that when the votes are totally ordered  the
kendall-tau distance can be seen as the  bubble sort  dis-
tance  i e   the number of pairwise adjacent transpositions
needed to transform one linear order into the other  given a
linear order π over a set of candidates c and a set π of votes
over c  the kemeny score of π with respect to π is defined
as the sum of the kendall-tau distances between π and each
vote in π  in this work  we consider the following problem 
problem name  kemeny rank aggregation  kra 
given  a list of partial votes π over a set of candidates c 
a non-negative integer k 
output  is there a linear order π on c such that the sum of
the kt-distances of π from all the partial votes is ≤ k 
hence  given partial votes π1          πm of c and a non-
negative integer k  the question is if there exists a linear order
π ⊆ c × c such that �m
i=1 kt-dist π  πi  ≤ k  
definition 2  given a set π of partial votes  the unanimity
order of π is simply the partial order ρ obtained as the inter-
section of all partial orders in π  in other words  a candidate
c1 has higher precedence than a candidate c2 in ρ if and only
if c1 precedes c2 in each vote in π 
as a consequence  the more disagreements there are among
the voters with respect to the relative orders of pairs of can-
didates  the denser the cocomparability graph of ρ will be
and therefore the greater its pathwidth will be  therefore  the
pathwidth of the cocomparability graph of the unanimity or-
der of π may be seen as a quantification of the amount of
disagreement among the votes in π 
the notion of diversity of solutions for computationally
hard problems has been considered under a variety of frame-
works  in this work  we define a notion of diversity for the
kemeny rank aggregation problem which is analo-
gous to the notion of diversity of vertex sets used in  baste
et al   2020  
more precisely  if r is a set of partial or-
ders  then we define the kendall-tau diversity of r as the
sum of kendall-tau distances between votes in the set r 
kt-div r  = �
π1 π2∈r kt-dist π1  π2  
we note that the restricted version of the kra problem
where all votes are linear orders  the requirements that a set of
solutions is at the same time diverse and only contains rank-
ings with small kemeny score are clashing  the problem is
that the very existence of two distinct rankings with small ke-
meny score is an impossible task  if two candidates c1 and c2
occur with the order  c1  c2  in one of the solutions and in the
order  c2  c1  in the other solution  then at least one of these
solutions will have a kemeny score of at least half the num-
ber of votes  however this opposition between diversity and
small kemeny score is not present in the setting where votes
are allowed to be partial  the generalization to partial votes
is one possible way to circumvent this conflict of desiderata 
another way we will be looking at is not to consider the cost
of the solutions directly but the difference between the cost
of solutions and the cost of an optimal solution  in this case 
we can have diversity and a small difference between the cost
and the cost of an optimal solution 
problem name  diverse kemeny rank aggrega-
tion  diverse-kra 
given  a list of partial votes π over a set of candidates c 
and k  r  d ∈ n 
output  is there a set r =  π1          πr  of linear orders on
c such that the kemeny score for each order πi is at most
k and kt-div r  ≥ d 
the problem kemeny rank aggregation is known
to be np-complete  bartholdi et al   1989   even if only four
votes are given at the input  dwork et al   2001   for this rea-
son  kra has been studied from the perspective of param-
eterized complexity theory under a variety of parameteriza-
tions  below  we consider two prominent parameterizations
for this problem 
the first parameter we consider is the cost of a solu-
tion 
simjour  2009  obtained an algorithm for the prob-
lem that runs in time o∗ 1 403k  
there are also sub-
exponential algorithms for kemeny rank aggregation
under this parameterization  karpinski and schudy  karpin-
ski and schudy  2010  obtained an algorithm for kemeny
rank aggregation that runs in o∗ 2o 
√
k   time  while
the algorithm of fernau et al   fernau et al   2011  fer-
nau et al   2014   based on a different methodology  runs in
o∗ ko 
√
k   time  recently  in  arrighi et al   2020   it was
proceedings of the thirtieth    ijcai-21 
12
 shown that kra on instances with only m = 4 votes on
some candidate set c and some integer k bounding the sum
of the kendall-tau distances to a solution cannot be solved
neither in time o∗ �
2o |c| �
nor in time o∗ �
2o 
√
k �
  un-
less eth fails  the mentioned np-hardness of kra im-
mediately translates to np-hardness results of kra and of
diverse-kra  in the latter case by setting r = 1 and d = 0 
the second parameter we consider is the unanimity width
of the set of votes  which is based on the notion of unanim-
ity order of a set of votes  charon and hudry  2007   the
unanimity width of π is defined as the pathwidth of the co-
comparability graph of ρ 
4
completion of an ordering
in this section  we will introduce the completion of an
ordering problem  a generalization of the positive com-
pletion of an ordering  pco  problem originally con-
sidered in  dujmovic et al   2003  sec  8  and  fernau  2005 
sec  6 4  
problem name  completion of an ordering  co 
given  a partial order ρ ⊆ c × c over a set c  a cost
function c   c × c → n  and some k ∈ n 
output  is there a linear order τ ⊇ ρ with c τ \ ρ  =
�
 x y ∈τ\ρ c x  y  ≤ k 
intuitively  given a partial order ρ and a cost function c 
the goal is to find a linear extension of ρ incurring a cost of
at most k  the only difference between co and the original
pco problem introduced in  dujmovic et al   2003  fernau 
2005  is that  in the latter  for every pair  x  y  ∈ c × c
such that x and y are incomparable in ρ  the cost of  x  y  is
strictly positive  c x  y  > 0  whereas in co  the cost can be
zero  c x  y  = 0  
we note that the notion of kendall-tau diversity introduced
in section 3 can also be used as a notion of diversity for co 
i e   given a set r of  not necessarily optimal  solutions for a
given instance  ρ  c  of co  we let kt-div r  be the diver-
sity of this set 
problem name  diverse completion of an order-
ing  diverse-co 
given  a partial order ρ ⊆ c ×c over a set c  a cost func-
tion c   c × c → n  and non-negative integers k  r  d ∈ n 
output  is there a set r =  τ1          τr  of linear exten-
sions of ρ such that c τi \ ρ  ≤ k for each i ∈  r   and
kt-div r  ≥ d  
next  we give a rather straightforward reduction from
kra to co  given an instance  π  c  of kra with partial
votes π =  π1          πm  and candidates c =  c1          cn  
we construct an instance  ρ  c  of co by letting ρ be the
unanimity order of π  and by defining the cost function
c   c × c → n as follows  for every pair of candidates
 c  c′   we define its cost  c c  c′   as the number of votes that
order c′ before c  more formally  c c  c′  = | i ∈  m  |
c′ <πi c |  with this reduction  it is straightforward to check
that a given linear order π of the candidates has kemeny score
�m
i=1 kt-dist π  πi  = �n
j=1
�n
k=1 c ck  cj  ck <π cj  
here  for a logical proposition p  we use the bracket nota-
tion  p  to denote the integer 1 if p is true the integer 0 if p is
false  in other words  �m
i=1 kt-dist π  πi  is the cost of π
as a linear extension of the ordering ρ 
it is important to note that if all votes in π are linear orders
then  ρ  c  is actually an instance of pco  in other words  if
two candidates c and c′ are incomparable in the unanimity or-
der  then the cost assigned by c to both pairs  c  c′  and  c′  c 
are strictly positive  this property will be used crucially in
the development of our sub-exponential time algorithm for
kra parameterized by cost 
we also note that since our reduction is solution preserving 
it is also immediate that it is diversity preserving  in other
words  r is a set of solutions of diversity d for an instance of
kra if and only if it is also a set of solutions of diversity d
for the corresponding instance of co 
5
diverse co parameterized by pathwidth
in this section  we devise a fixed parameter tractable algo-
rithm for diverse co parameterized by solution imperfec-
tion  number of solutions  scatteredness  and pathwidth of the
cocomparability graph of the input instance  given our re-
duction that preserves solution and parameters from kra to
co introduced in section 4  this algorithm immediately im-
plies that diverse kra is fixed parameter tractable when
parameterized by solution imperfection  number of solutions 
scatteredness  and unanimity width 
we start by defining a suitable notion of consistency be-
tween a path decomposition and a given partial order  let
g =  c  e  be a graph and ρ ⊆ c × c be a partial or-
der on the vertices of g  we say that a path decomposition
d =  b1          bl  is ρ-consistent if there is no pair of ver-
tices  x  y  ∈ ρ such that
max  i ∈  l  | y ∈ bi   < min  i ∈  l  | x ∈ bi   
in other words  if x is smaller than y in ρ  then y cannot be
forgotten in d before x is introduced in d  the ρ-consistent
pathwidth of g  denoted by cpw g  ρ   is the minimum width
of a ρ-consistent path decomposition of g 
it has been shown recently that for any partial order ρ ⊆
c × c  the pathwidth of the cocomparability graph gρ is
equal to the consistent pathwidth of gρ  arrighi et al   2020  
the proof of this result was based on the fact that the consis-
tent pathwidth of a cocomparability graph of a partial order is
equal to the interval width of the order  habib and m¨ohring 
1994   nevertheless  the problem of constructing  or even
approximating  a minimum-width consistent path decompo-
sition in fpt time was left open in  arrighi et al   2020  
by taking a closer look at the theory of cocomparability
graphs  we solve this open problem in a constructive way 
more precisely  in lemma 3 we show that for any partial or-
der ρ  one can construct a ρ-consistent path decomposition
of the cocomparability graph gρ in fixed-parameter tractable
time parameterized by the pathwidth of the graph gρ 
lemma 3  let ρ ⊆ c × c be a partial order and gρ be the
cocomparability graph of ρ  then one can construct a nice ρ-
consistent path decomposition p of gρ of width o pw gρ  
in time 2o pw gρ   · |c| 
let ρ be a partial order and p =  b1  b2          bl  be a
ρ-consistent path decomposition of gρ of width w  for each
proceedings of the thirtieth    ijcai-21 
13
 p ∈  l   let pp be the set of pairs of the form  s  τ  where
s is a subset of bp that contains vertices introduced by bp
 intro p  ⊆ s ⊆ bp   τ ⊇ ρ|s is a linear extension of the
restriction ρ|s ˙= s × s ∩ ρ of ρ to s 
definition 4  let p ∈  l   δ ∈ n  and f   pp → n  then 
we let tp f  δ  be the set of all triples of the form  s  τ  γ  
where  s  τ  ∈ pp and f s  τ  ≤ γ ≤ f s  τ    δ 
intuitively  the function f will be used by our dynamic pro-
gramming algorithm to record the optimal values of partial
solutions at each bag bp when processing the path decompo-
sition from left to right  see theorem 8 and theorem 10  and
δ will be the allowed solution imperfection  in the case of a
unique solution  this value will be 0 but this parameter will
be useful in the diverse case as we allow sub-optimal linear
extensions  a partial solution up to the p-th bag is a linear
order σ of �
j≤p bj  vertices that will be introduced in fu-
ture bags can be inserted in σ  to extend it  only after vertices
already forgotten in the p-th bag  if u will be introduced in
a future bag and v is in some bj but not in bp  then by con-
sistency of the path decomposition with respect to ρ  we have
v <ρ u  therefore  in bp  we only need to remember the
 last  part of σ  which are the vertices that are in bp and after
all forgotten vertices in σ 
remark 5  for each p ∈  l   f   pp → n and δ ∈ n  the size
of tp f  δ  is bounded by e ·  δ   1  ·  w  1   
for each p ∈  l − 1   f   pp → n and δ ∈ n  we say
that a triple  s  τ  γ  ∈ tp f  δ  is compatible with a triple
 s′  τ ′  γ′  ∈ tp 1 f  δ  if the following conditions hold 
c1 let v = maxτ s ∩ forg p   1   be the maximum vertex
of s forgotten by bp 1 according to the linear order τ 
then  we have the following equality s′ = intro p 1 ∪
 u ∈ s | v <τ u   this means that one can build s′
from s by removing all vertices that are either forgotten
by bp 1 or smaller than some vertex forgotten by bp 1 
and subsequently  by adding all vertices that have been
introduced by bp 1 
c2 τ|s∩s′ = τ ′|s∩s′  i e   τ and τ ′ agree on s ∩ s′ 
c3 γ′
=
γ   �
v∈intro p 1  �
u∈s′ u<τ′v c u  v   
�
u∈s∩s′ v<τ′u c v  u    �
u∈bp 1\s′ c u  v   
to
compute γ′  we add to γ the cost of adding the intro-
duced vertices in the order  the first two terms com-
pute the cost of each new vertex in τ ′ and the last one
computes the cost of placing the new vertices after all
vertices in bp 1 \ s′ 
a compatible sequence for p is a sequence of triples
γ =  s1  τ1  γ1         sl  τl  γl  such that for each p ∈  l  
 sp  τp  γp  is compatible with  sp−1  τp−1  γp−1  
our interest in compatible sequences stems from the two
following lemmas 
lemma 6  let ρ ⊆ c × c be a partial order over c 
c   c × c → n be a cost function  and p be a ρ-consistent
path decomposition of the graph gρ  let γ = t1       tl =
 s1  τ1  γ1         sl  τl  γl  be a compatible sequence for p 
then  the linear order π = tc ρ ∪ τ1 ∪ · · · ∪ τl  is a lin-
ear extension of ρ of cost γl 
lemma 7  let ρ ⊆ c × c be a partial order over c 
c   c × c → n be a cost function  and p be a ρ-consistent
path decomposition of the graph gρ  let π be a linear exten-
sion of ρ  and γ =  s1  τ1  γ1         sl  τl  γl  be a sequence
such that for each position p ∈  l   sp =  v ∈ bp | v >π
maxπ lp    τp = π|sp  and γp = c π|lp∪bp   then  γ is a
compatible sequence for p 
lemma 6 and lemma 7 immediately yield an fpt dy-
namic programming algorithm for computing a linear exten-
sion of ρ  to define the algorithm more precisely  we first
need to define the set of functions fp that we will use to de-
fine a set of triples with tp  for each p ∈  l   we define
fp   pp → n as follows  for each  s  τ  ∈ pp  we let γ be
the minimum cost of a partial solution π up to bag p such that
s =  v ∈ bp | v >π maxπ lp   and τ = π|sp  then we let
fp s  τ  = γ  intuitively  fp associates to each linear order τ
the cost of an optimal partial solution  ending  by τ  now 
we will describe the algorithm  we process the path decom-
position from left to right in l time steps  where at each time
step p  we construct the value of fp that we need and a subset
qp ⊆ tp fp  0  of promising triples  which are  intuitively 
triples that have a potential to lead to an optimal solution  at
time step 1  set q1 =   b1  τ  c τ   τ is a linear extension of ρ|b1  
at each time step p ≥ 2  qp is the set of all triples in tp fp  0 
that are compatible with some triple in qp−1  at the end of
the process  assuming that qp is non-empty for each p ∈  l  
we can reconstruct a compatible sequence by backtracking 
first  by selecting an arbitrary triple tl in ql  then by se-
lecting an arbitrary triple tl−1 in ql−1 compatible with tl 
and so on  once we have constructed a compatible sequence
t1       tl  we can extract a linear extension π of cost γl by set-
ting π = tc ρ ∪ τ1 ∪       τl   this description gives rise to the
following theorem 
theorem 8  let ρ ⊆ c × c  let n = |c|  let w be the
pathwidth of the cocomparability graph of ρ  and c   c×c →
 m 0 be a cost function  then  one can compute an optimal
solution in time o
�
w o 1  · n · log n · m 
�
 
now  leveraging on lemma 6 and lemma 7  we will
devise a fixed-parameter tractable algorithm for diverse-
co parameterized by solution imperfection  number of so-
lutions  scatteredness  and pathwidth of the cocomparability
graph of the input partial order  let ρ be a partial order and
p =  b1  b2          bl  be a ρ-consistent path decomposition
of gρ of width w 
definition 9  let p ∈  l   and f   pp → n  then  we let
ip f  δ  be the set of all tuples of the form
  s1  τ 1  γ1            sr  τ r  γr   ∂   ξ i j  1≤i<j≤r 
where ∂ ∈  d   1 0  for each 1 ≤ i < j ≤ r  ξ i j  ∈  s 0 
and for each i ∈  r    si  τ i  γi  is a triple in tp f  δ  
intuitively    si  τ i  γi  i∈ r  are r partial linear exten-
sions  ∂ will be the diversity of the r partial linear extensions
and ξ will be the distance between all pairs of the r partial
linear extensions  a diversity-compatible sequence is a se-
quence of the form
   s1
p  τ 1
p   γ1
p            sr
p  τ r
p  γr
p   ∂p   ξp
 i j  
1≤i<j≤r  
p∈ l  
proceedings of the thirtieth    ijcai-21 
14
 where for each i ∈  r    si
1  τ i
1  γi
1         si
l  τ i
l   γi
l  is a com-
patible sequence and for each p ∈  l − 1   ∂p keeps track of
the amount of diversity observed up to position p  ξp
 i j  keeps
track of the distance between partial solutions i and j 
a diversity-compatible sequence is a representation of r
solutions for an instance  ρ  c  r  δ  d  s  of diverse-co  in-
tuitively  computing such a sequence corresponds to com-
puting r compatible sequences in parallel  by processing the
given path decomposition from left to right  while using an
additional register to keep track of the overall diversity at each
time step and all the pairwise distances 
theorem 10  let ρ ⊆ c × c  let n = |c| and w be the
pathwidth of the cocomparability graph of ρ  and c   c×c →
 m 0 be a cost function  then  one can determine whether ρ
admits r linear extensions π1          πr at distance at most δ
from the optimum  diversity at least d  and scatteredness at
least s in time o
�
 w  · δ o r  · sr2 · d · n · log n2 · m 
�
 
by combining theorem 8 with our reduction from kra
to co  we have an fpt algorithm for kra  parameterized
by solution imperfection  number of solutions  scatteredness 
and unanimity width  corollary 11  
corollary 11  let π be a list of m partial votes over a set
of n candidates c 
let w be the unanimity width of π 
given π and non-negative integers δ  r  s and d  one can
determine in time o
�
 w  · δ o r  · sr2 · d · n · log n2 · m 
�
whether there is a set r =  π1          πr  of r linear or-
ders on c such that the kemeny score for each order πi
is at distance at most δ of the optimum  and we find that
kt-div r  ≥ d and that scatteredness is at least s 
6
sub-exponential time algorithm for pco
for special cases of pco  such as those arising from kra or
the graph-drawing problem oscm  single-exponential sub-
exponential time algorithms have been known  i e   algo-
rithms with running times of the form o∗ 2o 
√
k    in con-
trast  for the more general problem of pco  only algorithms
with running time o∗ k
√
k  were known before  where k is
the cost parameter  fernau et al   2014  
here  we prove
that pco also admits algorithms of the form o∗ 2o 
√
k    by
making use of several structural insights for cocomparability
graphs  more precisely  we prove the following theorem 
theorem 12  given a partial order ρ ⊆ c × c and a cost
function c   c × c → n  one can solve a pco instance
 ρ  c  k  in time |c| · 2o 
√
k    o |c|2 · log k   
our main technical result of this section is the following 
lemma 13  let g be a c≥5-free graph  let m be the number
of edges of g  then  we have m = ω tw g 2  
by combining lemma 13 with the fact that treewidth
equals pathwidth for cocomparability graphs and with the fact
that cocomparability graphs are c≥5-free  we get the follow-
ing lemma 
lemma 14  let g be a cocomparability graph and let m be
the number of edges of g  then  m = ω pw g 2  
now  in a pco instance  each edge contributes at least 1
to the cost of any solution  therefore  if a solution has cost
at most k  then the cocomparability graph of the input partial
order can have at most k edges  therefore  this observation 
together with lemma 14 yields the following lemma 
lemma 15  let  ρ  c  k  be an yes-instance of pco  then 
pw gρ  = o 
√
k  
to get the running time of theorem 12  we need to either
compute a ρ-consistent path decomposition of width at most
o 
√
k   or to trigger an early rejection  for this  we will use
the following lemma which is based on lemma 3 
lemma 16  there is a polynomial-time algorithm that takes
an instance of  ρ  c  k  of pco as input  and either constructs
a ρ-consistent path decomposition of the graph gρ of width
o 
√
k   or answers that this instance is a no-instance 
in section 5  in order to define our algorithm for diverse-
co  we first devised a simpler algorithm for the single-
solution version of co  that could be used as a building block
for the diverse algorithm  it turns out that if our only goal is to
solve the single-solution version of co  then the basic algo-
rithm developed in section 5 can be optimized  to become a
single-exponential time algorithm parameterized by the path-
width of the cocomparability graph of the input order  more
precisely  we have the following lemma 
lemma 17   arrighi et al   2020   theorem 1    given an
instance  ρ  c  k  of co and a ρ-consistent path decomposi-
tion p of the graph gρ  one can solve this instance in time
|c| · 2o pw gρ   · log k    o |c|2 · log k   
now we are ready to prove the statement of theorem 12 
given an instance  ρ  c  k  of pco  we apply the algorithm
stated in lemma 16  this algorithm either determines that
the instance is a no-instance  or constructs a ρ-consistent
path decomposition p of gρ of width o 
√
k   in the first
case  we are done and simply answer no  otherwise  we
give both the instance  ρ  c  k  and the decomposition p
to the algorithm stated in lemma 17 to determine in time
|c| · 2o 
√
k    o |c|2 · log k   whether  ρ  c  k  is a yes-
or a no-instance of pco  in case this is a yes-instance  the
algorithm also constructs a linear extension of ρ of cost at
most k  this concludes the proof of theorem 12 
acknowledgements
emmanuel arrighi acknowledges support from the research
council of norway  grant no  274526  and from is-daad
 grant no  309319    henning fernau acknowledges sup-
port from daad ppp  grant no  57525246    the research
of daniel lokshtanov is supported by bsf award 2018302
and nsf award ccf-2008838  mateus de oliveira oliveira
acknowledges support from the research council of nor-
way  grant no  288761   is-daad  grant no  309319  and
sigma2 network  nn9535k   petra wolf acknowledges sup-
port from dfg project fe 560/9-1 and daad ppp  grant
no  57525246  
proceedings of the thirtieth    ijcai-21 
15
 references
 arrighi et al   2020  e 
arrighi 
h 
fernau 
m  de oliveira oliveira  and p  wolf 
width notions
for ordering-related problems  in fsttcs  volume 182 of
lipics  pages 9 1–9 18  schloss dagstuhl  2020 
 bartholdi et al   1989  j  bartholdi  iii  c  a  tovey  and
m  a  trick  voting schemes for which it can be difficult
to tell who won the election  social choice and welfare 
6 157–165  1989 
 baste et al   2019  j  baste  l  jaffke  t  masaˇr ık  g  philip 
and g  rote  fpt algorithms for diverse collections of
hitting sets  algorithms  12 254  2019 
 baste et al   2020  j 
baste 
m 
fellows 
l 
jaffke 
t  masar ık  m  de oliveira oliveira  g  philip  and
f  rosamond 
diversity of solutions  an exploration
through the lens of fixed-parameter tractability theory  in
ijcai  pages 1119–1125  2020 
 bouchitt e et al   2004  v  bouchitt e  d  kratsch  h  m¨uller 
and i  todinca  on treewidth approximations  discret 
appl  math   136 2-3  183–196  2004 
 bredereck et al   2020  r  bredereck  a  kaczmarczyk  and
r  niedermeier  electing successive committees  com-
plexity and algorithms  in aaai  pages 1846–1853  aaai
press  2020 
 charon and hudry  2007  i  charon and o  hudry  a survey
on the linear ordering problem for weighted or unweighted
tournaments  4or  5 1  5–60  2007 
 chudnovsky et al   2020  m  chudnovsky  m  pilipczuk 
m  pilipczuk  and s  thomass e  quasi-polynomial time
approximation schemes for the maximum weight indepen-
dent set problem in h-free graphs  in soda  pages 2260–
2278  siam  2020 
 downey and fellows  1999  r  downey and m  fellows 
parameterized complexity  springer  1999 
 dujmovic et al   2003  v 
dujmovic 
h 
fernau 
and
m  kaufmann  fixed parameter algorithms for one-sided
crossing minimization revisited 
in gd  volume 2912 
pages 332–344  springer  2003 
 dwork et al   2001  c  dwork  r  kumar  m  naor  and
d  sivakumar  rank aggregation methods for the web  in
www  pages 613–622  acm  2001 
 farkas and timotity  2019  m  farkas and d  timotity  vot-
ing issues 
a brief history of preference aggregation 
worldquant  pages 26 1–7  november 2019 
 fernau et al   2011  h  fernau  f  fomin  d  lokshtanov 
m  mnich  g  philip  and s  saurabh  ranking and draw-
ing in subexponential time 
in iwoca  volume 6460 
pages 337–348  springer  2011 
 fernau et al   2014  h  fernau  f  fomin  d  lokshtanov 
m  mnich  g  philip  and s  saurabh  social choice meets
graph drawing  how to get subexponential time algo-
rithms for ranking and drawing problems  tsinghua sci-
ence and technology  19 4  374–386  2014 
 fernau  2005  h  fernau  parameterized algorithmics  a
graph-theoretic approach  habilitationsschrift  univer-
sit¨at t¨ubingen  germany  2005 
 fomin et al   2020  f  fomin 
p  golovach 
l  jaffke 
g  philip  and d  sagunov  diverse pairs of matchings 
in isaac  schloss dagstuhl  2020 
 galle  1989  p  galle  branch   sample  a simple strategy
for constraint satisfaction  bit  29 3  395–408  1989 
 habib and m¨ohring  1994  m  habib and r  m¨ohring 
treewidth of cocomparability graphs and a new order-
theoretic parameter  order  11 1  47–60  1994 
 ingmar et al   2020  l  ingmar  m  de la banda  p  stuckey 
and g  tack  modelling diversity of solutions  in aaai 
volume 34  pages 1528–1535  aaai press  2020 
 karpinski and schudy  2010  m  karpinski and w  schudy 
faster algorithms for feedback arc set tournament  ke-
meny rank aggregation and betweenness tournament  in
isaac  volume 6506  pages 3–14  springer  2010 
 kemeny  1959  j  kemeny  mathematics without numbers 
daedalus  88 571–591  1959 
 petit and trapp  2019  t  petit and a  trapp  enriching so-
lutions to combinatorial problems via solution engineer-
ing 
informs journal on computing  31 3  429–444 
2019 
 simjour  2009  n  simjour  improved parameterized algo-
rithms for the kemeny aggregation problem  in iwpec 
volume 5917  pages 312–323  springer  2009 
 wong and reingold  1991  d  wong and e  reingold 
probabilistic analysis of a grouping algorithm  algorith-
mica  6 2  192–206  1991 
proceedings of the thirtieth    ijcai-21 
16
 "
None,2021,https-www-ijcai-org-proceedings-2021-0003-pdf,School Choice with Flexible Diversity Goals and Specialized Seats,"Haris Aziz, Zhaohong Sun",None,https://www.ijcai.org/proceedings/2021/0003.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0003-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0003-pdf.pdf,"school choice with flexible diversity goals and specialized seats
haris aziz   zhaohong sun
unsw sydney
 haris aziz  zhaohong sun @unsw edu au
abstract
we present a new and rich model of school choice
with flexible diversity goals and specialized seats 
the model also applies to other settings such as
public housing allocation with diversity objectives 
our method of expressing flexible diversity goals
is also applicable to other settings in moral multi-
agent decision making where competing policies
need to be balanced when allocating scarce re-
sources 
for our matching model  we present a
polynomial-time algorithm that satisfies desirable
properties  including strategyproofness and stabil-
ity under several natural subdomains of our prob-
lem  we complement the results by providing a
clear understanding about what results do not ex-
tend when considering the general model 
1
introduction
diversity goals are prevalent in many scenarios including the
hiring of employees  student-intake  and public housing  ben-
abbou et al   2018   these may be affirmative action legal re-
quirements  institutional policies  or guidelines for ensuring
a healthier and better balance of various groups  as impor-
tant decisions are made concerning who gets the next job or
who gets their preferred school seat  it is critical that the al-
gorithms are transparent and fair  this is especially so when
they make complex decisions that simultaneously take into
account merit  priority  and diversity 
in the past few years  diversity issues have been heav-
ily studied in school choice  abdulkadiro˘glu and s¨onmez 
2003   the prototypical model of two-sided matching  in the
basic school choice problem  students have preferences over
schools and schools have priorities over students  the typical
goal is to match the students to schools in a way that is stable
 no student wants to take an vacant slot or wants to replace a
lower priority student   another property that is important in
this context is strategyproofness  no student has an incentive
to misreport her preferences  
in school choice with diversity goals  schools accept stu-
dents while not just taking into account the priority order-
ing over students  that could be based on test scores  but
also considering diversity requirements  such as keeping in
mind a target number of students with special talents or dis-
advantaged backgrounds   student placement under diver-
sity concerns has been considered in many countries includ-
ing israel  gonczarowski et al   2019  and india  baswana
et al   2019  
a prominent and successful approach for
these problems is to specify diversity requirements via up-
per and lower bounds on the types of students at the school
 ehlers et al   2014  aziz et al   2019   based on these quo-
tas  diversity is achieved by first admitting students whose
types have not reached the minimum quotas and then ad-
mitting students whose types have not reached the maxi-
mum quotas  see e g    kurata et al   2017  aziz et al   2020 
sun  2020   
there are limitations of specifying diversity goals just by
imposing upper and lower bounds on types  the first concern
is whether one should indeed treat the status of being under-
subscribed equally  for instance  suppose one school imposes
minimum quota 10 on two types  type t1 admits just 1 stu-
dent while type t2 admits 8 students  it is reasonable to give
higher precedence to students of type t1  who will help to
achieve a diversity balance  the second concern is whether
we should treat all types equally  it is common that some
types are more important than others  thirdly  lower and up-
per quotas are not sufficient to target proportionality ratios of
types  that captures desirable distributions of different types
of students   in particular  having targets on absolute numbers
does not achieve proportionality goals effectively 
we explain the third issue through the following example 
suppose there is a market where students are associated with
one of the three types t1  t2  and t3  consider one school c
with capacity 100 that has the target proportions of students
are as follows  t1   30   t2   30   t3   40   if we wish to
capture these targets via setting of lower bounds  one can im-
pose minimum quotas 30  30 and 40 on type t1  t2  t3 respec-
tively  suppose 15  60  and 60 students of type t1  t2  t3 apply
for the school c  then notable algorithms for the problem that
use minimum quotas would return an outcome with type dis-
tribution  t1   15  t2   45  t3   40   however  there exists an
outcome with type distribution  t1   15  t2   37  t3   48  that
is closer to the target proportions  such an outcome will be
computed by the algorithm we propose 
in this paper  we aim to address the following questions 
what is a powerful yet computationally tractable framework
of specifying diversity goals  that encompasses most of the
proceedings of the thirtieth    ijcai-21 
17
 particular diversity approaches in theory and practice  can
it also capture meaningful and well-motivated diversity goals
not yet addressed in the literature  can we use such a frame-
work and achieve desirable objectives in two-sided matching
market design such as stability and strategyproofness in a ro-
bust manner  what are the limits of such an approach when
students are allowed to express preferences over individual
school seats 
1 1
contributions
we present a new model of matching markets that general-
izes school choice with diversity goals in two important ways 
 1  firstly  we allow schools to have specialized seats that
are motivated by additional features such as accompanying
scholarships  tuition-fee waiver etc   2  secondly  we greatly
expand the type of diversity goals that can be specified  our
model introduces a flexible and general ordinal approach to
specifying diversity goals that capture lower and upper quotas
as well as proportionality concerns  we discuss how existing
approaches that only minimum and maximum quotas in the
intended ratios may not achieve outcomes that are closest to
the intended ratios  the approach applies to many other set-
tings including social choice and multi-agent decision mak-
ing in which diversity is a concern 
for the new model  we present an algorithm called gen-
eralized deferred acceptance with flexible diversity  gda-
fd   it is a novel algorithm that we design for schools to
choose students while taking into account flexible diversity
goals  gda-fd satisfies a natural notion of stability  strate-
gyproofness  and non-wastefulness when each agent has one
type and there are no specialized seats 
we then show that allowing for specialized seats but en-
forcing diversity over students leads to several challenges in
achieving stability and strategyproofness  in view of these
challenges  we then turn to an important domain in which we
allow for specialized seats but there is exactly one school 1
in this domain  we show that even if students have overlap-
ping types  gda-fd algorithm satisfies weak pareto optimal-
ity and two notions of strategyproofness  en route to proving
these results  we provide an alternative view of gda-fd by
showing its equivalence with an algorithm called sequential
allocation under dynamic diversity goals 
finally  we turn to a class of preferences called school-
based that generalizes the case of homogenous school seats
as well as the case of exactly one school  for school-based
preferences  we show that gda-fd is not strategyproof even
if each agent has a single type  however  strategyproofness
is regained by using another algorithm called modified gda-
fd that calls gda-fd on a modification of the problem in-
stance  since modified gda-fd is equivalent to gda-fd
when there are no special seats  our key message is that the
modified gda-fd works well on several important domains 
some of our results are summarized in table 1 
1the domain captures various committee selecting or hiring sce-
narios that take into account diversity goals 
preference
strategyproofness
stability
non-wastefulness
domain
no specialized seats



one school



school-based



table 1  properties satisfied by modified gda-fd  algorithm 4 
under different preference domains when each agent has a single
type  the positive results for the case of one school also hold for
multiple types 
2
related work
abdulkadiro˘glu and s¨onmez  2003  presented one of the
seminal works on the use of matching market design for
school choice  the problem of school choice with diversity
constraints or goals is an active area of research in market
design  in some of the earlier works  echenique and yen-
mez  2015  abdulkadiro˘glu and s¨onmez  2003  ehlers et al  
2014   it is assumed that each agent has at most one type 
recent papers have started exploring the case of  overlap-
ping types   e g    kurata et al   2017  aziz et al   2019 
ayg¨un and turhan  2020  gonczarowski et al   2019   
typically  each school imposes a maximum quota and
a minimum quota on each type
 ehlers et al   2014 
gonczarowski et al   2019  hafalir et al   2013  kojima  2012 
kominers and s¨onmez  2013  s¨onmez and yenmez  2019 
baswana et al   2019  aziz et al   2019   since stable match-
ings are not guaranteed to exist for hard lower quotas  and
the corresponding problems are np-hard  kurata et al   2017 
cheng et al   2008   most of the successful approaches treat
the quotas as soft  see  e g  ehlers et al   2014  and followup
works   we also adopt the approach of treating the quotas as
soft 
most work on school choice with diversity goals focuses
on minimum and maximum quotas  although there is some
recent work on ratio constraints  nguyen and vohra  2019  
our diversity goals are more general and flexible  and our
algorithmic solutions are different as well 
kominers and
s¨onmez  2016  considered a matching model in which each
school seat may have a different priority ordering over stu-
dents and students have rankings over schools 
we assume that when students are matched  they contribute
to the counts of all the types they satisfy  in a companion
paper  aziz and sun  2021   we take an alternative assump-
tion that students contribute to the count of exactly one of the
types they satisfy 
3
a model for school choice with flexible
diversity goals and specialized seats
in this section  we formalize the model of school choice with
flexible diversity goals and specialized seats  an instance
i of the setting consists of a tuple  s  t  h  c  x   ≿s  ≿c
  rc   there is a set of students denoted by s =  1          n  
each of whom belongs to some of the types from the type
space t =  t1          tk   let t i  denote the set of types
of student i  we will denote by c the set of schools with a
generic school denoted by bj or b  we will denote by h the
proceedings of the thirtieth    ijcai-21 
18
 set of school seats with a genertic seat denoted by h  school
seats h are partitioned into |c| schools  where bj ⊆ h is
the set of school seats controlled by school bj ∈ c  for
any two different schools bi  bj ∈ c  we have bi ∩ bj = ∅ 
the symbol rc denotes the precedence profile of schools that
captures flexible diversity goals  section 4 is devoted to the
precedence profile rc 
we follow the model of matching with contracts  hatfield
and milgrom  2005  where each contract x =  i  h  b  is a
student–seat–school tuple indicating that student i is matched
to seat h at school b  the set of all contracts is denoted by
x ⊆ s × h × c and we assume that for any  i  h  b  ∈ x  
we have h ∈ b  given any x ⊆ x   for each student i 
we denote by xi as the set of contracts pertaining to student
i  for each seat h  we denote by xh as the set of contracts
pertaining to seat h  for each school b  we denote by xb as the
set of contracts pertaining to school b  we denote by xt
b =
  i  h  b  ∈ xb | t ∈ t i   as the set of contracts involving
students of type t and school b  we extend the notation of
each individual to a set of agents by taking the union  i e   for
any s′ ⊆ s  xs′ = �
i∈s′ xi 
the preference profile of students s is denoted by ≿s=
 ≿1          ≿n  where for student i ∈ s  each ≿i specifies
the preference of student i over contracts xi  for instance 
 i  h1  b1  ≿i  i  h2  b2  means that student i weakly prefers
the contract  i  h1  b1  to the contract  i  h2  b2   let ≻i and
∼i denote the strict and indifferent relation  respectively  in
section 5 2  we will assume that a student is indifferent be-
tween all contracts involving seats of the same school  in
general  if some algorithm of ours requires strict preferences 
we will assume that the ties are broken according to a fixed
tie-breaking rule 
the priority profile of schools c is denoted by ≿c=  ≿b1
          ≿b|c|  where each ≿b specifies the priority ordering of
school b over contracts xb  we will assume that a school s
priority over contracts is based on an underlying priority re-
lation over students  which could be based on first-come first-
served basis  entrance exam scores or randomization 
next  we introduce several important properties for a de-
sirable outcome  a contract  i  h  b  is acceptable to student
i and school b if both  i  h  b  ≿i ∅ and  i  h  b  ≿b ∅ hold
where ∅ represents the option of being unmatched  with-
out loss of generality  we consider acceptable contracts only 
since we can remove any unacceptable contract from x   an
outcome or a matching x is a set of contracts  i e  x ⊆ x  
an outcome is feasible if each student is matched to at most
one contract  i e  ∀i ∈ s  |xi| ≤ 1  and each seat is matched
to at most one student  i e  ∀ h ∈ h  |xh| ≤ 1  a feasible
outcome y is non-wasteful if there exists no  i  h′  b′  ∈ y
such that there exists another contract  i  h  b  with  i  h  b 
≻i  i  h′  b′  and y ∪   i  h  b   \   i  h′  b′   is feasible 
given an instance i  an algorithm is strategyproof for stu-
dents if no student can be matched to a strictly better contract
when the student misreports his preferences 
4
framework for flexible diversity goals
in this section  we present a novel way for schools to select
students  a key component of the method is to design a novel
method to specify dynamic priorities of a school over stu-
dents  the dynamic priorities of a school b are based on the
static priority relation ≿b over students  and a dynamic prece-
dence relation rb over the types in t that we specify below 
given a feasible outcome x  each school b has a dynamic
precedence ordering rb x  over types t 
if t1rb x t2
holds  then for the outcome x  type t1 is weakly preferred to
type t2 in terms of achieving diversity goals of school b  let
pb and ib denote the strict and indifferent relation  respec-
tively  we denote by rc =  rb1         rb|c|  the precedence
profile of all schools 
4 1
dynamic precedence representation
next  we explain how we represent the dynamic precedence
rb over types  first  each school b specifies different levels
over each type t  denoted by lb t where each level ℓj
b t ∈ lb t
specifies the range of number of students of type t that are
matched to school b  for instance  in figure 1  ℓ1
b t =  0  10 
means that when the number of students of type t matched to
school b is weakly larger than 0 and smaller than 10  then it
falls into the level ℓ1
b t  we refer to lj
b =  ℓj
b t t∈t as level j
of school b for convenience  note that for each type t  it is not
necessary to define levels for every integer from  1       |s|  
0
10
25
· · ·
80
100
ℓ1
b t
ℓ2
b t
ℓ10
b t
figure 1  an instance of levels of type t at school b 
then the dynamic precedence ordering rb x  is deter-
mined as follows with indifference classes in decreasing order
of precedence from left to right  rb x     t ∈ t   |xt
b| ∈
ℓ1
b t    t ∈ t   |xt
b| ∈ ℓ2
b t            t ∈ t   |xt
b| ∈ ℓk
b t  
where |xt
b| denotes the number of students of type t matched
to school b in the outcome x  intuitively  for a given out-
come x  school b gives the highest precedence to types that
fall into level 1 of school b  the second highest precedence to
types that fall into level 2 of school b and so on 
next  we explain how to capture different diversity goals
through the dynamic precedence relation rb x  
lexicographic 
let there be a fixed precedence ordering
over types  say t1          t|t |  the lexicographic diversity goal
of school b is that whenever possible  it prefers to be matched
to students of type t with smaller index  in that case  for each
type ti  create one level ℓi
b ti =  0  |s|  
min and maximum quotas 
for each school b  let ηt
b and
ηt
b denote the minimum quota and the maximum quota of type
t  respectively  the diversity goal of school b under minimum
and maximum quotas is that  school b gives the highest prece-
dence to the student whose type has not reached the minimum
quota  medium precedence to the student whose type has
reached the minimum quota but not the maximum quota  and
the lowest precedence to the student whose type has reached
the maximum quota  ehlers et al   2014   in that case  for
proceedings of the thirtieth    ijcai-21 
19
 each type t  school b has three levels ℓ1
b t =  0  ηt
b − 1  
ℓ2
b t =  ηt
b  ηt
b − 1  and ℓ3
b t =  ηt
b  |s|  
proportional 
let there be |t| positive integers  say r1 
· · ·   r|t | corresponding to each type t  the proportional di-
versity goal of school b is that the number of students of each
type matched to school b is proportional to r1   · · ·   r|t | 
in that case  each school b has multiple levels over each type
t and leve number j  ℓj
b t =   j − 1  ∗ rt  j ∗ rt − 1   for
example  ℓ1
b t =  0  rt − 1  and ℓ2
b t =  rt  2rt − 1  
egalitarian 
egalitarian is a special case of proportionality
where the ratio among all types is 1  in that case  each school
b has multiple levels over each type t where each level ℓj
b t =
 j − 1  j − 1  
our diversity framework can also capture combinations of
the above objectives  next  we give an example of how our
approach can capture proportionality goals 
example 1  proportional diversity goals   consider a
school b and a set of types t =  t1  t2  t3  t4  with desired ra-
tios 1  2  3  2  then rb is depicted graphically in figure 2 
based on a current allocation of a school  each type has its
own count of how many admitted students satisfy that type 
which types have the highest precedence for the school de-
pends on current level of the types based on their counts  sup-
pose that the current allocation leads to the following counts
t1   0  t2   1  t3   4  and t4   7  then  then precedence level
of the types are as follows  t1   1  t2   1  t3   2  and t4   4 
hence  t1 and t2 are the highest precedence types 
t1
t2
t3
t4
0
5
10
4
8
12
8
3
6
9
6
2
4
6
4
1
2
3
2
# of students of type t matched to school b
level1
level2
level3
level4
figure 2  proportional goals in example 1 
4 2
choice function for flexible diversity goals
for a given school b  its priority relation ≿b over the students
along with its precedence relation rb over types can guide
the school to select students from applicants  we specify a
particular choice function for the schools 
we define a natural choice function of school b that chooses
a set of contracts in algorithm 1  the high level idea is that
it identifies the types whose precedence is most important
 based on which students are already selected  and then se-
lects the highest priority contract that involves a student who
algorithm 1 choice function chb of school b
input  a set of contracts yb  rb  and ≿b
output  a set of contracts z ⊆ yb
1  remove unacceptable contracts from yb 
2  z ← ∅
  z stores the set of contracts chosen by school b 
3  while yb ̸= ∅ and |z| is no more than school capacity do
4 
identify the set of types t ′ such that i  each type t ∈ t ′ has
the highest precedence based on rb z  and ii  there exists
some contract y =  i  h  b  ∈ yb with t i  ∩ t ′ ̸= ∅ 
5 
scan over yb based on priority ordering ≻b and select the
first contract y =  i  h  b  such that t i  ∩ t ′ ̸= ∅ 
6 
z ← z ∪  y   yb ← yb \  y  
7 
remove all contracts from yb that involve i or h 
8  return z
satisfies one of the types  the process is repeated until the
school capacity is reached or all students are selected 
next  we explain algorithm 1 in more detail  given a set
of contracts yb that pertain to school b  a priority ordering ≿b
over contracts and a precedence ordering rb over types  the
choice function chb works as follows  in the beginning  we
remove all unacceptable contracts from yb and initialize the
set z to be empty which is used to store the set of contracts
selected by school b  next  we repeat the following procedure
until the set of contracts yb becomes empty or the school ca-
pacity is reached  first  we identify the set of types t ′ such
that i  each type t ∈ t ′ has the highest precedence based on
rb z   and ii  there exists some contract x =  i  h  b  from
yb in which student i has some type from t ′  then  we scan
over the set of contracts yb based on the priority ordering
≻b of school b and select the first contract  i  h  b  such that
student i has one of the highest precedence types  finally  we
update z and y accordingly and remove any contract y′ from
yb that is associated with either student i or seat h 
note that our new choice function  algorithm 1  is a gen-
eralization of the one by ehlers et al   2014   and it is de-
signed for more general diversity goals instead of minimum
and maximum quotas only  it is also well-defined for students
having overlapping types  algorithm 1 can also easily incor-
porate hard upper bounds for each type  all of our results go
through with these hard upper bounds 
5
stable matching under flexible diversity
goals
in this section  we propose a two-sided matching algorithm
that deals with general diversity goals 
5 1
generalized deferred acceptance with
flexible diversity
the algorithm is well-defined whether students have strict
preferences over all the school seats or whether they are in-
different between all the school seats of the same school  it is
also well-defined even if students have multiple types 
given a set of contracts x  let chi x  denote the choice
function of student i that selects her favorite contract among
xi  let chb x  denote the choice function of school b that
selects a set of contracts among xb  which is not necessar-
ily unique  let chs x  = �
i∈s chi x  and chc x  =
proceedings of the thirtieth    ijcai-21 
20
 algorithm 2 generalized deferred acceptance  gda 
input  instance i  chs  chc  a set of contracts y
output  an outcome z ⊆ y
1  re ← ∅  x ← y  z ← ∅
2  while x ̸= z do
3 
x ← chs y \ re 
  students select contracts 
4 
z ← chc x 
  schools select contracts 
5 
re ← re ∪  x \ z 
  update rejected contracts 
6  return z
�
b∈c chb x  denote the choice functions of students s and
schools c  respectively 
armed with our specified choice function for schools  al-
gorithm 1    we consider the framework of the generalized
deferred acceptance  gda  by hatfield and milgrom  2005 
that works as follows  student first choose their favorite con-
tract from the set y   among all contracts proposed by stu-
dents  each school then chooses a set of contracts  all con-
tracts that are not selected by any school are removed from
the set y   the algorithm repeats these steps until no contract
is removed 
we will refer to the gda algorithm with the choice func-
tion defined in algorithm 1 as generalized deferred accep-
tance with flexible diversity  gda-fd  
here is an example illustrating how gda-fd works 
example 2  there are 4 students s =  1          4  where stu-
dents  1  2  3  belong to type t1 and student 4 belongs to type
t2  suppose there is one school b that has 3 school seats
h =  h1  h2  h3   a priority list 1  2  3  4 and precedence
relation that requires proportionality ratio of 2  1 between t1
and t2  the preference profile of students are as follows  h1
≻1 h2 ≻1 h3  h2 ≻2 h3 ≻2 h1  h3 ≻3 h2 ≻3 h1  h3 ≻4 h1
≻4 h2  we abuse the notation of preferences and contracts 
since there is only one school b  in the first round  students
propose  1  h1    2  h2    3  h3    4  h3  and school b chooses
 1  h1    2  h2    4  h3   in the second round  students pro-
pose  1  h1    2  h2    3  h2    4  h3  and school b chooses
 1  h1    2  h2    4  h3   in the final round  students propose
 1  h1    2  h2    3  h1    4  h3  and school b chooses  1  h1  
 2  h2   and  4  h3  
theorem 1  the gda-fd algorithm runs in polynomial-
time and returns a feasible outcome that is non-wasteful  even
if each student has multiple types 
next  we propose a stability concept for the setting of
school choice with flexible diversity goals and specialized
seats by taking the dynamic precedence of schools into ac-
count 
the following definition 1 captures a natural idea
called dynamic priority proposed in a influential work on
school choice with diversity goals  ehlers et al   2014   while
our new definition is applicable to any market with flexible di-
versity goals  when diversity goals are not considered  it is
equivalent to the standard stability concept 
definition 1  stability   given a feasible outcome y with
 i  h′  b′  ∈ y   a student i and a school b will form a block-
ing pair if  i  h  b  ≻i  i  h′  b′  and either i  the outcome
y ∪   i  h  b   \   i  h′  b′   is feasible  or ii  there exists
a contract  j  h  b  ∈ y such that for all t ∈ t i  and
all t′ ∈ t j  and for the outcome y ′ = y \   j  h  b   
one of the following conditions holds  a  t pb y ′  t′  or b 
 i  h  b  ≻b  j  h  b  and either t i  = t j  or t ib y ′  t′
holds  a feasible outcome is stable if there is no blocking pair 
we will try to understand how far stability can be achieved
under various conditions 
5 2
no specialized seats
we first focus on the case in which each school has identi-
cal/homogenous school seats or students are indifferent be-
tween school seats of the same school  this model is still
a significant generalization of the controlled school choice
problem  ehlers et al   2014  in which all the school seats are
identical and schools impose soft minimum and maximum
quotas on each type  in contrast  our model allows for much
more general diversity goals including type-specific quotas 
our first result is the following theorem 2 
theorem 2  when there are no specialized seats and each
student has one type  gda-fd is strategy-proof for the stu-
dents and yields a stable outcome 
note that to run gda-fd  students need to break ties lex-
icographically to derive a strict preference relation over con-
tracts  the proof idea for theorem 2 is as follows  we show
that in our framework  even though the choice functions of
schools capture complex diversity goals  they still satisfy two
key properties called substitutability  sub  and law of ag-
gregate demand  lad  as defined in  hatfield and milgrom 
2005   once these properties are established  we invoke a
general result in  hatfield and milgrom  2005  that the gener-
alized deferred acceptance is strategy-proof for the students
and always yields a stable outcome 
note that theorem 2 does not hold when each student may
have multiple types  as mentioned in theorem 3 
theorem 3  when there are no specialized seats and each
student has multiple types  gda-fd is no longer strategy-
proof for the students and does not always yield a stable out-
come 
6
specialized seats
in this section  we delve deeper into the case where students
may distinguish between certain seats of a school  we study
which positive properties of gda-fd such as strategyproof-
ness continue to hold under more general preferences  and
present negative results that stable outcomes are not guaran-
teed to exist even under very restrictive conditions 
6 1
case of a global school
we first warm up by getting an in-depth understanding of
gda-fd for the case of a global school  the case of a global
school is still an important setting that captures scenarios such
as hiring of candidates by a company under diversity goals 
we provide an alternative view of gda-fd by showing that
it is equivalent to a sequential allocation algorithm  algo-
rithm 3  under the assumption that there is a policy maker
who treats the set of school seats as one global school b that
has a global priority and a precedence ordering  algorithm 3
can be viewed as a generalized version of serial dictatorship
proceedings of the thirtieth    ijcai-21 
21
 or sequential allocation in which dynamic diversity priorities
are taken into account 
algorithm 3 sequential allocation under dynamic diversity
goals
input  an instance i with global priorities and precedence relation
for school b
output  an outcome z ⊆ x
1  while some student is unmatched and can get an unallocated
school seat do
2 
identify the set of types t ′ with the highest precedence based
on rb z  for which there exists some student who satisfies
some type in t ′
3 
among the students who satisfy some type in t ′  find the
student i ∈ s who has the highest school priority based on
≻b  which is achieved from ≿b by any fixed tie-breaking
rule 
4 
assign student i her favorite contract x =  i  h  b  among
x   z ← z ∪  x 
5 
remove the student i from the market  s ← s \  i 
6 
remove the set of contracts involving student i and seat h 
x \  xi ∪ xh 
7  return z
an outcome x is weakly pareto optimal if there is no other
outcome x′ such that all the students get a more preferred
outcome  an algorithm is type-strategyproof if no student
has an incentive to report a subset of her true types  next  we
summarize the properties of the algorithm 3 in theorem 4 
theorem 4  if there is one global school  even if students
have multiple types  algorithm 3 is strategyproof and type-
strategyproof and the outcome returned by algorithm 3 is
weakly pareto optimal 
next  we show algorithm 3 has a strong connection with
gda-fd for the setting in which students have strict prefer-
ences over the school seats and there is exactly one school 
theorem 5  when there is exactly one school  the gda-fd
algorithm returns the same outcome as algorithm 3 even if
each student may have multiple types
proof   sketch  assume algorithm 2 terminates in m itera-
tions  for each iteration k ∈  1  m   let y 1          y m denote
the set of contracts proposed by students  we prove that al-
gorithm 3 also returns the same outcome y m given the same
input in the appendix 
although the gda-fd remains strategyproof when there
is one global school and each student has a strict preference
over school seats  it does not return a stable outcome even if
each student has one type  as mentioned in theorem 6 
theorem 6  when each student has a strict preference over
school seats  then the gda-fd algorithm and algorithm 3 do
not return a stable outcome even if there is only one school
and each student has one type 
6 2
school-based preferences
in this section  we consider the case that students have school-
based preferences  a student has school-based preferences if
all the school seats of one school are preferred over all the
algorithm 4 modified gda-fd  algorithm for school-
based preferences
input  i  chs  chc  a set of contracts y
output  an outcome z ⊆ y
1  let i′ be the instance in which students are indifferent between
school seats of the same school 
2  let y denote the outcome after applying gda-fd to i′ 
3  let sj denote the set of students who get matched to school bj
in the outcome y  
4  for each j ∈  1  · · ·   m  where m = |c| do
5 
apply gda-fd to the set of students sj and school bj to al-
locate the school seats of bj to sj  with respect to the original
preferences ≻s in i  let the outcome be y ′
j  
6  return z = �m
j=1 y ′
j  
school seats of another school or vice versa  note that stu-
dents may have different preferences over school seats within
the same school  for school-based preferences  we assume
that all the school seats of a school are acceptable or none 
the model of school choice with identical school seats is a
special class of school-based preferences  the case of a sin-
gle school is also a special case of school-based preferences 
theorem 7  for school-based preferences  gda-fd is not
strategy-proof for students even if each student has one type 
next  we design a new algorithm  algorithm 4  for the case
of school-based preferences which invokes gda-fd twice 
in the first stage of algorithm 4  we first run gda-fd on a
modified instance i′ in which school seats within a school
are identical  this gives us information about which students
are matched to which schools  in the second stage  we ap-
ply gda-fd to each school and the set of students who are
matched to that school based on students  true preferences
over school seats  the second step determines which student
receives which school seat  algorithm 4 is strategyproof if
each student has a single type as shown in theorem 8 
theorem 8  for school-based preferences  when each stu-
dent has one type  algorithm 4 is strategy-proof for students 
next  we point out an impossibility result that the set of
stable outcomes may be empty for school-based preferences
even if under very restrictive conditions as shown in theo-
rem 9 
theorem 9  when each student has a strict preference over
school seats  the set of stable outcomes may be empty even
if each student has one type and all schools have the same
priority ordering over students 
7
conclusions
we proposed a matching market model for residential mar-
kets with flexible diversity goals  we provided a clear under-
standing of under which conditions a stable matching is guar-
anteed to exist  our diversity goal framework can be applied
to many other settings in which priorities for different types
dynamically change based on the current allocation  an in-
teresting research direction is to identify other sufficient con-
ditions for the guaranteed existence of stable outcomes under
diversity goals 
proceedings of the thirtieth    ijcai-21 
22
 references
 abdulkadiro˘glu and s¨onmez  2003  a  abdulkadiro˘glu and
t  s¨onmez  school choice  a mechanism design approach 
american economic review  93 3  729–747  2003 
 ayg¨un and turhan  2020  o  ayg¨un and b  turhan 
dy-
namic reserves in matching markets  theory and appli-
cations  journal of economic theory  188  2020 
 aziz and sun  2021  h  aziz and z  sun  multi-rank smart
reserves  in proceedings of the 22th acm conference on
electronic commerce  ec   2021 
 aziz et al   2019  h  aziz  s  gaspers  z  sun  and t  walsh 
from matching with diversity constraints to matching with
regional quotas  in proceedings of the 18th international
conference on autonomous agents and multiagent sys-
tems  aamas   pages 377–385  2019 
 aziz et al   2020  h  aziz  s  gaspers  and z  sun  mech-
anism design for school choice with soft diversity con-
straints 
in proceedings of the 28th international joint
conference on artificial intelligence  ijcai   pages 153–
159  2020 
 baswana et al   2019  s 
baswana 
p 
p 
chakrabarti 
s  chandran  y  kanoria  and u  patange 
centralized
admissions for engineering colleges in india 
in pro-
ceedings of the 20th acm conference on economics and
computation  pages 323–324  2019 
 benabbou et al   2018  n 
benabbou 
m 
chakraborty 
x  ho  j  sliwinski  and y  zick  diversity constraints in
public housing allocation  in proceedings of the 17th in-
ternational conference on autonomous agents and mul-
tiagent systems  aamas 2018  stockholm  sweden  july
10-15  2018  pages 973–981  2018 
 cheng et al   2008  c 
t 
cheng 
e 
mcdermid 
and
i  suzuki 
a unified approach to finding good stable
matchings in the hospitals/residents setting  theoretical
computer science  400 1-3  84–99  2008 
 echenique and yenmez  2015  f  echenique and m  b  yen-
mez  how to control controlled school choice  american
economic review  105 8  2679–2694  2015 
 ehlers et al   2014  l  ehlers  i  e  hafalir  m  b  yenmez 
and m  a  yildirim  school choice with controlled choice
constraints  hard bounds versus soft bounds  journal of
economic theory  153 648–683  2014 
 gonczarowski et al   2019  y  a  gonczarowski  n  nisan 
l  kovalio  and a  romm 
matching for the israeli
 mechinot  gap year  handling rich diversity require-
ments  in proceedings of the 20th acm conference on
economics and computation  ec   pages 321–321  2019 
 hafalir et al   2013  i  e  hafalir  m  b  yenmez  and m  a 
yildirim 
effective affirmative action in school choice 
theoretical economics  8 2  325–363  2013 
 hatfield and milgrom  2005  j  w  hatfield and p  r  mil-
grom  matching with contracts  american economic re-
view  95 4  913–935  2005 
 kojima  2012  f  kojima 
school choice  impossibilities
for affirmative action 
games and economic behavior 
75 2  685–693  2012 
 kominers and s¨onmez  2013  s 
d 
kominers
and
t  s¨onmez 
designing for diversity in matching 
in
proceedings of the 14th acm conference on electronic
commerce  ec   pages 603–604  2013 
 kominers and s¨onmez  2016  s 
d 
kominers
and
t  s¨onmez 
matching with slot-specific priorities 
theory  theoretical economics  11 2  683–710  2016 
 kurata et al   2017  r  kurata  n  hamada  a  iwasaki  and
m  yokoo  controlled school choice with soft bounds and
overlapping types  journal of artificial intelligence re-
search  58 153–184  2017 
 nguyen and vohra  2019  t  nguyen and r  vohra  stable
matching with proportionality constraints  operations re-
search  67 6  1503–1519  2019 
 s¨onmez and yenmez  2019  t  s¨onmez and m  b  yenmez 
constitutional implementation of reservation policies in
india  manuscript  2019 
 sun  2020  z  sun  mechanism design for matching with
constraints  phd thesis  university of new south wales 
sydney  australia  2020 
proceedings of the thirtieth    ijcai-21 
23
 "
None,2021,https-www-ijcai-org-proceedings-2021-0004-pdf,PROPm Allocations of Indivisible Goods to Multiple Agents,"Artem Baklanov, Pranav Garimidi, Vasilis Gkatzelis, Daniel Schoepflin",None,https://www.ijcai.org/proceedings/2021/0004.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0004-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0004-pdf.pdf,"propm allocations of indivisible goods to multiple agents
artem baklanov1   pranav garimidi2   vasilis gkatzelis3 and daniel schoepflin3
1hse university  russian federation
2columbia university
3drexel university
apbaklanov@hse ru  pg2682@columbia edu   gkatz schoep @drexel edu
abstract
we study the classic problem of fairly allocating a
set of indivisible goods among a group of agents 
and focus on the notion of approximate proportion-
ality known as propm  prior work showed that
there exists an allocation that satisfies this notion
of fairness for instances involving up to five agents 
but fell short of proving that this is true in general 
we extend this result to show that a propm alloca-
tion is guaranteed to exist for all instances  indepen-
dent of the number of agents or goods  our proof is
constructive  providing an algorithm that computes
such an allocation and  unlike prior work  the run-
ning time of this algorithm is polynomial in both
the number of agents and the number of goods 
1
introduction
the fair allocation of scarce resources to a group of compet-
ing agents is a fundamental problem in both computer science
and economics  a particularly natural and well-studied set-
ting is the fair allocation of indivisible goods to agents with
additive valuations  under additive valuations  an agent i has
a value vij for each good j and her value for a bundle of goods
s is equal to the sum of the values over each good j ∈ s  i e  
vi s  = �
j∈s vij  an indivisible good cannot be split and
shared by more than one agent so achieving  fairness  with
indivisible goods is often a difficult task  even determining
the appropriate definition of fairness can be non-trivial 
one standard notion of fairness is proportionality  an allo-
cation of a set of goods m to n agents is proportional if each
agent i receives a set of goods si for which she has value
vi si  ≥
1
nvi m   in words  proportionality requires that
every agent obtains at least a 1/n fraction of her total value 
unfortunately  when items are indivisible achieving propor-
tionality may not be possible  for instance  when allocating
a single indivisible good there is no way to provide any posi-
tive value to anyone other than the one agent that receives the
good  in fact  this example shows that one cannot even guar-
antee any multiplicative approximation of proportionality  on
the other hand  this instance does not rule out the existence of
allocations satisfying additive relaxations of proportionality 
three notable additive relaxations of proportionality are
prop1  propx  and propm  each of these notions requires
that agent i must receive value no less than 1
nvi m  − di for
some appropriately defined di ≥ 0  the least demanding of
these notions is prop1  wherein di is the largest value that
agent i has for any item allocated to another agent  conitzer et
al   2017   on the other extreme  for propx di is the small-
est value that agent i has for any item allocated to another
agent  moulin  2019   prop1 is known to be easy to sat-
isfy and provides weak guarantees  while propx is overly
demanding and known to not always exist  in the case of
propm  di corresponds to the maximin value that agent i has
among items allocated to other agents  baklanov et al   2020  
propm sits somewhere between prop1 and propx  and it
is the focus of this work 
baklanov et al   2020  demonstrated that there always ex-
ists a propm allocation for problem instances with up to five
agents  they also demonstrate that many other alternative re-
laxations of proportionality  e g   letting di be the value of
the minimax value item  the median value item  and the aver-
age value item  fail to exist even for instances of three agents 
propm then seems to be a rather unique notion of approxi-
mate proportionality in that it strikes a balance between pro-
viding non-trivial guarantees and seemingly being plausible
to exist in general cases  however  the techniques used to
prove this existence result required extensive case analysis 
suggesting that they would not be useful toward an analogous
proof for instances with many agents  two natural questions
then arise from  baklanov et al   2020   are propm alloca-
tions always guaranteed to exist for any number of agents  if
so  can they be efficiently computed  in this work  we answer
both these questions in the affirmative 
2
related work
as discussed above  it is impossible to guarantee any multi-
plicative approximation of proportionality in the indivisible
items setting  the first additive approximation   proportion-
ality up to the most valued item   prop1   was originally
proposed by conitzer et al   2017  where the authors demon-
strated that there always exists a pareto optimal allocation that
is also prop1  on the other hand  moulin  2019  showed that
if we instead consider  proportionality up to the least valued
item   propx  we can no longer guarantee existence  more-
over  aziz et al   2020  demonstrated that propx allocations
may not exist even for instances with only three agents 
another standard notion of fairness is  envy-freeness 
proceedings of the thirtieth    ijcai-21 
24
 wherein an agent is said to be envy-free if she has weakly
higher value for the set of goods she receives than the set
of goods any other agent receives 
the instance with the
single indivisible items  discussed above  verifies that envy-
freeness may not be achievable either  so prior work has
focused on notions of approximate envy-freeness  namely
 envy-freeness up to the most valued item   ef1   budish 
2011  and  envy-freeness up to the least valued item   efx 
 caragiannis et al   2019   similar to prop1  ef1 alloca-
tions are known to exist for any number of agents  lipton et
al   2004   on the other hand  the existence or non-existence
of efx allocations has not been proven in general  and it is
one of the main open problems in fair division 
plaut and roughgarden  2018  demonstrated that efx al-
locations always exist for two agents  even with combinato-
rial valuations  and chaudhury et al   2020a  established the
existence of efx allocations for instances with three agents
with additive valuations  extending the results in  chaud-
hury et al   2020a  to more than three agents remains a chal-
lenging problem as the proof relies on complex case analy-
sis  much like the proof of existence of propm allocations
for up to five agents in  baklanov et al   2020   central to
many of the proofs of existence for ef1 and efx is a varia-
tion of a procedure of lipton et al   2004  known as  envy-
cycle elimination   see  e g    plaut and roughgarden  2018 
chaudhury et al   2020b  oh et al   2019  amanatidis et al  
2020   wherein a graph representing a given allocation is con-
structed and an alternative allocation is produced by propa-
gating changes along the edges of the graph  our algorithm
for generating propm allocations has a very similar flavor 
beginning from a partial allocation and using a graph analy-
sis to imply a set of changes sufficient to arrive at a propm
allocation 
even if some fairness notion is shown to be achievable  it is
still crucial to study the computational tractability of finding a
solution that satisfies it  aziz et al   2020  provided a strongly
polynomial-time algorithm producing a prop1 and pareto
efficient allocation even in the presence of chores  i e   some
goods can have negative value   for ef1 allocations  cara-
giannis et al   2019  showed that maximizing the nash social
welfare  the geometric mean of the values of the agents  pro-
duces an allocation that is ef1 and pareto efficient  on the
other hand  lee  2017  demonstrated that computing this is
intractable  however  the work of barman et al   2018  pro-
vided an alternative pseudo-polynomial time algorithm that
computes an ef1 and pareto optimal allocation  for efx  the
picture is much less clear  the algorithmic result in  plaut
and roughgarden  2018  relies on computing the allocation
optimizing the leximin objective which may take exponen-
tial time and the result for three agents in  chaudhury et al  
2020a  leads only to a pseudo-polynomial time algorithm 
for propm  the existing results in  baklanov et al   2020  are
constructive but may require exponential time in the number
of items  even for just five agents  on the other hand  in this
work we demonstrate that propm allocations for any num-
ber of agents can  indeed  be computed in time polynomial in
the number of agents and items – a major improvement over
 baklanov et al   2020  
3
our results
prior to this work  we knew that an allocation satisfying
propm always exists for instances involving up to five
agents  in this paper  we significantly extend this result by
providing an algorithm that computes a propm allocation for
any number of goods and agents  moreover  our algorithm
operates in time polynomial in both the number of agents
and items  unlike the algorithm proposed in  baklanov et al  
2020   which was not polynomial even for a fixed number of
agents  in light of these results  propm stands out as a rare
example of a quite non-trivial fairness notion for which we
get universal existence and polynomial-time computability 
our algorithm employs a useful observation from  bak-
lanov et al   2020   see observation 3 in subsection 6 2 in
this paper  which characterizes the conditions under which
an instance can be split into agent- and item-disjoint sub-
problems which can  effectively  be solved completely sep-
arately  yielding a full solution for the initial instance  to
produce such sub-problems  we consider a novel graph rep-
resentation of our instance and search for paths through the
graph  these paths imply a series of gradual modifications
leading to the final decomposition of each problem instance
into sub-problems  we consider this algorithm to be of both
practical and theoretical interest 
4
preliminaries
we study the problem of allocating a set m of m indivisible
items  or goods  to a set of n agents n =  1  2          n   each
agent i has a value vij ≥ 0 for each good j and her value
for receiving some subset of goods s ⊆ m is additive  i e  
vi s  = �
j∈s vij  for ease of presentation  we normalize
the valuations so that vi m  = 1 for all i ∈ n  we also
assume that vij ≤ 1/n for all i ∈ n  j ∈ m  because any
item j with vij > 1/n could be assigned to i and reduce the
problem to finding a propm allocation of m\ j  to n\ i  1
we let mi s  = minj∈s vij  denote the value of the least
valuable good for agent i in bundle of goods s 
an allocation x =  x1  x2          xn  is a partition of the
goods into bundles such that xi is the bundle allocated to
agent i  we use di x  = maxi′̸=i mi xi′   to denote the
value of the maximin good of agent i in x  and we say that an
agent i is propm-satisfied by x if vi xi    di x  ≥ 1/n 
an allocation x is propm if it propm-satisfies every agent 
the goal of our algorithm is to use these bundles to decom-
pose the problem into smaller sub-problems  and compute a
propm allocation using a divide   conquer approach  a
sub-problem  a  n ′  is a pair consisting of a set of bundles
a =  a1  a2          ak  and a subset of agents n ′ ⊆ n 
in other words  a sub-problem  matches  a group of agents
with a group of bundles  and our goal is going to be to do
so in a way that computing a propm allocation for each
sub-problem yields a propm allocation for the original prob-
lem 
the value of an agent i for a set of bundles a is
vi a  = �
aj∈a vi aj   we call a sub-problem  a  n ′ 
proportional if vi a /|n ′| ≥ 1/n for all i ∈ n ′ 
1this fact is proven as lemma 2 in  baklanov et al   2020  
proceedings of the thirtieth    ijcai-21 
25
 given a set of bundles a and a set of agents n ′  a
decomposition is a division of these agents and bundles into
 bundle and agent  disjoint sub-problems  for example con-
sider a set of five agents n ′ =  1  2  3  4  5  and a set of five
bundles a =  a1  a2  a3  a4  a5   one possible decom-
position of  a  n ′  would be into the disjoint sub-problems
  a1  a2  a3    1  2  3   and   a4  a5    4  5   
we say
that a decomposition for  a  n ′  is proportional if all of its
included sub-problems are proportional  as we show later
on  as long as a decomposition is proportional  we can fo-
cus on solving each of its sub-problems recursively without
worrying about the allocation beyond that sub-problem 
consider 
again 
the example above of five agents
 1  2  3  4  5  and five bundles  a1       a5   for these five
agents assume agents 1  2  and 3 have the same valuation
function and assume agents 4 and 5 have the same valuation
functions  let the valuation functions for agents 1  2  and 3
be v a1  = 1
4 and v a2  = v a3  = v a4  = v a5  =
3
16
and let the valuation function for agents 4 and 5 be v a1  =
v a2  = v a3  = 1
6  v a4  =
3
20  and v a5  =
7
20  since
valuation functions are additive  we then have that vi a1 ∪
a2∪a3 /3 ≥ 1/5 for i ∈  1  2  3  and vi a4∪a5 /2 ≥ 1/5
for i ∈  4  5   thus  the decomposition of  a  n ′  described
above d =    a1  a2  a3    1  2  3      a4  a5    4  5   
is a proportional decomposition  we will see that this means
that we can solve the two sub-problems of allocating items in
a1 ∪a2 ∪a3 to agents 1  2  and 3 such that they are propm-
satisfied with respect to a1 ∪ a2 ∪ a3 and allocating items
in a4 ∪ a5 to agents 4  5 such that they are propm-satisfied
with respect to a4 ∪ a5 to produce an allocation where every
agent is propm-satisfied in the original problem 
5
propm algorithm
our algorithm begins by choosing some arbitrary agent i ∈ n
to serve as the  divider   we henceforth use i to refer to the
divider agent and n −i = n \  i  to refer to the set of all
other agents   the divider agent partitions the items into n
bundles  and then the algorithm proceeds to evaluate the other
agents  preferences over these bundles to decide which one
the divider should receive  once the divider s bundle has been
determined  the initial problem is decomposed into smaller
sub-problems that are solved recursively 
5 1
stage 1  the divider partitions the goods
in order to partition the goods  the divider  agent i  first
sorts them in non-decreasing order of value  from i s per-
spective  and indexes them accordingly  then  the first bun-
dle s1 corresponds to the longest prefix of goods in this or-
dering such that vi s1  ≤ 1/n  observe that  by construc-
tion  vi s1    vij > 1/n for all j ∈ m \ s1  moreover 
there is at least  n − 1 /n total value remaining for i out-
side s1 
we construct s2 by taking the longest prefix of
goods in m \ s1 such that i has value less than or equal to
1/ n−1 ·vi m \s1  for receiving all of them  similarly  we
let sk be the longest prefix of goods in m \  ∪k−1
j=1sj  such
that the divider s value for these items remains less than or
equal to 1/ n − k   1  · vi m \  ∪k−1
j=1sj   
5 2
stage 2  decomposing into sub-problems
using disjoint bundles s1  s2          sn from the divider s par-
tition  we now decompose the problem into sub-problems 
eventually solving them recursively  specifically  we care-
fully choose one of these n bundles  say st  and allocate it to
the divider  we then recursively allocate the items of bundles
s1          st−1 to some group nl of t−1 agents  and the items
of bundles st 1          sn to some group nr of n − t agents 
as the pseudocode of algorithm 1 shows  the decompo-
sition process works in a sequence of  up to  n iterations 
indexed by t ∈  1  2          n   at the beginning of every it-
eration t  the algorithm has already identified a proportional
decomposition d involving t − 1 agents and the bundles
s1  s2          st−1  at the end of step t  either the proportional
decomposition d has been updated to also include the bundle
st and a total of t agents  possibly different than the t−1 ones
that were participating in it at the beginning of the round   or
the bundle st has been assigned to the divider agent  and the
remaining problem has been decomposed into a list of pro-
portional sub-problems  throughout the execution of the al-
gorithm  nr is used to denote the set of agents that are not
participating in the proportional decomposition d 
the first thing that the algorithm does in each iteration t is
to evaluate c  the number of agents from nr whose average
value for the first t bundles is more than 1/n  if c is equal
to 0  this means that all the agents in nr essentially  prefer 
sharing the last n − t bundles instead of the first t bundles 
if this is the case  then the algorithm allocates bundle st to
the divider agent  it then recursively solves the proportional
decomposition d  whose sub-problems involve t − 1 agents
and the first t−1 bundles  and also recursively solves the sub-
problem involving the remaining n − t agents  i e   those in
nr  and the items from the last n − t bundles  st 1 to sn 
on the other hand  if the value of c is positive  this sug-
gests that there are agents in nr that  prefer  to share the
first t bundles rather than the last n − t bundles  intuitively 
this suggests that the first t bundles are  over-demanded   so
our algorithm calls updatedecomposition  a crucial sub-
routine  to update decomposition d  as we discuss in subsec-
tion 5 3  a single execution of this subroutine can have one of
two possible outcomes  i  either the value of c decreases by
1  or ii  the number of agents in the decomposition  denoted
|d agents| for notational simplicity  increases by 1  the al-
gorithm keeps calling this subroutine until either the decom-
position grows to include bundle st and t agents  or c drops
to 0  in the former case  it continues to the next iteration  i e  
t ← t   1   otherwise  it assigns st to the divider and recur-
sively solves the remaining sub-problems  figure 1 shows an
example of the algorithm running on a sample instance 
5 3
the updatedecomposition subroutine
the updatedecomposition subroutine plays a central
role in our propm algorithm  and it achieves the desired up-
date of the existing proportional decomposition d at iteration
t by propagating changes on a carefully constructed graph 
note that whenever we call this subroutine  the value of c is
positive  so there exists at least one agent k ∈ nr  i e   not
participating in d  for whom vk s1 ∪ · · · ∪ st /t > 1/n 
proceedings of the thirtieth    ijcai-21 
26
 algorithm 1  propm algorithm
1 let s1  s2          sn be the bundles the divider produces
2 let d be an  initially empty  decomposition
3 nr ← n −i
4 for t = 1 to n do
5
c ← | k ∈ nr   vk s1∪···∪st 
t
> 1
n |
6
while c > 0 and |d agents| < t do
7
d ← updatedecomposition
8
nr ← subset of n −i not participating in d
9
c ← | k ∈ nr   vk s1∪···∪st 
t
> 1
n |
10
if |d agents| < t then
11
allocate st to the divider agent  agent i 
12
recursively solve all sub-problems of d
13
recursively solve  st 1 ∪ · · · ∪ sn  nr 
14
return the combined allocation
given the decomposition of disjoint sub-problems d  we
construct a directed  sub-problem graph  g =  v  e   where
each vertex in v corresponds to a sub-problem in d and
and an edge  u  w  between two vertices u  w ∈ v exists
if and only if the corresponding sub-problems   au  nu  and
 aw  nw  satisfy the following condition  there exists some
agent k ∈ nu who satisfies vk aw 
|nw|
≥
1
n  in other words 
such an edge exists if and only if removing some agent from
nw and replacing her with agent k would maintain the pro-
portionality of the  aw  nw  sub-problem 
the sub-problems corresponding to the vertices of g in-
volve bundles s1          st−1 and some set of t − 1 agents so
the number of vertices in g is at most t−1  we add to g two
more vertices  the first vertex  wα  corresponds to the agent
k ∈ nr mentioned above  this vertex has outgoing edges to
all the sub-problems  a  n ′  of d for which vk a 
|n ′| ≥ 1
n  the
second vertex  wβ  corresponds to the bundle st that we wish
to introduce to this decomposition  this vertex has incoming
edges from any vertex whose sub-problem includes an agent
i′ with value vi′ st  ≥ 1/n  in this graph  let r be the set of
vertices that are reachable from wα via directed paths 
case 1  if this set r includes the vertex wβ  corresponding
to the bundle st  i e   if there is a path from wα to wβ  then
the subroutine reallocates agents along the sub-problems of
this path  specifically  for each edge  u  w  on this path  we
remove from the sub-problem of u the agent that is responsi-
ble for the existence of this edge  we choose one arbitrarily if
there are multiple  and we place that agent in the sub-problem
of w  as a result  d would then include bundle st as well as
agent k  thus increasing |d agents| and  as we argue in sec-
tion 6  this modification maintains the proportionality of the
decomposition 
case 2  if the set r does not include the vertex wβ  but it
includes some agent i′ with vi′ s1∪···∪st 
t
≤ 1
n  then we per-
form an analogous shift of the agents across the sub-problems
along the path from k to i′  but remove agent i′ from the de-
composition and add her to the set nr  this  again  does not
compromise the proportionality of the decomposition  but it
ensures that the updated value of c will drop by 1 since agent
k was removed from nr and replaced with agent i′ who does
not contribute toward an increase of the value of c 
case 3  finally  if neither of the cases above holds  the sub-
routine takes all the agents and all the bundles corresponding
to vertices in r and merges them into a single sub-problem 
together with agent k and bundle st  this  again  increases
|d agents| and as we show using a separate argument in sec-
tion 6  it maintains the proportionality of the decomposition 
6
correctness of the algorithm
to verify the correctness of the algorithm  we first show
that it always terminates and returns an allocation  in fact 
we demonstrate in section 7 that the algorithm completes in
polynomial time   as we verify in subsection 6 1  a single
call to the updatedecomposition subroutine returns an
updated decomposition that has either one additional agent
 and bundle  or has reduced the value of c by 1  since the
value of c at the beginning of each iteration can never be more
than n − 1  this ensures that the while loop will always ter-
minate within a finite number of iterations  if for some it-
eration t ≤ n − 1 the value of |d agents| drops below t 
then the algorithm recurses on smaller problems and returns
the induced allocation 
if  on the other hand  |d agents|
does not drop below t for any iteration t ≤ n − 1  then
when t = n we have an empty set nr  necessarily leading
to d including every agent except for the divider  meaning
|d agents| = n − 1 < t   also  note that the size of the sub-
problems solved recursively always strictly decreases  we
demonstrate in subsection 6 2 that this process yields a pro-
portional allocation for all agents 
6 1
correctness of updatedecomposition
we now formally prove that after every execution of the
updatedecomposition subroutine  either |d agents| in-
creases by 1  or the value of c drops by 1  in both cases  the
resulting decomposition remains proportional  throughout the
execution of the algorithm 
first  note that the set r of vertices that are reachable from
agent k is bound to be non-empty  this is due to the fact
that vk s1 ∪ · · · ∪ st /t > 1/n  i e   the agent s average
bundle value is more than 1/n and  by pigeonhole princi-
ple  there must exist some sub-problem  a  n ′  such that
vk a /|a| ≥ 1/n  since the set r is not empty  the descrip-
tion of the subroutine in the previous section clearly shows
that it always achieves either an increase of |d agents| or a
drop of the value of c  therefore  the rest of this subsection
focuses on proving that all of these updates on the decompo-
sition maintain its proportionality 
lemma 1  given a proportional decomposition  the de-
scribed re-allocation of agents across the directed edges of
a path in the decomposition s sub-problem graph leads to a
new decomposition that remains proportional 
proof  note that  by definition of the sub-problem graph  any
agent that caused the existence of an edge  u  w  must have
a value of at least |nw|/n for the bundles of the sub-problem
corresponding to vertex w  as a result that agent will still
satisfy proportionality if moved from u to w  this is true for
proceedings of the thirtieth    ijcai-21 
27
 4
nr
t = 1
2
3
5
6
s1
�
��
�
s2
� �� �
s3
�
��
�
s4
����
s5
����
s6
�
��
�
4
6
nr
t = 2
2
3
5
s1
�
��
�
s2
� �� �
s3
�
��
�
s4
����
s5
����
s6
�
��
�
4
5
2
nr
t = 3
3
6
s1
�
��
�
s2
� �� �
s3
�
��
�
s4
����
s5
����
s6
�
��
�
t = 4
4
5
2
3
6
1
s1
�
��
�
s2
� �� �
s3
�
��
�
s4
����
s5
����
s6
�
��
�
figure 1  the state of our algorithm after the completion of iterations t ∈  1  2  3  4  on a sample instance with six agents and agent 1 as
the divider  the circles correspond to items  which are grouped together into bundles  s1          s6  by the divider  the numbered boxes
beneath the items correspond to agents 2 through 6  and each of the larger rounded rectangles  containing bundles and agents  correspond to
sub-problems  in each iteration of the algorithm  captured by this figure  the dashed vertical line separates the bundles of the decomposition
d  on the left  from the remaining bundles  after each iteration t  either the decomposition is updated to include bundle st  as we see for
t ∈  1  2  3    or bundle st is allocated to the divider agent  as wee see for t = 4   finalizing the set of sub-problems to be solved recursively 
all the edges on this graph  including the ones connecting the
two added vertices wα and wβ   ensuring the proportionality
is maintained 
the more demanding case is to verify that proportionality
is also maintained by the third type of update that this subrou-
tine performs  i e   the creation of a sub-problem involving the
agents and goods in r as well as agent k and bundle st 
lemma 2  if a′ is the collection of all the bundles corre-
sponding to sub-problems not reachable from wα  excluding
st  then for every agent q from a sub-problem in r we have
vq a′ /|a′| < 1/n  the same is true for the agent k that
corresponds to vertex wα  i e   vk a′ /|a′| < 1/n 
proof  assume that this is not the case  i e   that either some
agent q corresponding to a sub-problem in r  or agent k  has
an average bundle value at least 1/n for the bundles in a′ 
by the pigeonhole principle  this implies that there must exist
some sub-problem not reachable from r such that this agent s
average value for the bundles in that sub-problem is at least
1/n  but  based on the definition of the sub-problem graph 
this would imply the existence of an edge from that agent s
vertex to this sub-problem s vertex  contradicting the fact that
the latter is not reachable from the former 
whenever the subroutine resorts to the third type of decom-
position update  case 3   this means that there is no agent i′
in a sub-problem in r such that vi′ s1∪···∪st 
t
≤ 1
n  case 2  
thus  agent k and all agents q from sub-problems in r have
value for the items in s1∪· · ·∪st greater than t/n  lemma 2
implies that their total value for the bundles in a′ is less than
|a′|/n  therefore  these agents  value for the items contained
in sub-problems in r is at least  t − |a′| /n 
also  note that the overall number of agents in the sub-
problems of g  excluding k  is t−1  and the number of agents
in the sub-problems not reachable from r are |a′|  so the total
number of agents in the sub-problems of r is t − |a′| − 1 
therefore  if we define a new sub-problem using the agents
from r  combined with agent k corresponding to vertex wα 
and the bundles from r  combined with st  then this sub-
problem will be proportional  because every agent s value for
the bundles in it will be at least  t − |a′| /n and the number
of agents in it is t − |a′| 
6 2
all agents are propm-satisfied
to verify that the induced allocation is always propm  we
first restate a useful observation from  baklanov et al   2020  
this observation provides us with a sufficient condition un-
der which  locally  satisfying propm in each sub-problem
yields a  globally  propm allocation  given an allocation
of a subset of items to a subset of agents  we say that this
partial allocation is propm if the agents involved would be
propm-satisfied if no other agents or items were present 
observation 3  let n1  n2 be two disjoint sets of agents 
let m1 and m2 = m \ m1 be a partition of the items into
two sets  and let x be an allocation of the items in m1 to
agents in n1 and items in m2 to agents in n2  then  if some
agent i ∈ n1 is propm-satisfied with respect to the par-
tial allocation of the items in m1 to the agents in n1  and
vi m1 
|n1|
≥
1
|n1 n2|  then i is propm-satisfied by x regard-
less of how the items in m2 are allocated to agents in n2 
we now prove a result regarding the partition implied by
the divider agent s preferences  which is analogous to a theo-
rem that is shown by  baklanov et al   2020  for a different 
much more complicated  partition of the items 
theorem 4  if the divider agent receives any bundle sℓ and
no item from s1 ∪ s2 ∪ · · · ∪ sℓ−1 is allocated to the same
agent as an item from sℓ 1 ∪ sℓ 2 ∪ · · · ∪ sn  then agent i
will be propm-satisfied 
proof  for all k ∈  n   we have vi sk  ≤
1
 n 1−k vi m \
 s1 ∪s2 ∪· · ·∪sk−1   by definition of sk  applying this up-
per bound on vi sk  for k = 1  because vi m  = 1 we have
that vi m\s1  ≥ 1− 1
n = n−1
n   by applying the upper bound
on vi sk  for k = 2 and our lower bound on vi m \ s1  we
get vi m \ s1 ∪s2   ≥ n−1
n −
1
n−1 · n−1
n
≥ n−2
n   iteratively
proceedings of the thirtieth    ijcai-21 
28
 repeating this process  we obtain that for all k ∈  n  we know
that vi m \  s1 ∪ s2 ∪ · · · ∪ sk   ≥
n−k
n   also by defi-
nition  we have that vi sℓ    minj∈m\ s1∪s2∪···∪sℓ  vij  ≥
1
 n 1−ℓ  ·vi m \ s1∪s2∪· · ·∪sℓ−1   ≥
1
n 1−ℓ · n− ℓ−1 
n
=
1
n  but finally  as long as the items from s1 ∪ s2 ∪ · · · ∪ sℓ−1
are not included in any of the bundles containing the items
in m \  s1 ∪ s2 ∪ · · · ∪ sℓ  in the complete allocation x 
we have that di x  ≥ minj∈m\ s1∪s2∪···∪sℓ  vij  so i is
propm-satisfied when allocated set sℓ 
lemma 5  the divider agent is always propm-satisfied  all
non-divider agents are always propm-satisfied as well 
proof  note that the divider agent always receives a bun-
dle st in some iteration t 
all the items from bundles
s1          st−1 are allocated to the agents that were in the de-
composition d at that time  while all the items from bundles
st 1          sn are allocated to the agents that were in nr at
the time  and hence not in d   then  given theorem 4  we
conclude that the divider agent is always propm-satisfied 
now observe that no agent other than the divider agent is
directly allocated a bundle by our algorithm  instead  the al-
location to the other agents is decided recursively in some
recursive call of a smaller sub-problem  when they are as-
signed the role of the divider  the important thing to verify is
that propm-satisfying these agents in a recursive call  based
on a subset of the agents and a subset of the goods  does  in
fact  imply that they are propm-satisfied with respect to the
original problem instances as well 
in order to ensure this fact  we combine the statement
of observation 3 with the definition of proportional sub-
problems and decompositions  in particular  our definition of
proportionality for a sub-problem guarantees that the condi-
tions of observation 3 are met  since we ensure that propor-
tionality is maintained after every execution of the updat-
edecomposition subroutine  we guarantee that the combi-
nation of propm allocations for the generated sub-problems
yields a propm allocation for the original problem 
7
running time
we now move to demonstrate that algorithm 1 completes in
time polynomial in the number of agents and items  lines
1 through 9 correspond to the  divide phase  and lines 10
through 14 correspond to the  conquer phase  
the running time of algorithm 1 can be expressed as
t m  n  = f m  n   
k
�
j=1
t mj  nj  
where f m  n  denotes the cost of the main call with m items
and n agents  and the sum captures the cost of the recursive
calls  the number of recursive calls is k  equal to the num-
ber of sub-problems from lines 12 and 13   while mj and nj
are the number of items and agents  respectively  of the j-th
sub-problem  since all the sub-problems consist of distinct
bundles and agents  we must have �k
j=1 mj ≤ m − 1 and
�k
j=1 nj ≤ n − 1  thus the width of any level of the recur-
sion tree is at most max m  n   furthermore  since the size
of each sub-problem strictly decreases through the recursion 
the recursion tree has at most depth min m  n   this means
the total number of vertices in the recursion tree is polynomial
in n and m  all that remains is to show f m  n  is polynomi-
ally bounded in m and n 
producing the divider s bundles takes polynomial time
since it requires only sorting the items in non-decreasing or-
der of value and a linear pass over the sorted items  in the
body of the for loop of algorithm 1  computing the initial
value of c takes time linear in the number of agents and items
by asking each agent their value for each item in s1∪· · ·∪st 
this initial value of c is at most n − 1  as demonstrated in
subsection 6 1  at each iteration of the while loop  beginning
at line 6  in algorithm 1  the updatedecomposition sub-
routine either increases the value of |d agents| from t − 1 to
t or decreases the value of c  thus  the number of iterations
of the while loop is at most n at any iteration of the for loop 
we now demonstrate that the body of the while loop takes
polynomial time  note that computing the new value of c
after then updatedecomposition subroutine takes linear
time  in the number of agents and items   to verify that up-
datedecomposition also takes polynomial time  observe
that the sub-problem graph induced by d in iteration t of the
for loop contains at most t − 1 vertices  which would occur
when all t−1 agents in d and bundles are assigned to distinct
sub-problems   we then add two additional vertices wα and
wβ so there are at most t   1 = o n  vertices overall at any
iteration of the for loop  note that checking if an edge ex-
ists between two vertices in the graph takes time linear in the
number of agents and goods in the two sub-problems and each
sub-problem has at most n agents and m items  thus  we can
construct the graph in time o n· n m    finally  computing
the set r of reachable vertices from wα can be accomplished
by a simple breadth-first-search which is known to take time
linear in the number of the vertices and edges in the graph 
since updating the decomposition just requires propagating
changes along a path of length at most n  the entire updat-
edecomposition process takes polynomial time 
8
conclusion
in this paper  we solve the problem of computing propm al-
locations among agents with additive valuations  but we leave
open another interesting problem proposed in  baklanov et
al   2020   the question of the existence and computation of
an average-efx  a-efx  allocation  to determine if an agent
is a-efx satisfied by some allocation  we remove i s least fa-
vorite item from each other agent s allocated bundle  and then
ask that i s value for her own bundle is at least as high as her
average value for all the other agents  bundles  this notion
is stronger than propm and may provide an interesting step-
ping stone toward the  much harder  efx problem 
acknowledgements
the first author gratefully acknowledges support from the
hse university basic research program  the last two au-
thors were partially supported by nsf grants ccf-2008280
and ccf-2047907  we would also like to thank maxim tim-
okhin for helpful feedback toward improving our algorithm 
proceedings of the thirtieth    ijcai-21 
29
 references
 amanatidis et al   2020  georgios amanatidis  evangelos
markakis  and apostolos ntokos  multiple birds with one
stone  beating 1/2 for efx and gmms via envy cycle
elimination  proceedings of the aaai conference on arti-
ficial intelligence  34 02  1790–1797  apr  2020 
 aziz et al   2020  haris aziz  herv e moulin  and fedor
sandomirskiy  a polynomial-time algorithm for comput-
ing a pareto optimal and almost proportional allocation 
operations research letters  2020 
 baklanov et al   2020  artem baklanov  pranav garimidi 
vasilis gkatzelis  and daniel schoepflin  achieving pro-
portionality up to the maximin item with indivisible goods 
corr  abs/2009 09508  2020 
to appear at the thirty-
fifth aaai conference on artificial intelligence  aaai
2021  
 barman et al   2018  siddharth barman  sanath kumar kr-
ishnamurthy  and rohit vaish  finding fair and efficient
allocations  in proceedings of the 2018 acm conference
on economics and computation  ithaca  ny  usa  june
18-22  2018  pages 557–574  2018 
 budish  2011  eric budish 
the combinatorial assign-
ment problem 
approximate competitive equilibrium
from equal incomes 
journal of political economy 
119 6  1061–1103  2011 
 caragiannis et al   2019  ioannis
caragiannis 
david
kurokawa  herv e moulin  ariel d  procaccia  nisarg
shah  and junxing wang  the unreasonable fairness of
maximum nash welfare 
acm trans  economics and
comput   7 3  12 1–12 32  2019 
 chaudhury et al   2020a  bhaskar ray chaudhury  jugal
garg  and kurt mehlhorn  efx exists for three agents  in
proceedings of the 21st acm conference on economics
and computation  ec  20  page 1–19  new york  ny 
usa  2020  association for computing machinery 
 chaudhury et al   2020b  bhaskar
ray
chaudhury 
telikepalli
kavitha 
kurt
mehlhorn 
and
alkmini
sgouritsa 
a little charity guarantees almost envy-
freeness 
in shuchi chawla  editor  proceedings of the
2020 acm-siam symposium on discrete algorithms 
soda 2020  salt lake city  ut  usa  january 5-8  2020 
pages 2658–2672  siam  2020 
 conitzer et al   2017  vincent conitzer  rupert freeman 
and nisarg shah  fair public decision making  in con-
stantinos daskalakis  moshe babaioff  and herv e moulin 
editors  proceedings of the 2017 acm conference on eco-
nomics and computation  ec  17  cambridge  ma  usa 
june 26-30  2017  pages 629–646  acm  2017 
 lee  2017  euiwoong lee  apx-hardness of maximizing
nash social welfare with indivisible items  inf  process 
lett   122 17–20  2017 
 lipton et al   2004  richard j  lipton  evangelos markakis 
elchanan mossel  and amin saberi 
on approximately
fair allocations of indivisible goods  in proceedings 5th
acm conference on electronic commerce  ec-2004  
new york  ny  usa  may 17-20  2004  pages 125–131 
2004 
 moulin  2019  herv e moulin  fair division in the internet
age  annual review of economics  11 407–441  2019 
 oh et al   2019  hoon oh  ariel d procaccia  and warut
suksompong 
fairly allocating many goods with few
queries  in proceedings of the aaai conference on ar-
tificial intelligence  volume 33  pages 2141–2148  2019 
 plaut and roughgarden  2018  benjamin plaut and tim
roughgarden  almost envy-freeness with general valua-
tions  in proceedings of the twenty-ninth annual acm-
siam symposium on discrete algorithms  soda 2018 
new orleans  la  usa  january 7-10  2018  pages 2584–
2603  2018 
proceedings of the thirtieth    ijcai-21 
30
 "
None,2021,https-www-ijcai-org-proceedings-2021-0005-pdf,Learning Within an Instance for Designing High-Revenue Combinatorial Auctions,"Maria-Florina Balcan, Siddharth Prasad, Tuomas Sandholm",None,https://www.ijcai.org/proceedings/2021/0005.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0005-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0005-pdf.pdf,"learning within an instance for designing high-revenue combinatorial auctions
maria-florina balcan1   siddharth prasad1 and tuomas sandholm1 2 3 4
1school of computer science  carnegie mellon university
2optimized markets  inc 
3strategic machine  inc 
4strategy robot  inc 
 ninamf  sprasad2  sandholm @cs cmu edu
abstract
we develop a new framework for designing truth-
ful 
high-revenue  combinatorial  auctions for
limited supply 
our mechanism learns within
an instance 
it generalizes and improves over
previously-studied random-sampling mechanisms 
it first samples a participatory group of bidders 
then samples several learning groups of bidders
from the remaining pool of bidders  learns a high-
revenue auction from the learning groups  and fi-
nally runs that auction on the participatory group 
previous work on random-sampling mechanisms
focused primarily on unlimited supply 
limited
supply poses additional significant technical chal-
lenges  since allocations of items to bidders must be
feasible  we prove guarantees on the performance
of our mechanism based on a market-shrinkage
term and a new complexity measure we coin par-
tition discrepancy  partition discrepancy simulta-
neously measures the intrinsic complexity of the
mechanism class and the uniformity of the set of
bidders 
we then introduce new auction classes
that can be parameterized in a way that does not
depend on the number of bidders participating  and
prove strong guarantees for these classes  we show
how our mechanism can be implemented efficiently
by leveraging practically-efficient routines for solv-
ing winner determination  finally  we show how to
use structural revenue maximization to decide what
auction class to use with our framework when there
is a constraint on the number of learning groups 
1
introduction
in a  limited-supply  combinatorial auction  a seller has m
indivisible items to allocate among a set s of n bidders  com-
binatorial auctions have various real-world applications  two
examples include auctions for allocating licenses for bands of
the electromagnetic spectrum and sourcing auctions for sup-
ply chain management  the design of truthful  high-revenue
combinatorial auctions is a central problem in mechanism de-
sign 
a comprehensive account of combinatorial auctions
may be found in cramton et al   2006  
a common strategy for designing truthful  high-revenue
auctions when there is an unlimited supply of each good
has been to use a random-sampling mechanism  a random-
sampling mechanism splits the bidders into two groups  and
applies the optimal auction for each group to the other group
 thereby achieving truthfulness  since the auction run on any
bidder s group is independent of her reported valuation   in
unlimited-supply settings  random-sampling mechanisms sat-
isfy strong guarantees  goldberg et al   2001  balcan et al  
2005  alaei et al   2009  
however  until now  there has been no unified  general-
purpose method of adapting the random-sampling approach
to analyze the limited-supply setting  limited supply poses
additional significant technical challenges  since allocations
of items to bidders must be feasible  for example  random-
sampling with any mechanism class that allows bidders to
purchase according to their demand functions would violate
supply constraints 
most adaptations of random-sampling
to limited supply deal with feasibility issues in complicated
ways  for example  by constructing intricate revenue bench-
marks to limit the number of buyers who can make a pur-
chase  balcan et al   2007   or by placing combinatorial con-
straints on the environment  devanur and hartline  2009 
devanur et al   2015  
in this paper we circumvent these issues by applying auc-
tion formats that generalize the classical vickrey-clarke-
groves  vcg  auction  vickrey  1961  clarke  1971  groves 
1973  to sell all m items to a random group of participatory
bidders 
these auctions prescribe feasible allocations and
payments  and are incentive compatible   several parame-
terized generalizations of the vcg auction have been studied
with the aim of increasing revenue by introducing weights
to favor certain bidders or allocations 
examples include
affine-maximizer auctions  amas   roberts  1979   virtual-
valuations combinatorial auctions  vvcas   likhodedov
and sandholm  2004  likhodedov and sandholm  2005 
sandholm and likhodedov  2015   λ-auctions  jehiel et al  
2007   mixed-bundling auctions with reserve prices  tang
and sandholm  2012   and mixed-bundling auctions  jehiel et
al   2007   however  little is known when it comes to formal
approximation guarantees for these auction classes 
a direct adaptation of vanilla random sampling can do
poorly when the auction class is rich  suppose we randomly
partition the set of bidders into two groups s1 and s2  and ap-
proceedings of the thirtieth    ijcai-21 
31
 ply the optimal mechanism for s1 to s2  consider learning
a second-price auction with a reserve in the case of selling
a single item  suppose there is one bidder who values the
item at 10 and the remaining buyers  values are in  0  9   the
high bidder is in s1 with probability 1/2  so with probabil-
ity 1/2  the optimal reserve price for s1 is 10  and the rev-
enue obtained from s2 is 0  more generally  since we study
large parameterized auction classes  the optimal auction for
s1 potentially overfits to a small number of bidders  another
adaption along the lines of vanilla random sampling to pre-
vent overfitting would be to partition the set s of bidders into
n groups  use the first n − 1 groups to learn a high-revenue
auction  and then apply that auction to the nth group  the is-
sue with this approach is that generalization guarantees would
require n large  thus the final mechanism only sells items to
a tiny fraction of bidders  incurring a large revenue loss 
our main learning-within-an-instance  lwi  mechanism
alleviates these issues by randomly drawing a set of participa-
tory bidders spar  and then sampling several proportionally-
sized learning groups from slrn  = s \ spar to learn an auc-
tion that is close-to-optimal in expectation for a random learn-
ing group  our approach is a form of automated mechanism
design  conitzer and sandholm  2002  sandholm  2003  
1 1
setup and the main mechanism
in our model  the seller has m indivisible items to allocate
among a set s of n bidders/buyers  each buyer is described
by her valuation function vi   2 1     m  → r≥0 over bundles
of the m items   we implicitly assume that each buyer s value
for getting the empty bundle is zero   we do not assume that
b ⊆ b′ implies v b  ≤ v b′   a common assumption called
free disposal   for an allocation α  vi α  denotes the value
buyer i assigns to the bundle she receives according to α  we
assume that buyers valuations are independent of what other
buyers  receive   for an allocation α  w α  = �n
i=1 vi α 
denotes the welfare of α  and w−i α  = �
j̸=i vj α  de-
notes the welfare of α when bidder i is absent  for a set of
bidders s  w s  = maxα w α  denotes the welfare of an
efficient allocation  that is  an allocation that maximizes wel-
fare  the vcg auction uses the efficient allocation α∗  and
bidder i pays maxα w−i α  − w−i α∗   the auctions we
study in this paper are parameterized generalizations of the
vcg auction that modify the welfare function by applying
boosts to specific allocations with the aim of increasing rev-
enue  for an auction m and a set of bidders s′ ⊆ s  we
denote by revm s′  the sum of the payments made by bid-
ders in s′ when the seller runs m among bidders in s′  we
write s′ ∼p s to denote a subset s′ being sampled from s by
including each bidder in s′ independently with probability p 
we now present the main mechanism of this paper 
learning-within-an-instance mechanism  lwi  parame-
ters  p  q  n
1  draw a group of participatory buyers spar ∼p s 
2  draw learning groups of buyers s1          sn ∼q s \ spar 
3  find the mechanism �
m ∈ m that maximizes empirical
revenue 1
n
�n
t=1 revm st  over the learning groups 
4  apply mechanism �
m to spar 
when m is a class of incentive-compatible mechanisms 
lwi is incentive-compatible since �
m does not depend on the
valuations of the bidders in spar 
1 2
summary of the contributions of this paper
in section 2 we provide the main guarantees satisfied by our
lwi framework  the guarantees are derived using learning-
theoretic techniques  informally  they provide  high proba-
bility  lower bounds on the performance of lwi of the form
rev�
m spar  ≥ w s  lm − εm n  δ   − τm  where lm
measures the revenue loss incurred by allocating items only
to participatory bidders  εm is a standard learning-theoretic
error term that depends on the intrinsic complexity of m  and
τm is an additional error term we coin partition discrepancy 
partition discrepancy is also a measure of the intrinsic com-
plexity of m  but is simultaneously a measure of the level of
uniformity in the set s of bidders  we provide examples and a
general bound to illustrate properties of partition discrepancy 
in section 3 we introduce a new class of auctions called
bundling-boosted auctions  these auctions are parameterized
in a way that does not depend on the number of bidders who
participate in the auction  unlike most previous generaliza-
tions of the vcg auction   we prove bounds on the intrin-
sic complexity of bundling-boosted auctions  and a few other
natural subclasses of auctions  that have no dependence on
the number of bidders  we show that under certain condi-
tions lwi on the class of bundling-boosted auctions yields an
 o p  − ε -approximation with high probability 
in section 4 we show how our learning-within-an-instance
mechanism can be implemented in a sample and compu-
tationally efficient manner for bundling-vcg auctions and
sparse bundling-boosted auctions by leveraging practically
efficient routines for solving winner determination 
in section 5 we show how to use structural revenue maxi-
mization to decide what auction class to use with lwi when
there is a constraint on the number of learning groups 
1 3
additional related research
there have been various alternate approaches to revenue
maximization for limited supply  balcan  blum  and man-
sour  2008  obtain a o 2
√log m log log m -approximation for
bidders with subadditive valuations  which was improved
to a o log2 m -approximation by chakraborty  huang  and
khanna  2013   both these works studied item-pricing mech-
anisms  sandholm and likhodedov  2005  2015  obtain a
 2   2 log h/l  -approximation when bidders have additive
valuations  where l and h are lower and upper bounds on the
valuation of any bidder for any item  our results significantly
improve upon these existing results in various situations  for
example  for w s  sufficiently large  we prove that our lwi
mechanism run on the class of bundling-boosted auctions
yields an  o p  − ε -approximation  in addition  previous
approximations are on expected revenue  while we give the
much stronger guarantee of high-probability revenue approx-
imation  furthermore  our results do not require restrictions
on valuation functions  giving them very broad applicability 
a recent line of work studies learning revenue-maximizing
auctions for limited supply across instances  mohri and med-
ina  2014  morgenstern and roughgarden  2015  balcan et
proceedings of the thirtieth    ijcai-21 
32
 al   2018   these works laid down the framework for under-
standing learning-theoretic quantities related to auctions in
order to prove generalization guarantees  our paper studies
the significantly tougher and unsolved problem of learning
from a single instance for limited supply  we extend the tech-
niques of balcan et al   2005   that can be viewed as learning
within an instance for unlimited supply  and show that learn-
ing theory combined with the power of parameterized auc-
tions provides a way to meaningfully learn within an instance
in the more challenging setting of limited supply 
2
main guarantees of our framework
in this section we present the main guarantees satisfied by
lwi in terms of structural properties of the auction class and
the set of bidders  our guarantees are in terms of partition dis-
crepancy  delineability  and the following quantity that con-
trols the revenue loss incurred by selling only to bidders in
spar  for s′ ⊆ s  let optm s′  = supm∈m revm s′ 
and let lm s′  = optm s′ /w s  
for a given participatory set of bidders spar  partition dis-
crepancy measures the worst-case deviation in an auction
class between the revenue on spar versus the expected rev-
enue on a set of bidders sampled from s\spar  for 0 < q < 1
and spar ⊂ s  partition discrepancy is defined as
τm q  spar  = sup
m∈m
���revm spar  −
e
s0∼qs\spar revm s0  
��� 
partition discrepancy is a measure of both the intrinsic com-
plexity of the class m and the amount of uniformity in the set
s of bidders  we now present general guarantees for lwi in
terms of partition discrepancy  the full derivations are in the
appendix   the guarantees follow from uniform convergence
results  and depend on the expected rademacher complexity
rm n  s \ spar  of m with respect to s \ spar and the
pseudodimension pdim m  of m  we provide definitions
and some standard results from learning theory that we use in
our proofs in the appendix  �
m denotes the empirical-revenue-
maximizing mechanism used by lwi 
theorem 1  let spar denote the participatory set of bidders
chosen by a run of lwi  then  with probability ≥ 1 − 2δ
over the draw of s1          sn ∼q s \ spar   a  rev �
m spar  ≥
w s 
�
lm spar  − 4rm n  s \ spar  −
�
2 ln 1/δ /n
�
−
2τm q  spar  and  b  rev �
m spar 
≥
w s 
�
lm spar  −
240
�
pdim m /n −
�
2 ln 1/δ /n
�
− 2τm q  spar  
proof sketch  uniform convergence results relate the empir-
ical revenue of �
m on the learning groups to the optimal ex-
pected revenue on a random learning group  partition dis-
crepancy ties both these quantities to revenue on spar 
if m has finite pseudodimension  this is not necessarily the
case if we only have a bound on rademacher complexity   we
can give an equivalent sample-complexity version of the guar-
antee  let n ε  δ  pdim m   = 4802 pdim m  ln
� 1
δ
�
/ε2 
corollary 1  let spar denote the participatory set of bid-
ders chosen by a run of lwi with parameters p  q  n  where
n ≥ n ε  δ  pdim m    then  with probability ≥ 1 − 2δ
over the draw of s1          sn ∼q s \ spar  rev�
m spar  ≥
w s  lm spar  − ε  − 2τm q  spar  
to understand the pseudodimension of various mechanism
classes  balcan et al   2018  introduced the notion of deline-
ability  a class of mechanisms m is  d  h -delineable if  1 
every m ∈ m can be parameterized by a vector θ ∈ rd  and
 2  for every set s of bidder valuations  there are at most h
hyperplanes partitioning rd such that revs θ   = revθ s  is
linear in θ over each connected component of rd determined
by the hyperplanes  the way we have stated delineability re-
quires h to be independent of the number of bidders in s 
we include an analysis of the case where h is allowed to be
a function of n in the appendix  the following example il-
lustrates delineability in a simple case  balcan et al   2018 
provide more examples and a more detailed discussion 
example 1  second-price auctions with a reserve price   the
class of second-price auctions with reserve prices for selling
a single item is  1  2 -delineable  indeed  if v1 and v2 are
highest and second-highest values for the item  respectively 
then for r < v2 the revenue of a second-price auction with
reserve r is v2  for v2 ≤ r ≤ v1 it is r  and for r > v1 it is 0 
rademacher complexity  pseudodimension  and delin-
eability are connected through the following relations 
rm n  slrn  ≤ 60w s 
�
pdim m /n  dudley  1987 
and if m is  d  h -delineable  pdim m  ≤ 9d ln 4dh   bal-
can et al   2018  
we present our main guarantee in terms of delineability 
theorem
2 
suppose
m
is
 d  h -delineable 
let
spar denote the participatory set of bidders chosen by
a run of lwi with parameters p  q  n  where n
≥
n ε  δ  9d ln 4dh    then  with probability ≥ 1 − 2δ over
the draw of s1          sn
∼q
s \ spar  rev�
m spar  ≥
w s  lm spar  − ε  − 2τm q  spar  
we provide analogous guarantees for mechanism classes
that satisfy a version of delineability that is dependent on the
number of bidders in the appendix 
2 1
partition discrepancy
in this section we develop a further understanding of partition
discrepancy  we first provide two examples illustrating struc-
tural properties of partition discrepancy  we then provide a
general-purpose high-probability bound on partition discrep-
ancy based on pseudodimension of the mechanism class 
the first example relates the failure of vanilla random sam-
pling to large partition discrepancy using the scenario given
in the introduction  we show how lwi alleviates that issue 
example 2  lwi versus random sampling   consider the ex-
ample from the introduction where a single item is for sale
and m is the class of second-price auctions with reserve 
there is one bidder with value 10  and all remaining bid-
ders  values are in  0  9   suppose lwi is run with parameters
p = 1/2  q = 1  which corresponds to vanilla random sam-
pling   then  for any participatory set spar  τm 1  spar  =
10 = w s   achieved by setting a reserve price of 10  if
instead lwi was run with parameters p = q < 1  the high
bidder is in s \ spar with probability 1 − p  and in this case
proceedings of the thirtieth    ijcai-21 
33
 τm q  spar  = 10q if  for example  p = q = 1/20  this is a
small additive loss in the overall revenue guarantee 
the next example involves replica economies  where the
set of bidders is composed of several copies of a ground set
of bidders  replica economies have been studied extensively
in economics  and recently from an algorithmic viewpoint  in
the context of convergence to equilibria  debreu and scarf 
1963  aumann  1964  barman and echenique  2020  
example 3  replica economies   suppose s0 =  v1  v2  v3  
and s consists of n0 replicas of s0  let m be a population-
size-independent auction class  we show in the appendix that
if n0 is sufficiently large  τm 1  spar  = 0 with high proba-
bility over the draw of spar ∼1/2 s 
we now present a general bound on partition discrepancy
in terms of the learning-theoretic complexity of m when lwi
is run with parameters p = 1/3 and q = 1/2  for each bidder
i  let ˜vi = max|s′|≥n/3−5√n supm∈m |revm s′ ∪  i   −
revm s′ | and let ˜v =  ˜v1          ˜vn  ∈ rn  these terms
measure how sensitive the mechanism class is to the addition
of a single bidder to an already large set of bidders  in the
following results on partition discrepancy  we condition on
the  probability ≥ 1 − e−25  event that |spar| ≥ n/3 − 5√n 
theorem
3 
with
probability
≥
1
−
δ
over
the
draw
of
spar
∼1/3
s 
τm 1/2  spar 
≤
||˜v||2
�
2n pdim m  ln 4e2 pdim m w  s 
δ
 
proof sketch  we bound τm for a single mechanism m us-
ing concentration bounds  we then apply a union bound over
a learning-theoretic cover of m  classical learning-theory
results bound the cover size in terms of pdim m  
combined with corollary 1  we have 
theorem 4  run lwi with parameters n  p = 1/3  q =
1/2  where n ≥ n ε  δ  pdim m   
then  with proba-
bility ≥ 1 − 3δ  rev�
m spar  ≥ w s  lm spar  − ε  −
2||˜v||2
�
2n pdim m  ln 4e2 pdim m w  s 
δ
 
when w s  is sufficiently large  we can condense the
bound on partition discrepancy to contribute at most an ε loss 
corollary 2  run lwi with parameters n  p
=
1/3 
q
=
1/2 
where
n
≥
n ε  δ  pdim m   
if
w s 2
−
8n||˜v||2
2 pdim m 
ε2
ln w s  
≥
8n||˜v||2
2 pdim m 
ε2
ln
� 4e2 pdim m 
δ
�
 
rev�
m spar 
≥
w s  lm spar  − 2ε  with probability ≥ 1 − 3δ 
remark  we emphasize that small partition discrepancy  for
example  stipulating that τm is a fixed constant  should be
viewed as a uniformity condition on the set of bidders  the-
orem 3 provides just one way of understanding partition dis-
crepancy by relating it to learning-theoretic quantities 
3
population-size-independent auctions
in this section we instantiate our main guarantee for spe-
cific mechanism classes m to obtain more concrete revenue
approximations  the following is a na¨ıve lower bound on
lm spar  for auction classes that can run a second-price
auction on the grand bundle  1          m  with a reserve price 
proposition 1  let v1 ≥ · · · ≥ vn denote the valuations of
each bidder in s on the grand bundle  for any 0 < α ≤ 1
such that αn is an integer  any mechanism class m contain-
ing the second-price auction on the grand bundle with reserve
price r for every r satisfies lm spar  ≥
vαn
w  s  with proba-
bility ≥ 1 − e−αnp over the draw of spar ∼p s 
however  any bidder s value for the grand bundle can be an
arbitrarily bad approximation to w s   in the remainder of
the paper we introduce some new auction classes and prove
more fine-tuned approximations for those classes 
we now study a handful of population-size-independent
auction classes  that is  auction classes that can be parame-
terized in a way that does not depend on the number of bid-
ders  traditional variants to the vcg auction including λ-
auctions and amas specify boosts based on particular alloca-
tions and are thus not independent of the population size  and
in particular cannot be used with lwi in a natural way since
s1          sn  spar can all vary in size   in contrast to these 
our auctions specify boosts based on bundles and bundlings 
a bundling is a partition of items  1          m  into bun-
dles  we say that an allocation respects a bundling if no two
items in the same bundle are allocated to different buyers 
for an allocation β  let blg β  denote the finest bundling re-
spected by β  that is  the bundling with the fewest number of
bundles that β respects  for example  if β allocates items
1 and 3 to bidder 1  and the remaining items to bidder 2 
blg β  =   1  3    2  4          m    let φ denote the collec-
tion of all bundlings  |φ| <  0 792m/ ln m   1  m  berend
and tassa  2010   we now introduce two new auction classes
that can be viewed as population-size-independent analogues
of λ-auctions and vvcas  respectively 
the class of bundling-boosted auctions is the class auctions
parameterized by real |φ|-dimensional vectors ω ∈ r|φ| that
specify additive boosts ω φ  for each bundling φ ∈ φ  the
overall allocation α∗ used by a bundling-boosted auction ω is
chosen to maximize w α    ω blg α    and bidder i pays
maxα w−i α    ω blg α    −  w−i α∗  − ω blg α∗    
equivalently  ω is the λ-auction with λ α  = ω blg α   
the class of bundle-boosted auctions is the class of auc-
tions parameterized by real 2m-dimensional vectors ω ∈
r2m that specify additive boosts ω b  for each bundle b ⊆
 1          m   the overall allocation α∗ is chosen to maximize
w α    �
b∈blg α  ω b   and bidder i pays maxα w−i α   
�
b∈blg α  ω b   −  w−i α∗    �
b∈blg α∗  ω b    equiva-
lently  the class of bundle-boosted auctions is the subclass of
vvcas where the parameters are constant across bidders 
the class of bundling-vcg auctions  kroer and sandholm 
2015  consists of all φ-vcg auctions  where a φ-vcg auc-
tion runs vcg while treating each bundle in φ as an indivisi-
ble item  the class of bundling-vcg auctions is a subclass of
the class of bundle-boosted auctions  the φ-vcg auction can
be represented by the bundle-boosted auction with ω b  = 0
if b can be represented as a union of bundles from φ  and
ω b  = −∞ otherwise  the class of bundle-boosted auc-
tions is a subclass of the class of bundling-boosted auctions 
a bundle-boosted auction is a bundling-boosted auction with
the restriction that ω φ  = �
b∈φ ω b  
since bundling-boosted and bundle-boosted auctions are
proceedings of the thirtieth    ijcai-21 
34
 bundle-boosted
auctions
bundling-vcg
auctions
bundling-boosted
auctions
⊂
⊂
bundle-size-
boosted auctions
⊂
mixed-bundling auctions
⊂
virtual-valuation
combinatorial auctions
⊂
λ-auctions
affine-maximizer
auctions
⊂
⊂
⊂
figure 1  containment relations between auction classes  new auc-
tion classes introduced in this paper are in boldface 
subclasses of λ-auctions  they are both delineable with
h n  =  n   1 2m 1 due to balcan et al   2018   see the ap-
pendix for a derivation of lwi guarantees when only weaker
delineability parameters that depend on the number of bidders
are known   the following is a much stronger delineability
result that has no dependence on the number of bidders 
theorem 5  the class of bundling-boosted auctions is
 |φ|  |φ|2   m|φ|3 -delineable and the class of bundle-
boosted auctions is  2m  |φ|2   m|φ|3 -delineable 
proof sketch  we prove that there are at at most m|φ| bidders
whose absence affects the allocations used by any bundling-
boosted auction  this allows us to count the relevant hyper-
planes delineating r|φ| in a way that is independent of n 
sandholm and likhodedov  2005  2015   implicitly  study
properties of the class of auctions parameterized by vectors
ω ∈ rm that specify additive boosts depending on the size of
the bundle  we call this class of auctions bundle-size-boosted
auctions 
bundle-size-boosted auctions are a subclass of
bundle-boosted auctions  the equivalent bundle-boosted auc-
tion satisfies ω b  = ω |b|   for the class of bundle-size-
boosted auctions  we can prove a stronger delineability result 
theorem 6  the class of bundle-size-boosted auctions is
 m  meo √m  -delineable 
figure 1 summarizes the containment relations between the
various auction classes 
3 1
guarantees for bundling-boosted auctions
the class of bundling-boosted auctions is a rich class of auc-
tions  if the efficient allocation when bidder i is absent also
maximizes welfare when all bidders are present among all
allocations respecting the same finest bundling  there is a
bundling-boosted auction that extracts revenue equal to the
welfare of the efficient allocation  more generally 
theorem 7  given a set of s bidders  let β denote
the efficient allocation and let β−i denote the efficient
allocation when bidder i is absent 
let ∆i s 
=
maxα blg α =blg β−i  w α  − w β−i  
there
exists
a
bundling-boosted auction with revenue w s  − �
i ∆i s  
proof sketch  let φ = blg β  and let φ−i = blg β−i   the
bundling-boosted auction with ω φ  = 0  ω φ−i  = w β −
w β−i   and ω φ′  = −∞ for all other bundlings φ′ ∈ φ \
 φ  φ−1          φ−n  extracts the claimed revenue 
we give a simple example of bidder valuations that satisfy
∆i s′  = 0 for every i and every s′ ⊆ s in the appendix 
concentration inequalities enable us to provide bounds
on lm spar  for the class of bundling-boosted auctions 
we have espar optm spar  
≥
espar w spar  −
�
i ∆i spar   ≥ pw s  − �
i ∆i spar   if we run lwi
with parameters p  q  n  we have  assuming for readabil-
ity that ∆i spar  = 0 for all i  lm spar  ≥  1 − η p
with probability ≥ 1 − e−2η2p2w  s 2/||¯v||2
2  where ¯v =
 maxb⊆ 1     m  vi b  i∈s ∈ rn  by mcdiarmid s inequality 
combined with theorem 2  we get our main guarantee for
the class of bundling-boosted auctions  for readability  we
state our guarantees assuming ∆i spar  = 0 for every i 
theorem 8  let m be the class of bundling-boosted auc-
tions  let n ≥ n ε  δ  pdim m   and run lwi with pa-
rameters n  p  q  as long as w s 2 ≥ ||¯v||2
2 ln 1/δ /2η2p2 
rev�
m spar  ≥ w s   1 − η p − ε  − 2τm q  spar  with
probability ≥ 1 − 3δ conditional on ∆i spar  = 0 for all i 
removing the assumption on ∆i spar  would replace the
 1 − η p loss term with  1 − η  p − �
i ∆i spar /w s   
4
efficient learning within an instance
we now explore two mechanism classes for which lwi can
be implemented efficiently by leveraging efficient routines for
solving winner determination  a generalization of the prob-
lem of computing efficient allocations   though computing
�
m = argmaxm∈m
1
n
�n
t=1 revm st  is np-hard since it
involves solving winner determination  which is well known
to be np-hard  winner determination can be solved efficiently
in practice  sandholm et al   2005  
for the class of bundling-vcg auctions  we show that the
branch-and-bound technique of kroer and sandholm  2015 
is compatible with lwi  we did not derive a revenue-
guarantee for this class of auctions  however  for the class
of sparse bundling-boosted auctions  which are bundling-
boosted auctions with a constant number of positive boosts 
we show that a revenue guarantee similar to  but more sample
efficient than  theorem 8 holds  we then show how lwi can
be efficiently implemented for this class 
4 1
bundling-vcg auctions
kroer and sandholm  2015  give a branch-and-bound al-
gorithm to compute the revenue-maximizing bundling-vcg
auction for a given set of bidders  while our setting is dif-
ferent than theirs  their integer-program techniques can be
directly used by lwi  let f denote a function used as an
upper bound in branch-and-bound to compute the optimal
bundling 
for learning groups s1          sn and x a node
in the search tree  corresponding to a partial bundling   let
ˆf x  =
1
n
�
t f x  st   recall that f is admissible if its
value at any node is an upper bound for the maximum revenue
obtainable in the subtree rooted at that node  and f is mono-
tonic if it decreases down each path in the search tree  these
properties ensure that branch-and-bound finds the revenue-
optimal bundling 
proceedings of the thirtieth    ijcai-21 
35
 proposition 2  if f is admissible for computing the optimal
bundling  ˆf is admissible for computing the empirically opti-
mal bundling  the same holds for monotonicity 
4 2
sparse bundling-boosted auctions
let φ0 ⊂ φ with |φ0| = b  and let m0 be the number
of bundles in the finest bundling in φ0  consider the sub-
class of bundling-boosted auctions for which ω φ  > 0 only
if φ ∈ φ0  and ω φ  = 0 otherwise   which we call φ0-
bundling-boosted auctions  the same argument used to prove
theorem 5 shows that the class of φ0-bundling-boosted auc-
tions is  b  b2  m0b3 -delineable  let w φ0 s  denote the
welfare of the welfare-maximizing allocation to bidders in s 
subject to the constraint that the finest bundling respected by
the allocation is in φ0  the same arguments used to obtain
theorem 7 yield a guarantee with respect to w φ0 s  
theorem 9  let m be the class of φ0-bundling-boosted auc-
tions  let n ≥ n ε  δ  pdim m   and run lwi with param-
eters n  p  q  as long as w φ0 s 2 ≥ ||¯v||2
2 ln 1/δ /2η2p2 
rev�
m spar  ≥ w φ0 s   1 − η p − ε  − 2τm q  spar  with
probability ≥ 1 − 3δ conditional on ∆i spar  = 0 for all i 
for b a fixed constant  the number of learning groups n
required by lwi is o b ln m0b    hiding the dependence
on ε and δ   in contrast  optimizing over the entire class of
bundling-boosted auctions as in theorem 8 would require n
to be exponential  in m   for this class of auctions  we de-
scribe an algorithm that implements lwi with run-time expo-
nential in b but polynomial in all other parameters  includ-
ing the run time of the winner determination routine used   a
similar algorithm was used in balcan et al   2020   though in
a different setting than ours 
theorem 10  let b
= |φ0|  and let m0 be the num-
ber of bundles in the finest bundling in φ0 
given
learning groups s1          sn  the empirical-revenue maxi-
mizing φ0-bundling-boosted auction can be computed in
 nm0b o b    2w m0  n nm0b time  where w m0  n  is
the time required to solve winner determination for n buyers
with valuations over m0 items 
proof sketch  we first show that there is a set h of at most
nb2   nm0b2 hyperplanes partitioning rb such that em-
pirical revenue is linear in ω within each region  writing
these hyperplanes down requires at most nb   nm0b calls
to our winner determination routine  the maximum empiri-
cal revenue in each region can be found by solving a linear
program with b variables and at most |h| constraints 
4 3
structural revenue maximization
suppose the mechanism designer can only sample a limited
number n of learning groups  due to a run-time constrant 
for example   we introduced several new auction classes 
but which one should the mechanism designer use in con-
junction with lwi  structural revenue maximization  srm 
helps answer this question  srm suggests maximizing em-
pirical revenue minus a regularization term that penalizes
more complex mechanisms to ensure that the chosen auc-
tion is indeed likely to generalize well  rather than overfit-
ting to the learning groups  our generalization guarantee in
theorem 1 provides the appropriate regularizer εm n  δ  =
240
�
pdim m /n  
�
2 ln 1/δ /n  say the mechanism
designer is deciding between auctions in m1 and auctions in
m2  let �
m1  �
m2 be the empirical-revenue-maximizing auc-
tions from m1 and m2  respectively  for one run of lwi  the
mechanism designer should use mechanism �
mk  k ∈  1  2  
that maximizes 1
n
�
t rev�
mk st  − εmk n  δ  since empir-
ical revenue minus εm n  δ  is a more accurate lower bound
on expected revenue than empirical revenue alone  an srm
approach combined with lwi is incentive compatible since
the final mechanism only depends on the learning groups of
bidders  our use of srm is similar to srm across instances 
which was discussed in balcan et al   2018   srm for auc-
tion design was first proposed by balcan et al   2005   also
for learning within an instance  but for unlimited supply  
5
conclusions and future research
we developed a new framework for designing truthful  high-
revenue combinatorial auctions for limited supply  our mech-
anism learns within an instance  it generalizes and improves
over previously-studied random-sampling mechanisms 
we proved guarantees on the performance of lwi based
on a market-shrinkage term and a new complexity measure
we coined partition discrepancy  which simultaneously mea-
sured intrinsic complexity of the auction class and unifor-
mity in the set of bidders  we explored examples and proved
a general bound on partition discrepancy 
we then intro-
duced new population-size-independent auction classes  and
proved strong generalization bounds for these classes  we
showed how lwi can be implemented efficiently by lever-
aging practically-efficient routines for solving winner deter-
mination  and showed how structural revenue maximization
helps choose the right auction class to prevent overfitting 
many interesting new directions arise from this work 
first  developing a fuller picture of partition discrepancy
would be of independent interest both in mechanism design
and learning theory more broadly 
next  population-size-
independent auctions are more versatile than other auction
formats since they may be designed and specified without
knowledge of the number of bidders participating  a fur-
ther study of such auctions could yield insights into other
revenue-maximization settings  for example  when the dis-
tribution over bidders is known  when the number of bidders
is unknown  finally  lwi-like frameworks could be applica-
ble to more general mechanism design settings that involve
optimization subject to incentive-compatibility constraints 
acknowledgements
this material is based on work supported by the nsf under
grants iis-1618714  iis-1718457  iis-1901403  and ccf-
1733556  ccf-1535967  ccf-1910321  and ses-1919453 
the aro under award w911nf2010081  darpa under co-
operative agreement hr00112020003  an aws machine
learning research award  an amazon research award  a
bloomberg research grant  and a microsoft research fac-
ulty fellowship 
proceedings of the thirtieth    ijcai-21 
36
 references
 alaei et al   2009  saeed alaei  azarakhsh malekian  and
aravind srinivasan  on random sampling auctions for dig-
ital goods  in ec  2009 
 aumann  1964  robert j aumann  markets with a contin-
uum of traders  econometrica  1964 
 balcan et al   2005  maria-florina balcan  avrim blum  ja-
son d hartline  and yishay mansour  mechanism design
via machine learning  in focs  2005 
 balcan et al   2007  maria-florina balcan  nikhil devanur 
jason d hartline  and kunal talwar  random sampling
auctions for limited supply 
2007 
technical report 
carnegie mellon university 
 balcan et al   2008  maria-florina balcan  avrim blum 
and yishay mansour  item pricing for revenue maximiza-
tion  in ec  2008 
 balcan et al   2018  maria-florina balcan  tuomas sand-
holm  and ellen vitercik  a general theory of sample com-
plexity for multi-item profit maximization  in ec  2018 
 balcan et al   2020  maria-florina
balcan 
siddharth
prasad  and tuomas sandholm  efficient algorithms for
learning revenue-maximizing two-part tariffs  in ijcai 
2020 
 barman and echenique  2020  siddharth barman and fed-
erico echenique 
the edgeworth conjecture with small
coalitions and approximate equilibria in large economies 
in ec  2020 
 berend and tassa  2010  daniel berend and tamir tassa 
improved bounds on bell numbers and on moments of
sums of random variables  probability and mathematical
statistics  2010 
 chakraborty et al   2013  tanmoy
chakraborty 
zhiyi
huang  and sanjeev khanna  dynamic and nonuniform
pricing strategies for revenue maximization 
siam
journal on computing  2013 
 clarke  1971  ed h  clarke 
multipart pricing of public
goods  public choice  1971 
 conitzer and sandholm  2002  vincent conitzer and tuo-
mas sandholm  complexity of mechanism design  in uai 
2002 
 cramton et al   2006  peter cramton  yoav shoham  and
richard steinberg  combinatorial auctions  mit press 
2006 
 debreu and scarf  1963  gerard debreu and herbert scarf 
a limit theorem on the core of an economy  international
economic review  1963 
 devanur and hartline  2009  nikhil r devanur and jason d
hartline 
limited and online supply and the bayesian
foundations of prior-free mechanism design  in ec  2009 
 devanur et al   2015  nikhil r devanur  jason d hartline 
and qiqi yan  envy freedom and prior-free mechanism
design  journal of economic theory  2015 
 dudley  1987  richard m dudley 
universal donsker
classes and metric entropy 
the annals of probability 
1987 
 goldberg et al   2001  andrew v goldberg  jason d hart-
line  and andrew wright  competitive auctions and digital
goods  in soda  2001 
 groves  1973  theodore groves 
incentives in teams 
econometrica  1973 
 jehiel et al   2007  philippe jehiel  moritz meyer-ter-vehn 
and benny moldovanu  mixed bundling auctions  journal
of economic theory  2007 
 kroer and sandholm  2015  christian kroer and tuomas
sandholm  computational bundling for auctions  in aa-
mas  2015 
 likhodedov and sandholm  2004  anton likhodedov and
tuomas sandholm  methods for boosting revenue in com-
binatorial auctions  in aaai  2004 
 likhodedov and sandholm  2005  anton likhodedov and
tuomas sandholm  approximating revenue-maximizing
combinatorial auctions  in aaai  2005 
 mohri and medina  2014  mehryar
mohri
and
andres
mu˜noz medina  learning theory and algorithms for rev-
enue optimization in second price auctions with reserve 
in icml  2014 
 morgenstern and roughgarden  2015  jamie
h
morgen-
stern and tim roughgarden 
on the pseudo-dimension
of nearly optimal auctions  in nips  2015 
 roberts  1979  kevin roberts  the characterization of im-
plementable social choice rules  in j-j laffont  editor  ag-
gregation and revelation of preferences  1979 
 sandholm and likhodedov  2015  tuomas sandholm and
anton likhodedov 
automated design of revenue-
maximizing combinatorial auctions  operations research 
2015 
 sandholm et al   2005  tuomas sandholm  subhash suri 
andrew gilpin  and david levine  cabob  a fast op-
timal algorithm for winner determination in combinatorial
auctions  management science  2005 
 sandholm  2003  tuomas sandholm 
automated mecha-
nism design  a new application area for search algorithms 
in cp  2003 
 tang and sandholm  2012  pingzhong tang and tuomas
sandholm  mixed-bundling auctions with reserve prices 
in aamas  2012 
 vickrey  1961  william vickrey  counterspeculation  auc-
tions  and competitive sealed tenders  journal of finance 
1961 
proceedings of the thirtieth    ijcai-21 
37
 "
None,2021,https-www-ijcai-org-proceedings-2021-0006-pdf,Combining Fairness and Optimality when Selecting and Allocating Projects,"Khaled Belahcène, Vincent Mousseau, Anaëlle Wilczynski",None,https://www.ijcai.org/proceedings/2021/0006.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0006-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0006-pdf.pdf,"combining fairness and optimality when selecting and allocating projects
khaled belahc ene1   vincent mousseau2 and ana¨elle wilczynski2
1universit e de technologie de compi egne  cnrs  heudiasyc
2mics  centralesup elec  universit e paris-saclay
khaled belahcene@hds utc fr   vincent mousseau  anaelle wilczynski @centralesupelec fr
abstract
we consider the problem of the conjoint selec-
tion and allocation of projects to a population of
agents  e g  students are assigned papers and shall
present them to their peers  the selection can be
constrained either by quotas over subcategories of
projects  or by the preferences of the agents them-
selves  we explore fairness and optimality issues
and refine the analysis of the rank-maximality and
popularity optimality concepts  we show that they
are compatible with reasonable fairness require-
ments related to rank-based envy-freeness and can
be adapted to select globally good projects accord-
ing to the preferences of the agents 
1
introduction
when allocating indivisible resources to a group of agents 
optimality and fairness are key considerations in order to sat-
isfy the agents with their assigned resources  bouveret et al  
2016   however  when not all resources are to be assigned 
the choice of the assigned resources may be particularly im-
portant  many real-world situations can illustrate this issue 
a first context concerns a university course where students
must be assigned to projects they have to work on  and present
to their peers at the end of the course  usually  an allocation
that takes into account the preferences of the students is desir-
able in order to motivate them to work  an optimal allocation
of projects to the students should maximize the global satis-
faction of the students  this allocation must also be fair oth-
erwise students could complain about the assignment  how-
ever  the choice of selected projects can also be fundamental
for pedagogical reasons  not all students should present simi-
lar projects since it is expected that even attendants will learn
from the presentations  therefore  some diversity constraints
according to the topics of the projects must be considered 
another example concerns the organization of a confer-
ence with invited speakers 
suppose each of the speak-
ers must be assigned a one hour time slot from monday to
wednesday  9 00-19 00   in such a context  speakers can ex-
press preferences over time slots  e g  preferably in the morn-
ing or early in the conference   the decisions to make involve
selecting time slots for presentations  and the allocation of a
time slot for each speaker  solving such selection/allocation
should account for the preferences of speakers both for the
conference timetable  and for the time of their presentation 
the two preceding examples involve agents and many re-
sources  more than the number of agents   referred to as
projects  to be assigned to agents by a central authority  the
assignment must be optimal and fair for the agents  and at the
same time the set of assigned projects should be selected re-
garding balance constraints with respect to groups of projects
 topics  days  or preferences of the agents  hence it can be
seen as a combination of multiwinner voting  elkind et al  
2017  faliszewski et al   2017   we want a good selection of
projects  and resource allocation problems  we want a fair
and optimal assignment of projects to agents  
in this paper  we focus on house allocation problems  hyl-
land and zeckhauser  1979  abdulkadiroˇglu and s¨onmez 
1998   where each agent must be assigned exactly one
project  optimality questions have been widely investigated 
especially with respect to pareto-optimality  abraham et al  
2004  and its refinements  such as rank-maximality  irving 
2003  irving et al   2006  and popularity  abraham et al  
2007  cseh  2017   concerning fairness  the most classical
criterion  envy-freeness  foley  1967  varian  1974   requires
that no agent prefers the project assigned to another agent
to her own assigned project  this criterion is too demand-
ing if the number of projects equals the number of agents 
hence  some relaxations of envy-freeness have been pro-
posed  beynier et al   2019   however  envy-freeness is more
interesting when there are more projects than agents  gan et
al   2019  
we focus in this article on a relaxation of envy-freeness 
called rank-envy-freeness  which requires that no agent
prefers the project assigned to another agent whereas she
ranked this project in a better position in her preference rank-
ing  this notion is present in the favoring higher ranks con-
cept introduced by ramezanian and feizi  2020   was im-
plicitly used by kojima and ¨unver  2014   and is equivalent
to no envy by rank in random assignment  harless  2018   we
propose a generalization of rank-envy-freeness and introduce
another concept  frustration-freeness  which relates both allo-
cation and selection issues  frustration-freeness imposes that
no agent prefers an unassigned project to her assigned project 
focusing on the personal satisfaction of an agent  it can be
viewed as a fairness concept  but also as an optimality concept
because it asks for no project waste  whereas optimality and
proceedings of the thirtieth    ijcai-21 
38
 fairness are often incompatible  bouveret and lang  2008  
we show that rank-envy-freeness and frustration-freeness are
necessary to characterize rank-maximality and popularity 
for choosing an adequate set of selected projects at the
same time as a good allocation of projects to agents  we inves-
tigate two ways  considering hard diversity constraints repre-
sented by lower and upper quotas over categories  or consid-
ering the preferences of the agents over the selected projects 
diversity constraints are relevant in multiwinner voting
when a committee with particular attributes is sought  brams 
1990  bredereck et al   2018   in resource allocation  it has
been investigated  e g   in public housing allocation  benab-
bou et al   2018   and in course allocation  cechl arov a and
fleiner  2017  where courses have capacities and open only if
a lower quota of participants is reached 
when preferences of the agents are taken into account for
selecting the projects to assign  a naive strategy is to first se-
lect the projects via a multiwinner voting rule and then al-
locate the projects  nevertheless  this approach may lead to
select projects that do not fit any agent personally  like in the
conference example  conversely  by only considering alloca-
tion purposes  one could impose conference days where only
a few attendants can be present  our model can be seen as a
particular case of house allocation with externalities where
agents care about their assignment and the set of selected
projects  but not about the identity of the owners   in the no-
tion of envy-freeness conditioned to the approval of the ma-
jority of agents  shams et al   2020   agents can also give their
opinion about the assignment of other agents  but there is no
concern of the set of selected projects  the goal of our arti-
cle is to find a reasonable way to combine both allocation and
selection goals  by focusing on fairness and optimality issues 
2
allocation of projects
we consider a set of agents n =  n   =  1          n  and a
set of projects p =  p1          pm  with m ≥ n  each agent
i has ordinal preferences over projects  represented by a lin-
ear order ≻i over p  a feasible allocation σ   n → p is
a matching  perfect w r t  the agents  where every agent is
assigned to exactly one project and no two agents share the
same project  i e   σ i  ̸= σ j  for every agents i ̸= j and
σ i  ∈ p denotes the project assigned to agent i in allocation
σ  typically  some projects may not be assigned  let pσ de-
note the set of assigned projects in allocation σ  i e   pσ  =
 p ∈ p   ∃i ∈ n such that σ i  = p   an instance of the
selection-allocation  sa  problem is i =  n  p   ≻i i∈n  1
2 1
finding an optimal and fair allocation
an allocation σ is pareto-optimal  po  if there is no feasible
allocation σ′ such that σ′ i  ⪰i σ i  for every agent i and
there exists an agent j such that σ′ j  ≻j σ j   in an or-
dinal setting  po can be refined with rank-maximality  rm  
the signature ρσ of allocation σ is the m-vector giving the
number of agents ρσ k  assigned to their kth most preferred
project in σ  for all k ∈  m   signature ρσ is lexicographically
strictly greater than signature ρσ′  denoted by ρσ >lex ρσ′  if
1the problem is similar to house allocation but we use a different
name to emphasize the combined goal of selection and allocation 
there exists an index i ∈  m  such that ρσ i′  = ρσ′ i′  for
all i′ < i and ρσ i  > ρσ′ i   an rm allocation can be
computed in polynomial time  irving et al   2006  
definition 1  rank-maximality  rm    an allocation σ is
rm if there is no feasible allocation σ′ such that ρσ′ >lex ρσ 
popularity is another optimality measure that refines po 
agent i prefers allocation σ to allocation σ′ if σ i  ≻i σ′ i  
an allocation σ is then more popular than another allocation
σ′ if the number of agents who prefer σ to σ′ is strictly greater
than the number of agents who prefer σ′ to σ 
definition 2  popularity  pop    an allocation σ is popular
if there is no feasible allocation σ′ more popular than σ 
a pop allocation may not exist but existence can be ef-
ficiently checked and  in the positive case  a pop allocation
can be computed in polynomial time  thanks to the following
characterization due to abraham et al   2007   an allocation
σ is pop iff  1  every first-ranked project is assigned in σ  and
 2  σ assigns to every agent either her first-ranked project or
the most preferred project that is not ranked first by an agent 
fairness issues can also be considered  we relax envy-
freeness with rank-envy-freeness  where an agent i is envious
towards an agent j only if agent i ranks the envied project in
a better position in her preference ranking than agent j  let
ri   p →  m  be the function giving the rank of a project in
≻i  i e   ri x  = | y ∈ p   y ⪰i x |  for project x ∈ p 
definition 3  rank-envy-freeness  r-ef    allocation σ is r-
ef if σ i  ≻i σ j  or rj σ j   ≤ ri σ j   for every i  j ∈ n 
a rank-maximal or popular allocation is also r-ef 
proposition 1  rm ⇒ r-ef and pop ⇒ r-ef 
proof  suppose that an rm allocation σ is not r-ef  there
exist agents i and j such that σ j  ≻i σ i  and ri σ j   <
rj σ j    hence  both ri σ j   < rj σ j   and ri σ j   <
ri σ i   hold  thus  by swapping the projects of i and j  we
get an allocation σ′ such that ρσ′ >lex ρσ  a contradiction 
suppose that a pop allocation σ is not r-ef  there ex-
ist agents i and j such that σ j  ≻i σ i  and ri σ j   <
rj σ j   
by rank-envy  neither agent i nor agent j is
assigned her first-ranked project in σ so  by abraham et
al   2007  s characterization  they are both assigned her most
preferred project that is not ranked first by an agent  since i
prefers σ j  to σ i   project σ j  must be ranked first by some
agent  contradicting the fact that agent j is assigned her most
preferred project that is not ranked first by any agent 
the reverse of both implications is not true  since r-ef does
not even imply po  moreover  although both rm and pop
imply r-ef  it is not true for their weaker requirement po 
example 1  for r-ef ̸⇒ po  simply consider an instance
with two agents and three projects with the following prefer-
ences  p1 ≻1 p2 ≻1 p3 and p1 ≻2 p3 ≻2 p2  allocation
assigning p2 to agent 1 and p3 to agent 2 is r-ef but not po 
for po ̸⇒ r-ef  consider an instance with three agents and
three projects  the preferences are given below 
1  
p1
≻
p3
≻
p2
2  
p2
≻
p1
≻
p3
3  
p2
≻
p1
≻
p3
proceedings of the thirtieth    ijcai-21 
39
 the encircled allocation is po but not r-ef  agent 1 is
envious towards agent 2 who owns her second ranked project
p1 which is the first-ranked project of agent 1 
for rank 0 ≤ k < m  we define a generalization of r-ef 
definition 4  rankk-envy-freeness  rk-ef    an allocation σ
is rankk-envy-free if for every agents i and j  σ i  ≻i σ j  or
rj σ j   ≤ min ri σ j    k  holds 
note that rk-ef ⇒ rk′-ef for every k′ > k  moreover 
rm−1-ef ⇔ r-ef and r0-ef ⇔ envy-freeness  ef   by the
fact that rm ⇒ r-ef  an rm−1-ef allocation always exists 
however  starting from k = m − 2  an rk-ef allocation may
not exist  as shown in the basic example with three agents and
three projects where every agent has the same preferences 
2 2
towards a good selection
we introduce a simple requirement imposing that no agent
prefers a project that has not even been assigned 
definition 5  frustration-freeness  ff    an allocation σ is
ff if σ i  ≻i p for every agent i and every project p ∈ p \pσ 
when m = n  all projects are selected so every allocation
is ff  frustration is defined according to selected projects  so
it does not say anything about global optimality  in particu-
lar  it is clear that an ff allocation may not be po  however 
conversely  in every sa instance  a po allocation  and thus
an rm or a pop allocation  is ff  otherwise by assigning the
preferred unassigned project to the agent who prefers it over
her current assigned project  we get an allocation that pareto-
dominates it  therefore  an ff allocation always exists 
the issues forbidding r-ef or ff to imply pareto-
optimality can be fixed by combining the two properties 
proposition 2  r-ef   ff ⇒ po 
proof  consider an allocation σ that is r-ef and ff  take an
allocation σ′ that pareto-dominates σ  for every agent i  ei-
ther σ′ i  = σ i   or σ′ i  ≻i σ i   so  by ff  we have pσ =
pσ′  consider an ameliorating cycle  i0  i1          ic−1  ⊆ n
from σ to σ′  i e   σ′ ij−1  = σ ij
mod c  for every j ∈  c  
since σ′ ij−1  = σ ij
mod c  ≻ij−1 σ ij−1   by r-ef we
must have rij
mod c σ ij
mod c   ≤ rij−1 σ ij
mod c   <
rij−1 σ ij−1    for every j ∈  c   a contradiction 
combining ff with r1-ef provides an alternative charac-
terization of pop  an agent i is r1-envious towards an agent j
only if the envied project is not ranked first by agent j 
theorem 1  for every sa instance  pop ⇔ r1-ef   ff 
3
hard constraints over the selected projects
in this section  we assume that the set of projects is parti-
tioned into q groups  i e   p = p1∪· · ·∪pq  and that a feasible
allocation must satisfy some quotas on the selected projects
within groups  let ℓj and uj denote the respective lower and
upper quotas for group pj for j ∈  q   trivially we assume that
ℓj ≤ uj ≤ |pj| for every j ∈  q   an allocation σ is feasible
if ℓj ≤ |pσ ∩ pj| ≤ uj for every j ∈  q   we suppose that
�
j∈ q  ℓj ≤ n ≤ �
j∈ q  uj  otherwise there is no feasible al-
location  an instance of this constrained selection-allocation
 csa  problem is  n  p   ≻i i∈n   pj j∈ q    ℓj  uj j∈ q   
an sa instance is a csa instance where ℓj = 0 and
uj = |pj| for every j ∈  q   an instance is said with no trivial
group upper quota if uj < |pj| for every j ∈  q   let ≻pj
i
be the preference ranking of agent i within group pj  prefer-
ences are group-oriented if every agent i s preferences can be
decomposed w r t  project groups  i e   there is a permutation
τi    q  →  q  such that for every projects p ∈ pj and p′ ∈ pj′ 
p ≻i p′ iff p ≻pj
i
p′ if j = j′ or τi j  < τi j′  otherwise 
contrary to the sa setting  even an rm and pop allocation
may not be ff in a csa instance  because of the constraints
on project groups  even if an ff allocation exists 
example 2  let us consider a csa instance with four agents
and five projects where p1 =  p1  p3  p4   p2 =  p2  p5  
and u1 = 2  the preferences are given below 
1  
p3
≻
p1
≻
p4
≻
p2
≻
p5
2  
p3
≻
p1
≻
p4
≻
p2
≻
p5
3  
p1
≻
p3
≻
p2
≻
p4
≻
p5
4  
p2
≻
p5
≻
p1
≻
p3
≻
p4
the framed allocation is rm with signature  3  0  0  0  1 
and pop  however  it is not ff since agent 1 is frustrated  she
prefers the unassigned project p4  nevertheless  the encircled
allocation  with signature  1  2  1  0  0   is both po and ff 
it follows that the characterization obtained in theorem 1
does not hold in a csa instance  by replacing ff by po  we
can nevertheless keep the validity of necessary conditions 
proposition 3  in every csa instance  pop ⇒ r1-ef   po 
proof  a pop allocation σ is trivially po  suppose that σ is
not r1-ef  there exist agents i and j such that σ j  ≻i σ i 
and rj σ j   > 1  thus  j does not rank σ j  first  if there
exists a project p ∈ pσ assigned to an agent k such that
p ≻j σ j  then  by assigning project σ j  to i  project p to
j and project σ i  to k  we reach an allocation more popular
than σ  i and j are better off and k may be worse off   a con-
tradiction  otherwise  there exists a project p ∈ p \ pσ such
that p ≻j σ j   if p cannot be assigned  it means that it be-
longs to a group pℓ whose upper quota uℓ is reached  by re-
moving from pσ an arbitrary project belonging to pℓ\ σ j  
that was assigned to an agent k  we can assign p to j  σ j 
to i and an arbitrary project respecting the constraints to k 
this new allocation is more popular than σ  i and j are bet-
ter off and k may be worse off   a contradiction  if there is
no assigned project belonging to pℓ different from σ j   then
uℓ = 1 and pσ ∩ pℓ =  σ j    hence  σ i  /∈ pℓ and reas-
signing project p to j instead of σ j  is feasible and construct
an allocation more popular than σ  a contradiction 
however  r1-ef   po ̸⇒ pop  as illustrated below 
example 3  let us consider a csa instance with three agents
and four projects where p1 =  p1  p4   p2 =  p2  p3  and
u1 = 1  the preferences are given below 
1  
p1
≻
p3
≻
p2
≻
p4
2  
p2
≻
p3
≻
p1
≻
p4
3  
p2
≻
p4
≻
p1
≻
p3
the encircled allocation is po and r1-ef but not popular 
the framed allocation is both rank-maximal and popular 
proceedings of the thirtieth    ijcai-21 
40
 in example 2  the intersection between the set of rm or
pop allocations and the set of ff allocations is empty  how-
ever  this does not hold for the weaker requirement po  if an
ff allocation exists  then an allocation that is both po and ff
exists  it suffices to start a top-trading cycle algorithm  shap-
ley and scarf  1974  from an ff allocation  in general  an
ff allocation may not exist  consider an instance with two
agents where their first-ranked projects are p1 and p2  respec-
tively  which belong to the same group with upper quota one 
moreover  deciding the existence of ff allocations is hard 
theorem 2  it is np-complete to decide whether there exists
an ff allocation in a csa instance  even either under group-
oriented preferences or with no trivial group upper quota 
in theorem 2 s reduction  preferences are group-oriented
or there is no trivial group upper quota  but not both simul-
taneously  indeed  under both restrictions  one can decide in
polynomial time about the existence of an ff allocation 
proposition 4  the existence of an ff allocation can be de-
cided in polynomial time in every csa instance with no trivial
group upper quota under group-oriented preferences  if ex-
istence is guaranteed  one can then construct an ff and rm
 or pop if exists  allocation in polynomial time 
sketch of proof 
let nj denote the set of agents who
prefer the most the projects in pj  one can show that  under
group-oriented preferences when uj < |pj| for every j ∈  q  
there exists an ff allocation iff ℓj ≤ |nj| ≤ uj for every
j ∈  q   under such conditions  each ff allocation or each
po allocation assigns to each agent in nj a project in pj 
thus  each po allocation is ff and is the concatenation of po
allocations in all sa sub-instances  nj  pj   ≻i i∈nj j∈ q  
recall that in each sa sub-instance  an rm allocation or pop
allocation  if exists  can be found in polynomial time 
4
selecting socially good projects
in this section  we aim to assign projects to the agents such
that the whole set of selected projects is  good  according
to the preferences of the agents  we evaluate the quality of
projects w r t  pairwise comparisons  let n p  p′  denote the
set of agents preferring project p to project p′  a project p is
said to dominate another project p′ if |n p  p′ | > n/2  the
set of projects that dominate project p is denoted by d p  
in a voting setting  when focusing on pairwise comparisons 
it is highly desirable to select a condorcet winner alternative
which dominates all the others  and to not select a condorcet
loser alternative which is dominated by all the others  we
adapt these requirements to the context of allocation 
definition 6  condorcet  winner / loser  criterion   cwc /
clc     allocation σ satisfies cwc if  when there exists a
condorcet winner project p then project p is assigned in σ 
allocation σ satisfies clc if  when m > n and there exists a
condorcet loser project p then project p is not assigned in σ 
there is already a conflict between selection and allocation
desiderata since the two condorcet axioms for selection can
be incompatible with ff  and thus po  rm and pop  
proposition 5  cwc or clc is incompatible with ff 
proof  let us consider an instance with n > 2 agents where
the preferences are given below 
1  
pcl
≻
pcw
≻
    
2  
p2
≻
pcw
≻
    
≻
pcl
     
n  
pn
≻
pcw
≻
    
≻
pcl
ff imposes to select all n first-ranked projects  and thus
condorcet loser pcl but not condorcet winner pcw  
preferences ≻ over single projects can be extended to sets
of projects by using a preference extension ≻ext  a pref-
erence extension ≻ext satisfies responsiveness  roth  1985 
barber a et al   2004  if ∀x ∈ x ⊂ p and ∀y ∈ p \ x 
 x\ x  ∪ y  ≻ext x holds iff y ≻ x holds  the responsive
set extension ≻rs is the minimal partial order that satisfies
responsiveness  we also consider extension ≻rs−  a weaker
version of ≻rs where transitivity is dropped  although the
latter notion may appear unnatural for modelling preferences 
in the context of an sa instance  it means that if two sets of
selected projects are too different then only the quality of the
allocation matters  when referring to a given preference ex-
tension ≻ext  we assume that each agent i uses ≻ext
i
 
we derive a variant of popularity for taking into account the
preferences of the agents over selected projects  let n1 σ′  σ 
denote the number of agents who get a better assignment in
σ′ than in σ  and n≻ext
2
 σ′  σ  the number of agents who get
the same assignment but prefer set pσ′ to pσ w r t  ≻ext 
let np op
≻ext σ′  σ  denote the number of agents who prefer al-
location σ′ to σ in the sense that they prefer to get a better
assigned project and if they keep the same project  they con-
sider the selected projects  i e   np op
≻ext σ′  σ  = n1 σ′  σ   
n≻ext
2
 σ′  σ   allocation σ is more popular w r t  ≻ext than
allocation σ′ if np op
≻ext σ′  σ  > np op
≻ext σ  σ′   this notion
generalizes standard popularity to an sa instance with exter-
nalities where agents care about the other assigned projects 
definition 7  popularity w r t  ≻ext  pop≻ext    an allocation
σ is pop≻ext if there is no other feasible allocation σ′ that is
more popular w r t  preference extension ≻ext 
a pop≻ext allocation may not be pop and vice versa  as
shown in example 4  however  when n = m the two notions
coincide  showing that a pop≻ext allocation may not exist 
an allocation σ satisfies dominion selection  ds  if
�
p∈pσ d p  ⊆ pσ  we show that  for any responsive ≻ext 
pop≻ext satisfies both dominion selection and r1-ef restricted
to the set of selected projects  called rpσ
1 -ef  where there is no
pair of agents i and j such that i prefers the project allocated
to j but this project is not ranked first by j within pσ 
proposition 6  if ≻ext is responsive  pop≻ext ⇒ ds rpσ
1 -ef 
proof  consider a pop≻ext allocation σ  suppose that σ does
not satisfy ds  then  there exists a project p ∈ pσ dominated
by p′ ∈ p \ pσ  consider the allocation σ′ constructed from
σ where agent i who was assigned p in σ is assigned p′  by
definition of dominance  at least ⌈ n 1
2 ⌉ agents prefer σ′ to
σ  a contradiction  suppose now that σ is not rpσ
1 -ef  there
exist agents i and j and project p ∈ pσ such that σ j  ≻i σ i 
proceedings of the thirtieth    ijcai-21 
41
 and p ≻j σ j   consider the allocation σ′ constructed from σ
where agent i is assigned σ j   agent j is assigned p and agent
k who was possessing p is assigned σ i   since pσ = pσ′  we
only need to consider the satisfaction of agents i  j and k  and
two of them  i and j  are better off in σ′  a contradiction 
from the satisfaction of ds  when m > n  a pop≻ext al-
location cannot select a condorcet loser p  for a responsive
≻ext  since p is dominated by at least n other projects  more-
over  a project that dominates at least m − n other projects
must be selected since at least one of its dominated projects
is selected  hence  the condorcet winner is selected 
corollary 1  if ≻ext is responsive  pop≻ext ⇒ cwc   clc 
contrary to standard popularity  as expected from proposi-
tion 5  if ≻ext is responsive  then pop≻ext fails ff  however 
from proposition 6  it satisfies a mild relaxation of ff  impos-
ing to an allocation σ that if there exists a project p ∈ p \ pσ
and an agent i such that p ≻i σ i   then p cannot dominate
any project in pσ  nevertheless  even pop≻rs may fail r-ef 
example 4  let us consider an sa instance with five agents
and six projects where the preferences are given below 
1  
p1
≻
p5
≻
p3
≻
p4
≻
p2
≻
p6
2  
p5
≻
p1
≻
p3
≻
p4
≻
p2
≻
p6
3  
p2
≻
p3
≻
p4
≻
p5
≻
p6
≻
p1
4  
p3
≻
p2
≻
p4
≻
p5
≻
p6
≻
p1
5  
p4
≻
p2
≻
p3
≻
p5
≻
p6
≻
p1
the underlined and encircled allocations are pop≻rs but
the latter is not r-ef  the only pop allocation is framed 
in case of r-ef failure  r-ef swaps can be performed 
agents i and j can swap their projects if i is rank-envious
towards j  we show that r-ef swaps preserve pop≻ext 
proposition 7  for every ≻ext  if a pop≻ext allocation σ ex-
ists  then an allocation that is both pop≻ext and r-ef can be
reached in polynomial time via r-ef swaps starting from σ 
proof  consider a pop≻ext allocation σ that is not r-ef  there
exist two agents i and j such that i is rank-envious towards
j  let σ′ denote the allocation resulting from an r-ef swap
between i and j in σ  we have pσ = pσ′  so n≻ext
2
 σ′  σ  =
n≻ext
2
 σ  σ′  = 0 
by rank-envy  σ′ i  ≻i σ i  
thus 
σ j  ≻j σ i   otherwise i and j would be rpσ
1 -envious in
σ  hence  σ′ is as popular w r t  ≻ext as σ  by rpσ
1 -ef and
ds  if an allocation is more popular w r t  ≻ext than σ′  then
it is also true for σ  a contradiction  hence  σ′ is also pop≻ext 
a pop≻ext allocation σ is pop when p = pσ and the num-
ber of pop allocations is polynomial  mcdermid and irving 
2011   since r-ef swaps transform a pop≻ext allocation σ
to another pop≻ext allocation σ′ where pσ′ = pσ but with
a strictly greater signature w r t  >lex  the dynamics of r-ef
swaps starting from σ converges in polynomial time 
however  although pop≻rs is attractive and despite the fact
that a popular allocation can be computed in polynomial time 
even the verification of a pop≻rs allocation is hard 
theorem 3  checking popularity w r t  ≻rs is co-np-hard 
the complexity proof mostly relies on set comparisons in-
duced by ≻rs  however  an allocation is not pop≻rs if there
exists an unselected project p that is preferred to a selected
project p′ by a  blocking  subset of agents and the remaining
subset of agents can be reassigned such that there are more 
or as many  better off agents than worse off agents  hence 
we conjecture that checking pop≻rs− is also hard 
to circumvent the problem of a blocking subset of agents 
we derive another variant of popularity that takes into account
the preferences of all agents over selected projects  for pref-
erence extension ≻ext  we denote by n≻ext
3
 σ′  σ  the number
of agents who prefer pσ′ to pσ  and define n2p op
≻ext  σ′  σ   =
n1 σ′  σ    n≻ext
3
 σ′  σ  
allocation σ′ is more 2popular
w r t  ≻ext than allocation σ if n2p op
≻ext  σ′  σ  > n2p op
≻ext  σ  σ′  
definition 8  2pop≻ext   allocation σ is  strictly  2popular
w r t  ≻ext if there is no other allocation that is more 2popular
 at least as 2popular  w r t  ≻ext 
2pop≻ext allocations always select a condorcet winner and
strictly 2pop≻ext allocations never select a condorcet loser 
proposition 8  if ≻ext is responsive  2pop≻ext ⇒ cwc and
strict 2pop≻ext ⇒ clc 
moreover  by the same proof idea as proposition 7  for ev-
ery ≻ext  if a 2pop≻ext exists then r-ef swaps can reach in
polynomial time an allocation that is both 2pop≻ext and r-ef 
by slightly adapting the proof of theorem 3  even the ver-
ification of 2pop≻rs is co-np-hard  we consequently focus
on the weaker version of ≻rs where transitivity is dropped 
note that 2pop≻rs− can be characterized based on rpσ
1 -ef  a
refinement of ff and dominance conditions w r t  unassigned
projects  these conditions can be verified in polynomial time 
theorem 4  2pop≻rs− can be verified in polynomial time 
the question of computation for 2pop≻rs− remains open 
5
empirical evaluation of allocations
in this section  we empirically evaluate the quality of different
procedures for assigning projects to agents  both according to
selection and allocation considerations  we generate 100 sa
instances with n = 5 agents and m = 15 projects  correlated
preferences are studied via the single-peaked preference do-
main  a preference ranking ≻i is single-peaked if there exists
a linear order > over p such that for all projects x  y  z with
x > y > z or z > y > x  x ≻i y implies y ≻i z  we
consider three types of preference generation  impartial cul-
ture  ic  where each preference ranking is uniformly drawn
from the set of all possible preference rankings  single-peaked
uniform peak  sp-up  where each single-peaked preference
ranking is generated by first uniformly selecting the peak
project then uniformly choosing the next ranked project ei-
ther on the left of the peak in axis > or on the right and so
on  conitzer  2009   and single-peaked uniform  sp-u  where
each preference ranking is uniformly drawn from the set of all
possible single-peaked rankings  walsh  2015   under sp-u
and sp-up  preferences are correlated w r t  a common axis >
along projects  under sp-up  a preference ranking with  as a
first-ranked project  an extreme point of the axis has the same
proceedings of the thirtieth    ijcai-21 
42
 ic
sp-up
sp-u
3
4
5
6
preferences
average of rank satisfaction
selection
pop
2poprs
2poprs r-ef
rm
bloc
k-borda
k-maximin
k-copeland
mwr pop
mwr rm
r-ef ff dyn 
ic
sp-up
sp-u
1
2
3
4
preferences
allocation
figure 1  average over 100 runs of the rank satisfaction for differ-
ent types of allocations when evaluating the selection  left  or the
allocation  right  for n = 5 and m = 15
probability to occur as one with a middle point of the axis 
hence  the generated preferences are more diverse under sp-
up than under sp-u  where the occurrence of a project at a
certain preference rank depends on a binomial coefficient 
for evaluating the quality of the set of selected projects
 selection goal   we compute the satisfaction of an agent by
considering the average rank in her preference ranking over
all selected projects  the global rank satisfaction is then com-
puted by averaging all individual average rank satisfactions 
for evaluating the quality of the allocation  allocation goal  
we consider the average over all agents of the rank given to
their allocated project  our results are given in figure 1 
all possible allocations are generated and the measures are
given in average for different types of allocations 
• optimal allocations  pop allocations or rm allocations 
• selection-based optimal  sel-opt  allocations  a multiwin-
ner voting rule  mwr  is used for selecting n projects  and
then a pop or an rm allocation is computed on an sa instance
where projects are restricted to this set  we use the following
excellence-based mwrs  bloc  k-borda  k-maximin  and k-
copeland  see faliszewski et al   2017  for definitions  
• selection   allocation  sa -based allocations  2pop≻rs−
allocations  2poprs   2pop≻rs− allocations that are r-ef 
and allocations  r-ef ff dyn   which are the result of the
dynamics of r-ef swaps and ff-agreement moves  an agent i
can get a more preferred unassigned project p if the majority
of agents prefers p to i s project  from a random allocation 
as expected  optimal allocations behave significantly bet-
ter under an allocation goal than sel-opt allocations and
reversely under a selection goal 
our variant of pop 
2pop≻rs−   is not satisfactory under ic where the average
rank satisfactions are always superior than those of pop or
rm  however  it performs a bit better with a selection goal
when preferences are correlated  indeed  under single-peaked
distributions  the satisfaction of condorcet criteria should
help to choose a better set of selected projects  surprisingly 
the stable allocation arising from the dynamics associated
with r-ef swaps and ff-agreement moves appears to be very
good for combining both goals of selection and allocation  it
has an intermediate behavior with an average rank satisfac-
tion closer to those of sel-opt allocations than optimal alloca-
tions with a selection goal  and closer to optimal allocations
than sel-opt allocations with an allocation goal  in average 
ten steps are sufficient to reach a stable allocation so we are
far from the exponential theoretical bound for r-ef swaps 
so far  we have evaluated the quality of an allocation  al-
location goal  via the optimality measure of average rank sat-
isfaction  for fairness  we compute the average minimum
k such that an allocation is rk-ef  our experiments show
that optimal allocations and sa-based allocations are very
fair  however  sel-opt allocations are very unfair in compari-
son  showing the need of combining allocation and selection
goals  in general  a slight tendency confirms the intuition un-
der which correlated preferences favor consensus in selection
whereas diverse preferences favor consensus in allocation 
6
conclusion
we investigated a variant of resource allocation where both
selection and allocation are important  we focused on pop-
ularity  pop  and rank-maximality  rm  optimality concepts
and showed that they are compatible with two notions of fair-
ness that we have introduced or refined  namely frustration-
freeness  ff  and rank-envy-freeness  r-ef   in an ordinal
context  r-ef appears as a very natural and flexible fairness
requirement that could easily be used as an argument for ex-
plaining a decision  the selection goal has been combined
with the allocation goal in two ways  via hard constraints rep-
resented by quotas on project groups or via the preferences of
the agents themselves  under hard constraints  rm and pop
lose their link with ff and this latter basic requirement even
becomes difficult to satisfy  however  we identified natural
restrictions under which the compatibility remains  when the
selection goal is conditioned by the preferences of the agents 
we derive variants of pop that can be connected with r-ef and
that are condorcet-consistent  however the most natural ex-
tension of pop in such a context suffers from a computational
burden  in practice  variants of pop slightly improve pop to-
wards the selection goal  nevertheless  the most interesting
notion empirically is the outcome of the dynamics associated
with r-ef swaps and ff-agreement moves which turns out to
satisfy the goal of combining both selection and allocation 
many interesting directions can be explored  technically 
some algorithmic questions remain open for our variants of
pop  moreover  we have focused on pairwise comparisons-
based refinements of pop but one could think about other
types of refinements  to further understand how selection and
allocation can be combined  an extensive study deserves to be
initiated on the dynamics associated with r-ef swaps and ff
moves  concerning optimality  one could also consider mini-
mizing the rank of the least happy agent and examine it under
the lens of r-ef  intuitively  r-ef seems to be very sensitive
to strategic manipulation  this point deserves to be formally
investigated  finally  the extension to more than one project
per agent or more than one agent per project is natural 
acknowledgements
this work has been partially supported by the cnrs  via the
project ins2i - 2021 - desire 
proceedings of the thirtieth    ijcai-21 
43
 references
 abdulkadiroˇglu and s¨onmez  1998  atila
abdulkadiroˇglu
and tayfun s¨onmez  random serial dictatorship and the
core from random endowments in house allocation prob-
lems  econometrica  66 3  689–701  1998 
 abraham et al   2004  david
j 
abraham 
katar ına
cechl arov a  david f  manlove  and kurt mehlhorn 
pareto optimality in house allocation problems 
in
proceedings of the 15th international symposium on
algorithms and computation  isaac-04   pages 3–15 
2004 
 abraham et al   2007  david j  abraham  robert w  irving 
telikepalli kavitha  and kurt mehlhorn  popular match-
ings 
siam journal on computing  37 4  1030–1045 
2007 
 barber a et al   2004  salvador barber a  walter bossert  and
prasanta k  pattanaik  ranking sets of objects  in hand-
book of utility theory  pages 893–977  springer  2004 
 benabbou et al   2018  nawal
benabbou 
mithun
chakraborty 
xuan-vinh ho 
jakub sliwinski 
and
yair zick 
diversity constraints in public housing
allocation  in proceedings of the 17th international con-
ference on autonomous agents and multiagent systems
 aamas-18   pages 973–981  2018 
 beynier et al   2019  aur elie beynier  yann chevaleyre 
laurent gourv es  ararat harutyunyan  julien lesca  nico-
las maudet  and ana¨elle wilczynski  local envy-freeness
in house allocation problems 
autonomous agents and
multi-agent systems  33 5  591–627  2019 
 bouveret and lang  2008  sylvain bouveret and j erˆome
lang  efficiency and envy-freeness in fair division of in-
divisible goods  logical representation and complexity 
journal of artificial intelligence research  32 525–564 
2008 
 bouveret et al   2016  sylvain bouveret  yann chevaleyre 
and nicolas maudet  fair allocation of indivisible goods 
in handbook of computational social choice  pages 284–
310  cambridge university press  2016 
 brams  1990  steven j  brams  constrained approval vot-
ing  a voting system to elect a governing board  inter-
faces  20 5  67–80  1990 
 bredereck et al   2018  robert
bredereck 
piotr
fal-
iszewski  ayumi igarashi  martin lackner  and piotr
skowron 
multiwinner elections with diversity con-
straints  in proceedings of the 32nd aaai conference on
artificial intelligence  aaai-18   pages 933–940  2018 
 cechl arov a and fleiner  2017  katar ına
cechl arov a
and
tam as fleiner 
pareto optimal matchings with lower
quotas  mathematical social sciences  88 3–10  2017 
 conitzer  2009  vincent conitzer 
eliciting single-peaked
preferences using comparison queries  journal of artificial
intelligence research  35 161–191  2009 
 cseh  2017   agnes cseh  popular matchings  in trends in
computational social choice  pages 105–122  ai access 
2017 
 elkind et al   2017  edith elkind  piotr faliszewski  piotr
skowron  and arkadii slinko  properties of multiwinner
voting rules  social choice and welfare  48 3  599–632 
2017 
 faliszewski et al   2017  piotr faliszewski  piotr skowron 
arkadii slinko  and nimrod talmon 
multiwinner vot-
ing  a new challenge for social choice theory  in trends
in computational social choice  pages 27–47  ai access 
2017 
 foley  1967  duncan k  foley  resource allocation and the
public sector  yale economic essays  7 1  45–98  1967 
 gan et al   2019  jiarui gan 
warut suksompong 
and
alexandros a  voudouris  envy-freeness in house allo-
cation problems  mathematical social sciences  101 104–
106  2019 
 harless  2018  patrick harless  immediate acceptance and
weak priorities  an adaptation that preserves efficiency
and respects rank  working paper  2018 
 hylland and zeckhauser  1979  aanund
hylland
and
richard zeckhauser 
the efficient allocation of indi-
viduals to positions 
journal of political economy 
87 2  293–314  1979 
 irving et al   2006  robert w  irving  telikepalli kavitha 
kurt mehlhorn  dimitrios michail  and katarzyna e 
paluch  rank-maximal matchings  acm transactions on
algorithms  talg   2 4  602–610  2006 
 irving  2003  robert w  irving  greedy matchings  techni-
cal report tr-2003-136  university of glasgow  2003 
 kojima and ¨unver  2014  fuhito
kojima
and
m
utku
¨unver  the  boston  school-choice mechanism  an ax-
iomatic approach 
economic theory  55 3  515–544 
2014 
 mcdermid and irving  2011  eric
mcdermid
and
robert w  irving 
popular matchings 
structure and
algorithms 
journal of combinatorial optimization 
22 3  339–358  2011 
 ramezanian and feizi  2020  rasoul
ramezanian
and
mehdi feizi  stepwise ordinal efficiency for the random
assignment problem  journal of mathematical economics 
2020 
 roth  1985  alvin e  roth  the college admissions prob-
lem is not equivalent to the marriage problem  journal of
economic theory  36 2  277–288  1985 
 shams et al   2020  parham shams  aur elie beynier  syl-
vain bouveret  and nicolas maudet  fair in the eyes of
others  in proceedings of the 24th european conference
on artificial intelligence  ecai-20   pages 203–210  2020 
 shapley and scarf  1974  lloyd shapley and herbert scarf 
on cores and indivisibility  journal of mathematical eco-
nomics  1 1  23–37  1974 
 varian  1974  hal r  varian  equity  envy  and efficiency 
journal of economic theory  9 1  63–91  1974 
 walsh  2015  toby walsh  generating single peaked votes 
arxiv preprint arxiv 1503 02766  2015 
proceedings of the thirtieth    ijcai-21 
44
 "
None,2021,https-www-ijcai-org-proceedings-2021-0007-pdf,Two Influence Maximization Games on Graphs Made Temporal,"Niclas Boehmer, Vincent Froese, Julia Henkel, Yvonne Lasars, Rolf Niedermeier, Malte Renken",None,https://www.ijcai.org/proceedings/2021/0007.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0007-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0007-pdf.pdf,"two influence maximization games on graphs made temporal
niclas boehmer   vincent froese   julia henkel  
yvonne lasars   rolf niedermeier and malte renken
technische universit¨at berlin  algorithmics and computational complexity
 niclas boehmer  vincent froese @tu-berlin de   henkel  y lasars @campus tu-berlin de 
 rolf niedermeier  m renken @tu-berlin de
abstract
to address the dynamic nature of real-world net-
works  we generalize competitive diffusion games
and voronoi games from static to temporal graphs 
where edges may appear or disappear over time 
this establishes a new direction of studies in the
area of graph games  motivated by applications
such as influence spreading  as a first step  we in-
vestigate the existence of nash equilibria in com-
petitive diffusion and voronoi games on different
temporal graph classes  even when restricting our
studies to temporal paths and cycles  this turns out
to be a challenging undertaking  revealing signifi-
cant differences between the two games in the tem-
poral setting  notably  both games are equivalent
on static paths and cycles  our two main technical
results are  algorithmic  proofs for the existence of
nash equilibria in temporal competitive diffusion
and temporal voronoi games when the edges are
restricted not to disappear over time 
1
introduction
as graph games help us to reason about a networked world 
playing games on graphs is an intensively researched topic
since decades  in this work  we focus on competitive games
on undirected graphs  here  some external parties influence
a small subset of agents who then spread some information
through the network  typical application scenarios for these
occur  for instance  when political parties aim to gain influ-
ence in a social network or in the context of viral marketing 
looking at two prominent  somewhat similar represen-
tatives  namely competitive diffusion games and voronoi
games  we put forward to model network dynamics more re-
alistically  specifically  while to the best of our knowledge
almost all work on graph games focused on static graphs  we
initiate the study of these two games on temporal graphs 
roughly speaking  in a temporal graph  the edge set may
evolve over discrete time steps  while the vertex set remains
unchanged  yielding time-ordered graph layers with different
edge sets  moving to the temporal setting has dramatic con-
sequences  for example  while competitive diffusion games
and voronoi games are equivalent on static paths and cy-
cles  sun et al   2020  and we understand well their properties
in these simple but important special cases  they are no longer
equivalent in the temporal case and their properties are much
more challenging to analyze 
our study takes a first step towards understanding both
games on temporal paths and cycles  it turns out that these
two backbone structures of graphs already confront us with
several technically challenging questions when looking for
the existence  and computation  of nash equilibria—one of
the most fundamental game-theoretic concepts  we refer to
the next section for formal definitions and examples of the
two  temporal  games  intuitively speaking  in both games
one can think of each player having a color and trying to color
as many vertices as possible by her own color  the coloring
process starts in a vertex freely chosen by each player and acts
through the neighborhood relation of the graph  herein  the
distance of a vertex to the start vertices plays a central role  in
both games  a player colors all vertices that are closest to her
start vertex  moreover  while in competitive diffusion games
a vertex that is at the same distance to two start vertices of
competing players can still get one of the two colors  this is
not the case for voronoi games 
related work 
competitive diffusion games were intro-
duced by alon et al   2010   research on competitive dif-
fusion games so far mainly focused on the existence of nash
equilibria on a variety of graph classes for different numbers
of players  alon et al   2010  bulteau et al   2016  fukuzono
et al   2020  roshanbin  2014  small and mason  2013  suke-
nari et al   2016  takehara et al   2012   also  the  parameter-
ized  computational complexity of deciding the existence of a
nash equilibrium has been studied  etesami and bas¸ar  2016 
ito et al   2015  
voronoi games have been originally studied for a one-
dimensional or two-dimensional continuous space  ahn et
al   2004  banik et al   2013  de berg et al   2019  cheong
et al   2004  fekete and meijer  2005   there  it is typically
assumed that players choose their initial sets of points sequen-
tially and that a player wins the game if a certain fraction of
all points is closest to her  voronoi games on graphs have also
been studied on different graph classes for various numbers of
players  bandyapadhyay et al   2015  d¨urr and thang  2007 
feldmann et al   2009  mavronicolas et al   2008  sun et al  
2020  teramoto et al   2011   again a focus lies on determin-
ing for which graphs a nash equilibrium exists and how to
compute one 
proceedings of the thirtieth    ijcai-21 
45
 superset monotonically monotonically
growing
shrinking
diffusion
temporal paths
  th  2 
  th  2 
  th  4 
temporal cycles   th  5 
  th  6 
  th  7 
voronoi
temporal paths
  th  8 
  th  9 
  co  1 
temporal cycles   th  8 
 
  co  1 
table 1  overview of our results     means that a nash equilibrium
is not guaranteed to exist     means that a nash equilibrium always
exists  see section 2 for formal definitions  voronoi games and
diffusion games on static paths and static cycles are guaranteed to
admit a nash equilibrium 
from a broader perspective  analyzing games played on
graphs from a game-theoretic perspective is an intensively
researched topic  recent examples include schelling games
 chauhan et al   2018  elkind et al   2019   b-matching
games  kumabe and maehara  2020   or network creation
games  echzell et al   2020  
as mentioned before  we know of basically no work sys-
tematically studying graph games in a temporal setting  the
only exception we are aware of is in the context of pursuit-
evasion games  erlebach and spooner  2020  studied the
pursuit-evasion game of cops and robbers on some spe-
cific temporal graphs  namely so-called edge-periodic graphs 
also different from our studies  their focus was on computing
winning strategies for the players  morawietz et al   2020 
and morawietz and wolf  2021  extended this study  also an-
swering an open question of erlebach and spooner  2020  
our contributions 
we put forward the study of game-
theoretic models on temporal graphs  we do so by generaliz-
ing two well-studied  static  graph games to temporal graphs 
namely competitive diffusion games and voronoi games  for
the two resulting temporal graph games we analyze the  con-
structive  existence of nash equilibria on different temporal
graph classes  focusing on different types of temporal paths
and cycles  see section 1 for an overview of our results  
we observe that  in contrast to the static case where both
games are equivalent and a nash equilibrium is guaranteed
to exist  roshanbin  2014   on temporal paths and cycles  the
games exhibit far more complex dynamics and a quite differ-
ent behavior  our main results are two proofs of guaranteed
existence of nash equilibria  namely in temporal diffusion
games on so-called monotonically growing temporal cycles 
and in temporal voronoi games on so-called monotonically
growing temporal paths  one conclusion from our work is
that temporal voronoi games seem to be more elusive to a full
understanding of fundamental properties than temporal com-
petitive diffusion games  correspondingly  section 1 identi-
fies one concrete open question for voronoi games where we
already have an answer for competitive diffusion games 
due to lack of space  we defer several proofs  marked ⋆ 
to a full version available at arxiv org/abs/2105 05987 
2
preliminaries
for a ≤ b ∈ n  let  a  b   =  a  a 1          b    a  b  =  a  a 
1          b − 1   and  a  b   =  a   1          b   further  let  n   =
 1  n  for n ∈ n 
2 1
temporal graphs
a temporal graph is a tuple g =  v  e1          eτ   or g =
 v   ei i∈ τ   for short   where v is the set of vertices
and e1          eτ a sequence of edge sets with et ⊆
�v
2
�
for t ∈  τ   we refer to τ as the lifetime of g  for t ∈  τ  
we call gt =  v  et  the t-th layer of g  let the underlying
graph of g be the graph g↓ =  v  e↓  with e↓  = �
t∈ τ  et 
a temporal path of size n  or a temporal cycle of size n 
is a temporal graph g
=  v   ei i∈ τ   with v
=  n 
such that g↓ is a path  or a cycle  of size n  for two ver-
tices u < v ∈  n   we say that u is left of v and v is right
of u  we refer to a temporal graph g as a temporal linear for-
est if the connected components of g↓ are paths  moreover 
we call a temporal graph g a superset temporal graph if its
last layer is identical to its underlying graph  i e   gτ = g↓ 
further  we call g monotonically growing if no edge disap-
pears over time  i e   ei ⊆ ei 1 for all i ∈  τ − 1   note that
each monotonically growing temporal graph is also a superset
temporal graph  symmetrically  g is monotonically shrink-
ing if edges do not appear over time  i e   ei 1 ⊆ ei for
all i ∈  τ − 1   for the definition of temporal voronoi games 
we now introduce a notion of temporal distance of two ver-
tices  in a temporal graph g =  v   ei i∈ τ    we define a
temporal walk from a vertex v0 to a vertex vd as a sequence of
tuples   v0  v1   t1     v1  v2   t2             vd−1  vd   td  such
that the following properties hold 
• ti ≤ ti 1 for all i ∈  d − 1  
•  vi−1  vi  ∈ eti for all i ∈  d  with ti ≤ τ 
•  vi−1  vi  ∈ eτ for all i ∈  d  with ti > τ 
we refer to td as the arrival time of the temporal walk 
note that the last condition can be interpreted as repeating
the last layer arbitrarily often  this is to allow for arrival
times td > τ which is somewhat natural and closer to the
static case  a temporal walk is called strict if ti < ti 1
holds for all i ∈  d − 1   moreover  we call a temporal walk
from v0 to vd foremost if there is no temporal walk from v0
to vd with a smaller arrival time  we now define the tem-
poral distance td u  v  from u to v as the arrival time of a
strict foremost walk1 from u to v  notably  in contrast to the
static case  temporal distances are not necessarily symmet-
ric  i e   td u  v  ̸= td v  u  is possible  by convention  we
set td v  v  = 0 for any vertex v  for two vertices u and v 
we say that u reaches v until step ℓ if td u  v  ≤ ℓ and that u
reaches v in step  or at time  ℓ if td u  v  = ℓ 
2 2
games on temporal graphs
we focus on games with two players  nevertheless  to high-
light the nature of our definitions  we directly introduce both
1we consider foremost walks since earliest arrival seems more
natural than other concepts such as fastest or shortest  bentert et al  
2020  in the context of influence spreading  moreover  we consider
strict temporal walks since they are closer to the static case and to
the diffusion process 
proceedings of the thirtieth    ijcai-21 
46
 games for an arbitrary number of players  since the games are
somewhat similar  we start by making some general defini-
tions for both temporal games before describing the specifics 
for a temporal graph g =  v   ei i∈ τ   and a number k ∈ n
of players  diff g  k 
�
vor g  k 
�
denotes the k-player tem-
poral diffusion game  temporal voronoi game  on the tempo-
ral graph g  where each player has her distinct color in  k  
moreover  we use the color 0 to which we refer as gray  the
strategy space of each player i ∈  k  is the vertex set v   i e  
each player i selects a single vertex pi ∈ v   which is then im-
mediately colored by her color i  if two players pick the same
vertex  then it is colored gray  a strategy profile of the game
is a tuple  p1          pk  ∈ v k containing the initially chosen
vertex of each player  we also use the term position to refer
to the vertex pi chosen by player i 
now  for both games the strategy profile  p1          pk  de-
termines a partial coloring of the vertices in v with col-
ors from 0          k  some vertices might remain uncolored 
as described below 
for a strategy profile  p1          pk  
let ui p1          pk  be the set of vertices with color i in the
resulting coloring and let ui p1          pk   = |ui p1          pk |
be the number of vertices with color i  for a strategy pro-
file  p1          pk   the payoff or outcome  of the game  of
player i is ui p1          pk  
we say that a player i ∈  k 
plays a best response to the other players in the strategy
profile  p1          pk  if for all vertices p′
∈
v it holds
that ui p1          pi−1  p′  pi 1          pk  ≤ ui p1          pk   a
strategy profile  p1          pk  is a nash equilibrium if every
player i ∈  k  plays a best response to the other players 
it remains to specify how the strategy profile  p1        pk 
determines the coloring of the vertices v in the two games 
temporal diffusion games 
in a temporal diffusion game 
the temporal graph g is colored by the following propagation
process over time  we call a vertex uncolored if no color has
been assigned to it  so far   in step t ∈  τ   we consider the
layer gt  we color a so far uncolored vertex v with color i ∈
 k  if v has at least one neighbor in gt that is colored with
color i ∈  k  and no neighbor in gt that is colored with any
other color j ∈  k \ i   every uncolored vertex with at least
two neighbors in gt colored by two different colors i  j ∈
 k  is colored gray  in step t > τ  the propagation process
continues on gτ until the coloring of the vertices does not
change between two consecutive steps  we again  repeat  the
last layer to be consistent with the static case  
temporal voronoi games 
in a temporal voronoi game  a
vertex v is colored with color i ∈  k  if the arrival time of a
strict foremost walk from pi to v is smaller than the respective
arrival times for all other players  i e   vertex v ∈ v is colored
with color i ∈  k  if td pi  v  < td pj  v  holds for all j ̸=
i ∈  k   if at least two players have the earliest arrival time 
then the vertex is colored gray 
note that we defined temporal diffusion games and tempo-
ral voronoi games such that both temporal games played on
a temporal graph g with identical layers are equivalent to the
 non-temporal  game played on the static graph g↓  an ex-
ample of a temporal diffusion game and a temporal voronoi
game is shown in figure 1  notably  in the displayed tempo-
ral diffusion game each player colors a superset of the vertices
p1 p2
layer
start
1
5
1
6
 a  temporal diffusion game 
p1 p2
layer
1
5
1
6
start
 b  temporal voronoi game 
figure 1  example of the two games on the temporal path g =
  6   e1          e5  with et =   t  t 1   for t ∈  5   where player 1
selects vertex p1 = 2 and player 2 selects vertex p2 = 3  for
temporal voronoi games  we color a vertex in layer x if the ver-
tex is reached by a player until step x   in the diffusion game  the
color of a player cannot  pass  a vertex colored by the other player 
thus  the two players split the vertices  i e   player 1 colors the ver-
tices in  1  2   while player 2 colors the vertices in  3  6   in con-
trast to this  in the voronoi game  player 1 is able to  catch up 
with player 2  they both  arrive  at the vertices 4  5  and 6 at the
same time  the displayed strategy profile is a nash equilibrium in
vor g  2  but not in diff g  2  
they color in the temporal voronoi game  in fact  by defini-
tion of the two games  this holds for every temporal graph  as
in the static case  
3
temporal diffusion games
we start with temporal paths followed by temporal cycles 
3 1
temporal paths
we first prove that on a temporal path  in general  a nash
equilibrium is not guaranteed to exist  even if each edge only
appears in one layer  afterwards  we show that as soon as the
temporal path fulfills the superset property  up to symmetry
and tie-breaking  every game admits a unique nash equilib-
rium  lastly  we prove that enforcing that edges do not appear
over time is not enough to guarantee the existence of a nash
equilibrium  even if the graph consists of only two layers 
we start by showing that the temporal diffusion game on
the temporal path depicted in figure 1  where every edge of
the underlying graph only occurs at one point of time  does
not admit a nash equilibrium  this is in contrast to the static
case where a nash equilibrium is guaranteed to exist on every
path  roshanbin  2014  theorem 1  
theorem 1  there is a temporal path p such that there is no
nash equilibrium in diff p  2  
proof  we prove the theorem by showing that for p
=
  6   e1          e5  with et =   t  t   1   for t ∈  5   see
figure 1   there is no nash equilibrium in diff p  2   for the
sake of contradiction  assume that  p1  p2  with p1 < p2 is a
nash equilibrium in diff p  2   player 1 colors all vertices
in  max 1  p1 − 1   p2 − 1  and player 2 all vertices in  p2  n  
note that p2 = p1  1 must hold  as otherwise player 2 can
color additional vertices by moving to vertex p1   1  more-
over  if p1 ≥ 3  then player 1 can additionally color vertex 1
proceedings of the thirtieth    ijcai-21 
47
 layer
1
2
1
8
figure 2  a monotonically shrinking temporal path p for which
neither in diff p  2  nor in vor p  2  a nash equilibrium exists 
by moving to vertex 1  thus  p1 ∈  1  2   p2 = p1   1 
and p2 ∈  2  3   however  this implies that player 1 colors at
most two vertices and can increase her payoff by moving to
vertex 4  thereby coloring three vertices 
superset paths
as soon as the last layer of the examined temporal path is
the same as the underlying graph  i e   the superset property
is fulfilled   a nash equilibrium for temporal diffusion games
is guaranteed to exist and can even be precisely character-
ized  notably  the characterization is exactly the same as in
the static case  roshanbin  2014  theorem 1  
theorem 2  ⋆   let p be a superset temporal path of size n
and p1 < p2 ∈  n   a strategy profile  p1  p2  is a nash
equilibrium in diff p  2  if and only if p1 ∈  ⌊ n
2 ⌋  ⌈ n
2 ⌉ 
and p2 = p1   1 
proof  sketch   we only prove the  if -direction here  since
the last layer of p is a path connecting all vertices and the
diffusion process continues on the last layer  player 1 colors
all vertices in  1  p1  and player 2 colors all vertices in  p2  n  
observe that each player colors at least ⌊ n
2 ⌋ vertices  more-
over  for none of the two players is it possible to color more
than ⌊ n
2 ⌋ vertices by changing positions  as there exist only at
most ⌊ n
2 ⌋ vertices to the left of p1 and to the right of p2 
using a slightly more involved yet similar argument  we
can also show that there exists a nash equilibrium on every
superset temporal linear forest 
theorem 3  ⋆   on every superset temporal linear forest f
a nash equilibrium in diff f  2  can be found in linear time 
monotonically shrinking paths
we have seen above that a nash equilibrium is guaranteed to
exist on superset and thereby also on monotonically growing
temporal paths  it turns out that enforcing the opposite  i e  
the graph is monotonically shrinking  does not guarantee the
existence of a nash equilibrium 
theorem 4  there is a monotonically shrinking temporal
path p consisting of two layers which only differ in one edge
such that there is no nash equilibrium in diff p  2  
proof  let p =   8   e1  e2  with e1 =   i  i   1  | i ∈
 7   and e2 = e1 \   2  3    see figure 2   for the sake
of contradiction  assume that  p1  p2  is a nash equilibrium
in diff p  2   we distinguish two cases 
1  p1 ∈  3  or p2 ∈  3   let p1 = i ∈  3   then  p2 = i 1 
as this is the unique best response of player 2  player 1 can
improve by deviating to vertex i   2 
2  p1 ∈  4  8  and p2 ∈  4  8   if p1 = i ∈  4  5   then
p2 = i   1 is the unique best response of player 2 from the
relevant interval  4  8   player 1 can improve by choosing ver-
tex 3  if p1 = 6  then p2 = 3 is the unique best response of
player 2  if p1 = i ∈  7  8   then p2 = i − 1 is the unique best
response of player 2 from the relevant interval  4  8   player 1
can improve by choosing vertex 3 
intuitively  the reason why a disappearing edge is enough
to prevent the existence of a nash equilibrium on a temporal
path is that players may want to play in the immediate sur-
rounding of such a disappearing edge  in order to color some
part of the temporal path that otherwise remains uncolored
 in figure 2  these are the vertices  1  2    however  if the
disappearing edge is not located around the center  then the
player close to this edge is at risk of loosing many vertices to
the other player  this is in contrast to monotonically growing
temporal graphs where edges are not allowed to disappear 
as a consequence of theorem 4  it follows that nash equi-
libria cannot be guaranteed for non-superset temporal paths
when edges are allowed to disappear 
3 2
temporal cycles
in this section  we prove that in contrast to paths  a nash
equilibrium may fail to exist on a superset temporal cycle 
however  enforcing that edges do not disappear over time is
enough to guarantee the existence of a nash equilibrium 
superset cycles
the guaranteed existence of a nash equilibrium on superset
temporal paths  theorem 2  does not extend to superset tem-
poral cycles despite the fact that as on superset paths all ver-
tices will be colored in the end  this can be shown using the
graph depicted in figure 1 with an additional layer connecting
all vertices to a cycle and a similar argument as in theorem 1 
theorem 5  ⋆   there is a superset temporal cycle c such
that there is no nash equilibrium in diff c  2  
monotonically growing cycles
if we require that edges do not disappear over time  then a
nash equilibrium is again guaranteed to exist 
theorem 6  ⋆   on every monotonically growing temporal
cycle c =   n    ei i∈ τ   a nash equilibrium in diff c  2 
can be found in o τ · n  time 
as the proof of theorem 6 is quite involved  we present
only a high-level overview here  we start our description by
making some definitions that are only relevant for temporal
diffusion games 
definitions 
let p =   n    ei i∈ τ   be a temporal path
and v1  v2 ∈  n  with v1 ≤ v2  let ℓ  = v2 − v1   1  if ℓ is
odd  then we call m  = v1 ⌊ ℓ
2⌋ the central vertex of  v1  v2  
if ℓ is even  then we call ml  = v1   ℓ
2 −1 and mr  = v1   ℓ
2
central vertices of  v1  v2  
without loss of generality  we assume that for a given tem-
poral cycle c =   n    ei i∈ τ    it holds that τ > 1 and that
the last two layers differ  i e   eτ ̸= eτ−1  for a temporal
cycle c =   n    ei i∈ τ    we denote by f c  the monotoni-
cally growing temporal linear forest that results from deleting
the last layer from c  i e   f c  =   n    ei i∈ τ−1   
proceedings of the thirtieth    ijcai-21 
48
 in the proof of theorem 6  see full version   we look at two
variants of temporal diffusion games  which are both zero-
sum games 
temporal difference diffusion games  ddiff  a variant of
temporal diffusion games where the payoff of a player
is the difference between the number of vertices colored
by her and the number of vertices colored by the other
player 
temporal lifetime difference diffusion games  lddiff  a
variant of temporal difference diffusion games where
only one diffusion step is carried out on the last layer 
the proof of theorem 6 is split into two parts  in the first
part  we prove the following lemma 
lemma 1  let c be a monotonically growing temporal cycle 
a nash equilibrium in ddiff c  2  is guaranteed to exist 
to prove the lemma  it is sufficient to find a nash equilib-
rium in lddiff f c   2   as both players color the same num-
ber of vertices after step τ − 1 in ddiff c  2   we show that
in all temporal lifetime difference diffusion games on mono-
tonically growing temporal linear forests there always exists
some non-empty set of vertices such that in case a player se-
lects one of them  she always colors at least as many vertices
as the other player  these are the nice central vertices 
definition 1  let f =   n    ei i∈ τ   be a monotonically
growing temporal linear forest  let r be the maximum num-
ber of vertices that are reachable from any vertex in f until
step τ  a vertex v is a nice central vertex if v reaches r ver-
tices until step τ and if v is a central vertex of the set of ver-
tices reachable from v until step τ 
notably  each strategy profile where the players play
on different nice central vertices is a nash equilibrium
in lddiff f  2   in addition  we prove that if only one nice
central vertex v exists  then  v  v   1  is a nash equilibrium 
in the second part of the proof  we show that at least one
nash equilibrium in ddiff c  2  described above is also a
nash equilibrium in diff c  2  
monotonically shrinking cycles
the example in figure 2 can be modified to show that en-
forcing edges to only disappear over time is not enough to
guarantee the existence of a nash equilibrium on a temporal
cycle  as in the case of temporal paths  
theorem 7  ⋆   there is a monotonically shrinking tempo-
ral cycle c with two layers such that there is no nash equilib-
rium in diff c  2  
4
temporal voronoi games
in this section  we study temporal voronoi games  in contrast
to temporal diffusion games  here  the color of a vertex v is
determined solely by the temporal distances from the players 
positions to v 
4 1
monotonically shrinking paths and cycles
in section 2  we observed that temporal diffusion games and
temporal voronoi games might already differ on a simple
temporal path  in contrast to this  both games are equiva-
lent on monotonically shrinking temporal linear forests and
cycles  as no foremost walk ever needs to wait at any vertex
in these graphs 
lemma 2  let g =   n    ei i∈ τ   be a monotonically
shrinking temporal linear forest or cycle and let p1  p2 ∈  n  
for strategy profile  p1  p2   the final coloring of the vertices
is the same in diff g  2  and in vor g  2  
proof  as already noted in section 2  a vertex v colored with
color i ∈  2  in vor g  2  is colored the same in diff g  2  
as pi reaching v first implies that pi also reaches every vertex
on a foremost walk from pi to v first 
to see that on monotonically shrinking temporal linear for-
est and cycles the converse also holds  assume that v gets col-
ored with color 1 in diff g  2   note that there is exactly one
temporal walk from p1 to v which does not use vertex p2 and
no vertex repeatedly  since no foremost walk ever needs to
wait in g and v is colored in color 1  this temporal walk must
have fewer edges than any temporal walk from p2 to v  for
the same reason  the walk from p1 to v consists of exactly
td p1  v  edges  thus  td p1  v  < td p2  v  
in particular  using lemma 2  we can transfer theorem 4
and theorem 7 to temporal voronoi games 
corollary 1  there is a monotonically shrinking temporal
path p and a monotonically shrinking temporal cycle c both
consisting of two layers such that there is no nash equilib-
rium in vor p  2  and no nash equilibrium in vor c  2  
4 2
superset paths and cycles
in contrast to temporal diffusion games  a nash equilibrium in
a temporal voronoi game on a superset temporal path may fail
to exist  in fact  the underlying dynamics of temporal voronoi
games on superset temporal paths might be quite intriguing
and far more complex than for temporal diffusion games  as
highlighted in the next subsection  
theorem 8  there is a superset temporal path p and a su-
perset temporal cycle c such that there is no nash equilibrium
in vor p  2  and no nash equilibrium in vor c  2  
proof  let p =   8    e1  e2   be the temporal path from
figure 2  by lemma 2 and the proof of theorem 4  there
is no nash equilibrium in vor p  2   by appending to p the
last layer p2 five times  we can ensure that either every vertex
is colored by some player until step seven or both players
reach the same set of vertices until step seven  appending
any additional layers to p does not enable any player to color
further vertices  however  some additional vertices may be
colored gray   in particular  we may append a layer which is
a complete path or cycle 
4 3
monotonically growing paths
our main result for temporal voronoi games is the guaranteed
existence of a nash equilibrium on monotonically growing
temporal paths  it is open whether this can be extended to all
monotonically growing temporal cycles 
proceedings of the thirtieth    ijcai-21 
49
 theorem 9  ⋆   on every monotonically growing tempo-
ral path p a nash equilibrium in vor p  2  can be found in
o n2  time 
while the complete proof of theorem 9 can be found in
the full version  we give an overview of some key ingredients
here  subsequently  we always assume that the graph is a
monotonically growing path p =   n    ei i∈ τ   
a vertex b ≤ v is called a left boundary of v if
⃗
τ b >
td v  b   where
⃗
τ b denotes the index of the first layer in which
the edge  b − 1  b  appears  or ∞ if b = 1   symmetrically  a
vertex b ≥ v is a right boundary of v if ⃗τb > td v  b  with ⃗τb
referring to the first appearance of  b  b   1   note that 1  v 
and n are always boundaries of v  the importance of bound-
aries arises from the following lemma 
lemma 3  for three vertices v < w < x ∈  n   td v  x  =
td w  x  if and only if there exists a right boundary r of v
with w ≤ r < x 
proof  if there is such a right boundary r  then v will
reach r   1 at time ⃗τr  clearly  the same holds for w  there-
fore  td v  x  = td w  x  for all x > r 
conversely  assume that td v  x  = td w  x  and let x be
minimal with this respect  since td w  x − 1  < td v  x −
1  ≤ td v  x  − 1 = td w  x  − 1  i e   w needed to wait at
x − 1   we must have that ⃗τx−1 = td w  x  = td v  x  >
td v  x − 1   i e   x − 1 is a right boundary of v 
let ℓ < ℓ′ be two left boundaries of a vertex v such that
there is no other left boundary of v in between them  we call
the interval  ℓ  ℓ′  ⊂  n  a left boundary interval of v  the
definition of right boundary intervals is analogous  note that
the boundary intervals of v partition  n \ v   for any w ̸= v 
we write ȷv w  to denote the boundary interval of v which
contains w  from lemma 3  the following can be derived 
for an example  consider figure 3 
lemma 4  let p be a monotonically growing temporal path
and p1  p2 ∈  n   in vor p  2   it holds u1 p1  p2  ⊆ ȷp2 p1 
and u2 p1  p2  ⊆ ȷp1 p2  
proof  as
all
other
cases
are
symmetric 
we
only
show u1 p1  p2  ⊆ ȷp2 p1  and assume that ȷp2 p1  =  r  r′ 
is a right boundary interval of p2 
thus 
we have
p2 ≤ r < p1 ≤ r′ 
lemma 3 implies that all vertices
strictly to the right of r′ are colored gray  further  as r is a
right boundary of p2  p2 reaches r before the edge  r  r   1 
appears and thus before td p1  r   this implies that neither r
nor any vertex to the left of it is colored with color 1 
this allows us to easily find best responses 
lemma 5  let p1 be an arbitrary vertex and j be a largest
boundary interval of p1  then the vertex p2 ∈ j which is
closest to p1 is a best response to p1 
proof  for strategy profile  p1  p2   by lemma 3  player 2
colors all vertices in j  by lemma 4  the claim follows 
starting with an arbitrary vertex v1 and iteratively applying
lemma 5  we obtain a sequence of vertices v1  v2          each
being a best response to its predecessor  the following lemma
then implies theorem 9 
p1
p2
layer
start
1
10
1
15
ℓ
r1
r2
r3 r4
figure 3  voronoi game on a monotonically growing temporal path 
the left boundaries of p1 are 1  ℓ  and p1 and the left boundaries
of p2 are 1  ℓ  p1  and p2  the right boundaries of p1 are p1  r3  r4 
and 15  the right boundaries of p2 are p2  r1          r4  and 15  as
guaranteed by lemma 4  the sets of vertices colored by the players
satisfy  p1  = u1 p1  p2  ⊆ ȷp2 p1  =  p1  p2  and  p2  r3  =
u2 p1  p2  ⊆ ȷp1 p2  =  p1  r3  
lemma 6  ⋆   let v1  v2        be a best response sequence
as defined above  then there exists an index i ≤ n such that
 vi  vi 1  is a nash equilibrium 
5
conclusion
our work is meant to initiate further systematic studies of
 not only competitive  games on  classes of  temporal graphs 
there is a wealth of unexplored research directions to pursue 
an immediate and very concrete challenge from our work
is to analyze whether a nash equilibrium is guaranteed to ex-
ist in all temporal voronoi games on monotonically growing
temporal cycles  there are also many more special temporal
graphs to study  another direction is to consider variations
of temporal diffusion and voronoi games  for example  one
could limit the time horizon such that players can only color
vertices which they reach until the last layer  note that theo-
rem 2 does not hold in this case   also  the payoff could be
defined as the difference of the number of vertices colored by
the players  it is also natural to study the games with more
than two players or more initially chosen vertices  in addi-
tion  considering model variations already studied on static
games such as  splitting  gray vertices between players is
possible  finally  for voronoi games  there are several dif-
ferent temporal distance notions to consider  for example 
one may study non-strict walks  for which theorem 9 triv-
ially holds  in fact  we have no example of a temporal graph
without a nash equilibrium in a non-strict voronoi game  
acknowledgements
niclas boehmer was supported by dfg project mamu
 ni 369/19   malte renken was supported by dfg project
mate  ni 369/17  
proceedings of the thirtieth    ijcai-21 
50
 references
 ahn et al   2004  hee-kap ahn  siu-wing cheng  otfried
cheong  mordecai j  golin  and ren e van oostrum  com-
petitive facility location  the voronoi game  theor  com-
put  sci   310 1-3  457–467  2004 
 alon et al   2010  noga alon  michal feldman  ariel d
procaccia  and moshe tennenholtz  a note on competi-
tive diffusion through social networks  inf  process  lett  
110 6  221–225  2010 
 bandyapadhyay et al   2015  sayan bandyapadhyay  aritra
banik  sandip das  and hirak sarkar  voronoi game on
graphs  theor  comput  sci   562 270–282  2015 
 banik et al   2013  aritra banik  bhaswar b  bhattacharya 
and sandip das  optimal strategies for the one-round dis-
crete voronoi game on a line  j  comb  optim   26 4  655–
669  2013 
 bentert et al   2020  matthias bentert  anne-sophie him-
mel  andr e nichterlein  and rolf niedermeier  efficient
computation of optimal temporal walks under waiting-
time constraints  appl  netw  sci   5 1  73  2020 
 bulteau et al   2016  laurent bulteau  vincent froese  and
nimrod talmon  multi-player diffusion games on graph
classes  internet math   12 6  363–380  2016 
 chauhan et al   2018  ankit chauhan  pascal lenzner  and
louise molitor 
schelling segregation with strategic
agents  in proc  of sagt  18  pages 137–149  springer 
2018 
 cheong et al   2004  otfried cheong 
sariel har-peled 
nathan linial  and jiˇr ı matouˇsek  the one-round voronoi
game  discrete comput  geom   31 1  125–138  2004 
 de berg et al   2019  mark de berg  s andor kisfaludi-bak 
and mehran mehr 
on one-round discrete voronoi
games  in proc  of isaac  19  pages 37 1–37 17  schloss
dagstuhl - leibniz-zentrum f¨ur informatik  2019 
 d¨urr and thang  2007  christoph d¨urr and nguyen kim
thang  nash equilibria in voronoi games on graphs  in
proc  of esa  07  pages 17–28  springer  2007 
 echzell et al   2020  hagen echzell  tobias friedrich  pas-
cal lenzner  and anna melnichenko  flow-based network
creation games  in proc  of ijcai  20  pages 139–145 
ijcai org  2020 
 elkind et al   2019  edith
elkind 
jiarui
gan 
ayumi
igarashi 
warut
suksompong 
and
alexandros
a 
voudouris  schelling games on graphs  in proc  of ijcai
 19  pages 266–272  ijcai org  2019 
 erlebach and spooner  2020  thomas
erlebach
and
jakob t  spooner  a game of cops and robbers on graphs
with periodic edge-connectivity  in proc  of sofsem  20 
pages 64–75  springer  2020 
 etesami and bas¸ar  2016  seyed rasoul etesami and tamer
bas¸ar  complexity of equilibrium in competitive diffusion
games on social networks  automatica  68 100–110  2016 
 fekete and meijer  2005  s andor p  fekete and henk mei-
jer 
the one-round voronoi game replayed 
comput 
geom   30 2  81–94  2005 
 feldmann et al   2009  rainer feldmann  marios mavroni-
colas  and burkhard monien  nash equilibria for voronoi
games on transitive graphs  in proc  of wine  09  pages
280–291  springer  2009 
 fukuzono et al   2020  naoka fukuzono  tesshu hanaka 
hironori kiya  hirotaka ono  and ryogo yamaguchi 
two-player competitive diffusion game  graph classes
and the existence of a nash equilibrium  in proc  of sof-
sem  20  pages 627–635  springer  2020 
 ito et al   2015  takehiro ito  yota otachi  toshiki saitoh 
hisayuki satoh  akira suzuki  kei uchizawa  ryuhei ue-
hara  katsuhisa yamanaka  and xiao zhou  competitive
diffusion on weighted graphs  in proc  of wads  15  pages
422–433  springer  2015 
 kumabe and maehara  2020  soh kumabe and takanori
maehara  convexity of b-matching games  in proc  of
ijcai  20  pages 261–267  ijcai org  2020 
 mavronicolas et al   2008  marios mavronicolas  burkhard
monien  vicky g  papadopoulou  and florian schopp-
mann  voronoi games on cycle graphs  in proc  of mfcs
 08  pages 503–514  springer  2008 
 morawietz and wolf  2021  nils
morawietz
and
petra
wolf 
a timecop s chase around the table 
corr 
abs/2104 08616  2021 
 morawietz et al   2020  nils morawietz  carolin rehs  and
mathias weller 
a timecop s work is harder than you
think  in proc  of mfcs  20  pages 71 1–71 14  schloss
dagstuhl - leibniz-zentrum f¨ur informatik  2020 
 roshanbin  2014  elham roshanbin  the competitive dif-
fusion game in classes of graphs  in proc  of aaim  14 
pages 275–287  springer  2014 
 small and mason  2013  lucy small and oliver mason 
nash equilibria for competitive information diffusion on
trees  inf  process  lett   113 7  217–219  2013 
 sukenari et al   2016  yuki
sukenari 
kunihito
hoki 
satoshi takahashi  and masakazu muramatsu  pure nash
equilibria of competitive diffusion process on toroidal grid
graphs  discrete appl  math   215 31–40  2016 
 sun et al   2020  xiaoming sun  yuan sun  zhiyu xia  and
jialin zhang  the one-round multi-player discrete voronoi
game on grids and trees  theor  comput  sci   838 143–
159  2020 
 takehara et al   2012  reiko takehara  masahiro hachi-
mori  and maiko shigeno  a comment on pure-strategy
nash equilibria in competitive diffusion games  inf  pro-
cess  lett   112 3  59–60  2012 
 teramoto et al   2011  sachio teramoto  erik d  demaine 
and ryuhei uehara  the voronoi game on graphs and its
complexity  j  graph algorithms appl   15 4  485–501 
2011 
proceedings of the thirtieth    ijcai-21 
51
 "
None,2021,https-www-ijcai-org-proceedings-2021-0008-pdf,Winner Robustness via Swap- and Shift-Bribery: Parameterized Counting Complexity and Experiments,"Niclas Boehmer, Robert Bredereck, Piotr Faliszewski, Rolf Niedermeier",None,https://www.ijcai.org/proceedings/2021/0008.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0008-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0008-pdf.pdf,"winner robustness via swap- and shift-bribery 
parameterized counting complexity and experiments
niclas boehmer1   robert bredereck2   piotr faliszewski3 and rolf niedermeier1
1algorithmics and computational complexity  tu berlin  germany
2humboldt-universit¨at zu berlin  germany
3agh university  poland
niclas boehmer@tu-berlin de  robert bredereck@hu-berlin de  faliszew@agh edu pl 
rolf niedermeier@tu-berlin de
abstract
we study the parameterized complexity of counting
variants of swap- and shift-bribery  focusing
on the parameterizations by the number of swaps
and the number of voters  facing several compu-
tational hardness results  using sampling we show
experimentally that swap-bribery offers a new
approach to the robustness analysis of elections 
1
introduction
consider a university department which is about to hire a new
professor  there are m candidates and the head of the depart-
ment decided to choose the winner by borda voting  each
faculty member  i e   each voter  ranked the candidates from
the most to the least appealing one  each candidate received
m − i points for each vote where he or she was ranked as
the i-th best  and the candidate with the highest score was
selected  however  after the results were announced  some
voters started wondering if  perhaps  some other voters acci-
dentally  misranked  some of the candidates  worrying about
mistakes in the votes is an old democratic tradition   for in-
stance  if some voter viewed two candidates as very similar 
then he or she could have ranked them either way  depending
on an impulse  or  some voter would have ranked two can-
didates differently if he or she had more information on their
merits  it is  thus  natural to ask for the probability of chang-
ing the election outcome by making some random swaps  in-
deed  this approach was recently pursued by baumeister and
hogrebe  2020  and we follow-up on it  but with a different
focus  see the discussion of related work  
specifically  in our model for each r ∈ n and each candi-
date c  we let pc r  be the probability that c wins an election
obtained by making r random swaps of candidates ranked on
adjacent positions in the votes  we refer to such elections as
being at swap distance r from the original one   such values
can be quite useful  for example  if for each r we had  some
estimate of  the probability that in total there are r acciden-
tal swaps in the votes  then we could compute the probability
of each candidate s victory  if it were small for the original
winner  then we might want to recount the votes or reexamine
the election process  the values pc r  are also useful with-
out the distribution of r s  for example  we may want to find
the smallest number of swaps for which the probability of
the original winner s victory drops below some value  such
as 50   or for which he or she is no longer the most prob-
able winner  as we show in our experiments  this approach
provides new insights on the robustness of election results 
to determine the value pc r   we need to divide the num-
ber of elections at swap distance r where c wins  by the total
number of elections at this distance  while computing the
latter is easy—at least in the sense that there is an efficient
algorithm for this task—computing the former requires solv-
ing the counting variant of the swap-bribery problem  de-
noted #swap-bribery   briefly put  in the decision variant
of the problem  we ask if it is possible to ensure that a des-
ignated candidate wins a given election by making r swaps
of adjacent candidates in the votes  we assume the unit prices
setting  see section 2   in the counting variant  we ask how
many ways there are to achieve this effect  using exactly r
swaps   unfortunately  already the decision variant is np-
hard for many voting rules  and we show that the counting
one is hard even for plurality  on the positive side  we can
get a good estimate of pc r  by sampling  see footnote 2  
we also consider the shift-bribery problem  a variant
of swap-bribery where we can only shift the designated
candidate forward  in the constructive case  or backward  in
the destructive one  where the goal is to ensure that the des-
ignated candidate loses   these problems also can be used
to evaluate robustness of election results but  to maintain fo-
cus  in our experiments we only consider swap-bribery 
yet  we include shift-bribery in our complexity analysis
because it illustrates some interesting phenomena 
main contributions 
we focus on #swap- and #shift-
bribery for the plurality and borda voting rules  for unit
prices   we consider their computational complexity for pa-
rameterizations by the number of unit swaps/shifts  which we
refer to as the swap/shift radius  and by the number of voters
 see table 1   we also present experiments  where we use
#swap-bribery to evaluate the robustness of election re-
sults  our main results are as follows 
1  for plurality  swap-bribery is known to be in p  but
we show that the counting variant is #w 1 -hard when
parameterized by the swap radius 
2  for borda  hardness results for #swap-bribery follow
from those for #shift-bribery  which themselves are
intriguing  e g   the destructive variant parameterized by
proceedings of the thirtieth    ijcai-21 
52
 the shift radius is #w 1 -hard  but the constructive one
is in fpt  in the decision setting the former is easier 1
3  using sampling  we estimate the candidate s winning
probabilities in elections from a dataset generated by
szufa et al   2020   one of the high-level conclusions
is that the score differences between the election win-
ners and the runners-up can be quite disconnected from
their strengths  measured using #swap-bribery  
we defer several proofs  marked ⋆  and analyses to a full
version available at arxiv org/abs/2010 09678 
related work 
our work is most closely related to the pa-
pers of hazon et al   2012   bachrach et al   2010   and
baumeister and hogrebe  2020   similarly to our approach 
their authors study the complexity of computing the probabil-
ity that a given candidate wins  provided that the votes may
change according to some probability distribution  in partic-
ular  hazon et al   2012  assume that each voter is endowed
with an explicitly encoded list of possible votes  each with its
own probability of being cast  bachrach et al   2010  consider
elections where the votes are partial and all completions are
equally likely  and baumeister and hogrebe  2020  consider
both these models  as well as a third one  which—in terms
of computational complexity—is equivalent to our model for
swap bribery 
there are two methodological differences between our
work and the three above-discussed papers  foremost  we
provide an experimental analysis showing that counting vari-
ants of swap-bribery are indeed helpful for evaluating
the robustness of election winners  in contrast  bachrach et
al   2010  and baumeister and hogrebe  2020  focus entirely
on the complexity analysis  whereas hazon et al   2012  also
provide experiments  but their focus is on the running time
and memory consumption of their algorithm 
the second difference is that we focus on a parameterized
complexity analysis—with an explicit focus on establishing
fpt and #w 1 -hardness results—which was not done in
previous works  except for obtaining xp algorithms for fixed
numbers of candidates or voters  
historically  swap- and shift-bribery were introduced
by elkind et al   2009  
various authors studied these
problems for different voting rules  see  e g   the works of
maushagen et al   2018  and zhou and guo  2020  regarding
iterative elections   sought approximation algorithms  elkind
and faliszewski  2010  faliszewski et al   2019   established
parameterized complexity results  dorn and schlotter  2012 
bredereck et al   2016a  knop et al   2020   considered re-
stricted preference domains  elkind et al   2020   and ex-
tended the problem in various ways  bredereck et al   2016b 
kaczmarczyk and faliszewski  2019  baumeister et al   2019 
yang et al   2019   the idea of using swap-bribery to mea-
sure the robustness of election results is due to shiryaev et
al   2013   but is also closely related to computing the mar-
gin of victory  magrino et al   2011  cary  2011  xia  2012 
brill et al   2020   recently it was also applied to committee
elections  bredereck et al   2021  
1we abuse notation here by using p and fpt for also referring
to algorithmically positive counting complexity results although for-
mally these classes are only defined for decision problems 
plurality
borda
decision
counting
decision
counting
swap-
#p-hard
np-hard
#p-hard
bribery
p
#w 1 -h  r 
fpt r 
 
fpt n 
w 1 -h  n  #w 1 -h  n 
const 
np-hard
#p-hard
shift-
p
p
fpt r 
fpt r 
bribery
w 1 -h  n  #w 1 -h  n 
dest 
#p-hard
shift-
p
p
p
#w 1 -h  r 
bribery
#w 1 -h  n 
table 1 
 parameterized  complexity of swap- and shift-
bribery with unit prices  r and n refer to the parameterizations by
the swap/shift radius and by the number of voters  respectively  re-
sults for the counting variants are new  however  see also the work
of baumeister and hogrebe  2020  for results related to the #p-
hardness of plurality swap-bribery   results for the decision
variants are due to elkind et al   2009   bredereck et al   2016b  
bredereck et al   2016a   and kaczmarczyk and faliszewski  2019  
so far  the complexity of counting problems received lim-
ited attention in the context of elections  in addition to the
works of hazon et al   2012   bachrach et al   2010   and
baumeister and hogrebe  2020   we mention two more  woj-
tas and faliszewski  2012  studied counting solutions for con-
trol problems  and kenig and kimelfeld  2019  followed up
on the work of bachrach et al   2010  and provided approxi-
mation algorithms for their setting 
2
preliminaries
for each integer k  by  k  we mean the set  1          k  
elections 
an election e
=
 c  v   consists of a set
c =  c1          cm  of candidates and a collection v
=
 v1          vn  of voters  each voter vi has a preference order 
which ranks all candidates from the most to the least desired
one  we sometimes refer to preference orders as votes   for
a voter vi  we write vi   c1 ≻ c2 ≻ · · · ≻ cm to indicate that
he or she ranks c1 first  then c2  and so on  if we put a subset
of candidates in such a description of a preference order  then
we mean listing its members in an arbitrary order 
voting rules 
a voting rule r is a function that  given an
election  returns a set of candidates that tie as winners  we fo-
cus on plurality and borda  which assign scores to the candi-
dates and select those with the highest ones  under plurality 
each voter gives one point to the top-ranked candidate  un-
der borda  each voter gives |c| − 1 points to the top-ranked
candidate  |c|−2 points to the next one  and so on  we write
scoree c  to denote the score of candidate c in election e
 the voting rule will be clear from the context  
swap distance 
let u and v be two votes over the same
candidate set 
the swap distance between u and v  de-
noted dsw u  v   is the length of the shortest sequence of
swaps of adjacent candidates whose application transforms u
into v  given elections e =  c  v   and e′ =  c  v ′   where
v =  v1          vn  and v ′ =  v′
1          v′
n   their swap dis-
tance is �n
i=1 dsw vi  v′
i   by r e  r   we denote the set of
proceedings of the thirtieth    ijcai-21 
53
 elections that are at swap distance r from e 
swap- and shift-bribery 
let r be a voting rule  in the
decision variant of the r swap-bribery problem  we are
given an election e  a designated candidate p  and a budget r 
further  for each voter and each two candidates c and d  we
have a nonnegative price πv c  d  for swapping them in v s
preference order  a swap is legal if at the time of its applica-
tion c and d are adjacent   we ask if there is an election e′
where p is an r-winner  such that e′ can be obtained from e
by performing a sequence of legal swaps of cost at most r  in
the counting variant  we ask for the number of such elections 
and we require the cost of swaps to be exactly r  the last con-
dition is for our convenience and all our results would still
hold if we asked for cost at most r  the same would be true if
instead of counting elections where p won  we would count
those where he or she lost   since we are interested in com-
puting the candidates  probabilities of victory in elections at
a given swap distance  we focus on the case where each swap
has the same  unit price 
constructive shift-bribery is a variant of swap-
bribery where all swaps must involve the designated can-
didate  shifting him or her forward  destructive shift-
bribery is defined analogously  except that our goal is to
preclude the designated candidate s victory  and we can only
shift him or her backward  kaczmarczyk and faliszewski 
2019   counting variants are defined in a natural way  we
focus on the case where each unit shift has a unit price and 
in general  speak of shift or swap radius r instead of budget 
counting complexity 
we assume basic familiarity with
 parameterized  complexity theory  including the classes p 
np  fpt  and w 1   and reducibility notions 
let x be a decision problem from np  where for each in-
stance we ask if there exists some mathematical object with
a given property 
in its counting variant  traditionally de-
noted #x  we ask for the number of such objects  for ex-
ample  in matching we are given an integer k and a bi-
partite graph g—with vertex set u g  ⊎ v  g  and edge set
e g —and we ask if g contains a matching of size k  i e  
a set of k edges  where no two edges touch the same vertex  
in #matching we ask how many such matchings exist 
the class #p is the counting analog of np  a problem be-
longs to #p if it can be expressed as the task of counting
the number of accepting computations of a nondeterminis-
tic polynomial-time turing machine  we say that a counting
problem #a  polynomial-time  turing reduces to #b if there
exists an algorithm that solves #a in polynomial time  pro-
vided that it has oracle access to #b  a problem is #p-hard if
every problem from #p turing reduces to it  while match-
ing is in p  it is well known that #matching is #p-hard
and #p-complete  valiant  1979  
#w 1  relates to w 1  in the same way as #p relates to
np 
as examples of #w 1 -hard problems  we mention
counting size-k cliques in a graph  parameterized by k  flum
and grohe  2004  and #matching  parameterized by the
size of the matching  curticapean and marx  2014  
for-
mally  #w 1 -hardness is defined using a slightly more gen-
eral notion of a reduction  but for our purposes polynomial-
time turing reductions  where the parameters in the queried
instances are bounded from above by a function of the param-
eter in the input instance  will suffice 
3
algorithms and complexity results
in this section  we present our results regarding the complex-
ity of #swap- and #shift-bribery  we first consider plu-
rality  mostly focusing on #swap-bribery  and then discuss
borda  mostly focusing on #shift-bribery 
3 1
plurality and #swap-bribery
we start with a hardness result  while there is a polynomial-
time algorithm for the decision variant of plurality swap-
bribery  elkind et al   2009   the counting variant is in-
tractable  even with unit prices  #p-hardness for a slightly
different but computationally equivalent model is also re-
ported by baumeister and hogrebe  2020   
theorem 1  plurality #swap-bribery is #p-hard and
#w 1 -hard when parameterized by the swap radius  even
for unit prices 
proof  we give a reduction from #matching  we will use
a swap radius upper-bounded by a function of the desired
matching size  so we obtain both #p- and #w 1 -hardness 
let  g  k  be an instance of #matching  where g is
a bipartite graph with vertex set u g  ⊎ v  g  and k is
the size of matchings that we are to count 
assume that
u g  =  u1          un   v  g  =  v1          vn   and k ≤
n  to form an election  we let the candidate set be c  =
u g ⊎v  g ⊎ p  a  b ⊎x  where x  =  x1          x3k 1  
the candidates in u g  ⊎ v  g  will model the graph  p will
be our designated candidate  a and b will control the size of
the matching  and the candidates in x will block undesirable
swaps  we will have the following scores of the candidates 
∀c ∈ c \  a  b   scoree c  = n 
scoree a  = n − k  scoree b  = n   k 
we form the following four groups of voters 
1  for each  ui  vj  ∈ e g   there is an edge voter eij
with preference order eij   ui ≻ vj ≻ x ≻ · · ·  
2  for each j ∈  n   we have an a-voter aj with preference
order aj   vj ≻ a ≻ x ≻ · · ·  
3  for each i ∈  n   we have a b-voter bi with preference
order bi   b ≻ ui ≻ x ≻ · · ·  
4  finally  the score voters implement the desired plurality
scores  for each candidate c ∈ u g  ∪ v  g  ∪  p  
there are exactly as many voters with preference order
c ≻ x ≻ · · · as necessary to ensure that in total c has
score n  similarly  for each xi ∈ x there are n voters
with preference order xi ≻ x \  xi  ≻ · · ·   there are
also n − k voters with preference order a ≻ x ≻ · · ·
and k voters with preference order b ≻ x ≻ · · ·  
let e be an election with the above-described candidates
and voters  we form an instance i of plurality #swap-
bribery with this election  unit prices  and swap radius r  =
3k  then  we make an oracle query for i and return its an-
swer  in the remainder of the proof  we argue that this answer
proceedings of the thirtieth    ijcai-21 
54
 is equal to the number of size-k matchings in g  the idea is
that to make p a winner  we have to transfer k points from b
to a via swaps that correspond to a matching 
let e′ be some election in r e  r   i e   an election at swap
distance r from e  where p wins  we note that p and the
candidates from x have score n in e′  indeed  in elections
from r e  r   p has score at most n and the average score of
the candidates in x is at least n   further  in e′ each edge
voter  a-voter  and b-voter either ranks on top the same can-
didate as in e or the candidate that he or she ranked second
in e  and each score voter ranks the same candidate on top
as in e  otherwise some candidate in x would have score
above n   we call this the top-two rule 
since b must have at most n points in e′  by the top-two
rule  there must be at least k b-voters in e′ that rank members
of u g  on top  let ub be the set of these members of u g  
as each member of u g  can be swapped with b at most once
in the b-votes  we have |ub| ≥ k 
compared to e  in e′ each member of ub gets an addi-
tional point from the b-voters  thus  for each ui ∈ ub there
must be a voter that ranked ui on top in e but does not do
so in e′  by the top-two rule  this must be an edge voter 
let m be the set of pairs  ui  vj  such that in e edge voter eij
ranks ui on top  but in e′ he or she ranks vj on top  naturally 
we must have |m| ≥ |ub| 
for each pair  ui  vj  ∈ m  there must be a voter who
swapped vj out of the top position in e′  because other-
wise vj would have more than n points  by the top-two rule 
this must be voter aj  let va be the set of those members
of v  g  that in e′ are swapped out of the top positions in the
a-votes  it must be that |va| ≥ |m| 
altogether  we have |va| ≥ |m| ≥ |ub| ≥ k and  in
fact  each of these sets must have exactly k elements  because
their elements correspond to unique swaps   further  m is a
matching  if it were not  then some member of u g ⊎v  g 
would appear in two pairs in m  but then we would have to
have two a-voters or two b-voters that corresponded to this
candidate  which is not possible in our construction 
this way we have shown that for each election in r e  r 
where p wins  there is a corresponding size-k matching  as
the other direction is immediate  the proof is complete 
a natural way to circumvent such intractability results is
to seek fpt algorithms parameterized by the number of can-
didates or by the number of voters  for the former  one typ-
ically expresses swap-bribery problems as integer linear
programs  ilps  and invokes the classic algorithm of lenstra 
jr   1983   or some more recent one  see  e g   the work of
knop et al   2020   unfortunately  in case of counting there
are two issues  first  counting analogues of these algorithms 
dating back to the seminal work of barvinok  1994   have
xp running times  however  fortunately  the ilps used for
swap-bribery have such a special form that in their case
barvinok s algorithm would run in fpt time for the param-
eterization by the number of candidates  the second obstacle
is more serious  even though we could count the number
of solutions to our ilps  each of these solutions would poten-
tially correspond to a different number of solutions for swap-
bribery  dealing with this problem  so far  remains elusive
and we leave it as an open problem  yet  for unit prices we
do show an fpt algorithm parameterized by the number of
voters 
theorem 2  ⋆   for unit prices  plurality #swap-
bribery parameterized by the number of voters is in fpt 
the restriction to unit prices in theorem 2 is necessary 
otherwise  a reduction from the problem of counting linear
extensions of a partially ordered set  brightwell and winkler 
1991  shows #p-hardness even for a single voter 
theorem 3  ⋆   plurality #swap-bribery is #p-hard
even for a single voter and unary-encoded prices 
we conclude with a brief mention of #shift-bribery 
both the constructive and the destructive variant are in p 
even with arbitrary unary-encoded prices  for the binary en-
coding  #p-hardness follows by a reduction from #par-
tition  
our algorithms use dynamic programming over
groups of voters with the same candidate as their top choice 
theorem 4  ⋆   for unary-encoded prices  both the con-
structive and the destructive variant of plurality #shift-
bribery are in p 
3 2
borda and #shift-bribery
our results for borda #swap-bribery follow from those
for #shift-bribrey  so we focus on the latter problem 
in the decision setting  the constructive variant of borda
shift-bribery is np-hard  and is in fpt when parame-
terized by the shift radius  but is w 1 -hard for the number of
voters   whereas the destructive variant is in p  in the count-
ing setting  both variants are #p-hard and #w 1 -hard for
the parameterization by the number of voters  the result for
the constructive case follows from a proof for the decision
variant due to bredereck et al   2016b  and for the destructive
case  we use a similar approach with a few tricks on top 
theorem 5  ⋆   both the constructive and the destruc-
tive variant of borda #shift-bribery are #p-hard and
#w 1 -hard when parameterized by the number of voters 
surprisingly  when parameterized by the shift radius  the
constructive variant is in fpt and the destructive variant is
#w 1 -hard  not only does the problem that was easier in
the decision setting now become harder  but also—to the best
of our knowledge—it is the first example where a destruc-
tive variant of an election-related problem is harder than the
constructive one  yet  shift-bribery is quite special as the
two variants differ in the available actions  i e   either shifting
the designated candidate forward or backward  typically  de-
structive voting problems have the same sets of actions as the
constructive ones  
the fpt algorithm for the constructive case relies on the
fact that if we can ensure victory of the designated candidate
by shifting him or her by r positions forward  then there are
at most r candidates that we need to focus on  the others will
be defeated irrespective of what exact shifts we make   there
are no such bounds in the destructive setting 
theorem 6  ⋆   parameterized by the shift radius  borda
#constructive shift-bribery is in fpt  for unary-
encoded prices   but the destructive variant is #w 1 -hard 
even for unit prices 
proceedings of the thirtieth    ijcai-21 
55
 proof sketch  destructive case   we give a polynomial-time
turing reduction from #matching to borda #destruc-
tive shift-bribery 
let  g  k  be an instance of
#matching  where g is a bipartite graph with vertex set
u g  ⊎ v  g   and k is a positive integer 
assume that
u g  =  u1          un   v  g  =  v1          vn   and k ≤ n 
our reduction proceeds as follows  first  we form the set
of relevant candidates r  =  d  p  ⊎ u g  ⊎ v  g   where
d is the designated candidate  moreover  for each relevant
candidate r ∈ r  we form a set d r  of 3k   1 dummy
ones  we will form an election e  where these candidates will
have the following borda scores  x is some positive integer 
whose value depends on the specifics of the construction  we
will be counting ways in which d can cease to be a winner by
shifting him or her backward by 3k positions  
scoree d  = x   3k 
scoree p  = x − k   1 
scoree u1  = · · · = scoree un  = x − 1 
scoree v1  = · · · = scoree vn  = x − 1  and
each dummy candidate has score at most x − 3k − 1 
election e contains the following voters 
1  for each edge e =  ui  vj  of the input graph  there is
an edge voter ve with preference order ve   d ≻ ui ≻
vj ≻ p ≻ d p  ≻ · · ·  
2  there is a group of voters who ensure that the scores
are as described above  they rank at least 3k dummy
candidates between each two relevant ones  so shifting d
by 3k positions back cannot change the score of another
relevant candidate  
next  we form an election f identical to e  except that one of
the edge voters ranks p one position lower  so that p s score
in f is x − k   let ie and if be instances of borda #de-
structive shift-bribery with designated candidate d 
shift radius 3k  unit prices  and elections e and f  respec-
tively  our reduction queries the oracle for the numbers of
solutions for ie and if   subtracts the latter from the former 
and outputs this value  we claim that it is exactly the number
of size-k matchings in g 
to see why this is the case  consider some solution for ie 
there are two possibilities  either d passes some member
of u g  ⊎ v  g  twice  in which case this candidate gets at
least x   1 points  whereas d always gets exactly x points  
or d passes each member of u g  ⊎ v  g  at most once  in
the latter case  only p can defeat d  all other candidates have
at most x points   however  for this to happen  d must pass p
exactly k times  with the shift radius of 3k  d cannot pass p
more times   further  since we assumed that d never passes a
member of u g  ⊎ v  g  more than once  the votes where d
passes p must correspond to a size-k matching in g  we refer
to such solutions as matching solutions 
the set of solutions for if contains all solutions for ie
except for the matching ones  because in if   p ends up with at
most x points and not x  1   so  by subtracting the number
of solutions for if from the number of solutions for ie  we
get exactly the number of size-k matchings in g 
for borda #swap-bribery  we obtain #p-hardness
and #w 1 -hardness when parameterized by the number of
voters by noting that the proofs for #shift-bribery still
apply in this case  the parameterization by the swap radius
remains open  though  the proof of theorem 6 does not work
as many new  hard to control  solutions appear  
corollary 1  borda #swap-bribery is #p-hard and
#w 1 -hard when parameterized by the number of voters 
even for the case of unit prices 
4
experiments
in the following  we use #swap-bribery to analyze the ro-
bustness of election winners experimentally  for clarity  in
this section we use normalized swap distances  which specify
the fraction of all possible swaps in a given election 
we used a dataset of 800 elections  each with 10 candidates
and 100 voters  prepared by szufa et al   2020   this dataset
contains elections generated from various statistical cultures
such as the impartial culture  urn  mallows  td-cube  and td-
sphere model  see our full version for definitions  
for each election e and candidate c  let pe c r  be the
probability that c wins—under a given voting rule—in an
election chosen uniformly at random from r e  r  
ide-
ally  we would like to compute these values exactly  how-
ever  since #swap-bribery is #p-hard for both our rules 
instead of computing these values exactly  we resorted to
sampling 
specifically  for each election  except those
with tied winners  and each normalized swap distance r ∈
 0 05  0 1          1  we sampled 500 elections at this distance
and for each candidate recorded the proportion of elections
where he or she won2  see our full version for a detailed de-
scription of the sampling procedure   for each election  we
quantify the robustness of its winner by identifying the small-
est swap distance r  among the considered ones  for which he
or she has a winning probability below 50   we refer to this
value as the 50 -winner threshold 
we present some of our findings and refer to the full
version for more detailed experiments and a deeper analy-
sis 
we start by analyzing the relation between the 50 -
winner threshold and two other measures of winner robust-
ness  namely  the score difference between the winner and the
runner-up  i e   the candidate ranked in the second place  and
the minimum number of swaps of adjacent candidates that
are necessary to change the election winner  this is simply
the optimal cost of a destructive swap-bribery with
unit prices  see the work of shiryaev et al   2013 3   to this
end  let us turn to figure 1a  for plurality  and figure 1b  for
borda   which are both split into a black part  dots  and a red
part  pluses   in both parts  each election is represented as a
marker of the respective color whose y-coordinate is the score
difference between the winner and the runner up  and whose
x-coordinate is either 
2by hoeffding s inequality  the probability that the estimated
winning probability for a given candidate deviates by more than
10  from the true one can be upper-bounded by 0 1  
3notably  both plurality destructive swap-bribery
and borda destructive swap-bribery are in p  shiryaev et
al   2013   for both problems  it suffices to iterate over all candidates
d ̸= c  where c is the original winner  and calculate the minimum
cost of modifying the election so that d has a higher score than c 
proceedings of the thirtieth    ijcai-21 
56
 0  05  1  15  2  25  3  35  4  45
0
20
40
60
80
100
50 -winner threshold  
 
score difference
0
10
20
30
40
50
optimal bribery  
 
 a  plurality
 05 1 15 2 25 3 35 4 45 5
0
50
100
150
200
250
50 -winner threshold  
 
score difference
0
50
100
150
200
optimal bribery  
 
 b  borda
figure 1  each election is represented by a red plus and a black dot
marker  the y-coordinate of each marker gives the difference be-
tween the scores of the winner and the runner-up  the x-coordinate
of the black dot gives the 50 -winner threshold  perturbed  if many
elections would overlap   while the x-coordinate of the red plus
gives the minimum cost of a successful destructive swap bribery 
0
0 2
0 4
0 2
0 4
0 6
0 8
1
r
pc r 
577
575
535
482
 a  urn 0 01
0
0 2
0 4
0 2
0 4
0 6
0 8
1
r
707
703
642
518
 b  urn 0 02
figure 2  plots showing pe c r  under borda as a function of r for
two selected elections  each line represents pe c r  for one partic-
ular candidate  in the legend  the borda scores of the candidates in
the original election are displayed  only the four candidates with
the highest borda scores are included  both elections were sampled
from the urn model 
1  the 50 -winner threshold  for black dots  perturbed a
bit if many elections were to take the same place   or
2  the minimum cost of a successful destructive swap
bribery  for red pluses  
finding 1  the score difference between the winner and the
runner-up strongly correlates with the minimum cost of a suc-
cessful destructive bribery  by contrast  the score difference
has a limited predictive value for the 50 -winner threshold 
examining the figures  we see that the score difference is
very strongly correlated with the minimum cost of a success-
ful destructive swap bribery  but that the correlation between
the score difference and the 50 -winner threshold is far less
pronounced  indeed  the same score difference may lead to
a wide range of 50 -winner thresholds  e g   for plurality a
score difference of 10 may lead to the threshold being any-
thing between 0 1 and 0 4   thus our framework adds a new
dimension to the robustness analysis of election winners 
to exemplify this phenomenon  we visualize pe c r  un-
der borda for two particular elections from the 800-elections
dataset in figure 2  for these two elections  we estimated
pe c r  for r ∈  0 0125  0 025          0 5  using 10 000 sam-
ples in each case   we want to emphasize that these elections
are not artificial extreme examples but were generated both
as part of 180 elections generated by the urn model with dif-
ferent parameters  in fact  there exist several other elections
in the dataset exhibiting a similar behavior 
noticeably  the difference between the borda score of the
red and the blue candidate in both elections is quite similar 
i e   in election  a  the difference is two and in election  b  the
difference is four  nevertheless  the robustness of the election
winner is quite different  in election  a   the winner is very
sensitive to random swaps  the blue candidate already wins
a majority of elections even if only a 0 0125 fraction of all
possible swaps are applied  i e   about half a swap per vote 
on average   it is quite surprising that so few random swaps
may change the outcome with a fairly high probability  in
contrast  in election  b   the 50 -winner threshold is around
swap distance 0 3 and the red candidate even stays the most
probable winner until more than 40  of swaps are performed 
we now turn to the differences between plurality and
borda when it comes to the robustness of election winners 
finding 2  the borda winner of an election is usually more
robust against random swaps than the plurality winner 
for borda  230 elections out of the 800 considered have
a 50 -winner threshold of 0 45  while every other threshold
occurs fewer than 90 times  in contrast  for plurality the dis-
tribution is more uniform  with small spikes of around 110
elections at thresholds 0 1 and 0 45   so  plurality elections
are more likely to change results after relatively few swaps
than the borda ones  two explanations are that  a  under plu-
rality there can be  strong contenders  who do not win  but
who are often ranked close to the first place and  thus  can
overtake the original winner after a few swaps  and  b  the
plurality winner has the highest chance of losing points  as
he or she is ranked first most often  under borda  the candi-
dates usually have similar chances of both gaining and losing
a point with a single swap 
5
conclusions
we have shown that the counting variants of swap-bribery
have high worst-case complexity  but  nonetheless  are very
useful for analyzing the robustness of election winners  in
particular  we have observed that the scores of the candidates
do not suffice to evaluate their strengths  establishing the
complexity of borda #swap-bribery parameterized by
the swap radius and the complexity of all considered #p-hard
problems parameterized by the number of candidates remain
as intriguing open problems 
acknowledgments
nb was supported by the dfg project mamu  ni 369/19  
work started while pf was visiting tu berlin based on a
friedrich wilhelm bessel award from the alexander von
humboldt foundation  rb was partially supported by the
dfg project affa  br 5207/1 and ni 369/15  
proceedings of the thirtieth    ijcai-21 
57
 references
 bachrach et al   2010  y  bachrach  n  betzler  and p  fal-
iszewski  probabilistic possible winner determination  in
proceedings of aaai-2010  pages 697–702  2010 
 barvinok  1994  a  barvinok  a polynomial time algorithm
for counting integral points in polyhedra when the dimen-
sion is fixed  math  oper  res   19 4  769–779  1994 
 baumeister and hogrebe  2020  d 
baumeister
and
t  hogrebe 
complexity of election evaluation and
probabilistic robustness  extended abstract  in proceed-
ings of aamas-2020  pages 1771–1773  2020 
 baumeister et al   2019  d  baumeister  t  hogrebe  and
l  rey  generalized distance bribery  in proceedings of
aaai-2019  pages 1764–1771  2019 
 bredereck et al   2016a  r  bredereck  j  chen  p  fal-
iszewski  a  nichterlein  and r  niedermeier  prices mat-
ter for the parameterized complexity of shift bribery  inf 
comput   251 140–164  2016 
 bredereck et al   2016b  r 
bredereck 
p 
faliszewski 
r  niedermeier  and n  talmon 
complexity of shift
bribery in committee elections 
in proceedings of
aaai-2016  pages 2452–2458  2016 
 bredereck et al   2021  r 
bredereck 
p 
faliszewski 
a  kaczmarczyk  r  niedermeier  p  skowron  and
n  talmon  robustness among multiwinner voting rules 
artif  intell   290 103403  2021 
 brightwell and winkler  1991  g  brightwell and p  win-
kler  counting linear extensions  order  8 3  225–242 
1991 
 brill et al   2020  m  brill 
u  schmidt-kraepelin 
and
w  suksompong  refining tournament solutions via mar-
gin of victory  in proceedings of aaai-2020  pages 1862–
1869  2020 
 cary  2011  d  cary  estimating the margin of victory for
instant-runoff voting  presented at 2011 electronic voting
technology workshop/workshop on trushworthy elec-
tions  2011 
 curticapean and marx  2014  r  curticapean and d  marx 
complexity of counting subgraphs  only the bounded-
ness of the vertex-cover number counts  in proceedings
of focs-2014  pages 130–139  2014 
 dorn and schlotter  2012  b  dorn and i  schlotter  multi-
variate complexity analysis of swap bribery  algorithmica 
64 1  126–151  2012 
 elkind and faliszewski  2010  e  elkind and p  faliszewski 
approximation algorithms for campaign management  in
proceedings of wine-2010  pages 473–482  2010 
 elkind et al   2009  e 
elkind 
p 
faliszewski 
and
a  slinko 
swap bribery 
in proceedings of sagt-
2009  pages 299–310  2009 
 elkind et al   2020  e  elkind  p  faliszewski  s  gupta  and
s  roy  algorithms for swap and shift bribery in structured
elections 
in proceedings of aamas-2020  pages 366–
374  2020 
 faliszewski et al   2019  p  faliszewski  p  manurangsi  and
k  sornat  approximation and hardness of shift-bribery 
in proceedings of aaai-2019  pages 1901–1908  2019 
 flum and grohe  2004  j  flum and m  grohe  the param-
eterized complexity of counting problems  siam j  com-
put   33 4  892–922  2004 
 hazon et al   2012  n  hazon  y  aumann  s  kraus  and
m  wooldridge  on the evaluation of election outcomes
under uncertainty  artif  intell   189 1–18  2012 
 kaczmarczyk and faliszewski  2019  a  kaczmarczyk and
p  faliszewski  algorithms for destructive shift bribery 
auton  agents multi-agent syst   33 3  275–297  2019 
 kenig and kimelfeld  2019  b  kenig and b  kimelfeld 
approximate inference of outcomes in probabilistic elec-
tions  in proceedings of aaai-2019  pages 2061–2068 
2019 
 knop et al   2020  d  knop  m  koutecky  and m  mnich 
voting and bribing in single-exponential time  acm trans 
econ  comput   8 3  12 1–12 28  2020 
 lenstra  jr   1983  h  lenstra  jr  integer programming with
a fixed number of variables  math  oper  res   8 4  538–
548  1983 
 magrino et al   2011  t  magrino  r  rivest  e  shen  and
d  wagner  computing the margin of victory in irv elec-
tions  in proceedings of evt/wote-2011  2011 
 maushagen et al   2018  c 
maushagen 
m 
neveling 
j  rothe  and a -k  selker  complexity of shift bribery in
iterative elections  in proceedings of aamas-2018  pages
1567–1575  2018 
 shiryaev et al   2013  d  shiryaev  l  yu  and e  elkind  on
elections with robust winners  in proceedings of aamas-
2013  pages 415–422  2013 
 szufa et al   2020  s  szufa  p  faliszewski  p  skowron 
a  slinko  and n  talmon  drawing a map of elections in
the space of statistical cultures  in proceedings of aamas-
2020  pages 1341–1349  2020 
 valiant  1979  l  valiant  the complexity of computing the
permanent  theor  comput  sci   8 2  189–201  1979 
 wojtas and faliszewski  2012  k 
wojtas
and
p 
fal-
iszewski 
possible winners in noisy elections 
in
proceedings of aaai-2012  pages 1499–1505  2012 
 xia  2012  l  xia  computing the margin of victory for var-
ious voting rules  in proceedings of ec-2012  pages 982–
999  2012 
 yang et al   2019  y  yang  y  raj shrestha  and j  guo  on
the complexity of bribery with distance restrictions  theor 
comput  sci   760 55–71  2019 
 zhou and guo  2020  a  zhou and j  guo  parameterized
complexity of shift bribery in iterative elections  in pro-
ceedings of aamas-2020  pages 1665–1673  2020 
proceedings of the thirtieth    ijcai-21 
58
 "
None,2021,https-www-ijcai-org-proceedings-2021-0009-pdf,Putting a Compass on the Map of Elections,"Niclas Boehmer, Robert Bredereck, Piotr Faliszewski, Rolf Niedermeier, Stanisław Szufa",None,https://www.ijcai.org/proceedings/2021/0009.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0009-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0009-pdf.pdf,"putting a compass on the map of elections
niclas boehmer1   robert bredereck2   piotr faliszewski3  
rolf niedermeier1 and stanisław szufa4
1algorithmics and computational complexity  tu berlin  germany
2humboldt-universit¨at zu berlin  germany
3agh university  poland
4jagiellonian university  poland
niclas boehmer@tu-berlin de  robert bredereck@hu-berlin de  faliszew@agh edu pl 
rolf niedermeier@tu-berlin de  stanislaw szufa@uj edu pl
abstract
in their aamas 2020 paper  szufa et al  pre-
sented a  map of elections  that visualizes a set of
800 elections generated from various statistical cul-
tures  while similar elections are grouped together
on this map  there is no obvious interpretation of
the elections  positions  we provide such an inter-
pretation by introducing four canonical  extreme 
elections  acting as a compass on the map  we use
them to analyze both a dataset provided by szufa
et al  and a number of real-life elections  in ef-
fect  we find a new parameterization of the mallows
model  based on measuring the expected swap dis-
tance from the central preference order  and show
that it is useful for capturing real-life scenarios 
1
introduction
experiments are gaining increasing attention in the computa-
tional social choice literature  while such studies often give
insights that would be very difficult to obtain otherwise  they
are not easy to design  for example  if we wanted to eval-
uate the running time of a certain algorithm for computing
election winners  what data should we run it on  to answer
such questions  we need to understand the space of possible
elections  this includes knowing  e g   what elections arise in
practice  what elections are generated from standard election
models  what makes elections difficult for our algorithm  and
so on  in this paper we continue the quest for understanding
the space of election by means of analyzing their distances 
as initiated by szufa et al   2020  
specifically  szufa et al   2020  proposed a technique for
visualizing sets of ordinal elections—i e   elections where
each voter ranks the candidates from the most to the least ap-
pealing one—based on given distances between them  they
have applied this technique to 800 elections coming from
various statistical cultures  ranging from the classic urn and
mallows models to various types of restricted domains  and
they obtained a map of elections  where elections with similar
properties are grouped together  see figure 1  each dot rep-
resents a single election and  generally  the closer two elec-
tions are in the picture  the smaller is their distance   indeed 
figure 1  a map for the 10x100 dataset of szufa et al   2020  
we see that elections from the same statistical cultures  repre-
sented with the same color  are nicely grouped together  sz-
ufa et al   2020  have also shown other evidence that nearby
elections are closely related 1 yet  the map has two major
drawbacks  first  while similar elections are plotted next to
each other  there is no clear meaning to absolute positions on
the map  second  the map regards statistical cultures only
and it is not obvious where real-life elections—such as those
stored in preflib  mattei and walsh  2013 —would lie on the
map  our goal is to address both these issues 
we start by looking more closely at the distance metric
for elections that szufa et al   2020  used  the idea is that
given an election with m candidates  one computes an m×m
frequency matrix which specifies what fraction of the voters
ranks each candidate in each position  such matrices are bi-
stochastic  i e   their entries are nonnegative and each column
and each row sums up to one   measuring the distance be-
tween two elections boils down to computing their frequency
matrices and summing up the earth mover s distances be-
tween their columns  where columns are reordered to min-
1the map in the figure regards elections with 10 candidates and
100 voters  whereas szufa et al   2020  focused on the case of
100 candidates and 100 voters  nonetheless  they also provided such
smaller datasets and we focus on them because we want to compare
them to real-life elections  which typically have few candidates 
proceedings of the thirtieth    ijcai-21 
59
  a  the compass and the dataset of szufa et al   2020  
 b  the compass and various real-life elections 
figure 2  maps of elections for the 10x100 dataset of szufa et al   2020   on the left  and some real-life elections  on the right   the maps
include the compass matrices and their connecting paths  shown in black  red  and blue   to highlight the paths  the dots corresponding to
the elections of szufa et al   2020   in the left figure  are shown in lighter colors than in figure 1  on the right  the pale blue area is where
mallows elections end up  for various φ parameters  and the pale orange area is where urn elections end up  for various α parameters  
imize the distance  see section 2 for definitions   szufa et
al   2020  call this distance positionwise  using frequency
matrices makes it possible to compare elections with different
numbers of voters  and reordering the columns ensures that
candidate names are irrelevant  as suggested for such settings
by faliszewski et al   2019   
our first result is an algorithm that  given a bistochastic
matrix and a number n  finds some election with n voters
whose frequency matrix is  nearly  identical to the one from
the input  achieving perfect accuracy is not always possible 
but our algorithm achieves the best result one may  in general 
hope for   as a consequence  instead of considering elections 
we may directly look at the space of bistochastic matrices 
which simplifies many discussions  consequently  we often
speak of matrices and elections interchangeably 
next  we form what we call a compass  the idea is to pick
matrices that  on the one hand  are far away from each other 
and  on the other hand  have natural interpretations  specifi-
cally  we consider the following four  extreme  matrices  cor-
responding to four types of  dis agreement among the voters 
1  the identity matrix  id  modelling perfect agreement
 all voters have the same preference order  
2  the uniformity matrix  un  modelling lack of agree-
ment  each candidate takes each position equally often  
3  the stratification matrix  st  modelling partial agree-
ment  voters agree that half of the candidates are better
than the other half  but lack agreement on anything else  
4  the antagonism matrix  an  modelling conflict  half of
the voters have opposite preferences to the other half  
for each two of these  compass  matrices  we also con-
sider a spectrum of their convex combinations   paths  be-
tween the matrices   in visualizations  these paths appear as
a parallelogram-like shape with corresponding  diagonals  
see  e g   figure 2a  where we apply the compass method to
the dataset from figure 1  the black  blue  and red points are
certain convex combinations of the corresponding endpoints 
which are the compass matrices   the remainder of the paper
largely consists of explaining why we get what we see here 
the compass allows us to make a number of observa-
tions  for example  in figure 2a we see that 1d interval elec-
tions are closer to the antagonism matrix  whereas higher-
dimensional hypercube elections are closer to the stratifica-
tion one  this is intriguing as  on a formal level  these two
kinds of elections are very similar  figure 2b  which shows
a map of real-life elections  some from preflib and some
new ones  is even more striking  most of the real-life elec-
tions  including all political ones  end up in one  quadrant 
of the parallelogram  and essentially all elections end up in
the vicinity of some mallows elections  the pale blue area is
where mallows elections end up  depending on the parameter
of the model  the pale orange area is where urn elections end
up   so  if one were to run experiments with a single statisti-
cal culture  the mallows model might be a wise choice 
yet  we find that seemingly natural ways of sampling mal-
lows elections  e g   by choosing the mallows parameter uni-
formly at random  or using a fixed parameter for different
numbers of candidates   which are used in many research pa-
pers  are biased  we propose a normalization and argue  both
theoretically and by considering the compass  that it produces
more balanced results  in other words  we recommend using
the mallows model  but in conjunction with our normaliza-
tion 
we provide details missing from this paper in its full ver-
sion  available as a technical report  boehmer et al   2021  
2
preliminaries
given an integer t  we write  t  to denote the set  1          t  
by r  we mean the set of nonnegative real numbers  given a
vector x =  x1          xm   we interpret it as an m × 1 matrix 
i e   we use column vectors  for a matrix x  we write xi j to
refer to the entry in its i-th row and j-th column 
proceedings of the thirtieth    ijcai-21 
60
 elections 
an election e is a pair  c  v    where c =
 c1          cm  is a set of candidates and v =  v1          vn 
is a collection of voters  each voter v ∈ v has a preference
order ≻v  which ranks the candidates from the most to the
least desirable one according to v  if v prefers candidate a
to candidate b  then we write v  a ≻ b  and we extend this
notation to more candidates in a natural way  for a voter v
and a candidate c  we write posv c  to denote the position
on which v ranks c  the top-ranked candidate has position 1 
the next one has position 2  and so on   we refer to both the
voters and their preference orders as the votes  the intended
meaning will always be clear from the context 
position and frequency matrices 
let e =  c  v   be an
election  where c =  c1          cm  and v =  v1          vn  
for a candidate c ∈ c and position i ∈  m   we write
#pose c  i  to denote the number of voters in election e that
rank c on position i  by #pose c  we mean the vector 
 #pose c  1   #pose c  2           #pose c  m   
the position matrix for election e  denoted #pos e   is the
m × m matrix that has vectors #pose c1           #pose cm 
as its columns  we also consider vote frequencies rather than
absolute counts  to this end  for a candidate c and a po-
sition i ∈  m   let #freqe c  i  = #pose c i /n  let vector
#freqe c  =  #freqe c  1           #freqe c  m    and let the
frequency matrix for election e  denoted #freq e   consist
of columns #freqe c1           #freqe cm   note that in each
position matrix  each row and each column sums up to the
number of voters in the election  similarly  in each frequency
matrix  the rows and columns sum up to one  such matrices
are called bistochastic  
example 1  let e =  c  v   be an election  where c =
 a  b  c   v =  v1          v6   and the preference orders are
v1   a ≻ b ≻ c  v2   a ≻ b ≻ c  v3   a ≻ b ≻ c  v4   b ≻ a ≻
c  v5   c ≻ a ≻ b  v6   c ≻ a ≻ b  the position and frequency
matrices for this election are 
�
a
b
c
1
3
1
2
2
3
3
0
3
0
2
4
�
and
�
a
b
c
1
1/2
1/6
1/3
2
1/2
1/2
0
3
0
1/3
2/3
�
earth mover s distance  emd  
let x =  x1          xt  and
y =  y1          yt  be two vectors from rt
   whose entries sum
up to 1  the earth mover s distance between x and y  denoted
emd x  y   is defined as the lowest total cost of operations
that transform vector x into vector y  where each operation
is of the form  subtract δ from position i and add δ to posi-
tion j  and costs δ · |i − j|  such an operation is legal if the
current value at position i is at least δ  emd x  y  can be
computed in polynomial time using a greedy algorithm 
positionwise distance 
let e =  c  v   and f =  d  u 
be two elections with m candidates each  we do not require
that |v | = |u|  
the positionwise distance between e
and f  denoted pos e  f   is defined in terms of fre-
quency matrices #freq e  =  e1          em  and #freq f  =
 f1          fm  as follows  szufa et al   2020  
pos e  f   = minσ∈sm
��m
i=1 emd ei  fσ i  
�
 
where sm is the permutation group on m elements 
in
other words  the positionwise distance is the sum of the earth
mover s distances between the frequency vectors of the can-
didates from the two elections  matched optimally according
to σ  the positionwise distance is invariant to renaming the
candidates and reordering the voters 
statistical cultures 
we define the following three statisti-
cal cultures  i e   models of generating random elections 2
impartial culture under the impartial culture  ic  model 
we sample all votes uniformly at random 
p olya-eggenberger urn model  berg  1985  the urn mo-
del uses a nonnegative parameter α  which gives the
level of correlation between the votes  this parameter-
ization is due to mccabe-dansted and slinko  2006   
to generate an election with m candidates  we start with
an urn containing one copy of each possible preference
order and generate the votes iteratively  in each step we
uniformly at random draw an order from the urn  this is
the voter s preference order  and return it to the urn to-
gether with αm  copies  for α = 0 we obtain the ic
model 
mallows model  mallows  1957  the mallows model uses
parameter φ ∈  0  1  and a central preference order v 
each vote is generated randomly and independently  the
probability of generating preference order u is propor-
tional to φκ v u   where κ v  u  is the swap distance be-
tween u and v  i e   the minimum number of swaps of
adjacent candidates needed to transform u into v  
maps of elections 
szufa et al   2020  drew a map of elec-
tions by computing the positionwise distances between 800
elections drawn from various statistical cultures and visual-
izing them using the force-directed algorithm of fruchter-
man and reingold  1991   they focused on elections with
100 candidates and 100 voters  but also generated smaller
datasets  available on their website  we consider their dataset
with 10 candidates and 100 voters  see figure 1 for its map  
we use the same algorithm as they do for our visualizations 
except that for each two elections we set their attraction coef-
ficient to be the square of their positionwise distance  and not
the distance itself  as done by szufa et al   this groups simi-
lar elections more tightly and gives more visually appealing
results for elections with few candidates   we stress that the
maps that both we and szufa et al   2020  provide are help-
ful tools to illustrate the distances between particular  fami-
lies of  elections  but are certainly not perfect  for example 
since the visualization algorithm is randomized  we can get
slightly different maps for each run of the algorithm  the vi-
sualizations also depend on the exact composition of the set
of depicted elections  thus  whenever we say that some two
elections are close to each other  we mean that their position-
wise distance is small  while this is typically reflected by
these two elections being close on the map  on its own  close-
ness on the map does not suffice for such a claim 
2sometimes  we refer to other statistical cultures used by szufa
et al   2020   we do not define them formally here  but we attempt
to make our discussions intuitively clear 
proceedings of the thirtieth    ijcai-21 
61
 3
recovering elections from matrices
throughout this paper we often deal with frequency matri-
ces of elections  while computing a frequency matrix of an
election is straightforward  the reverse direction is less clear 
we first note that each m × m position matrix has a cor-
responding m-candidate election with at most m2 − 2m   2
distinct preference orders 
proposition 1  leep and myerson  1999    given an m ×
m position matrix x  one can compute in o m4 5  time an
election e with at most m2 − 2m   2 different votes  such
that #pos e  = x 
next  we consider recovering elections based on frequency
matrices  given an m × m bistochastic matrix x and a num-
ber n of voters  we would like to find an election e with po-
sition matrix nx  this may be impossible as nx may have
fractional entries  but we can get very close to this goal  the
next proposition justifies speaking of elections and frequency
matrices interchangeably 
proposition 2  given an m × m bistochastic matrix x
and an integer n  one can compute in polynomial time an
election e with n voters whose position matrix p satisfies
|nxi j − pi j| ≤ 1 for each i  j ∈  m  and  under this condi-
tion  minimizes the value �
1≤i j≤m |nxi j − pi j| 
4
setting up the compass
our  compass  consists of two main components  four ma-
trices that occupy very different areas of the election space
and represent different types of  dis agreement among the
voters  and six paths consisting of their convex combinations 
4 1
the four matrices
below we define the four matrices and explain our choice 
identity and uniformity 
our first two matrices are the
identity matrix  idm  with ones on the diagonal and zeros
elsewhere  and the uniformity matrix  unm  with each entry
equal to 1/m  the identity matrix corresponds to elections
where each voter has the same preference order  i e   there is
a common ordering of the candidates from the most to the
least desirable one  in contrast  the uniformity matrix cap-
tures elections where each candidate is ranked on each po-
sition equally often  i e   where  in aggregate  all the candi-
dates are viewed as equally good  uniformity elections are
quite similar to the ic ones and  in the limit  indistinguish-
able from them  i e   with sufficiently many voters  we would
not see a difference between ic and un  with fewer voters 
ic elections are at some small distance from uniformity  
stratification 
the next matrix  stratification  is defined as
follows  we assume that m is even  
stm =
�
unm/2
0
0
unm/2
�
 
stratification matrices correspond to elections where the vot-
ers agree that half of the candidates are more desirable than
the other half  but  in aggregate  are unable to distinguish be-
tween the qualities of the candidates in each group 
antagonism 
let ridm be the matrix obtained by reversing
the order of the columns of the identity matrix idm  we de-
fine the antagonism matrix  anm  to be 1/2idm   1/2ridm 
such matrices are generated  e g   by elections where half of
the voters rank the candidates in one order  and half of the
voters rank them in the opposite one  so there is a clear con-
flict  in some sense  stratification and antagonism are based
on similar premises  under stratification  the group of can-
didates is partitioned into halves with different properties 
whereas in antagonism the voters are partitioned  however 
the nature of the partitioning is  naturally  quite different 
we chose the above matrices because they capture natural 
intuitive phenomena and seem to occupy very different ar-
eas of the space of elections  although we are sure that other
choices would be possible  too   below we calculate the po-
sitionwise distances between our matrices 
proposition 3  if m is divisible by 4  then it holds that 
1  pos idm  unm  = 1
3 m2 − 1  
2  pos idm  anm  = pos unm  stm  = m2
4  
3  pos idm  stm  = pos unm  anm  = 2
3  m2
4 − 1  
4  pos anm  stm  = 13
48m2 − 1
3 
to normalize these distances  we divide them by d m  =
pos idm  unm   which we suspect to be the largest posi-
tionwise distance between two matrices over m candidates 
for each two matrices x and y among our four  we let
d x  y    = limm→∞ p os xm ym /d m   a simple compu-
tation shows the following  see also figure 3a  we sometimes
omit the m subscript for clarity  
d id  un  = 1 
d id  an  = d un  st  = 3/4 
d an  st  = 13/16 
d id  st  = d un  an  = 1/2 
for small m  using ilps  we verified that each compass
matrix is almost as far away as possible from the others  sim-
ilarly  for each m ∈  3          7  we verified that idm and
unm are the two most distant matrices under the position-
wise distance  indeed  we believe that id and un are the two
most distant frequency matrices  i e   they form the diameter
of our space  however  showing this seems to be challenging 
4 2
paths between election matrices
next  we consider convex combinations of frequency matri-
ces  given two such matrices  x and y   and α ∈  0  1  
one might expect that matrix z = αx    1 − α y would
lie at distance  1 − α pos x  y   from x and at distance
αpos x  y   from y   so that we would have 
pos x  y   = pos x  z    pos z  y   
however  without further assumptions this is not necessarily
the case  indeed  if we take x = idm and y = ridm 
then 0 5x   0 5y
= anm and pos x  y   = 0  but
pos x  0 5x   0 5y   = pos id  an  > 0  yet  if we
arrange the two matrices x and y so that their positionwise
distance is achieved by the identity permutation of their col-
umn vectors  then their convex combination lies exactly be-
tween them 
proceedings of the thirtieth    ijcai-21 
62
 un
id
an
st
1
1
2
3
4
13
16
3
4
1
2
 a  normalized distances be-
tween the four matrices 
 b  urn elections  orange   α fol-
lows the gamma distribution 
 c  mallows elections  teal   φ
chosen uniformly at random 
 d  mallows elections  teal   rel-φ
chosen uniformly at random 
figure 3  visualization of our four matrices and the connecting paths  in figure 3a we show the normalized distances between the four
matrices  whereas in the remaining three pictures we show the matrices  the connecting paths  and  respectively  urn elections and mallows
elections  for two distributions of their parameter   these visualizations are for 20 candidates and 100 voters 
proposition 4  let x =  x1          xm  and y =  y1        ym 
be two m × m frequency matrices such that 
pos x  y   = �m
i=1 emd xi  yi  
then  for each α ∈  0  1  it holds that pos x  y   =
pos x  αx    1 − α y     pos αx    1 − α y  y   
using proposition 4  for each two compass matrices we
can generate a sequence of matrices that form a path between
them  for example  matrix 0 5id   0 5un is exactly at the
same distance from id and from un  in figure 2a we show
a map of elections that  in addition to the dataset of szufa et
al   2020   contains our four compass matrices and for each
two of them  a set of ⌈50·d x  y  ⌉ matrices obtained as their
convex combinations with values of α uniformly distributed
in  0  1   for all other maps including the compass  the six
paths were generated in the same way  the positionwise dis-
tances between any two of our four matrices are achieved by
the identity permutation  as required by proposition 4 
5
applying the compass
in this section  we apply our compass for a deeper under-
standing of the map of elections created by szufa et al   2020 
and place some real-life elections on the map  we also con-
sider where mallows and urn elections land on the maps 
5 1
a map of statistical cultures with a compass
in figure 2a  we show a map of the 800 elections provided
by szufa et al   2020  in their 10x100 dataset  together with
the compass  as expected  the uniformity matrix is close to
the impartial culture elections  but still at some distance from
them  similarly  the identity matrix is very close to the mal-
lows elections with close-to-zero values of φ  indeed  such
elections consist of nearly identical votes 
the red path  linking an and st  roughly partitions the
elections into those closer to un and those closer to id 
the latter group consists mostly of mallows and urn elections
 with low φ or high α  respectively   but single-crossing and
some single-peaked elections also make an appearance 
analyzing the distances of elections to an and st  it is
striking that 1d interval elections lie closer to an  while
other hypercube elections lie closer to st  even though  for-
mally  they are similar  it is also intriguing that single-peaked
elections generated according to the walsh model  walsh 
2015  are closer to st  whereas those from the conitzer
model  conitzer  2009   which are very similar to the 1d in-
terval ones  are closer to an 3 a brief explanation for read-
ers familiar with single-peaked elections is as follows  in the
conitzer model  given a societal axis  i e   an underlying or-
der of the candidates  e g   from left to right in the political
spectrum   we generate a vote by choosing a top-ranked can-
didate uniformly at random and extending the vote with can-
didates to the left and to the right  on the axis  with equal
probability 
so  by choosing close-to-extreme candidates
from different sides of the axis as top-ranked  we generate
close-to-opposite preference orders with fairly high probabil-
ity  under the walsh model  we choose each single-peaked
preference order uniformly at random  there are few such
preference orders with extreme candidates ranked highly  but
many with the center ones on top  this leads to stratification 
5 2
urn and mallows elections
our next goal is to place  paths  of urn and mallows elections
on the map  in both cases it requires some care  recall that
the urn model has parameter α  which takes values between 0
and ∞  to generate an urn election  we choose α according
to the gamma distribution with shape parameter k = 0 8 and
scale parameter θ = 1  this ensures that about half of the urn
elections are closer to un than to id  see figure 3b  
regarding the mallows model  we have a parameter φ that
takes values between 0 and 1  where 0 leads to generating id
elections and 1 leads to generating ic ones  it is thus intuitive
to choose φ uniformly at random from the  0  1  interval  yet 
as seen in figure 3c  doing so places elections quite unevenly
on the map  similarly  for different numbers of candidates
the same value of φ leads to choosing elections at different
distances from id  see the left part of figure 4   thus we
seek a new parameterization of the mallows model 
normalizing mallows 
consider a setting with m candi-
dates  for φ ∈  0  1   let expswaps m  φ  be the expected
swap distance between an m-candidate vote generated us-
ing the mallows model with parameter φ and the center
vote  we define the relative expected number of swaps as
relswaps m  φ  =
expswaps m φ 
m m−1 /2
 see the right part of fig-
ure 4 for plots of this value   in our approach  we choose
3the average distance of walsh elections to st is about half of
their distance to an  for conitzer elections this relation is reversed 
proceedings of the thirtieth    ijcai-21 
63
 0 0
0 2
0 4
0 6
0 8
1 0
0 0
0 2
0 4
0 6
0 8
1 0
φ parameter
normalized distance from id
m=5
m=10
m=20
m=50
m=100
0 0
0 2
0 4
0 6
0 8
1 0
0
0 1
0 2
0 3
0 4
0 5
φ parameter
exp  rel  number of swaps
m=5
m=10
m=20
m=50
m=100
figure 4  average normalized positionwise distances of mallows
elections from id  on the left   and relative expected number of
swaps in votes drawn from the mallows model  on the right   both
depending on φ and for different numbers m of candidates 
a value rel-φ ∈  0  1  as a parameter  find a φ such that
relswaps m  φ  = rel-φ  and draw an election from the mal-
lows model using this φ  see the full paper for details   work-
ing on rel-φ instead of φ not only allows for an intuitive and
natural interpretation of the parameter as the relative expected
number of swaps in each vote  or the normalized distance
from id   but also for obtaining comparable elections for dif-
ferent numbers of candidates  in figures 3c and 3d we vi-
sualize mallows elections generated with φ ∈  0  1  and rel-
φ ∈  0  0 5  chosen uniformly at random  respectively  we use
rel-φ ≤ 0 5 because for larger values one obtains analogous
elections  but reversed  e g   both rel-φ = 0 and rel-φ = 1
lead to identity elections   figure 3d shows a far more bal-
anced distribution of points 
importance of the new normalization 
the new param-
eterization of mallows seems to be important 
the mal-
lows model is often used in experiments and—in light of our
findings—using a fixed φ for different numbers of candidates
or drawing φ from a distribution independent of the number
of candidates  may be questionable  yet  this is not uncom-
mon  as witnessed  e g   in the works of betzler et al   2014  
goldsmith et al   2014   skowron et al   2015   bachrach et
al   2016   garg et al   2019   and in a number of other pa-
pers  we mention these works as examples only  their au-
thors designed their experiments as best practice suggested at
the time and we do not challenge their high-level conclusions 
our point is that given the current evidence  they might prefer
to design their experiments a bit differently 
5 3
real-life elections on the map
let us now consider where real-life elections appear on the
map  we start by describing the datasets that we use  mostly
from preflib  due to mattei and walsh  2013    see the full
paper for details on how the data was selected and prepro-
cessed  in particular  we converted partial preference orders
to complete ones using a simplified variant of the approach
proposed by doucette  2016   whenever we speak of real-life
elections in this section  we mean elections from our datasets 
we chose eleven real-life datasets  where each belongs
to one of three groups 
the first group contains politi-
cal elections  city council elections from glasgow and as-
pen   o neill  2013    elections from north dublin  meath
 irish   and elections held by non-profit organizations  trade
unions  and professional organizations  ers   the second
group consists of sport elections  tour de france  tdf   giro
d italia  gdi   speed skating  and figure skating  the former
three dataset are due to us   the last group consists of sur-
veys  preferences over sushi  t-shirt designs  and costs of
living and population in different cities   caragiannis et al  
2019    for tdf and gdi  each race is a vote  and each
season is an election  for speed skating  each lap is a vote 
and each competition is an election  for figure skating  each
judge s opinion is a vote  and each competition is an election 
in figure 2b we show a map of these real-life elections
along with the compass  mallows  and urn elections  for
readability we present mallows and urn elections as large 
pale-colored areas  not all real-life elections form clear clus-
ters  hence the labels refer to largest compact groupings 
while the map is not a perfect representation of distances
among elections  analyzing it leads to many conclusions 
most strikingly  real-life elections occupy a very limited area
of the map  this is especially true for political elections and
surveys  except for several sport elections  all elections are
closer to un than to id  strictly speaking  this is true for 142
elections out of 165   and none of the real-life elections falls
in the top-right part of the map  in the visualization   an-
other observation is that mallows elections go right through
the real-life elections  while urn elections are on average far
away  this means that for most real-life elections there exists
a parameter φ such that elections generated according to the
mallows model with that parameter are relatively close  in
particular  we suggest using rel-φ ∈  0 36  0 39  to capture
political elections  see the full paper for more details  
most of the political elections lie close to one another and
are located next to mallows elections and high-dimensional
hypercube ones  sport elections are spread over a larger part
of the map and  with the exception of gdi  are shifted toward
id  as to the surveys  the city survey is basically equivalent
to a sample from ic  the sushi survey is similar to political
elections  the t-shirt survey is shifted toward stratification 
6
summary
we have provided a way to interpret locations on the map of
elections of szufa et al   2020   we have also shown where
real-life elections end up on this map  which lead to a number
of observations regarding both synthetic and real-life elec-
tions  in doing so  we identified and fixed a certain flaw in a
typical way of sampling mallows elections  it is important to
confirm our experimental observations theoretically  perhaps
the most pressing such issue is to verify if identity and uni-
formity indeed are the two most distant frequency matrices 
acknowledgments
niclas boehmer was supported by the dfg project mamu
 ni 369/19   this project has received funding from the eu-
ropean research council  erc  under the european union s
horizon 2020 research and innovation programme  grant
agreement no 101002854  
proceedings of the thirtieth    ijcai-21 
64
 references
 bachrach et al   2016  y  bachrach  o  lev  y  lewenberg 
and y  zick  misrepresentation in district voting  in pro-
ceedings of ijcai-2016  pages 81–87  2016 
 berg  1985  s  berg  paradox of voting under an urn model 
the effect of homogeneity  public choice  47 2  377–387 
1985 
 betzler et al   2014  n  betzler  r  bredereck  and r  nie-
dermeier  theoretical and empirical evaluation of data for
exact kemeny rank aggregation  autonomous agents and
multiagent systems  28 5  721–748  2014 
 boehmer et al   2021  n  boehmer  r  bredereck  p  fal-
iszewski  r  niedermeier  and s  szufa 
putting a
compass on the map of elections 
technical report
arxiv 2105 07815  cs gt   arxiv org  may 2021 
 caragiannis et al   2019  i  caragiannis  x  chatzigeorgiou 
g  krimpas  and a  voudouris 
optimizing positional
scoring rules for rank aggregation  artificial intelligence 
267 58–77  2019 
 conitzer  2009  v  conitzer  eliciting single-peaked pref-
erences using comparison queries 
journal of artificial
intelligence research  35 161–191  2009 
 doucette  2016  j  doucette  social choice for partial pref-
erences using imputation  phd thesis  university of wa-
terloo  2016 
 faliszewski et al   2019  p 
faliszewski 
p 
skowron 
a  slinko  s  szufa  and n  talmon 
how similar are
two elections 
in proceedings of aaai-2019  pages
1909–1916  2019 
 fruchterman and reingold  1991  t 
fruchterman
and
e  reingold  graph drawing by force-directed placement 
software  practice and experience  21 11  1129–1164 
1991 
 garg et al   2019  n  garg  l  gelauff  s  sakshuwong  and
a  goel  who is in your top three  optimizing learn-
ing in elections with many candidates  in proceedings of
hcomp-2019  pages 22–31  2019 
 goldsmith et al   2014  j  goldsmith  j  lang  n  mattei 
and p  perny  voting with rank dependent scoring rules 
in proceedings of aaai-2014  pages 698–704  2014 
 leep and myerson  1999  d  leep and g  myerson  mar-
riage  magic  and solitaire  the american mathematical
monthly  106 5  419–429  1999 
 mallows  1957  c  mallows  non-null ranking models  bio-
metrica  44 114–130  1957 
 mattei and walsh  2013  n  mattei and t  walsh  preflib 
a library for preferences  in proceedings of adt-2013 
pages 259–270  2013 
 mccabe-dansted and slinko  2006  j 
mccabe-dansted
and a  slinko 
exploratory analysis of similarities
between social choice rules 
group decision and
negotiation  15 77–107  2006 
 o neill  2013  j  o neill  open stv  www openstv org 
2013  accessed  2021-05-26 
 skowron et al   2015  p  skowron 
p  faliszewski 
and
a  slinko 
achieving fully proportional representation 
approximability result 
artificial intelligence  222 67–
103  2015 
 szufa et al   2020  s  szufa  p  faliszewski  p  skowron 
a  slinko  and n  talmon  drawing a map of elections in
the space of statistical cultures  in proceedings of aamas-
2020  pages 1341–1349  2020 
 walsh  2015  t  walsh 
generating single peaked votes 
technical report arxiv 1503 02766  cs gt   arxiv org 
march 2015 
proceedings of the thirtieth    ijcai-21 
65
 "
None,2021,https-www-ijcai-org-proceedings-2021-0010-pdf,Loyalty in Cardinal Hedonic Games,"Martin Bullinger, Stefan Kober",None,https://www.ijcai.org/proceedings/2021/0010.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0010-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0010-pdf.pdf,"loyalty in cardinal hedonic games
martin bullinger and stefan kober
technical university of munich
bullinge@in tum de  stefan kober@tum de
abstract
a common theme of decision making in multi-
agent systems is to assign utilities to alternatives 
which individuals seek to maximize  this rationale
is questionable in coalition formation where agents
are affected by other members of their coalition 
based on the assumption that agents are benevolent
towards other agents they like to form coalitions
with  we propose loyalty in hedonic games  a bi-
nary relation dependent on agents  utilities  given
a hedonic game  we define a loyal variant where
agents  utilities are defined by taking the minimum
of their utility and the utilities of agents towards
which they are loyal  this process can be iterated
to obtain various degrees of loyalty  terminating in
a locally egalitarian variant of the original game 
we investigate axioms of group stability and effi-
ciency for different degrees of loyalty  specifically 
we consider the problem of finding coalition struc-
tures in the core and of computing best coalitions 
obtaining both positive and intractability results  in
particular  the limit game possesses pareto optimal
coalition structures in the core 
1
introduction
decision making in multi-agent systems is highly driven by
the idea of the homo economicus  a rational decision taker
that seeks to maximize her individual well-being  follow-
ing the classical theory of games and economic behavior
by von neumann and morgenstern  agents assign utilities to
alternatives and aim for an outcome that maximizes individ-
ual utility  such behavior entails many delicate situations in
non-cooperative game theory such as the prisoner s dilemma
or the tragedy of the commons  hardin  1968   where agents
take decisions in their individual interest without regarding
other agents  this leads to outcomes that are bad for the so-
ciety as a whole and often  as it is the case in the prisoner s
dilemma  agents have an incentive to coordinate to improve
their respective situation 
from the theoretical point of view  one can either accept
the existence of such dilemmata and study their social im-
pact  for instance  by means of the price of anarchy  kout-
soupias and papadimitriou  1999   or one can ask for the de-
gree of individual dependency on the social outcome neces-
sary to escape a situation of inferior welfare  the latter idea
is implemented by adapting the utility function of players as
a weighted sum of individual and joint utility  an idea repeat-
edly developed in network design  elias et al   2010   arti-
ficial intelligence  apt and sch¨afer  2014   or public choice
 mueller  1986   specifically  the selfishness level by apt and
sch¨afer is the lowest weight on the joint utility such that a
nash equilibrium becomes a social optimum 
on the other hand  empirical evidence does not only ques-
tion whether agents behave according to the utility model
by von neumann and morgenstern  kahneman and tversky 
1979   but even supports the hypothesis that human behavior
is steered by the well-being of the whole society  colman et
al   2008   however  in scenarios of high competition  agents
might also act spiteful towards other agents  i e   there is an
incentive to harm other agents  levine  1998  
in cooperative game theory  it seems to be an even more
reasonable assumption to include other agents into the own
valuation  we follow this line of thought in the setting of
coalition formation  where we propose loyalty  a possibility
to modify utilities by taking into account other agents  utili-
ties towards which loyalty is perceived  loyalty is a binary
relation directly extracted from the agents  utilities over part-
nership  i e   coalitions of size 2  loyalty is sensed towards
the agents within the own coalition that yield positive utility
in a partnership  following the paradigm of a chain that is
only as strong as its weakest link  loyal utilities are obtained
by taking the minimum of the own utility and the utilities of
agents receiving our loyalty  as such  we obtain a loyal vari-
ant of the original game  which is itself a coalition formation
game  and we can iterate towards various degrees of loyalty 
as we will see  this process terminates in a game which satis-
fies a high degree of egalitarianism  we consider common so-
lution concepts concerning group stability and efficiency for
different degrees of loyalty and the limit game  and provide
both existential and computational results 
we study coalition formation in the framework of hedonic
games  dr eze and greenberg  1980  banerjee et al   2001 
bogomolnaia and jackson  2002   our contribution lies in
studying aspects of empathy in hedonic games  brˆanzei and
larson  2011  monaco et al   2018  nguyen et al   2016   pre-
vious work considers empathy between agents through vari-
proceedings of the thirtieth    ijcai-21 
66
 ous alternative utility functions based on friendship relations
among the agents extracted from utility functions or a social
network  closest to our work are altruistic hedonic games in-
troduced by nguyen et al   2016  and subsequently studied
by wiechers and rothe  2020   kerkmann and rothe  2020  
and schlueter and goldsmith  2020   our first degree of loy-
alty in symmetric friend-oriented hedonic games coincides
with minimum-equal-treatment altruistic hedonic games as
defined by wiechers and rothe  2020   we significantly ex-
tend their model  but since most of our hardness results work
for the restricted class of symmetric friend-oriented hedonic
games  they have immediate consequences for this type of al-
truistic hedonic games  also  loyal variants of hedonic games
fit into the framework of super altruistic hedonic games by
schlueter and goldsmith  2020  if their aggregation is mod-
ified by taking the average instead of the minimum of other
agents  utilities 
2
preliminaries and model
we start with some notation  define  i  =  1          i  and
 i  j  =  i          j  for i  j ∈ z  i ≤ j 
also  we use standard notions from graph theory  let g =
 v  e  be an undirected graph  for a subset of agents w ⊆
v   denote by g w  the subgraph of g induced by w  given
two vertices v  w ∈ v   we denote by dg v  w  their distance
in g  i e   the length of a shortest path connecting them  the
graph g is called regular if there exists a non-negative integer
r such that every vertex of g has degree r 
in the following subsections  we introduce hedonic games 
our concept of loyalty  and desirable properties of coalition
structures 
2 1
cardinal hedonic games
let n =  1          n  be a finite set of agents  a coalition is a
non-empty subset of n  by ni we denote the set of coalitions
agent i belongs to  i e   ni =  s ⊆ n   i ∈ s   a coalition
structure  or simply a partition  is a partition π of the agents
n into disjoint coalitions  where π i  denotes the coalition
agent i belongs to  a hedonic game is a pair  n  ≿   where
≿ =  ≿i i∈n is a preference profile specifying the prefer-
ences of each agent i as a complete and transitive preference
relation ≿i over ni  in hedonic games  agents are only con-
cerned about their own coalition  accordingly  preferences
over coalitions naturally extend to preferences over partitions
as follows  π ≿i π′ if and only if π i  ≿i π′ i  
throughout the paper  we assume that rankings over the
coalitions in ni are given by utility functions ui   ni → r 
which are extended to evaluate partitions in the hedonic way
by setting ui π  = ui π i    a hedonic game together with
a representation by utility functions is called cardinal hedo-
nic game  because the sets ni are finite  preferences could
in principle always be represented by cardinal values  this is
impractical due to two reasons  first  such utility functions
require exponential space to represent  therefore it would be
desirable to consider classes of hedonic games with succinct
representations  second  we would like to compare different
agents  utility functions such that a certain cardinal value ex-
presses the same intensity of a preference for all agents  this
cannot be guaranteed by arbitrary utility representations of
ordinal preferences  our model of loyalty is therefore partic-
ularly meaningful in succinctly representable classes of car-
dinal hedonic games  these include the following classes of
hedonic games  which aggregate utility functions over single
agents of the form ui   n → r where ui i  = 0  which can
be represented by a complete weighted digraph 
• additively separable hedonic games  ashgs   bogo-
molnaia and jackson  2002   utilities are aggregated
by taking the sum of single utilities  i e   ui π  =
�
j∈π i  ui j  
• friend-oriented hedonic games  fohgs   dimitrov et
al   2006   the restriction of ashgs where utilities for
other agents are either n  the agent is a friend  or −1
 the agent is an enemy   i e   for all i  j ∈ n with
i ̸= j  ui j  ∈  n  −1  
given an fohg  the set
fi =  j ∈ n   ui j  = n  is called friend set of agent i 
the unweighted digraph gf =  n  a  where  i  j  ∈ a
if and only if j ∈ fi is called friendship graph  an
fohg can be represented by specifying the friend set
for every agent or by its friendship graph 
• modified fractional hedonic games  mfhgs   olsen 
2012   utilities are aggregated by dividing the sum of
single utilities by the size of the coalition minus 1  i e  
ui π  = 0 if π i  =  i   and ui π  =
�
j∈π i  ui j 
|π i |−1
  oth-
erwise  in other words  the utility of a coalition structure
is the expected utility achieved through another agent in
the own coalition selected uniformly at random 
a cardinal hedonic game is called mutual if  for all pairs
of agents i  j ∈ n  ui j  > 0 implies uj i  > 0  it is called
symmetric if  for all pairs of agents i  j ∈ n  ui j  = uj i  
clearly  symmetric games are mutual  throughout most of
the paper  we will consider at least mutual variants of the
classes of hedonic games  which we just introduced 
2 2
loyalty in hedonic games
we are ready to define our concept of loyalty  given a cardi-
nal hedonic game  its loyal variant needs to specify two key
features  first  for every agent  we need to identify a loyalty
set  which contains the agents towards which loyalty is ex-
pressed  second  we need to specify how loyalty is expressed 
i e   how to obtain new  loyal utility functions 
formally  given a cardinal hedonic game and an agent
i ∈ n  we define her loyalty set as li =  j ∈ n \
 i   ui  i  j   > 0   in other words  agents are affected
by agents that influence them positively when being in a
joint coalition 
note that for all hedonic games consid-
ered in this paper  the loyalty set is equivalently given by
li =  j ∈ n \  i   ui  i  j   > ui i    i e   it contains
the agents with which i would rather form a coalition of size
2 than staying on her own  the loyalty graph is the directed
graph gl =  n  a  where  i  j  ∈ a if and only if j ∈ li 
it remains to specify how agents aggregate utilities in a
loyal way  given a cardinal hedonic game  its loyal variant
is defined on agent set n by the utility function ul
i  π  =
minj∈π i ∩ li∪ i   uj π i    interestingly  the loyal variant
is itself a hedonic game  and we can consider its own loyal
proceedings of the thirtieth    ijcai-21 
67
 variant  following this reasoning  we recursively define the
k-fold loyal variant by setting the 1-fold loyal variant to the
loyal variant and the  k   1 -fold loyal variant to the loyal
variant of the k-fold loyal variant  also  we denote by uk
i and
lk
i the utility function and the loyalty set of an agent i  and
by gk
l the loyalty graph of the k-fold loyal variant 
in fact  we will see that this process terminates after at
most n steps in a limit game that satisfies egalitarianism at
the level of coalitions  for simplicity  we restrict attention
to mutual cardinal hedonic games  where the loyalty sets
defines a symmetric binary relation and the loyalty graph
can be represented by an undirected graph 1 for an agent
i ∈ n  let gπ
l i  be the agents in the connected compo-
nent of the subgraph of gl induced by π i  containing i 
now  define the locally egalitarian variant of a cardinal he-
donic game as the game on agent set n with utilities given
by ue
i  π  = minj∈gπ
l i  uj π   in other words  an agent re-
ceives the minimum utility among all agents reachable within
her coalition in the loyalty graph 
finally  we introduce a technical assumption  a mutual
cardinal hedonic game is called loyalty-connected if  for all
agents i ∈ n and coalition structures π  ui gπ
l i   ≥ ui π  
this property precludes negative influence through agents
outside the reach of loyalty  and is satisfied by reasonable
classes of cardinal hedonic games like ashgs  mfhgs  or
fractional hedonic games  aziz et al   2019  
2 3
solution concepts
we evaluate the quality of coalition structures by measures of
stability and efficiency 
a common concept of group stability is the core  given
a coalition structure π  a coalition c ⊆ n is blocking π
 respectively  weakly blocking π  if for all agents i ∈ c 
ui c  > ui π   respectively  for all agents i ∈ c  ui c  ≥
ui π   where the inequality is strict for some agent in c   a
coalition structure π is in the core  respectively  strict core 
if there exists no non-empty coalition blocking  respectively 
weakly blocking  π 
a fundamental concept of efficiency is pareto optimality 
a coalition structure π′ pareto dominates a coalition struc-
ture π if  for all i ∈ n  ui π′ i   ≥ ui π i    where the
inequality is strict for some agent in n  a coalition struc-
ture π is called pareto optimal if it is not pareto dominated by
another coalition structure  in other words  given a pareto op-
timal coalition structure  every other coalition structure that
is better for some agent  is also worse for another agent 
another concept of efficiency concerns the welfare of a
coalition structure  there are many notions of welfare depen-
dent on how to aggregate single agents  utilities for a social
evaluation  in the context of loyalty  egalitarianism seems to
be especially appropriate  it aims to maximize the well-being
of the agent that is worst off  formally  the egalitarian wel-
fare of a partition π is defined as e π  = mini∈n ui π i   
also  let ek π  denote the egalitarian welfare of the k-fold
loyal variant  following this definition  coalition structures
1this restriction is in accordance with our results  but it can be
lifted with some technical effort 
maximizing egalitarian welfare are not necessarily pareto op-
timal  however  there exists always a pareto optimal coali-
tion structure maximizing egalitarian welfare  specifically 
a coalition structure maximizes leximin welfare if its utility
vector  sorted in non-decreasing order  is lexicographically
largest  a coalition structure maximizing leximin welfare is
pareto optimal and maximizes egalitarian welfare 
apart from finding efficient coalition structures  an indi-
vidual goal of an agent i is to be in a best coalition  i e   in a
coalition in ni maximizing her utility  formally  the problem
of  given a cardinal hedonic game  an agent i∗ ∈ n  and a ra-
tional number q ∈ q  deciding if there exists a subset c ⊆ n
with i∗ ∈ c and ui∗ c  ≥ q  is called bestcoalition 
3
loyalty propagation and best coalitions
our first proposition collects some initial observations 
it
states  how loyalty propagates through the loyalty graph for
higher degree loyal variants  terminating with the locally
egalitarian variant  and considers egalitarian welfare 
proposition 1  let a mutual cardinal hedonic game on agent
set n with |n| = n be given  let k ≥ 1  i ∈ n  and π a
coalition structure  then  the following statements hold 
1  the loyalty graph and loyalty sets are the same for all
loyal variants  i e   gk
l = g1
l and lk
i = l1
i  
2  loyalty extends to agents at distance k  i e   uk
i  π  =
min uj π   j ∈ π i  with dgl π i   i  j  ≤ k  
3  utilities converge to the utilities of the locally egalitar-
ian variant  i e   ul
i = ue
i for all l ≥ n 
4  egalitarian welfare is preserved  i e   ek π  = e π  
proof  the first statements follow immediately from mutual-
ity  we prove the second statement by induction over k  for
k = 1  the assertion follows directly from the definition of
the loyal variant 
now  let k ≥ 2 be an integer  let c = π i   cl = π i  ∩
 li ∪  i    h = gl π i    and for p ≥ 1  let cp j  =  m ∈
c with dh j  m  ≤ p   then 
uk
i  π  = min
j∈cl uk−1
j
 c 
= min
j∈cl min um c   m ∈ ck−1 j  
=
min
j∈c   dh i j ≤1 min um c   m ∈ ck−1 j  
= min uj c   j ∈ c with dh i  j  ≤ k  
there  the second equality follows by induction  the third
equality by definition of the loyalty graph  and the last equal-
ity by observing that the vertices with a distance of at most
k from i are precisely the vertices with a distance of at most
k − 1 from an arbitrary neighbor 
the third statement follows from the second one  and the fi-
nal statement follows from the observation that the minimum
utility among agents in a coalition structure is preserved when
transitioning to a loyal variant 
example 1  we provide an example showing that part 4
of proposition 1 does not extend to leximin welfare 
proceedings of the thirtieth    ijcai-21 
68
 z1
z2
c1
c2
c3
c4
a3
b3
a4
b4
a1
b1
a2
b2
figure 1  friendship graph of example 1  the black and white coali-
tions constitute a coalition structure minimizing leximin welfare for
the 2-fold loyal variant  which is not pareto optimal under the origi-
nal utilities 
consider a symmetric fohg with agent set n
=
 ai  bi  ci   1 ≤ i ≤ 4  ∪  z1  z2   and the friendship
graph in figure 1 
it can be shown that the coalition
structure π =   zi  a2i−1  a2i  b2i−1  b2i  c2i−1  c2i   i =
1  2  maximizes leximin welfare for its 2-fold loyal vari-
ant  consider agents of type bi  
however  π is not
even pareto optimal under the original utilities 
indeed 
π′ =   z1  a1  a4  b1  b4  c1  c4    z2  a2  a3  b2  b3  c2  c3  
is a pareto improvement  all agents receive at least the same
utility  and a2  a4  c1  and c3 are better off 
our next goal is to reason about finding best coalitions for
an agent  note that this problem can usually be solved in
polynomial time  for instance  in ashgs  given an agent i 
every coalition that contains i together with all agents that
give positive utility to i and no agent that gives negative util-
ity to i is a best coalition for i  by contrast  we obtain hard-
ness results for loyalty even in symmetric fohgs  while it
is possible to determine the number of friends of the unhap-
piest friend in a best coalition in polynomial time  wiechers
and rothe  2020   the problem becomes hard if the number of
enemies is to be minimized at the same time  we omit some
proof details and proofs due to space restrictions  but they can
all be found in the extended version of the paper 
theorem 2  let k ≥ 1  then  bestcoalition is np-
complete for the k-fold loyal variant of symmetric fohgs 
proof sketch  membership in np is clear 
for hardness 
we provide a reduction from the np-complete problem
setcover  karp  1972   an instance of setcover con-
sists of a triple  a  s  κ   where a is some finite ground set 
s ⊆ 2a is a set of subsets of a  and κ is an integer  the in-
stance  a  s  κ  is a yes-instance if there exists s′ ⊆ s with
�
b∈s′ b = a and |s′| ≤ κ  the reduction is illustrated in
figure 2 
let k ∈ n 
define m =
� k−1
2
�
 
given an instance
 a  s  κ  of setcover  define a = |a|  we define an in-
stance   n   fi i∈n   i∗  q  of bestcoalition based on
an fohg  n   fi i∈n  represented via friend sets by speci-
fying each individual component  the agent set is defined as
n =  wi   i ∈  0  a 2  ∪ vi   i ∈  0  a−1  ∪ αj
i  βj
i   i ∈
 a   j ∈  m   ∪ a ∪ s  and consists of representatives of the
elements of a and s  and auxiliary agents  if k is even  set
i∗ = w0 and if k is odd  i∗ = v0  the friend sets are given as
• fw0 =  w1  v0          va−1  
• fw1 =  w0  w2  w3          wa 2  
a
s
ka 2
w0
v0
v1
s1
v2
s2
v3
s3
α1
1
βm
1
x1
α1
2
βm
2
x2
α1
3
βm
3
x3
α1
4
βm
4
x4
   
   
   
   
m times
figure 2  schematic of the hardness reduction in theorem 2 for
k ≥ 2 
the figure shows the friendship graph for the instance
of setcover given by a =  x1  x2  x3  x4  and s =  s1 =
 x1  x2  x3   s2 =  x1  x3  x4   s3 =  x2  x4    the black ver-
tex indicates a complete subgraph on a   2 vertices 
we ask
bestcoalition for the agents v0 and w0  respectively  indicated
by double circles 
• fwi =  wj   j ∈  a   2   j ̸= i  for i ∈  2  a   2  
• fvi =  w0  α1
1          α1
a  for i ∈  0  a − 1  if k > 2 
• fvi =  w0  ∪ a for i ∈  0  a − 1  if k ≤ 2 
• fα1
i =  v0          va−1  β1
i   for i ∈  a  
• fαj
i =  βj−1
1
          βj−1
a
  βj
i   for i ∈  a   j ∈  2  m  
• fβj
i =  αj
i  αj 1
1
          αj 1
a
  for i ∈  a   j ∈  m − 1  
• fβm
i
=  αm
i   ∪ a for i ∈  a  
• fx =  βm
i   i ∈  a   ∪  s ∈ s   x ∈ s  for x ∈ a if
k > 2 
• fx =  v0          va−1  ∪  s ∈ s   x ∈ s  for x ∈ a if
k ≤ 2  and
• fs =  x ∈ a  x ∈ s  for s ∈ s  in other words 
fs = s  
finally  with n = |n|  specify the threshold utility q =
n a   1  −  a   κ  for k = 1 and q = n a   1  −
 1   κ   2 m   1 a   otherwise  note that the distance be-
tween i∗ and the xi in the loyalty graph is exactly k 
if  a  s  κ  is a yes-instance  let s′ ⊆ s be a set cover
of a with at most κ sets  for k = 1  consider the coalition
c = a ∪ s′ ∪  v0          va−1  w0  w1   for k ≥ 2  consider
the coalition c =  n \ s  ∪ s′  it is quickly checked that in
each case uk
v0 c  ≥ q 
conversely  assume that c is a coalition with i∗ ∈ c and
uk
i∗ c  ≥ q  then  all agents that have a distance of at most
k in the loyalty graph have to be included due to the degrees
of vertices at a distance of at most k  in particular  a ⊆ c for
any k  let s′ = c ∩ s 
first  consider the case k = 1  then  uv0 c  = n a  
1  − a − |s′|  hence u1
v0 c  ≥ q implies that |s′| ≤ κ  in
addition  every agent x ∈ a must have at least a   1 friends
present in c  in other words  for every x ∈ a there exists
s ∈ s′ with x ∈ s  hence  s′ is a cover of a with at most κ
elements 
proceedings of the thirtieth    ijcai-21 
69
 for arbitrary k ≥ 2  it holds that ui∗ c  = n a   1  − 1 −
|s′| −  m   2 a  hence u1
v0 c  ≥ q implies that |s′| ≤ κ 
the remainder follows analogous to the case k = 1 
since the instances in the previous reduction contain agents
with an arbitrarily large distance  parametrized by k   we
cannot deduce direct consequences for the locally egalitarian
variant  however  it is possible to bound the diameter in the
reduced instances globally to obtain a similar result 
theorem 3  bestcoalition is np-complete for the lo-
cally egalitarian variant of symmetric fohgs 
if we change the underlying class of hedonic games  we
can circumvent the hardness results of the last two theorems 
theorem 4  let k ≥ 1  then  bestcoalition can be
solved in polynomial time for the k-fold loyal variant and the
locally egalitarian variant of symmetric mfhgs 
4
coalition structures in the core
in this section we consider group stability in the locally egal-
itarian variant and the loyal variants 
4 1
core in the locally egalitarian variant
we start with a general lemma yielding a sufficient condition
for existence of pareto optimal coalition structures in the core 
lemma 5  consider a class of hedonic games with the fol-
lowing two properties 
1  restrictions of the game to subsets of agents are in the
class 
2  for every coalition in any game of the class  the value of
the coalition is the same for every player in the coalition 
then  for every game in the class  there exists a coalition
structure in the core which is pareto optimal 
weakening the second condition of the lemma to the ex-
istence of some coalition that is best for all of its members
is sufficient to find a coalition structure in the core  we dis-
cuss this in the extended version of the paper  interestingly 
the lemma can be applied to the locally egalitarian variant of
cardinal hedonic games under fairly weak assumptions 
theorem 6  let a loyalty-connected  mutual cardinal hedo-
nic game be given  then  there exists a pareto optimal coali-
tion structure in the core of its locally egalitarian variant 
proof  let a loyalty-connected  mutual cardinal hedonic
game be given and consider its locally egalitarian variant  we
modify the utility functions such that ue
i  c  stays the same if
c is connected in the loyalty graph  and set it to 0  otherwise 
it suffices to find a pareto optimal member of the core un-
der this modification  because  by loyalty-connectivity  split-
ting coalitions into their connected components in the loyalty
graph is weakly better for every agent  even under ue  con-
sider the class of hedonic games given by this modified n-fold
loyal variant together with all of its restrictions  in which we
apply the same modifications towards the utility values for
non-connected coalitions 
by proposition 1  the utility for a coalition is the same
for every player in the coalition  hence  all requirements of
lemma 5 are satisfied and we find the desired coalition struc-
ture 
in the extended version of the paper  we provide an exam-
ple for the necessity of loyalty-connectivity in the previous
theorem 
example 2  we extend an example by wiechers and
rothe  2020  that shows that the previous result cannot be
strengthened to find a coalition structure in the strict core 
consider the symmetric fohg on agent set  a  b  c  d  e 
with loyalty graph depicted below 
a
b
c
d
e
consider its locally egalitarian variant  then   a  b  c  is
the unique best coalition for agents b and c and among the
best coalitions for agent a  hence  it has to be contained in
every coalition structure in the strict core  similarly   a  d  e 
has to be a coalition in the strict core  as these conditions
cannot be satisfied simultaneously  the strict core is empty 
note that both the coalition structure   a  b  c    d  e  
and   a  d  e    b  c   are in the core and pareto optimal 
the construction in lemma 5 gives rise to a simple recur-
sive algorithm that computes pareto optimal coalition struc-
tures in the core  still  the computational complexity highly
depends on the underlying cardinal hedonic game  while a
modified version of the algorithm by bullinger  2020  for
computing pareto optimal coalition structures in symmetric
mfhgs finds a coalition structure in the core of their locally
egalitarian variants  a version of our reduction on best coali-
tions shows an intractability for fohgs 
theorem 7  the following statements hold 
1  computing a coalition structure in the core can be done
in polynomial time for the locally egalitarian variant of
symmetric mfhgs 
2  computing a coalition structure in the core is np-hard
for the locally egalitarian variant  even in the class of
symmetric fohgs with non-empty core 
4 2
core in the loyal variants
in contrast to the locally egalitarian variant  the k-fold loyal
variant may have an empty core for arbitrary k  this is even
true in a rather restricted class of symmetric ashgs with in-
dividual values restricted to  n  n   1  −1  
proposition 8  for every k ≥ 1  there exists a symmetric
ashg with o k  agents such that the core of its k-fold loyal
variant is empty 
proof sketch  we only describe the instance  let k ∈ n 
we define an ashg  n   ui i∈n  
set m = k if k is
an even number and m = k   1 if k is odd  let ai =
 ai  bi
1          bi
m  ci
1          ci
m  for i
∈
 3  
define n
=
�3
i=1 ai as the set of agents and let n = |n|  reading in-
dices i modulo 3  we define symmetric utilities according to
• u ai  bi
1  = u ai  ci
1  = n   1 for i ∈  3  
• u bi
m  ai 1  = u ci
m  ai 1  = n for i ∈  3  
proceedings of the thirtieth    ijcai-21 
70
 • u bi
j  bi
j 1  = u ci
j  ci
j 1  = n   1 for i ∈  3   j ∈
 m − 1   and
• u v  w  = −1 for all other utilities 
note that |n| = 3 2m   1  = o k  
we can use the previous counterexample as a gadget in a
sophisticated reduction to obtain computational hardness 
theorem 9  let k ≥ 1  deciding whether the core is non-
empty is np-hard for the k-fold loyal variant of symmetric
ashgs 
naturally  the question arises whether the core is always
non-empty for loyal variants of fohgs 
while we leave
the ultimate answer to this question as an open problem  we
give evidence into both directions  first  we determine cer-
tain graph topologies that allow for coalition structures in the
core  by contrast  we provide an intractability result for the
computation of coalition structures in the core  and in the ex-
tended version of the paper we show that the dynamics related
to blocking coalitions can cycle 
proposition 10  let a symmetric fohg with connected  reg-
ular friendship graph be given  then the coalition structure
consisting of the grand coalition is in the strict core for the
k-fold loyal variant for every k ≥ 1 
proof  assume that the friendship graph is regular with ev-
ery vertex having degree r  singleton coalitions are clearly
not weakly blocking  so we may assume that r ≥ 2  in addi-
tion  we may assume that a weakly blocking coalition induces
a connected subgraph of g  in a weakly blocking coalition
c ⊊ n  some agent would have less than r friends  strictly
decreasing her utility  hence  the grand coalition is in the
strict core 
albeit the previous proposition may look rather innocent 
regular substructures in the loyalty graph have been very use-
ful in dealing with core  non- existence  see  e g   the many
cycles in the games of proposition 8 and theorem 9  
for symmetric fohgs with a tree as loyalty graph  it is
easy to see that a coalition structure is in the core if and only
if its coalitions form an inclusion-maximal matching  in the
case of ashgs  we can apply a greedy matching algorithm
to compute coalition structures in the core 
proposition 11  let k ≥ 1  a coalition structure in the core
of the k-fold loyal variant can be computed in polynomial
time for symmetric ashgs with a tree as loyalty graph 
on the negative side  even under the existence of core par-
titions  it may be hard to compute them  interestingly  the
next theorem does not cover the case k = 1 
theorem 12  let k ≥ 2  computing a coalition structure in
the core is np-hard for the k-fold loyal variant of symmetric
fohgs with non-empty core 
on the other hand  if the games originate from symmetric
mfhgs  we obtain a polynomial-time algorithm by a modi-
fication of the algorithm in theorem 7 
theorem 13  let k ≥ 1  computing a coalition structure in
the core can be done in polynomial time for the k-fold loyal
variant of symmetric mfhgs 
symmetric k-fold
best coalition
core solution
loyal variant
fohgs
orig 
poly 
poly  
 dimitrov et al   2006 
k = 1
np-h  thm  2 
open  
k ≥ 2
np-h  thm  2 
np-h     thm  12 
limit
np-h  thm  3 
np-h    thm  7 
ashgs
orig 
poly 
np-h −
 aziz et al   2013 
k ≥ 1
np-h  thm  2 
np-h −  thm  9 
limit
np-h  thm  3 
np-h    thm  7 
mfhgs
all
poly  thm  4 
poly    thms  7 13 
table 1  computational complexity of computing best coalitions and
core partitions  the circled    −  and   indicate whether elements
in the core always exist  may not exist  or whether this is unknown 
5
conclusion and open problems
we have introduced loyalty in hedonic games as a possible
way to integrate relationships of players in a coalition into
the coalition formation process  given a hedonic game  play-
ers can modify their utilities to obtain a new hedonic game
which regards loyalty among coalition partners  applying
loyalty multiple times yields a sequence of hedonic games
with increasing loyalty  eventually terminating in a hedonic
game with utilities that represent a local form of egalitarian-
ism  the limit game usually contains pareto optimal coalition
structures in the core  but their efficient computability is de-
pendent on the initial input game  we show that computing
best coalitions is hard if the input is an fohg  a reduction
that can also be applied to the computation of coalition struc-
tures in the core  revealing a close relationship of the two
problems  an overview of our results is given in table 1 
our work offers plenty directions for further investigation 
first  similarly to altruistic hedonic games  one can make the
aggregation mechanism for loyal utilities dependent on a pri-
ority amongst the agents  or take averages instead of sums 
this yields new notions of loyalty that are worth to inves-
tigate and compare  second  it would be interesting to ap-
proach loyalty for other underlying classes of hedonic games
such as fractional hedonic games  this includes also to find
a reasonable way to define loyalty for purely ordinal input 
note that our  equivalent  definition of the loyalty set is also
applicable in this case  finally  an intriguing open problem
concerns the existence of coalition structures in the core for
loyal variants of fohgs  in particular for the 1-fold variant 
where we could not show hardness of the computational prob-
lem 
acknowledgements
this work was supported by the german research founda-
tion under grants br 2312/12-1 and 277991500/grk2201 
we would like to thank ina seidel  johannes bullinger  anna
maria kerkmann  and j¨org rothe for valuable discussions 
and thank the anonymous reviewers 
proceedings of the thirtieth    ijcai-21 
71
 references
 apt and sch¨afer  2014  k  r  apt and g  sch¨afer  selfish-
ness level of strategic games  journal of artificial intelli-
gence research  49 207–240  2014 
 aziz et al   2013  h  aziz  f  brandt  and h  g  seedig 
computing desirable partitions in additively separable he-
donic games  artificial intelligence  195 316–334  2013 
 aziz et al   2019  h  aziz  f  brandl  f  brandt  p  har-
renstein  m  olsen  and d  peters 
fractional hedonic
games  acm transactions on economics and computa-
tion  7 2  1–29  2019 
 banerjee et al   2001  s 
banerjee 
h 
konishi 
and
t  s¨onmez  core in a simple coalition formation game 
social choice and welfare  18 135–153  2001 
 bogomolnaia and jackson  2002  a 
bogomolnaia
and
m  o  jackson  the stability of hedonic coalition struc-
tures 
games and economic behavior  38 2  201–230 
2002 
 brˆanzei and larson  2011  s  brˆanzei and k  larson  social
distance games  in proceedings of the 22nd international
joint conference on artificial intelligence  ijcai   pages
273–279  2011 
 bullinger  2020  m  bullinger  pareto-optimality in cardi-
nal hedonic games  in proceedings of the 19th interna-
tional conference on autonomous agents and multiagent
systems  aamas   pages 213–221  2020 
 colman et al   2008  a  m  colman  b  d  pulford  and
j  rose  collective rationality in interactive decisions  evi-
dence for team reasoning  acta psychologica  128 2  387–
397  2008 
 dimitrov et al   2006  d  dimitrov  p  borm  r  hendrickx 
and s  c  sung  simple priorities and core stability in he-
donic games  social choice and welfare  26 2  421–433 
2006 
 dr eze and greenberg  1980  j  h  dr eze and j  greenberg 
hedonic coalitions  optimality and stability  economet-
rica  48 4  987–1003  1980 
 edmonds  1965  j  edmonds 
paths  trees and flowers 
canadian journal of mathematics  17 449–467  1965 
 elias et al   2010  j  elias  f  martignon  k  avrachenkov 
and g  neglia  socially-aware network design games  in
proceedings of the 29th ieee conference on computer
communications  infocom   pages 1–5  ieee  2010 
 hardin  1968  g  hardin  the tragedy of the commons  sci-
ence  1632 1243–1248  1968 
 kahneman and tversky  1979  d  kahneman and a  tver-
sky  prospect theory  an analysis of decision under risk 
econometrica  47 2  263–292  1979 
 karp  1972  r  m  karp  reducibility among combinatorial
problems  in r  e  miller and j  w  thatcher  editors  com-
plexity of computer computations  pages 85–103  plenum
press  1972 
 kerkmann and rothe  2020  a  m  kerkmann and j  rothe 
altruism in coalition formation games  in proceedings of
the 29th international joint conference on artificial intel-
ligence  ijcai   pages 461–467  2020 
 koutsoupias and papadimitriou  1999  e  koutsoupias and
c  h  papadimitriou  worst-case equilibria  in proceed-
ings of the 16th annual symposium on theoretical aspects
of computer science  stacs   pages 404–413  1999 
 levine  1998  d  k  levine  modeling altruism and spite-
fulness in experiments 
review of economic dynamics 
1 3  593–622  1998 
 monaco et al   2018  g  monaco 
l  moscardelli 
and
y  velaj  hedonic games with social context  in proceed-
ings of the 19th italian conference on theoretical com-
puter science  pages 24–35  2018 
 mueller  1986  d  c  mueller  rational egoism versus adap-
tive egoism as fundamental postulate for a descriptive the-
ory of human behavior  public choice  51 1  3–23  1986 
 nguyen et al   2016  n-t  nguyen  a  rey  l  rey  j  rothe 
and l  schend  altruistic hedonic games  in proceed-
ings of the 15th international conference on autonomous
agents and multiagent systems  aamas   pages 251–259 
2016 
 olsen  2012  m  olsen  on defining and computing com-
munities 
in proceedings of the 18th computing  aus-
tralasian theory symposium  cats   volume 128 of con-
ferences in research and practice in information technol-
ogy  crpit   pages 97–102  2012 
 schlueter and goldsmith  2020  j  schlueter and j  gold-
smith 
super altruistic hedonic games 
in proceedings
of the 33rd international florida artificial intelligence
research society conference  flairs   pages 160–165 
2020 
 von neumann and morgenstern  1947  j  von neumann and
o  morgenstern  theory of games and economic behav-
ior  princeton university press  2nd edition  1947 
 wiechers and rothe  2020  a  wiechers and j  rothe  sta-
bility in minimization-based altruistic hedonic games  in
proceedings of the 9th european starting ai researcher
symposium  stairs   2020 
proceedings of the thirtieth    ijcai-21 
72
 "
None,2021,https-www-ijcai-org-proceedings-2021-0011-pdf,Approximating the Shapley Value Using Stratified Empirical Bernstein Sampling,"Mark A. Burgess, Archie C. Chapman",None,https://www.ijcai.org/proceedings/2021/0011.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0011-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0011-pdf.pdf,"approximating the shapley value using stratified empirical bernstein sampling
mark a  burgess1 and archie c  chapman2
1australian national university  canberra  australia
2the university of queensland  brisbane  australia
mark burgess@anu edu au  archie chapman@uq edu au
abstract
the shapley value is a well recognised method
for dividing the value of joint effort in coopera-
tive games  however  computing the shapley value
is known to be computationally hard  so stratified
sample-based estimation is sometimes used  for
this task  we provide two contributions to the state
of the art  first  we derive a novel concentration
inequality that is tailored to stratified shapley value
estimation using sample variance information  sec-
ond  by sequentially choosing samples to minimize
our inequality  we develop a new and more efficient
method of sampling to estimate the shapley value 
we evaluate our sampling method on a suite of test
cooperative games  and our results demonstrate that
it outperforms or is competitive with existing strat-
ified sample-based estimation approaches to com-
puting the shapley value 
1
introduction
the shapley value is a cornerstone measure in cooperative
game theory  it is an axiomatic approach to allocating a di-
visible reward or cost between participants where there is a
clearly defined notion of how much surplus or profit a group
or  coalition  of participants could achieve by themselves  it
has many applications  including analyzing the power of vot-
ing blocks in weighted voting games  bachrach et al   2009  
in cost and surplus division problems  soufiani et al   2014 
o brien et al   2015  aziz et al   2016  chapman et al   2017  
as a measure of network centrality  michalak et al   2013  
and as a method of explaining the predictions of machine
learning models  lundberg and lee  2017   specifically  un-
der the shapley value  each player is allocated their aver-
age marginal contribution across every possible sequence of
player join orderings  although the shapley value is concep-
tually simple  its use is hampered by the fact that its exact
computation requires exponentially many evaluations of the
marginal contributions of the players in the coalition 
given this difficulty  one can exploit the fact that the shap-
ley value is an average by using estimation techniques to
approximate it 
in particular  the coalitions evaluated in
the shapley value computation can be naturally stratified by
coalition size  allowing it to be reformulated as an average
over strata averages 
it is then possible to separately and
efficiently estimate these strata averages via sample alloca-
tion techniques  such techniques in literature include simple
random sampling  castro et al   2009   simple stratified ran-
dom sampling  and a neyman-type allocation  castro et al  
2017   and allocating stratified samples to minimize a ho-
effding type inequality  maleki et al   2013  
in this paper  we improve on these approaches by develop-
ing a method for stratified sampling to maximally reduce an
expression of the uncertainty in the shapley value estimate 
to do this  we develop a general expression associated with
that uncertainty  which takes the form of a concentration in-
equality  specifically  a stratified empirical bernstein bound
 sebb   this inequality considers factors such as  the sizes
of all the strata and the proportion of each that are sampled 
the sample variances of the samples from each of the strata 
the differences in the range of data of each strata  any addi-
tional importance weightings on the strata  and  whether any
 or all  of the strata are sampled with or without replacement 
using our sebb  we propose an online method for se-
quentially sampling in order to maximally reduce the bound
at each iteration  called the stratified empirical bernstein
method  sebm   we numerically demonstrate the value of
the sebm by using it to compute the shapley value in a suite
of benchmark cooperative games  our comparisons to exist-
ing sample-based approaches to computing the shapley value
show that our method is almost uniformly superior 
next  section 2 frames some context of the paper  sec-
tion 3 provides several component lemmas  from this sec-
tion 4 provides the derivation of our concentration inequality 
in section 5  we evaluate the performance of our bound in
approximating the shapley value  section 6 discusses a mul-
tidimensional extension to the concentration inequality  and
section 7 concludes 
2
background
stratified sampling is a well known sampling technique 
which estimates the mean of a population by partitioning it
into mutually exclusive subgroups  or strata  it proceeds by
applying a sampling estimator to each stratum  before weight-
ing and combining these estimates to form an estimate of the
population mean  if strata and their sizes are naturally given
or determined  there exists a further question of how to allo-
cate the sampling between the strata 
proceedings of the thirtieth    ijcai-21 
73
 one way of deriving a sampling method is to use a con-
centration inequality as a confidence bound on the error of
the population mean  and then selecting additional samples to
minimise it  for instance  minimising chebyshev s inequality
on the variance of the estimation of the population mean re-
sults in the well-known neyman allocation  1938   which has
been inspiration as a method of estimating the shapley value
 castro et al   2017   hoeffding s inequality is another com-
monly used concentration inequality whose minimisation has
also been adapted in the context of shaplay value sampling
 maleki et al   2013  
recently  there has been interest in concentration inequal-
ities called empirical bernstein bounds  ebbs   maurer and
pontil  2009   which are probabilistic bounds for the sample
mean and sample variance  ebbs have been subject to rapid
development  audibert et al   2009  audibert et al   2007 
bardenet and maillard  2015  and have replaced hoeffding s
inequality in a number of computational applications  mnih
et al   2008  thomas et al   2015  carpentier et al   2011  
sampling without replacement offers the opportunity to
further tighten the concentration bounds over the sampling-
with-replacement case 
the refinement was first demon-
strated with a martingale argument by serfling  1974  which
was recently improved to created an ebb suitable for sam-
pling without replacement by bardenet and maillard  2015  
our observation  is that the components of these analyses
can be used to create a variance-sensitive concentration in-
equality tailored for stratified random sampling  which then
can be minimised in the context of shapley value estimation 
3
preliminaries
we now state lemmas which we use to derive our stratified
empirical bernstein bound  sebb   the proofs of lemmas and
theorems are as supplemental documentation  section a   the
first lemma is an often-used and rather weak result used to
fuse simple statements of probability 
lemma 3 1  probability union   for any random variables 
p a > c  ≤ p a > b    p b > c 
the next lemma is a result of algebra that relates the sample
squares about the mean to the sample variance 
lemma 3 2  variance relation   for random variable x
with mean µ  and n samples  xk k=1     n  the sample mean
ˆµ = 1
n
�
k xk  sample variance  ˆσ2 = 1
n
�
k xk − ˆµ 2  cen-
tered average sample squares ˆσ2
0 = 1
n
�
k xk − µ 2  obey 
ˆσ2
0 − ˆσ2 =  ˆµ − µ 2  
we use this result to create bounds for the sample variance
from bounds on the sample squares  we also use the next
lemma  which extends directly from markov s inequality 
lemma 3 3  chernoff bound   for a random variable x 
and for any s > 0 and t 
p x ≥ t  ≤ e  exp sx   exp −st 
many well-known inequalities follow from upper bounds for
e  exp sx    also known as the moment generating function 
3 1
bounds on the moment generating function
the next three lemmas give three upper bounds for moment
generating functions 
the first is the famous hoeffding s
lemma  1963  which is essentially constructed by fitting a line
over the exponential function of the moment generating func-
tion 
lemma 3 4  hoeffding s lemma   for random variable x
bounded a ≤ x ≤ b with d = b − a  for any s > 0 
e  exp s x − e x     ≤ exp
�1
8d2s2
�
 
the next is a similar bound on the moment generating func-
tion that involves information about the variance 
lemma 3 5  for random variable x bounded a ≤ x ≤ b
with d = b − a and variance σ2  for any s > 0 
e  exp s x − e x     ≤ exp
��d2
17   σ2
2
�
s2
�
the proof of this lemma is provided in supplementary ma-
terial  section a   and essentially involves fitting a parabola
 instead of a line  over the exponent in the moment generat-
ing function  this lemma is a simplified half-way result used
in a derivation of bennett s inequality as presented by ho-
effding  1963   and derived by bennett  1962  
the next lemma stems from the creation of an upper bound
on the random variable −x2 instead of x 
in this con-
text the moment generating function becomes the expectation
value of a gaussian function which can be bound above by a
parabola  yielding 
lemma 3 6  for random variable x bounded a ≤ x ≤ b 
with d = b − a and variance σ2 and for any q > 0 
e exp q σ2 −  x − e x  2    ≤ exp
�1
2σ2q2d2
�
the three inequalities above  lemmas 3 4  3 5 and 3 6  are
used in the derivation of our stratified sampling concentration
inequality in section 4 
3 2
moment generating function of means
in the previous subsection we considered bounds on the mo-
ment generating function of random variables  but we must
also relate these to bounds on the moment generating func-
tion of sample means from that of the random variables  the
first is the most straightforward way to do this in the case of
sampling with replacement  and directly assumes the inde-
pendence of the samples 
lemma 3 7  replacement bound   for random variable x
bounded a ≤ x ≤ b with a mean of zero  with d = b − a
and variance σ2  let χm =
1
m
�m
i=1 xi be the average of
m independently drawn  with replacement  samples  if there
exists an α  β ≥ 0 such that for any s > 0 that
e exp sx   ≤ exp  αd2   βσ2 s2 
then 
e exp sχm   ≤ exp  αd2ωn
m   βσ2ψn
m s2 
where ωn
m = ψn
m = 1
m
proceedings of the thirtieth    ijcai-21 
74
 however  for the context of sampling without replacement 
there is an alternative result which can be substituted and may
be  or may not be  tighter  in this context substituting one for
the other can be done judiciously on a case-by-case basis to
create the tightest possible bound  all the numerical results
in this paper have been produced with this judicious choice
conducted  this result directly extends a reverse martingale
argument from bardenet and maillard  2015  
lemma 3 8  martingale bound  
for finite data set
x1  x2        xn that is bounded a ≤ xi ≤ b  and has a mean of
zero and variance σ2 = 1
n
�n
i=1 x2
i   denote x1  x2          xn
the random variables corresponding to the data sequentially
drawn randomly without replacement  and χm the average of
the first m of them 
e exp sχm   ≤ exp  αd2 ¯ωn
m   βσ2 ¯ψn
m s2 
where
¯ωn
m =
n−1
�
k=m
1
k2 ≤  m   1  1 − m/n 
m2
and
¯ψn
m =
n−1
�
k=m
n
k2 k   1  ≤ n   1 − m
m2
 
under the assumption that for any random variable z with
a mean of zero such that a ≤ z ≤ b and d = b − a  with
variance σ2
z that there exists an α  β ≥ 0 such that for any
s > 0 that e exp sz   ≤ exp  αd2   βσ2
z s2  
proofs of both of these lemmas are found in supplementary
material  section a  
4
the stratified finite empirical bernstein
bound and sampling method
we derive a novel probability bound for the error of the strat-
ified sampling estimate  we begin by precisely defining the
context of our derivations  to which our bound applies 
definition 4 1  problem context   let a population consist of
n number of strata of finite data points  where ni is the num-
ber of data points in the ith stratum  all values in a stratum
are bound within a finite support of width di  denote the
mean and variance of the ith stratum µi and σ2
i   respectively 
denote random variables for values sequentially drawn  with
or without  replacement as xi 1  xi 2          xi ni  then  for
the first mi of these samples 
• χi mi =
1
mi
�mi
j=1 xi j is their average 
• their biased sample variance is ˆσ2
i =
1
mi
�mi
j  xi j −
χi mi 2  and 
• their unbiased sample variance is ˆˆσ2
i = miˆσ2
i / mi − 1  
we are interested in the average of the means of the strata
as weighted by constant positive factors  τi i∈ 1   n   in the
derivation we use arbitrary positive variables  θi i∈ 1   n  
given this context  the following two sections contain the
derivation of the stratified empirical bernstein bound  sebb 
and the sequential sampling method  sebm   respectively 
4 1
bound derivation
the bound is now developed in four theorems  which build
on each other in sequence 
1  theorem 4 2 bounds the error in the stratified population
mean estimate �n
i=1 τiχi mi in the context of variance
information 
2  theorem 4 3 bounds the variance information in the con-
text of sample variance information and the squared stra-
tum mean errors 
3  theorem 4 4 bounds the squared stratum mean errors 
4  theorem 4 5 combines the three previous theorems to-
gether using union bounds  to eliminate the dependence
on variance information and squared stratum mean er-
rors   to create a concentration inequality for the error in
the stratified population mean estimate given the sample
variance information 
we begin with an expression for a probability bound on the
absolute error of the weighted stratified sample means about
the weighted strata means  and is developed from lemma 3 5 
theorem 4 2  assuming the context given in definition 4 1 
and let ωni
mi and ψni
mi be given as in lemma 3 7  then 
p
�|�n
i=1 τi χi mi − µi |
≥
�
4 log 2/t  �n
i=1
� 1
17d2
i ωni
mi   1
2σ2
i ψni
mi
�
τ 2
i
�
≤ t
 1 
in most cases  the weights τi can be considered as the prob-
ability weights τi = ni/ �n
j=1 nj   and in this context this
probability bound can be used as-is for a measure of uncer-
tainty in stratified random sampling if the true variances  or
alternatively  upper bounds on the true variances  of the strata
are known  however  in other contexts  the weighted sum of
variances must be estimated from the data collected  and to
include this factor we develop and incorporate a probability
bound for the estimate of the sum of variances  as weighted
by arbitrary θi   as follows from use of lemma 3 6 
theorem 4 3  assuming the context given in definition 4 1 
then with ψni
mi per lemma 3 7 
p
��n
i=1 θi σ2
i − ˆσ2
i −  µi − χi mi 2 
≥
�
2 log 1/y  �n
i=1 σ2
i θ2
i d2
i ψni
mi
�
≤ y
 2 
this inequality gives the probability bound between the
weighted variances of the strata  the weighted  biased  sam-
ple variances and the weighted square error of the sample
means  although the weighted square error of the sample
means may go to zero quickly as additional samples are taken 
we nonetheless develop another probability bound to incorpo-
rate specific consideration of it  from lemma 3 4 
theorem 4 4  assuming the context given in definition 4 1 
then with ωni
mi as in lemma 3 7 
p
� n
�
i=1
θi µi − χi mi 2 ≥ log 2n/r 
2
n
�
i=1
θid2
i ωni
mi
�
≤ r
 3 
proceedings of the thirtieth    ijcai-21 
75
 this theorem bounds the weighted square error of the sam-
ple means  in the next  and final  step we combine the in-
equalities of equations  1    2  and  3  together  to complete
our derivation of the sebb 
theorem
4 5
 stratified
empirical
bernstein
bound
 sebb    assuming the context given in definition 4 1  then
with ωni
mi  ψni
mi per lemma 3 7 
p
�
|�n
i=1 τi χi mi − µi |
�
log 6/p 
≥
�
α  
��
β   √γ
�2
�
≤ p
 4 
where 
α =
n
�
i=1
4
17ωni
mid2
i τ 2
i  
β = log 3/p 
�
max
i
τ 2
i ψni
mi
2d2
i
�
γ =2
n
�
i=1
τ 2
i ψni
mi mi − 1 ˆˆσ2
i /mi
  log 6n/p 
�
i
τ 2
i d2
i ωni
miψni
mi
  log 3/p 
�
max
i
τ 2
i ψni
mi
2d2
i
�
this completes the derivation 
in equation  4  of the-
orem 4 5  we have a concentration inequality for the sum
of weighted strata sample mean errors relative to the sam-
ple variances  in this context  the weights τi are flexible but
would naturally be probability weights proportional to strata
size  τi = ni/ �n
j=1 nj   in which case the inequality pro-
vides a concentration of measure in stratified random sam-
pling  based on this bound  we proceed to propose an online
process of sequentially choosing samples from the strata in
order to minimize it 
the derivation of our inequality extends from considera-
tion of chernoff bounds and probability unions in a simi-
lar vein to other ebb derivations  maurer and pontil  2009 
bardenet and maillard  2015   however  the various bounds
on the moment generating functions that we developed in
section 3 use some loosening approximations in their deriva-
tions  and hence stronger and/or more representative bounds
could be developed at the cost of greater mathematical com-
plexity 
alternatively  integrating other kinds of inequali-
ties such as entropic  boucheron et al   2003  or efron-stein
 efron and stein  1981  could result in different and poten-
tially tighter bounds  nonetheless  when we use this bound
in a sequential sampling algorithm  as described next  we see
clear-cut estimation efficiency improvements in the shapley
value estimation task  as demonstrated in section 5 
4 2
sequential sampling using the stratified
empirical bernstein method
we introduce a method of sampling  the stratified empirical
bernstein method  sebm  which sequentially minimizes the
bound in theorem 4 5  sebb   pseudocode for the calcula-
tion of the bound and the process of sampling to minimize it 
is given in algorithm 1 
algorithm 1 stratified empirical bernstein method  sebm 
with replacement
require  probability p  strata number n  stratum sizes ni 
initial sample numbers mi  initial stratum sample vari-
ances ˆˆσ2
i   weights τi  widths di  sample budget b
1  while �
i mi < b do
2 
beststrata ← −1
3 
lowestbound ← ∞
4 
for k = 0 to n do
5 
mk ← mk   1
6 
a ←  0  0   b ←  0  0   c ←  0  0   d ←  0  0 
7 
for i = 0 to n do
8 
ωmin ← min ¯ωni
mi  ωni
mi 
9 
ψmin ← min ¯ψni
mi  ψni
mi 
10 
a0 ← a0   log 6n/p d2
i ¯ψni
miωminτ 2
11 
a1 ← a1   log 6n/p d2
i ψni
miωminτ 2
12 
b0 ← max b0  log 3/p d2
i ¯ψni
miψminτ 2 
13 
b1 ← max b1  log 3/p d2
i ψni
miψminτ 2 
14 
c0 ← c0   2¯ψni
mi  mi − 1 ˆˆσ2
i /mi τ 2
15 
c1 ← c1   2ψni
mi  mi − 1 ˆˆσ2
i /mi τ 2
16 
d0 ← d0   4
17d2
i ¯ωni
miτ 2
17 
d1 ← d1   4
17d2
i ωni
miτ 2
18 
end for
19 
w ←
�
minj dj    
�
cj   aj   bj  
�
bj 2 
20 
if w < lowestbound then
21 
beststrata ← k
22 
lowestbound ← w
23 
end if
24 
mk ← mk − 1
25 
end for
26 
take an extra sample from strata  beststrata
27 
mbeststrata ← mbeststrata   1
28 
recalculate ˆˆσ2
beststrata
29  end while
specifically  algorithm 1 is a repetitive process involving a
scan through the possible strata and then the selection of one
stratum to sample from to minimize the sebb under mild
assumptions  the process of scanning involves calculating
the confidence bound width  sebb  that would result if an
additional sample were to be taken from that stratum with-
out changing its sample variance  line numbers 5-17 in al-
gorithm 1   the stratum that yields the smallest confidence
bound width in the context of an additional sample is then
selected  line 18-21  and sampled  line 24   the sample vari-
ance of that stratum is updated  line 26   this process repeats
until the maximum sample budget is reached  per the outer
loop  line 1   in this way the process attempts to iteratively
minimize the sebb in expectation with each additional sam-
ple taken  and hence lead to potentially greater accuracy in
stratified sampling as a result 
we note that computing the sebb requires the sample vari-
ances of all the strata having been calculated  accordingly 
algorithm 1 must be initialized with at least two samples
from each stratum so that sample variance can be calculated 
proceedings of the thirtieth    ijcai-21 
76
 algorithm 1 describes a process specific to sampling with-
out replacement and involves the calculation of the sebb
with the tightest possible uses of lemmas 3 8 and 3 7  in par-
ticular  for any stratum i that is sampled without replacement 
any specific bound with an associated ωni
mi and ψni
mi may be
substituted for ¯ωni
mi and ¯ψni
mi to potentially tighten the bound 
and this corresponds to choice of lemma 3 8 or lemma 3 7
in the bound s derivation  since the sebb is a composition of
such bounds with such choices throughout  there is a structure
of valid pairs of substitutions ω  ψ for ¯ω  ¯ψ in the optimal
calculation of the sebb  which is shown in the steps 8-15 of
algorithm 1  using partial terms  a  b  c  d   the equivalent
algorithm for sampling with replacement simply is the same
algorithm altered by replacing all use of ¯ω  ¯ψ with ω  ψ 
5
numerical evaluation  shapley value
approximation
we assess the benefits of using our sampling method by com-
paring its performance to other approaches in a set of example
cooperative games 
for each game  we compute the exact shapley value  and
then the average absolute errors in the approximated shap-
ley value for a given budget of marginal-contribution samples
across multiple computational runs  the results are shown
in table 1  where esebm is the error associated with our
method  sebm  which is compared to the average absolute
error in the shapley value by sampling with 
• a hoeffding-bound method  maleki et al   2013   de-
noted ema 
• simple random sampling of the without stratification 
the described  approshapley  method  castro et al  
2009   denoted eapp
• the
stratified
simple
sampling
method
 st-
approshapley   castro et al   2017   denoted esim
• castro s
neyman-type
sampling
method
 st-
approshapley-opt   castro et al  
2017  
denoted
eca
next  we describe the example cooperative games  and
then discuss our results 
5 1
example cooperative games
in general  a cooperative game  ⟨n  v⟩ ∈ gn  comprises a
set of n players  n =  1  2          n   and a characteristic
function  v   s ⊂ n → r  which is a function specifying
the reward which can be achieved if a subset of the players
s ⊂ n cooperate  where v ∅  = 0  in this context the shap-
ley value ϕ is a unique mapping from cooperative games to
the player rewards gn → rn which satisfies many attractive
axioms  if vi k is the average marginal contribution which
player i can make across coalitions of size k 
vi k =
1
�n−1
k
�
�
s⊂n\ i  |s|=k
 v s ∪  i   − v s  
 5 
then the shapley value can be expressed as an average 
ϕi ⟨n  v⟩  = 1
n
n−1
�
k=0
vi k
 6 
the example games are described next  where w is a vector
of weights in all the games  the first two are inspired by other
benchmark games  castro et al   2017  
example game 1  airport game   an n = 15 player game
with characteristic function 
v s  = max
i∈s wi
where
w =  1  1  2  2  2  3  4  5  5  5  7  8  8  8  10 
the maximum marginal contribution is 10  so we assign
di = 10 for all i 
example game 2  voting game   an n = 15 player game
with characteristic function 
v s  =
�
1 
if
�
i∈s wi > �
j∈n wj/2
0 
otherwise
where
w =  1  3  3  6  12  16  17  19  19  19  21  22  23  24  29 
the maximum marginal contribution is 1  so we assign
di = 1 for all i 
example game 3  simple reward division   an n = 15
player game with characteristic function 
v s  = 1
2
��
i∈s
wi
100
�2
where
w =  45  41  27  26  25  21  13  13  12  12  11  11  10  10  10 
the maximum marginal contribution is 1 19025  so we assign
di = 1 19025 for all i 
example game 4  complex reward division   an n = 15
player game with characteristic function 
v s  =
��
i∈s
wi
50
�2
−
��
i∈s
wi
50
�2
where
w =  45  41  27  26  25  21  13  13  12  12  11  11  10  10  10 
in this game  we assign di = 2 for all i 
5 2
results and discussion
overall  the results in table 1 show that our method has ex-
cellent performance across the benchmark example games 
specifically  in comparison to existing approaches to approx-
imating the shapley value  our sampling method shows im-
proved performance on almost all accounts  as shown in ta-
ble 1  this was particularly the case in the context of large
sample budgets  as our method  sebm  with error esebm 
is sampled without replacement  while the other methods  per
their design  are sampled with replacement 
despite this performance  we make note of the computa-
tional overhead of iteratively minimizing  one sample at a
proceedings of the thirtieth    ijcai-21 
77
 a  airport game average errors
m/n2
10
50
100
500
1000
ema
298 4
133 1
99 64
41 96
29 26
eapp
883 6
394 8
266 5
117 0
79 15
esim
357 8
146 1
106 2
44 55
36 33
eca
325 7
115 8
75 85
31 01
22 12
esebm
259 2
73 8
54 76
7 71
1 30
b  voting game average errors
m/n2
10
50
100
500
1000
ema
131 0
57 78
41 52
18 66
13 18
eapp
154 7
71 65
47 88
21 57
15 27
esim
145 7
59 72
40 31
17 56
12 84
eca
142 1
47 35
31 05
14 08
9 800
esebm
122 8
47 44
33 18
8 55
1 995
c  simple reward division game average errors
m/n2
10
50
100
500
1000
ema
25 68
11 62
7 792
3 481
2 290
eapp
101 4
47 55
34 03
14 52
9 949
esim
22 10
9 045
6 218
2 642
1 938
eca
22 37
8 925
6 692
2 727
1 940
esebm
19 25
7 044
5 158
1 183
0 2817
d  complex reward division game average errors
m/n2
10
50
100
500
1000
ema
276 1
118 9
87 00
40 15
27 44
eapp
276 0
124 8
82 78
38 01
28 11
esim
251 4
108 0
78 63
34 64
26 82
eca
290 5
116 5
81 82
35 70
26 50
esebm
214 2
78 47
54 10
12 45
2 711
table 1  average absolute errors in the shapley value calculation across all players in the four cooperative games  units in 10−4   for the
different sampling schemes with different sampling budgets m per number of strata  with n2 = 152 for all   lowest error results are boldened 
time  our inequality in the context of our simple example
games  where this overhead can be a significant drawback 
however  on more complicated games  such as where the
characteristic function is slower to calculate  e g  as in  aziz
et al   2016  or  o brien et al   2015    any overhead asso-
ciated with the sampling choice is expected to be much less
relevant  we also note that our method s performance may be
further improved by selecting more refined di values for our
example games 
one primary limitation of our method is that it rests
on assumption of known data widths di  and in the case
of sampling-without-replacement  also on strata sizes ni  
which may not be exactly known in practice  one way to
overcome this may be to use our method with a reliable over-
estimate these parameters  by expert opinion or otherwise  
in practice  may also be advisable to run our method with an
underestimate of the data widths di  as the sampling process
is sensitive to the shape of the inequality and not necessarily
its magnitude or accuracy as a bound  finally  although there
may be ways to further strengthen our concentration inequal-
ity at the cost of greater mathematical complexity  our compu-
tational results1 show that using our bound greatly improves
stratified sampling methods for shapley value estimation 
6
multidimensional extension
looking beyond shapley value estimation  our concentration
inequality and sampling method can also be extended directly
to the context of multidimensional data  specifically  instead
of considering data that is single-valued  we consider data
points that are vectors 
formally  for n strata of finite data points which are all
vectors of size m  let ni be the number of data points in
the ith stratum 
let the data in the ith stratum have a
1see  https //github com/markopolo141
/stratified empirical bernstein sampling
mean vector values µi  with µi j for the jth component of
the vector   which are value bounded within a finite width
di j  and have vector value variances σ2
i j  given this  let
xi 1  xi 2          xi ni  where xi k j is the jth component  of
the kth vector from stratum i  be vector random variables cor-
responding to those data values randomly and sequentially
drawn  with or without  replacement 
denote the average of the first mi of these random variables
from the ith stratum by χi mi =
1
mi
�mi
k=1 xi k  with χi mi j
being the jth component of that vector average   and let
ˆˆσ2
i j =
i
mi−1
�mi
k=1 xi k j − χi mi j 2 be the unbiased sam-
ple variance of the mi variables in the jth component  as
before  we assume weights τi for each stratum 
in this context we have the following theorem  proof pro-
vided in supplimentary material  
theorem 6 1  vector sebm bound   in the context above 
then with ωni
mi  ψni
mi per lemma 3 7 
p
��m
j=1  �n
i=1 τi χi mi j − µi j  2 ≥
log 6/p  �m
j=1
�
αj  
��
βj   √γj
�2�
�
≤ mp
 7 
where 
αj =
n
�
i=1
4
17ωni
mid2
i jτ 2
i  
βj = log 3/p 
�
max
i
τ 2
i ψni
mi
2d2
i j
�
γj =2
n
�
i=1
τ 2
i ψni
mi mi − 1 ˆˆσ2
i j/mi
 
log 6n/p 
�
i
τ 2
i d2
i jωni
miψni
mi
 
log 3/p 
�
max
i
τ 2
i ψni
mi
2d2
i j
�
proceedings of the thirtieth    ijcai-21 
78
 the left hand side of  7  is the square euclidean dis-
tance between our weighted stratified sample vector estimate
�n
i=1 τiχi mi and the true mean stratified vector �n
i=1 τiµi 
7
conclusion
this paper develops an improved stratified sampling method
for estimating the shapley value of cooperative games  the
sampling method is built on a novel empirical bernstein
bound  a concentration inequality for sampling from strata
without replacement 
this bound is used in a sampling
strategy tailored to shapley value estimation  numerical re-
sults clearly demonstrate the benefit of our stratified sampling
method for shapley value estimation  by consistently outper-
forming the state of the art 
acknowledgements
a great thanks to sylvie thi ebaux and paul scott for aca-
demic advice  encouragement and support 
a
supplementary material  proofs
proof of lemma 3 1  for any events a and b 
p a ∪ b  ≤ p a    p b  hence 
p   a > b  ∪  b > c   ≤ p a > b    p b > c  
if a > c  then  a > b  ∪  b > c  is true irrespective of b  so 
p a > c  ≤ p   a > b  ∪  b > c  
proof of lemma 3 2  by expanding terms 
ˆσ2 = 1
n
�
i
�
xi − 1
n
�
j xj
�2
= 1
n
�
i x2
i −
1
n2
�
i j xixj
ˆσ2
0 = 1
n
�
i  xi − µ 2 = 1
n
�
i x2
i − 2µ
n
�
i xi µ2 therefore 
ˆσ2
0−ˆσ2 =
1
n2
�
i j xixj− 2µ
n
�
i xi µ2 =
�
1
n
�
j xj − µ
�2
proof of lemma 3 3  p x ≥ t  = p  exp sx  ≥ exp st  
≤ e  exp sx   exp −st  by markov s inequality 
theorem a 1  parabola fitting   for a < b and b  z > 0 
there exists α  β  γ that  αx2   βx   γ ≥ exp x  for all a ≤
x ≤ b  and zα   γ =  z exp b    b2 exp −z/b   z   b2 −1 
proof  parabola αx2 βx γ that satisfies these requirements
touches the exponential curve at one point  at x = f < b  and
intersects it at another  at x = b   per figure 1  thus 
�α
β
γ
�
=
�
�
b2
b
1
f 2
f
1
2f
1
0
�
�
−1 �exp b 
exp f 
exp f 
�
this gives α  β  γ  in terms of f and b  hence 
zα γ =    z fb−b  f−b−1 −b ef  f 2 z eb  b−f −2
minimizing with f occurs at f = −z
b and gives the result 
proof of lemma 3 5  assume wlog that x has a mean of
zero 
we construct an upper bound for e  exp sx   by
parabola over exp sx   there exists a parabola defined by
α  β  γ  theorem a 1  and thus we expand  e  exp sx  
≤ e αs2x2   βsx   γ  = αs2 e x2    γ = αs2σ2   γ
=
�
σ2
b2 exp
�
s
�
b   σ2
b
��
  1
�
exp
�
− sσ2
b
� �
σ2
b2   1
�−1
 
this is monotonically increasing with b  and d > b 
therefore  log e  exp sx    ≤
log
�
σ2
d2 exp
�
s
�
d   σ2
d
��
  1
�
− sσ2
d − log
�
σ2
d2   1
�
using the fact that for any κ  x ≥ 0 
log κ exp x    1  ≤ log κ   1   
xκ
κ 1   x2
1
17   κ
2
 κ 1 2
the result follows using κ = σ2
d2 and x = s d  σ2/d  
proof of lemma 3 6  assume wlog x has a mean of
zero  we construct an upper bound for e
�
exp −qx2 
�
by
parabola over exp −qx2   for α  γ such that αx2   γ ≥
exp −qx2  for all a < x < b  if we define d = max b  −a 
we can choose γ = 1 and α =  exp −qd2  − 1 d−2
 see figure 2  which results in 
log e exp −qx2   ≤ log
�
σ2
d2 exp −qd2  − σ2
d2   1
�
given that for any 0
≤
κ
≤
0 5 and γ
≤
0 that 
log  κ exp γ  − κ   1  ≤ κγ   1
2κ 1 − κ γ2
letting κ = σ2
d2 and γ = −qd2
 which is valid by popoviciu s inequality σ2 ≤ d2/4 
e exp −qx2   ≤ exp
� 1
2σ2q2 d2 − σ2  − σ2q
�
≤ exp
� 1
2σ2q2d2 − σ2q
�
and the result follows by multiplying by exp qσ2  
proof of lemma 3 7  by the independence of samples 
e exp sχm   = e
�
exp
� s
m
�m
i=1 xi
��
=
�m
1 e
�
exp
� s
mx
��
≤ exp
�
s2
m2
�m
1
�
αd2   βσ2��
proof of lemma 3 8  χm = 1
m
�m
i=1 xi
= χm 1   1
m χm 1 − xm 1 
=  χm − χm 1     χm 1 − χm 2    · · ·    χn−1 − χn 
=
1
m χm 1 − xm 1   
1
m 1 χm 2 − xm 2    · · ·  
1
n−1 χn − xn 
then because  exp sχm  = �n−1
k=m exp
� s
k χk 1 − xk 1 
�
e exp sχm   =
e
��n−1
k=m e
�
exp
� s
k χk 1 − xk 1 
�
|χk 1       χn
��
by repeated application of the law of total expectation 
since  e xk 1|χk 1       χn  = χk 1 then χk 1 − xk 1 is
a random variable with a mean of zero bounded within width
d  and it also has a variance given by 
σ2
k 1 =
nσ2−�n
j=k 1 x2
j
n− n−k−1 
− χ2
k ≤ nσ2
k 1
by application of lemma 3 2  therefore 
e exp sχm   ≤ exp
��n−1
k=m
�
αd2   β nσ2
k 1
�
s2
k2
�
proof of theorem 4 2  applying lemma 3 3 
p  �n
i=1 τiχi mi − �n
i=1 τiµi ≥ t 
≤ e  exp  �n
i=1 τis  χi mi − µi    exp −st 
= �n
i=1 e  exp  τis  χi mi − µi    exp −st 
by independence of the sampling between the strata  this is
sufficient for lemmas 3 7  and 3 5 to apply giving 
proceedings of the thirtieth    ijcai-21 
79
 p  |�n
i=1 τi χi mi − µi | ≥ t 
≤ 2 exp
��n
i=1
� 1
17d2
i ωni
mi   1
2σ2
i ψni
mi
�
τ 2
i s2 − st
�
minimizing with s and rearranging gives result 
proof of theorem 4 3  to
bound
the
sum
of
variances
 weighted by arbitrary positive θi   consider the aver-
age square of samples about the strata means 
applying
lemma 3 3 gives 
p
��n
i=1 θi σ2
i −
1
mi
�mi
j=1 xi j − µi 2  ≥ y
�
≤
e
�
exp
��n
i=1 sθi
�
σ2 −
1
mi
�mi
j=1 xi j − µi 2���
exp −sy 
≤ exp −sy  �n
i=1 e
�
exp
�
sθi
mi
�mi
j=1 σ2 −  xi j − µi 2 
��
by independence of the sampling between the strata  this is
sufficient for lemma 3 7 with lemma 3 6 to apply 
p
��n
i=1 θi σ2
i −
1
mi
�mi
j=1 xi j − µi 2  ≥ y
�
≤
exp
� 1
2
�n
i=1 σ2
i θ2
i s2d2
i ψni
mi − sy
�
minimizing with respect to s  rearranging  and applying
lemma 3 2 gives result 
proof of theorem 4 4  we consider the weighted square
error of the sample means 
p
��n
i=1 θi µi − χi mi 2 ≥ r
�
≤ 1 − �n
i=1 p
�
θi µi − χi mi 2 ≤ ri
�
= 1−
�n
i=1
�
1 − p
�
µi − χi mi ≥
�
ri
θi
�
− p
�
χi mi − µi ≥
�
ri
θi
��
such that � ri = r  by independence of the sampling and
probability complementarities 
applying lemma 3 3 together with lemmas 3 7  3 4  gives 
p
��n
i=1 θi µi − χi mi 2 ≥ r
�
≤ 1 − �n
i=1
�
1 − 2 exp
�
−
2ri
θid2
i ω
ni
mi
��
choosing ri to minimize this expression gives 
ri =
�
rθid2
i ωni
mi
� ��
j θjd2
jωnj
mj
�−1
thus  p
��n
i=1 θi µi − χi mi 2 ≥ r
�
≤
1 − �n
i=1
�
1 − 2 exp
�
−2r
�
j θjd2
j ω
nj
mj
��
using log 1 −  1 − exp x  n  ≤ x   log n  for negative x 
and rearranging  gives result 
proof of theorem 4 5  by widening the bound of equa-
tion  2  we get 
p
��n
i=1 θiσ2
i − �n
i=1 θi ˆσ2
i    µi − χi mi 2  ≥
�
2 log 1/y  maxi θid2
i ψni
mi  �n
i=1 θiσ2
i
�
≤ y
completing the square gives for
��n
i=1 θiσ2
i gives 
p
�
�
�
�
�
�
�
�
n
�
i
θiσ2
i ≥
��n
i θi ˆσ2
i    µi − χi mi 2 
  log 1/y 
2
�
maxi θid2
i ψni
mi
�
 
�
log 1/y 
2
 maxi θid2
i ψni
mi 
�
�
�
� ≤ y 
combining
with
equation
 3 
with
a
union
bound
 lemma 3 1  gives 
p
�
�
�
�
�
�
�
�
�
�
n
�
i
θiσ2
i ≥
�
�
�
�
�
�n
i θiˆσ2
i
  log 2n/r 
2
�
i θid2
i ωni
mi
  log 1/y 
2
�
maxi θid2
i ψni
mi
�
 
�
log 1/y 
2
 maxi θid2
i ψni
mi 
�
�
�
�
�
�
≤ y  r 
which is a bound for the weighted sum variances in terms of
the sample variances  letting θi = 1
2τ 2
i ψni
mi and combining
with  1  with a union bound  lemma 3 1   and then assigning
r = t = y = p/3 and rewriting in terms of unbiased sample
variance  gives the result 
proof of theorem 6 1  squaring  4  and applying it specifi-
cally to the jth component of all the vectors gives 
p
�
 �n
i=1 τi χi mi − µi  2
log 6/p 
≥ αj  
��
βj   √γj
�2
�
≤ p
taking a series of union bounds  lemma 3 1  over j gives us
our result 
x
ex
αx2   βx   γ
a
f
b
figure 1  a parabola parametarized by touching and in-
tercepting points f  b above an exponential curve for all
a ≤ x ≤ b
x
e−qx2
g x 
a
b
figure 2  parabola g x  =  exp −qd2  − 1 d−2x2   1
over function exp −qx2  for all a ≤ x ≤ b where d =
max b  −a 
proceedings of the thirtieth    ijcai-21 
80
 references
 audibert et al   2007  jean-yves audibert  r emi munos 
and csaba szepesv ari 
tuning bandit algorithms in
stochastic environments 
in marcus hutter  rocco a 
servedio  and eiji takimoto  editors  proceedings of the
18th international conference on algorithmic learning
theory  alt 07   pages 150–165  berlin  heidelberg 
2007  springer berlin heidelberg 
 audibert et al   2009  jean-yves audibert  r emi munos 
and csaba szepesv ari  exploration-exploitation tradeoff
using variance estimates in multi-armed bandits  theoret-
ical computer science  410 19  1876–1902  2009 
 aziz et al   2016  haris aziz  casey cahan  charles gret-
ton  philip kilby  nicholas mattei  and toby walsh  a
study of proxies for shapley allocations of transport costs 
journal of artificial intelligence research  56 573–611 
2016 
 bachrach et al   2009  yoram
bachrach 
evangelos
markakis  ezra resnick  ariel d  procaccia  jeffrey s 
rosenschein  and amin saberi 
approximating power
indices  theoretical and empirical analysis  autonomous
agents and multi-agent systems  aamas   20 105–122 
2009 
 bardenet and maillard  2015  r emi bardenet and odalric-
ambrym maillard 
concentration inequalities for sam-
pling without replacement  bernoulli  21 3  1361–1385 
08 2015 
 bennett  1962  george bennett  probability inequalities for
the sum of independent random variables  journal of the
american statistical association  57 297  33–45  1962 
 boucheron et al   2003  stephane boucheron  g abor lu-
gosi  and pascal massart  concentration inequalities us-
ing the entropy method 
the annals of probability 
31 3  1583–1614  2003 
 carpentier et al   2011  alexandra carpentier  alessandro
lazaric  mohammad ghavamzadeh  r emi munos  and
peter auer  upper-confidence-bound algorithms for ac-
tive learning in multi-armed bandits  in proceedings of
the 22nd international conference on algorithmic learn-
ing theory  alt 11   pages 189–203  berlin  heidelberg 
2011  springer-verlag 
 castro et al   2009  javier castro  daniel g omez  and juan
tejada  polynomial calculation of the shapley value based
on sampling  computers   or  36 5  1726–1730  2009 
 castro et al   2017  javier castro  daniel g omez  elisenda
molina  and juan tejada  improving polynomial estima-
tion of the shapley value by stratified random sampling
with optimum allocation  computers   operations re-
search  82 180 – 188  2017 
 chapman et al   2017  archie
c 
chapman 
sleiman
mhanna  and gregor verbiˇc 
cooperative game theory
for non-linear pricing of load-side distribution network
support  in proceedings of the 10th bulk power systems
dynamics and control symposium  irep 17   2017 
 efron and stein  1981  bradley efron and charles stein 
the jackknife estimate of variance  annals of statistics 
9 3  586–596  05 1981 
 hoeffding  1963  wassily hoeffding  probability inequal-
ities for sums of bounded random variables  journal of
the american statistical association  58 301  13–30  mar
1963 
 lundberg and lee  2017  scott m lundberg and su-in lee 
a unified approach to interpreting model predictions  in
advances in neural information processing systems  pages
4765–4774  2017 
 maleki et al   2013  sasan maleki  long tran-thanh  greg
hines  talal rahwan  and alex rogers  bounding the es-
timation error of sampling-based shapley value approxi-
mation  arxiv e-prints  page arxiv 1306 4265  june 2013 
 maurer and pontil  2009  andreas maurer and massimil-
iano pontil  empirical bernstein bounds and sample vari-
ance penalization  in proceedings of the 22nd annual con-
ference on learning theory  colt 2009   june 2009 
 michalak et al   2013  tomasz p  michalak  karthik v  aa-
dithya  piotr l  szczepanski  balaraman ravindran  and
nicholas r  jennings  efficient computation of the shap-
ley value for game-theoretic network centrality  journal of
artificial intelligence research  46 1  607–650  january
2013 
 mnih et al   2008  volodymyr mnih  csaba szepesv ari  and
jean-yves audibert 
empirical bernstein stopping 
in
proceedings of the 25th international conference on ma-
chine learning  icml   icml  08  pages 672–679  new
york  ny  usa  2008  acm 
 neyman  1938  j  neyman  contribution to the theory of
sampling human populations 
journal of the american
statistical association  33 201  101–116  1938 
 o brien et al   2015  geaorid o brien  abbas el gamal 
and ram rajagopal  shapley value estimation for compen-
sation of participants in demand response programs  ieee
transactions on smart grid  6 6  2837–2844  2015 
 serfling  1974  robert j  serfling  probability inequalities
for the sum in sampling without replacement  the annals
of statistics  2 1  39–48  01 1974 
 soufiani et al   2014  hossein azari soufiani 
denis x
charles  david m chickering  and david c parkes  ap-
proximating the shapley value via multi-issue decomposi-
tion  in proc  autonomous agents and multi-agent sys-
tems  14  acm  2014 
 thomas et al   2015  philip
s 
thomas 
georgios
theocharous  and mohammad ghavamzadeh 
high-
confidence off-policy evaluation 
in proceedings of the
29th aaai conference on artificial intelligence  january
25-30  2015  austin  texas  usa   pages 3000–3006 
2015 
proceedings of the thirtieth    ijcai-21 
81
 "
None,2021,https-www-ijcai-org-proceedings-2021-0012-pdf,Picking Sequences and Monotonicity in Weighted Fair Division,"Mithun Chakraborty, Ulrike Schmidt-Kraepelin, Warut Suksompong",None,https://www.ijcai.org/proceedings/2021/0012.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0012-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0012-pdf.pdf,"picking sequences and monotonicity in weighted fair division
mithun chakraborty1   ulrike schmidt-kraepelin2 and warut suksompong3
1department of electrical engineering and computer science  university of michigan  usa
2efficient algorithms research group  tu berlin  germany
3school of computing  national university of singapore  singapore
dcsmc@umich edu  u schmidt-kraepelin@tu-berlin de  warut@comp nus edu sg
abstract
we study the problem of fairly allocating indivis-
ible items to agents with different entitlements 
which captures  for example  the distribution of
ministries among political parties in a coalition
government 
our focus is on picking sequences
derived from common apportionment methods  in-
cluding five traditional divisor methods and the
quota method  we paint a complete picture of these
methods in relation to known envy-freeness and
proportionality relaxations for indivisible items as
well as monotonicity properties with respect to the
resource  population  and weights  in addition  we
provide characterizations of picking sequences sat-
isfying each of the fairness notions  and show that
the well-studied maximum nash welfare solution
fails resource- and population-monotonicity even
in the unweighted setting  our results serve as an
argument in favor of using picking sequences in
weighted fair division problems 
1
introduction
after a national election  the parties forming a coalition gov-
ernment are faced with the task of dividing the ministries
among themselves  how can they perform this task in a fair
manner  taking into account both their preferences on min-
istries and the votes that they received in the election 
the study of fairly allocating resources to interested agents
 in this case  parties   commonly known as fair division  has a
long history dating back several decades  brams and taylor 
1996  moulin  2003   among the most prominent fairness
criteria are envy-freeness—no agent prefers another agent s
allocated bundle over her own—and proportionality—if there
are n agents  then every agent receives at least 1/n of her
value for the entire resource  these criteria implicitly assume
that all agents have the same entitlement to the resource  an
assumption that is made in the vast majority of the fair di-
vision literature  yet utterly fails in our ministry example as
well as when allotting supplies to districts  organizations  or
university departments  which typically have different sizes 
fortunately  both envy-freeness and proportionality allow for
taking the entitlements  or weights  into account in a natu-
ral way  for instance  if agent a s weight is twice that of
agent b  then a will be satisfied with respect to weighted
envy-freeness as long as she derives at least twice as much
value for her own bundle as for b s bundle 
while such
weight-based extensions of classical fairness concepts are ap-
propriate for scenarios with different entitlements  they some-
times cannot be satisfied when allocating indivisible items
like ministries  e g   when every party places all of its value
on the same important ministry   consequently  recent work
has proposed relaxations including weighted envy-freeness up
to one item  wef1   chakraborty et al   2020  and weighted
proportionality up to one item  wprop1   aziz et al   2020  
each of which can always be fulfilled 
an attractive class of procedures for allocating items is the
class of picking sequences  these procedures let agents take
turns picking their favorite items according to a prespecified
order  picking sequences are intuitive  can be implemented
efficiently  and help preserve privacy since each agent only
has to reveal the picks in her turns as opposed to her full
preferences  in fact  several methods for apportioning seats
in a parliament—a setting commonly known as apportion-
ment—can be formulated as picking sequences 1 for exam-
ple  adams  method assigns each pick to an agent i who min-
imizes ti/wi  where ti and wi denote the number of times
that agent i has picked so far and her weight  respectively 
brams and kaplan  2004  proposed using picking sequences
to allocate ministries  noting that such sequences have been
used in northern ireland and denmark  and chakraborty et
al   2020  showed that the allocation produced by adams 
method always fulfills wef1 but not necessarily wprop1 
it is therefore an important question which fairness criteria  if
any  are satisfied by picking sequences based on other preva-
lent apportionment methods 
in addition to fairness  another desirable set of properties
for allocation procedures is monotonicity in terms of the pa-
rameters of the setting  in particular  resource-monotonicity
means that whenever an extra item is added  no agent re-
ceives a lower utility as a result 
similarly  population-
monotonicity stipulates that introducing an additional agent
should not increase the utility of any existing agent  and
weight-monotonicity implies that when the weight of an agent
increases  her utility does not go down 2 segal-halevi and
1note that apportionment is a special case of our setting where
all items are identical  balinski and young  2001  
2resource-monotonicity is known as house-monotonicity in the
proceedings of the thirtieth    ijcai-21 
82
 sziklai  2019  showed that for divisible items in the un-
weighted setting  the maximum nash welfare  mnw  solu-
tion  which chooses an allocation maximizing the product of
the agents  utilities  is resource- and population-monotone 
how do picking sequences and  a weighted generalization of 
mnw perform with respect to monotonicity properties in the
weighted allocation of indivisible items 
1 1
our results
in this paper  we conduct a thorough investigation of picking
sequences based on common apportionment methods  as well
as the maximum  weighted  nash welfare solution  in relation
to fairness and monotonicity properties  in addition to wef1
and wprop1  we consider weak weighted envy-freeness up
to one item  wwef1   a weakening of wef1 proposed by
chakraborty et al   2020   for brevity  we say that an allo-
cation rule satisfies a fairness notion if the allocation that it
produces for an arbitrary input instance satisfies that notion 
we begin in section 3 by establishing fundamental re-
sults on our properties in the context of picking sequences 
in particular  we define three consistency properties with
respect to the resource  population  and weights—for ex-
ample  resource-consistency means that whenever an item
is added  the new picking sequence should simply be the
old one with an additional pick appended at the end  we
show that resource- and population-consistency imply the re-
spective monotonicity properties for any number of agents 
while weight-consistency implies weight-monotonicity only
for two agents  in addition  for each fairness notion  we char-
acterize the picking sequences whose output always satisfies
that notion 
with this groundwork laid  we proceed to determine the
properties satisfied by each allocation rule in section 4  first 
we consider the picking sequences derived from five tradi-
tional divisor methods due to adams  jefferson  webster 
hill  and dean  these methods assign each pick to an agent i
who minimizes the ratio f ti /wi capturing the proportion
between the number of times the agent has picked so far and
the agent s weight  where the function f varies from method
to method  we establish that all five methods satisfy resource-
and population-monotonicity for any number of agents as
well as weight-monotonicity for two agents  however  they all
fail weight-monotonicity when there are three agents  on the
fairness front  all of the methods satisfy wwef1  but adams 
is the only one satisfying the stronger notion of wef1 while
jefferson s is the only one fulfilling wprop1 
next  in section 5  we address the picking sequence de-
rived from another important apportionment method  the
quota method  while not itself a divisor method  the quota
method has a definition similar to that of jefferson s method 
which uses the function f t  = t   1  but also imposes a
 quota  to determine each agent s eligibility  we show that
the quota method exhibits similar monotonicity behavior as
the divisor methods  with the notable exception that it fails
context of apportionment  a violation of it is referred to as the al-
abama paradox  balinski and young  2001   likewise  violations
of  variants of  population- and weight-monotonicity are called the
new states paradox and the population paradox  respectively 
population-monotonicity 
as for fairness  like jefferson s
method  the quota method satisfies wwef1 and wprop1 
in fact  these two rules are the first to have been shown to
satisfy both wwef1 and wprop1  to the best of our knowl-
edge 
finally  in section 6  we examine the maximum weighted
nash welfare  mwnw  solution  which is a natural gener-
alization of the well-studied mnw solution to the weighted
setting 
chakraborty et al   2020  already proved that
mwnw satisfies wwef1 but not wef1  we show that
it fails wprop1 
we then present examples demonstrat-
ing that even in the unweighted setting  where mwnw re-
duces to mnw   the rule fails both resource- and population-
monotonicity 
this result stands in stark contrast to the
aforementioned result of segal-halevi and sziklai  2019  that
mnw is resource- and population-monotone in the context of
divisible items  and is perhaps even more striking given that
mnw is known to fulfill several desirable properties  cara-
giannis et al   2019  halpern et al   2020   on the positive
side  mwnw satisfies weight-monotonicity for any number
of agents  and is the only rule to do so among the ones we
consider in this paper 
our results are summarized in table 1  overall  we be-
lieve that they serve as an argument in favor of using picking
sequences in division problems with unequal entitlements in
view of both fairness and monotonicity considerations 
1 2
related work
the fair allocation of indivisible items has received substan-
tial recent attention  notably among computer scientists—see
the surveys of bouveret et al   2016  and markakis  2017  
a large majority of work assumes that all agents have equal
entitlements  in which case the notions envy-freeness up to
one item  ef1   lipton et al   2004  budish  2011  and pro-
portionality up to one item  prop1   conitzer et al   2017 
aziz et al   2019a  are often considered  both wef1 and
wwef1 reduce to ef1 in the unweighted setting  while
wprop1 reduces to prop1 
even though ef1 implies
prop1  chakraborty et al   2020  showed that no rule can si-
multaneously satisfy wef1 and wprop1  aziz et al   2020 
gave a protocol satisfying wprop1 along with the eco-
nomic efficiency notion of pareto optimality  while babaioff
et al   2019  considered competitive equilibrium for agents
with different budgets representing their weights 
farhadi
et al   2019  proposed a weighted version of maximin share
fairness  budish  2011  kurokawa et al   2018   and aziz et
al   2019b  studied the analogous notion for chores  i e   items
that yield negative utilities  
like fair division  apportionment methods have given
rise to a long line of work that analyzes their advantages
and disadvantages according to various desiderata  balin-
ski and young  2001  pukelsheim  2014   as balinski and
young  2001  noted  adams  method tends to favor agents
with smaller weights and jefferson s typically benefits those
with larger weights  whereas the other three divisor meth-
ods lie in between  apportionment has also attracted interest
in artificial intelligence  brill et al   2017  brill et al   2020 
bredereck et al   2020  as well as in philosophy  wintein and
heilmann  2018  
proceedings of the thirtieth    ijcai-21 
83
 resource-mon 
population-mon 
weight-mon 
wef1
wwef1
wprop1
adams






jefferson






webster






hill






dean






quota






mwnw






table 1  summary of our results  chakraborty et al   2020  showed that adams  method satisfies wef1 and wwef1 but not wprop1 
while mwnw satisfies wwef1 but not wef1  all other results are new to this paper  all rules satisfy weight-monotonicity in the case of
two agents  mwnw fails resource- and population-monotonicity even in the unweighted setting 
finally  picking sequences have been studied by several au-
thors due to their simplicity and practicality  bouveret and
lang  2011  bouveret and lang  2014  aziz et al   2015 
tominaga et al   2016  beynier et al   2019   with a number of
authors investigating manipulation issues  we assume in this
paper that agents are not strategic and always pick their most
preferred item available  in the unweighted setting  a popu-
lar picking sequence is the round-robin algorithm  which lets
agents pick items in cyclic order until the items run out 
2
preliminaries
we consider a discrete resource allocation setting with a set
of agents n =  n  and a set of indivisible items m =  m  
where  k   =  1  2          k  for any k ∈ n  each agent i ∈
n is endowed with a weight wi > 0 and a utility function
ui   2m → r≥0  for convenience  we sometimes write ui j 
instead of ui  j   for an item j ∈ m  as is very common in
the fair division literature  we assume that the utility functions
are additive  i e   ui m ′  = �
j∈m ′ ui j  for all i ∈ n and
m ′ ⊆ m  an allocation m =  m1          mn  is a partition
of the items into n bundles so that agent i receives bundle mi 
an instance consists of the agents  items  weights  and utility
functions  when all weights are equal  in which case we can
take them to be 1 without loss of generality   we refer to the
resulting setting as the unweighted setting 
we consider the following three fairness notions  the first
two notions were proposed by chakraborty et al   2020  and
the third by aziz et al   2020  
definition 2 1  an allocation  m1          mn  is said to satisfy
• weighted envy-freeness up to one item  wef1  if for any
i  j ∈ n  there exists b ⊆ mj with |b| ≤ 1 such that
ui mi 
wi
≥ ui mj\b 
wj
 
• weak weighted envy-freeness up to one item  wwef1 
if for any i  j ∈ n  there exists b ⊆ mj with |b| ≤ 1
such that ui mi 
wi
≥ ui mj\b 
wj
or ui mi∪b 
wi
≥ ui mj 
wj
 
• weighted proportionality up to one item  wprop1  if
for any i ∈ n  there exists b ⊆ m \ mi with |b| ≤ 1
such that ui mi  ≥
�
wi
�
i′∈n wi′ · ui m 
�
− ui b  
chakraborty et al   2020  showed that no rule can simulta-
neously satisfy wef1 and wprop1  in particular  consider
an instance where m = n and every agent has a nonzero
utility for every item  any wef1 allocation has to assign
exactly one item to each agent 3 on the other hand  if a cer-
tain agent has the same utility for all items and a sufficiently
larger weight than every other agent  wprop1 will require
this agent to receive at least m − 1 items 
a domain refers to a set of instances 
a domain may
include all instances with any number of agents and items 
weights  and utility functions  or it may only include—for
example—all instances with two agents  or all instances with
equal weights  this corresponds to the unweighted setting  
an allocation rule is a function that maps each instance in a
given domain to an allocation  it is said to satisfy a fairness
notion if the allocation that it produces always fulfills that
notion  we now define the three monotonicity properties that
we consider—the first two have been studied by segal-halevi
and sziklai  2018  2019   while the third has not been studied
in fair division to the best of our knowledge 
definition 2 2  an allocation rule r with domain i satisfies
• resource-monotonicity if the following holds  for any in-
stance with m items  when an extra item is added as item
m   1  if both the original and the modified instance be-
long to i  then each agent receives no higher utility from
the allocation produced by r in the original instance
than in the modified instance 
• population-monotonicity if the following holds  for any
instance with n agents  when an extra agent is added as
agent n 1  if both the original and the modified instance
belong to i  then each of the first n agents receives at
least as much utility from the allocation produced by r
in the original instance as in the modified instance 
• weight-monotonicity if the following holds  for any in-
stance  when the weight of an agent increases  if both the
original and the modified instance belong to i  the util-
ity that the agent receives from the allocation produced
by r does not decrease 
while these monotonicity properties are intuitive and it
may seem that any reasonable allocation rule should satisfy
them  this is in fact not the case  in the full version of our
paper  chakraborty et al   2021   we show that two popu-
lar fair division algorithms—the envy cycle elimination al-
3otherwise an agent with no item will  weighted- envy an agent
with at least two items by more than one item 
proceedings of the thirtieth    ijcai-21 
84
 gorithm and the adjusted winner procedure—fail resource-
monotonicity even in the unweighted setting 
next  we provide definitions related to picking sequences 
definition 2 3  a picking sequence on n agents and m items
is a sequence πn m w =  a1  a2          am   where ai ∈ n
for each i ∈ m  a family of picking sequences is a col-
lection π =  πn m w   with at most one picking sequence
for each pair of positive integers n  m and weight vector
w =  w1          wn   a family of picking sequences π is called
• resource-consistent if for every n  m  w such that both
πn m w and πn m 1 w belong to π  the sequence πn m w
forms a prefix of πn m 1 w 
• population-consistent if for every n  m  w  w′ such that
w′ =  w1          wn  w′
n 1  where w′
n 1 is the weight of
agent n 1 and both πn m w and πn 1 m w′ belong to π 
the sequence πn 1 m w′ can be obtained from πn m w by
inserting agent n   1 in some positions  possibly none 
and trimming the suffix of the resulting sequence so that
the sequence has length m 
• weight-consistent if the following holds 
for every
n  m  w and w′
i > wi such that both πn m w and πn m w′
belong to π  where w′ =  w1          w′
i          wn   the se-
quence πn m w′ can be obtained from πn m w by moving
some of agent i s picks earlier  possibly none   inserting
agent i in some positions  possibly none   and trimming
the suffix of the resulting sequence so that the sequence
has length m 
given a picking sequence  a1          am  and the agents 
utility functions  we assume that in the ith turn  agent ai picks
her highest-valued item from among the remaining items 
breaking ties in a consistent manner  say  in favor of lower-
numbered items  
we sometimes drop the subscript from
πn m w when n  m  w are clear from the context  a family
of picking sequences generates an allocation rule  which we
will refer to interchangeably with the family itself  we also
refer to a picking sequence π interchangeably with the family
of picking sequences that consists only of π 
all omitted proofs can be found in the full version of this
paper  chakraborty et al   2021  
3
general picking sequences
we begin by proving results for general picking sequences  in
addition to being interesting in their own right  these results
will later help us determine the properties that each appor-
tionment method satisfies  first  we present characterizations
of picking sequences whose output is guaranteed to satisfy
each of the fairness notions wef1  wwef1  and wprop1 
in particular  we show that a picking sequence guarantees a
fairness notion for agents with arbitrary utility functions if
and only if it does so for agents with identical utility func-
tions that put utility 1 on some items and 0 on the remaining
items  this means that the fairness guarantees for general
utilities can be expressed as relatively simple conditions on
the number of picks in each prefix of the picking sequence 
theorem 3 1  a picking sequence π satisfies wef1 if and
only if for every prefix of π and every pair of agents i  j with
tj ≥ 2  we have
ti
tj−1 ≥ wi
wj   where ti and tj denote the num-
ber of agent i s and agent j s picks in the prefix  respectively 
theorem 3 2  a picking sequence π satisfies wwef1 if and
only if for every prefix of π and every pair of agents i  j with
tj ≥ 2  both of the following hold 
•
ti
tj−1 ≥ wi
wj if wi ≥ wj 
•
ti 1
tj
≥ wi
wj if wi ≤ wj 
where ti and tj denote the number of agent i s and agent j s
picks in the prefix  respectively 
as an example of a picking sequence that satisfies wwef1
but not wef1  suppose that n = 2  w1 = 1  w2 = 2  and
consider the sequence  1  2  2  2  2   for this sequence  we
have t1 = 1 and t2 = 4  and therefore t1 1
t2
= w1
w2 >
t1
t2−1 
theorem 3 3  a picking sequence π satisfies wprop1 if
and only if for every prefix of π and every agent i  we have
ti ≥
�
wi
�
i′∈n wi′ · k
�
− 1  where ti and k denote the number
of agent i s picks in the prefix and the length of the prefix 
respectively 
next  we establish a strong relationship between resource-
and population-consistency and the corresponding mono-
tonicity notions 
theorem 3 4  any resource-consistent family of picking se-
quences satisfies resource-monotonicity 
theorem 3 5  any population-consistent family of picking
sequences satisfies population-monotonicity 
the relationship between weight-consistency and weight-
monotonicity is less straightforward  we show that the former
implies the latter in the case of two agents  as we will see
later  proposition 4 2   this relationship breaks down when
there are three agents 
theorem 3 6  for two agents  any weight-consistent family
of picking sequences satisfies weight-monotonicity 
4
divisor methods
as we explained in the introduction  a divisor apportionment
method gives rise to a picking sequence that  in each turn 
lets an agent i with the smallest f ti /wi pick the next item
 breaking ties in a consistent manner  say  in favor of lower-
numbered agents   where ti denotes the number of times
that agent i has picked so far and f   z≥0 → r≥0 is a
strictly increasing function specific to the method such that
t ≤ f t  ≤ t   1 
4 we will refer to the divisor meth-
ods and their associated families of picking sequences in-
terchangeably 
by definition  it is clear that every divisor
method yields a family of picking sequences  for all n  m  w 
that are resource-  population-  and weight-consistent  theo-
rems 3 4  3 5  and 3 6 therefore imply the following 
corollary 4 1  every divisor method satisfies resource-
monotonicity and population-monotonicity  it also satisfies
weight-monotonicity when there are two agents 
4some non-divisor apportionment methods such as hamilton s
method do not give rise to a picking sequence and are therefore not
useful in our context  brams and kaplan  2004  p  149  
proceedings of the thirtieth    ijcai-21 
85
 the five traditional divisor methods of adams  jefferson 
webster  hill  and dean have the function f t  equal to t 
t   1  t   1
2 
�
t t   1   and t t 1 
t  1
2   respectively  balinski
and young  2001  p  99   we prove that  perhaps surprisingly 
all five methods fail weight-monotonicity in the case of three
agents 5 this also means that weight-consistency does not
imply weight-monotonicity beyond two agents 
proposition 4 2  each of the five traditional divisor meth-
ods does not satisfy weight-monotonicity even when there are
three agents 
we now explore how the five divisor methods fare with
respect to the three fairness notions  starting with wef1 
theorem 4 3  of the five traditional divisor methods 
adams  method is the only one satisfying wef1 
next  we show that interestingly  all five methods satisfy
wwef1  meaning that each of them can guarantee fairness
beyond the setting with identical items  i e   apportionment  
theorem 4 4  all five traditional divisor methods satisfy
wwef1 
proof  we claim that any divisor method whose function f
fulfills the following two conditions satisfies wwef1 
•
f a 
f b  ≤ a
b for any integers 1 ≤ b ≤ a 
•
f a 
f b  ≤ a 1
b 1 for any integers 0 ≤ a ≤ b with b ̸= 0 
to prove the claim  consider such a divisor method  and fix a
pair of agents i  j  it suffices to show that every time agent j
picks an item starting from her second pick  the conditions
in theorem 3 2 are satisfied 
by definition of the divisor
method  after agent j s pick it holds that f tj−1 
wj
≤
f ti 
wi  
otherwise agent i should have picked instead of agent j  con-
sider two cases as in the conditions of theorem 3 2 with
tj ≥ 2 
case 1  wi ≥ wj  since f is strictly increasing  we have
f tj − 1  > f 0  ≥ 0  and so 1 ≤
wi
wj ≤
f ti 
f tj−1   this
means that ti ≥ tj − 1  and our assumption on f implies that
wi
wj ≤
f ti 
f tj−1  ≤
ti
tj−1  as desired 
case 2  wi ≤ wj  we have f tj − 1  > 0 and wi
wj ≤
f ti 
f tj−1   if ti ≥ tj − 1  then wi
wj ≤ 1 ≤ ti 1
tj   otherwise 
ti < tj − 1  and our assumption on f implies that wi
wj ≤
f ti 
f tj−1  ≤
ti 1
 tj−1  1 = ti 1
tj   as desired 
next  we show that the functions f of all five divisor
methods satisfy the two conditions above 
first  consider
f t  = t   c for any constant c ∈  0  1   if 1 ≤ b ≤ a 
the function a x
b x is non-increasing for x ≥ 0  so a c
b c ≤ a
b  
on the other hand  if 0 ≤ a ≤ b with b ̸= 0  the function a x
b x
is non-decreasing for x ≥ 0  so a c
b c ≤ a 1
b 1   this shows that
5brams and kaplan  2004  p  157  showed that for n = 3  an
agent can do worse when her picks move earlier in the picking se-
quence  however  their example does not correspond to a weight
increase with respect to a divisor method and moreover assumes that
agents are strategic rather than truthful 
adams   jefferson s  and webster s methods fulfill wwef1 
for hill s method  when 1 ≤ b ≤ a  the desired condition
√
a a 1 
√
b b 1  ≤ a
b is equivalent to a 1
b 1 ≤ a
b   which holds by our
previous observation  an analogous statement can be made for
the case 0 ≤ a ≤ b with b ̸= 0  finally  for dean s method 
when 1 ≤ b ≤ a  the desired condition a a 1 / a  1
2  
b b 1 / b  1
2   ≤ a
b is
equivalent to a 1
b 1 ≤ a  1
2
b  1
2   which holds by our previous ob-
servation  a similar statement can again be made for the case
0 ≤ a ≤ b with b ̸= 0 
we now turn to wprop1  where we illustrate a strong re-
lationship with a notion from the apportionment setting  a
picking sequence πn m w is said to satisfy lower quota if for
any i ∈ n  it holds that ti ≥
�
wi·m
�
i′∈n wi′
�
  where ti denotes
the number of picks in πn m w assigned to agent i 
proposition 4 5  let π be a picking sequence such that every
prefix of π satisfies lower quota  then π satisfies wprop1 
since jefferson s method satisfies lower quota  balinski
and young  2001  p  130  and is resource-consistent  any
prefix of its associated picking sequence also satisfies lower
quota  by proposition 4 5  the method satisfies wprop1  we
prove that it is the only traditional divisor method to do so 
theorem 4 6  of the five traditional divisor methods  jeffer-
son s method is the only one satisfying wprop1 
5
quota method
although divisor methods are widely used in practice  they
do come with an axiomatic downside  no divisor method
satisfies an arguably natural axiom known as quota  balin-
ski and young  2001  p  130  
a picking sequence sat-
isfies the quota axiom if for every i ∈ n  it holds that
�
wi·m
�
i′∈n wi′
�
≤ ti ≤
�
wi·m
�
i′∈n wi′
�
  where ti is the number
of picks assigned to agent i by the picking sequence—note
that the lower bound simply corresponds to the lower quota
notion introduced before proposition 4 5  motivated by this
observation   balinski and young  1975  proposed the quota
method which satisfies the quota axiom as well as resource-
consistency  intuitively  this method can be seen as a con-
strained version of jefferson s method where we choose an
agent i minimizing  ti  1 /wi over a restricted subset of  el-
igible  agents  the picking sequence for the quota method is
determined iteratively  for each round k ∈  m   let ti be the
number of times agent i has picked in rounds 1          k − 1 
an agent is eligible if she would not exceed her upper bound
in the quota axiom upon getting an additional pick in round
k  equivalently  the set of eligible agents is u w  t  k  =
�
i ∈ n
��� ti <
wi·k
�
i′∈n wi′
�
  where t =  t1          tn   among
all eligible agents  the next pick is assigned to an agent min-
imizing  ti   1 /wi  breaking ties in a consistent manner 
the method trivially satisfies resource-consistency  which by
theorem 3 4 implies the following 
corollary
5 1 
the
quota
method
satisfies
resource-
monotonicity 
proceedings of the thirtieth    ijcai-21 
86
 however  satisfying the quota axiom comes at a price 
in contrast to all divisor methods  corollary 4 1   the quota
method fails population-monotonicity 
moreover  like the
five traditional divisor methods  proposition 4 2   the quota
method fails weight-monotonicity for n = 3 
proposition 5 2 
the quota method does not satisfy
population-monotonicity 
in addition  it does not satisfy
weight-monotonicity even when there are three agents 
as we observed in section 4  all divisor methods are
weight-consistent for any number of agents by definition  and
therefore weight-monotone for two agents by theorem 3 6 
in contrast  we show in the full version of our paper that the
quota method is not weight-consistent  chakraborty et al  
2021   however  for two agents  we prove that the method
is weight-consistent and hence weight-monotone 
theorem 5 3  the quota method satisfies weight-consistency
and weight-monotonicity when there are two agents 
next  we address fairness criteria for the quota method 
theorem 5 4  the quota method fails wef1 but satisfies
wwef1 and wprop1 
6
maximum  weighted  nash welfare
given any instance in the unweighted setting  the maximum
nash welfare  mnw  solution chooses an allocation that max-
imizes the nash welfare  i e   the product of the agents 
utilities 
mnw is known to satisfy strong fairness guar-
antees including ef1  caragiannis et al   2019  halpern et
al   2020   when weights are present  a natural generaliza-
tion called maximum weighted nash welfare  mwnw   which
maximizes6 the weighted product �n
i=1 ui mi wi  satisfies
wwef1 but not wef1  chakraborty et al   2020  
segal-halevi and sziklai  2019  showed that for divisi-
ble items in the unweighted setting  mnw satisfies both
resource- and population-monotonicity  it is therefore rather
surprising that the same is not true for indivisible items 
proposition 6 1  in the unweighted setting  mnw satisfies
neither resource-monotonicity nor population-monotonicity 
proof  for resource-monotonicity  consider four items and
two agents  both with weight 1  with the following utilities 
item 1
item 2
item 3
item 4
agent 1
3
2
2
2
agent 2
2
2
1
1
with only the first three items available  the unique mnw
allocation gives items 1 and 3 to agent 1 and item 2 to agent 2 
resulting in a utility of 5 for agent 1  however  when we add
6ties can be broken arbitrarily unless the maximum weighted
nash welfare is 0  which occurs  for example  when m < n   in this
exceptional case  we choose a maximum subset of agents who can be
given positive utilities simultaneously  breaking ties in a consistent
manner among all such subsets independently of the weights  e g  
lexicographically with respect to the agent indices   we then pick
an allocation maximizing the weighted nash welfare of the agents
in this subset 
item 4  mnw uniquely allocates items 3 and 4 to agent 1
and items 1 and 2 to agent 2  so agent 1 s utility drops to 4 
violating resource-monotonicity 
the example for population-monotonicity uses three
agents and four items and can be found in the full version
of our paper  chakraborty et al   2021  
on the other hand  we prove that mwnw fulfills weight-
monotonicity  making it the only rule among the ones we con-
sider in this paper to do so 
theorem 6 2  mwnw satisfies weight-monotonicity 
as mentioned  mwnw is known to satisfy wwef1 but
not wef1  to complete the picture  we show that it does not
satisfy wprop1  this contrasts with the unweighted setting 
where mnw satisfies prop1  since ef1 implies prop1  
proposition 6 3  mwnw does not satisfy wprop1 
7
conclusion and future work
in this paper  we have thoroughly investigated picking se-
quences derived from common apportionment methods  in-
cluding the five traditional divisor methods and the quota
method  in relation to fairness and monotonicity properties 
our results indicate that picking sequences based on divisor
methods provide strong guarantees in weighted fair division
scenarios such as allocating ministries to political parties 
with adams  and jefferson s methods standing out for ful-
filling wef1 and wprop1  respectively  since jefferson s
method tends to favor large parties while adams  often ben-
efits smaller ones  see section 1 2   an interesting question
is whether there are compelling fairness notions in addition
to wwef1 that the other three traditional divisor methods 
which intuitively lie somewhere in the middle  satisfy 
a natural direction for future work is to construct rules
that exhibit a stronger axiomatic behavior than the ones con-
sidered in this paper  or to prove that such rules do not ex-
ist  satisfying the three monotonicity properties simultane-
ously is trivial  one can always allocate all items to a fixed
agent  or ignore the weights and use the round-robin algo-
rithm with a fixed ordering  however  this will not result in
a fair allocation with respect to the weights  does there ex-
ist a rule fulfilling the three monotonicity properties along
with  say  wwef1  other notions that one could consider
include strategyproofness and pareto optimality—even in the
unweighted setting  we are not aware of any rule that simul-
taneously fulfills ef1  pareto optimality  and resource- or
population-monotonicity  our work leaves many intriguing
combinations of properties to investigate  which we hope will
lead to more interesting rules for fair resource allocation 
acknowledgments
this
work
was
partially
supported
by
the
deutsche
forschungsgemeinschaft under grant br 4744/2-1 and by an
nus start-up grant  we would like to thank dominik pe-
ters for helpful discussion and the anonymous reviewers for
valuable feedback 
proceedings of the thirtieth    ijcai-21 
87
 references
 aziz et al   2015  haris aziz  toby walsh  and lirong xia  pos-
sible and necessary allocations via sequential mechanisms  in
ijcai  pages 468–474  2015 
 aziz et al   2019a  haris
aziz 
ioannis
caragiannis 
ayumi
igarashi  and toby walsh  fair allocation of indivisible goods
and chores  in ijcai  pages 53–59  2019 
 aziz et al   2019b  haris aziz  hau chan  and bo li  weighted
maxmin fair share allocation of indivisible chores 
in ijcai 
pages 46–52  2019 
 aziz et al   2020  haris aziz  herv e moulin  and fedor san-
domirskiy  a polynomial-time algorithm for computing a pareto
optimal and almost proportional allocation  operations research
letters  48 5  573–578  2020 
 babaioff et al   2019  moshe babaioff  noam nisan  and inbal
talgam-cohen  fair allocation through competitive equilibrium
from generic incomes  in fat∗  page 180  2019 
 balinski and young  1975  michel l  balinski and h  peyton
young  the quota method of apportionment  american math-
ematical monthly  82 7  701–730  1975 
 balinski and young  2001  michel l  balinski and h  peyton
young  fair representation  meeting the ideal of one man  one
vote  brookings institution press  2001 
 beynier et al   2019  aur elie beynier  sylvain bouveret  michel
lemaˆıtre  nicolas maudet  simon rey  and parham shams  ef-
ficiency  sequenceability and deal-optimality in fair division of
indivisible goods  in aamas  pages 900–908  2019 
 bouveret and lang  2011  sylvain bouveret and j erˆome lang  a
general elicitation-free protocol for allocating indivisible goods 
in ijcai  pages 73–78  2011 
 bouveret and lang  2014  sylvain bouveret and j erˆome lang 
manipulating picking sequences  in ecai  pages 141–146  2014 
 bouveret et al   2016  sylvain bouveret  yann chevaleyre  and
nicolas maudet 
fair allocation of indivisible goods 
in fe-
lix brandt  vincent conitzer  ulle endriss  j erˆome lang  and
ariel d  procaccia  editors  handbook of computational social
choice  chapter 12  pages 284–310  cambridge university press 
2016 
 brams and kaplan  2004  steven j  brams and todd r  kaplan 
dividing the indivisible  procedures for allocating cabinet min-
istries to political parties in a parliamentary system  journal of
theoretical politics  16 2  143–173  2004 
 brams and taylor  1996  steven j  brams and alan d  taylor  fair
division  from cake-cutting to dispute resolution  cambridge
university press  1996 
 bredereck et al   2020  robert
bredereck 
piotr
faliszewski 
michal furdyna  andrzej kaczmarczyk  and martin lackner 
strategic campaign management in apportionment elections  in
ijcai  pages 103–109  2020 
 brill et al   2017  markus brill  jean-franc¸ois laslier  and piotr
skowron  multiwinner approval rules as apportionment methods 
in aaai  pages 414–420  2017 
 brill et al   2020  markus brill  paul g¨olz  dominik peters  ulrike
schmidt-kraepelin  and kai wilker  approval-based apportion-
ment  in aaai  pages 1854–1861  2020 
 budish  2011  eric budish  the combinatorial assignment prob-
lem  approximate competitive equilibrium from equal incomes 
journal of political economy  119 6  1061–1103  2011 
 caragiannis et al   2019  ioannis caragiannis  david kurokawa 
herv e moulin  ariel d  procaccia  nisarg shah  and junxing
wang 
the unreasonable fairness of maximum nash welfare 
acm transactions on economics and computation  7 3  12 1–
12 32  2019 
 chakraborty et al   2020  mithun chakraborty  ayumi igarashi 
warut suksompong  and yair zick  weighted envy-freeness in
indivisible item allocation  in aamas  pages 231–239  2020 
 chakraborty et al   2021  mithun chakraborty  ulrike schmidt-
kraepelin  and warut suksompong 
picking sequences and
monotonicity in weighted fair division  corr  abs/2104 14347 
2021 
 conitzer et al   2017  vincent conitzer  rupert freeman  and nis-
arg shah  fair public decision making  in ec  pages 629–646 
2017 
 farhadi et al   2019  alireza farhadi  mohammad ghodsi  mo-
hammadtaghi hajiaghayi  sebastien lahaie  david pennock 
masoud seddighin  saeed seddighin  and hadi yami  fair al-
location of indivisible goods to asymmetric agents  journal of
artificial intelligence research  64 1–20  2019 
 halpern et al   2020  daniel halpern  ariel d  procaccia  alexan-
dros psomas  and nisarg shah  fair division with binary valua-
tions  one rule to rule them all  in wine  pages 370–383  2020 
 kurokawa et al   2018  david kurokawa  ariel d  procaccia  and
junxing wang  fair enough  guaranteeing approximate maximin
shares  journal of the acm  64 2  8 1–8 27  2018 
 lipton et al   2004  richard
j 
lipton 
evangelos
markakis 
elchanan mossel  and amin saberi  on approximately fair al-
locations of indivisible goods  in ec  pages 125–131  2004 
 markakis  2017  evangelos markakis  approximation algorithms
and hardness results for fair division 
in ulle endriss  editor 
trends in computational social choice  chapter 12  pages 231–
247  ai access  2017 
 moulin  2003  herv e moulin  fair division and collective wel-
fare  mit press  2003 
 pukelsheim  2014  friedrich pukelsheim 
proportional repre-
sentation 
apportionment methods and their applications 
springer  2014 
 segal-halevi and sziklai  2018  erel segal-halevi and bal azs r 
sziklai  resource-monotonicity and population-monotonicity in
connected cake-cutting  mathematical social sciences  95 19–
30  2018 
 segal-halevi and sziklai  2019  erel segal-halevi and bal azs r 
sziklai 
monotonicity and competitive equilibrium in cake-
cutting  economic theory  68 2  363–401  2019 
 tominaga et al   2016  yuto tominaga  taiki todo  and makoto
yokoo  manipulations in two-agent sequential allocation with
random sequences  in aamas  pages 141–149  2016 
 wintein and heilmann  2018  stefan wintein and conrad heil-
mann  dividing the indivisible  apportionment and philosoph-
ical theories of fairness 
politics  philosophy   economics 
17 1  51–74  2018 
proceedings of the thirtieth    ijcai-21 
88
 "
None,2021,https-www-ijcai-org-proceedings-2021-0013-pdf,Fractional Matchings under Preferences: Stability and Optimality,"Jiehua Chen, Sanjukta Roy, Manuel Sorge",None,https://www.ijcai.org/proceedings/2021/0013.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0013-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0013-pdf.pdf,"fractional matchings under preferences  stability and optimality
jiehua chen∗   sanjukta roy and manuel sorge
tu wien  austria
 jiehua chen  sanjukta roy  manuel sorge @tuwien ac at
abstract
we study generalizations of stable matching in
which agents may be matched fractionally  this
models time-sharing assignments  we focus on the
so-called ordinal stability and cardinal stability  and
investigate the computational complexity of finding
an ordinally stable or cardinally stable fractional
matching which either maximizes the social wel-
fare  i e   the overall utilities of the agents  or the
number of fully matched agents  i e   agents whose
matching values sum up to one  
we complete
the complexity classification of both optimization
problems for both ordinal stability and cardinal sta-
bility  distinguishing between the marriage  bipar-
tite  and roommates  non-bipartite  cases and the
presence or absence of ties in the preferences  in
particular  we prove a surprising result that finding
a cardinally stable fractional matching with maxi-
mum social welfare is np-hard even for the mar-
riage case without ties  this answers an open ques-
tion and exemplifies a rare variant of stable mar-
riage that remains hard for preferences without ties 
we also complete the picture of the relations of the
stability notions and derive structural properties 
1
introduction
 a joy shared is a joy doubled   as we will see  this may
hold particularly true in matching markets  such a market
is described by a set of agents who have preferences over
whom they want to have as a partner 
traditionally  the
goal is to find a stable integral matching  gale and shapley 
1962   i e   to match the agents one-to-one such that no two
agents prefer to be with each other rather than with their
matched partners  unfortunately  a stable integral matching
does not always exist 
if however the agents are allowed
to share partners  then we will see that a stable matching
is guaranteed to exist and the social welfare may increase 
that is  we allow fractional matchings which are functions
that assign each pair of agents a value between 0 and 1  as
opposed to integral matching which assigns either 0 or 1 to
each pair  such that for each agent  the sum of the matching
∗contact author
values of all pairs containing this agent is at most one  in
this paper  we study structural properties of stable fractional
matchings and computational aspects of maximizing their
social welfare and the number of the fully matched agents 
stable fractional matchings have been studied since the
90s  vande vate  1989  roth et al   1993  abeledo and
rothblum  1994  teo and sethuraman  1998  and enjoy
continued interest  bir o et al   2008  kintali et al   2013 
do˘gan and yıldız  2016  kesten and ¨unver  2015  ishizuka
and kamiyama  2018  aziz and klaus  2019  caragiannis et
al   2020   they have applications in time-sharing assign-
ments and random assignments  for example  in a job market
the agents may be partitioned into two sets  freelancers and
companies  a fractional matching models the amount of time
a freelancer spends working for a company  the preferences
can model intensity of interest in working with the agents
of the other set  and then stability models an equilibrium in
such a job market  similar scenarios are time-sharing assign-
ments between advisors and apprentices or between workers
and projects  an instance of the non-bipartite case occurs
when agents  e g   nurses  work in multiple shifts  and each
shift is carried out by two workers  a fractional matching
determines the fraction of shifts that each worker carries out
with another worker over the total number of shifts for an
agent  the preferences can model the intensity of willingness
to work with each other  and then stability models the situa-
tion where no two workers want to change shifts to work more
with each other  fractional matchings also find application in
random matching  roth et al   1993  kesten and ¨unver  2015 
aziz and klaus  2019   in the bipartite case  by the birkhoff-
von neumann theorem  a fractional matching can be inter-
preted as a probability distribution over integral matchings 
choosing an integral matching at random instead of deter-
ministically enables many desirable properties such as fair-
ness and increased expected welfare  aziz and klaus  2019  
stability for fractional matchings 
while the definition
of stability in the integral case is straightforward  there are
several natural ways to define stability for fractional match-
ings 
we consider the following three stability concepts
which have been recently discussed  aziz and klaus  2019 
caragiannis et al   2020   the setting is given by a graph g =
 v  e   where v is the set of agents  and a preference function
sat  v × v → q≥0  where sat u  v  specifies the satisfac-
tion of u towards v  a fractional matching m   e →  0  1  is
proceedings of the thirtieth    ijcai-21 
89
 a
b
c
d
e
f
1
3
2
2
3
1
1
3
1
3
2
2
1
2
decreasing
decreasing
preferences
preferences
a  d ≻ c ≻ b  d  c ≻ e ≻ a 
b  a ≻ c 
e  d ≻ f 
c  b ≻ a ≻ d  f   e 
ab
ac
ad
bc
cd
de
ef
other edges
m1
0 5
0 5
0
0 5
0
1
0
0
m2
0 5
0
0 5
0 5
0 5
0
1
0
figure 1  left  acceptability graph with 6 agents a  b  c  d  e  f  the
values on an edge denote the satisfactions of the endpoints of the
edge towards each other  e g   a s satisfaction towards b is 1 and b s
satisfaction towards a is 3  right  the ordinal preferences derived
from the satisfactions  bottom  fractional matchings m1 and m2 
cardinally  ordinally  or linearly stable if it does not admit a
blocking pair  u  v  ∈ e of the corresponding type 
a cardinally blocking pair for m models the situation
that the agents in the pair both obtain more utility from
being integrally matched to each other than from the as-
signment under m  caragiannis et al   2020  
herein 
the utility of an agent v ∈ v under m is usat m v   =
�
 v u ∈e g  sat v  u  · m  v  u    if sat is clear from the
context  we omit it in usat m  thus  pair  u  v  is cardinally
blocking m if um u  < sat u  v  and um v  < sat v  u  
an ordinally blocking pair concerns ordinal prefer-
ences 
as the preferences of an agent v we consider
only the relative order of the agents u acceptable to v
that is induced by sat v  u   but ignore the magnitude
of sat v  u  
an ordinally blocking pair  u  v  for m
models the case when u and v both are not satisfied
with m  i e   u is matched by a fraction of less than one
to agents that she weakly prefers to v and analogously
for v  aharoni and fleiner  2003   for convenience  define
m x  ⪰y 
 =
�
y′∈v   sat x y′ ≥sat x y  m x  y′  
then 
 u  v  is ordinally blocking m if m u  ⪰v 
<
1 and
m v  ⪰u  < 1  ordinal stability has also been studied under
the name ex-ante weak stability  kesten and ¨unver  2015  
finally   u  v  is a linearly blocking pair of m if
m u  ⪰v  m v  ⪰u −m u  v  < 1  that is  linear stabil-
ity arises from the linear-programming formulation of com-
puting a stable  integral  matching by relaxing the integrality
constraints  roth et al   1993  abeledo and rothblum  1994  
we give examples in figure 1  matching m1  green  is
cardinally stable  ordinally stable  and linearly stable  match-
ing m2  red  is cardinally stable and every agent is fully
matched  i e  each agent s matching values sum up to one 
however  m2 is neither ordinally stable nor linearly stable 
due to  d  e   due to the agents a  b  c  no integral matching
is stable  note that all three stability concepts are the same
when restricting to integral matchings  figure 2 illustrates
the relations between all discussed stability concepts 
our contribution 
we first show that a stable fractional
matching for all three stability concepts always exists  even
when ties are present in the preferences and in the roommates
case  i e  g is not necessarily bipartite   this extends previous
observations by caragiannis et al   2020  and aharoni and
stable
integral
ordinally
stable
linearly stable
cardinally stable
figure 2  relation between the stability concepts  where  α → β 
means that  an α matching is also β   no directed path between two
concepts means that neither implies the other 
fleiner  2003  for more restricted cases 
motivated by this positive result  we study the complexity
of two optimization problems  we aim to maximize  1  the
social welfare of the resulting matching  i e   the sum of the
utilities of the agents obtained from the matching  or  2  the
number of fully matched agents 
the second objective is
a natural generalization of checking for perfect matchings
and it is motivated by aims of being inclusive and avoiding
unspent resources  for example  the freelancers  non-working
time in the introductory scenario 
for linear stability both optimization problems are poly-
nomial  because they can be formulated as linear programs 
for ordinal stability and cardinal stability  together with a
previous result  caragiannis et al   2020   we obtain a com-
plete complexity classification  distinguishing the marriage
 bipartite  and roommates  non-bipartite  cases and whether
ties are present in the preferences  see the summary in ta-
ble 1  for ordinal stability both optimization problems are
polynomial in the marriage case without ties  the proof re-
lies on a decomposition of the optimal fractional matching
into integral matchings that consequently yields that an opti-
mal integral matching is also optimal for the fractional case 
unfortunately  most of the other cases become np-hard  we
found particularly interesting that maximizing the social wel-
fare remains np-hard for cardinal stability in the marriage
case without ties because it stands in stark contrast to the in-
tegral stability and ordinal stability for which the problem is
tractable  this result thus reveals that the difficulty of com-
puting optimal stable fractional matchings depends not only
on ties or the fractionality but also on the cardinalities  np-
hardness in the case without ties has been asked as an open
question by caragiannis et al   2020  and the influence of ties
on the complexity in the integral setting has been extensively
studied  gusfield and irving  1989  manlove  2013  
apart from the above complexity results we also study
the structure of the  families of  matchings under the three
stability notions  we show that the family of ordinally stable
matchings form a lattice in the marriage case and that they
adhere to the so-called median property in the roommates
case  apart from being interesting insights into the structure
of the solution space  these properties are useful because
they can enable efficient algorithms that solve additional op-
timization goals or find matchings with additional desirable
properties  omitted results and proofs marked with  ⋆  are
available in a full version  chen et al   2020  
related work 
roth et al   1993  studied linear stabil-
ity  they called it fractional stability  in marriage markets
without ties  and showed that the set of linearly stable match-
ings enjoys a lattice structure  abeledo and rothblum  1994 
studied linear stability  but in roommates markets  they ob-
served that the set of linearly stable matchings in roommates
proceedings of the thirtieth    ijcai-21 
90
 cardinal stability
ordinal stability
marriage
roommates
marriage
roommates
no ties
ties
no ties
ties
no ties
ties
no ties
ties
always exists 
yes
 ♣ 
yes
 ♣ 
yes
 p 3 5 
yes
 p 3 5  yes
 ♥ 
yes
 p 3 5  yes
 ♥ 
yes
 p 3 5 
max-#-fully-matched np-c  t 5 9 
np-c  t 5 7  np-c
 t 5 9 
np-c
 t 5 7  p
 p 4 5 
np-c  t 5 1  p
 p 4 5 
np-c
 t 5 1 
max-welfare
np-c  t 5 7  np-c
 ♣ 
np-c
 t 5 7  np-c
 ♣ 
p
 t 4 3 
np-c  t 5 1  np-c
 t 5 2 
np-c
 t 5 2 
table 1  new and known results for deciding a cardinally stable  resp  ordinally stable  matching with max  # of fully matched agents  resp 
max-welfare   results marked with ♣ and ♥ are from caragiannis et al   2020  and aharoni and fleiner  2003   respectively  results marked
in red and green are new  green means polynomial-time algorithms and red np-completeness 
markets does not have a lattice structure in general  but are
closed under the so-called median operation  following the
authors  we obtain the same results for ordinal stability 
aziz and klaus  2019  considered multiple fractional
stability concepts in marriage markets  including linear
stability and ordinal stability  which they called fractional
stability and ex-ante stability  kesten and ¨unver  2015   
but not cardinal stability  they showed that ordinal stability
implies linear stability  we strengthen their result by showing
the same for the roommates case 
caragiannis et al   2020  introduced the problem of
finding maximum-welfare cardinally stable matchings in
marriage markets  they showed that the problem is np-hard
and hard to approximate even if each agent has at most
three different satisfaction values but may contain ties in her
preferences  we improve on this by showing np-hardness
even when no ties are present and each agent finds at most
five agents acceptable 
a subset of the structural results 
namely the ones about cardinal stability in the marriage
setting and for perfect matchings  see observation 3 1 
has been observed independently in parallel in their recent
journal version  caragiannis et al   2020  appendix a  
aharoni and fleiner  2003  studied ordinal stability in the
hypergraphic setting  they found that scarf s lemma from
game theory guarantees the existence of ordinally stable
matchings 
for an overview on stable integral matchings
refer to gusfield and irving  1989  and manlove  2013  
2
preliminaries
given an integer z  we use  z  to denote the set  1  2          z  
we consider instances  g  sat  where g =  v  e  is a
graph and sat  v × v → q≥0 is a function  and where v
denotes a set of vertices  also called agents   e denotes a
set of edges such that an edge between two vertices means
that the corresponding agents find each other acceptable  and
sat specifies the cardinal preferences of an agent towards an-
other agent  i e   for all u  v ∈ v   sat u  v  specifies the sat-
isfaction of u towards v  we also refer to g as the accept-
ability graph underlying the cardinal preferences sat 
we
assume throughout that  1  g contains no isolated vertices 
 2  ∀u ∈ v   sat u  u  = 0  and  3  ∀u  v ∈ v    u  v  ∈
e ⇔  sat u  v  > 0 or sat v  u  > 0  
from the function sat for g we derive a preference list ⪰v
over the neighborhood ng v  =  u |  v  u  ∈ e  of
each v ∈ v as follows  let ⪰v denote a complete and
transitive binary relation of ng v  such that for each two
acceptable agents x  y ∈ ng v  it holds that x ⪰v y if and
only if sat v  x  ≥ sat v  y   we say that v weakly prefers x
to y  we use x≻ vy to denote that sat v  x  > sat v  y   i e  
v  strictly  prefers x to y  we use p =  ⪰v v∈v to denote
the collection of the preference lists derived from sat  we
say that x is a most preferred agent of v if for each acceptable
agent y ∈ ng v  we have x ⪰v y 
we say that an instance  g  sat  has complete preferences
if g is a complete graph  otherwise it has incomplete
preferences  and that it contains  preferences with  ties if
there exists v ∈ v and two neighbors x  y ∈ ng v  with
sat v  x  = sat v  y   otherwise it has strict preferences 
a fractional matching m   e → r≥0 is an assignment
of non-negative weights to each edge e ∈ e such that
�
 v u ∈e m  u  v   ≤ 1 for each agent v ∈ v  
if it
is not ambiguous we abbreviate  fractional matchings 
to  matchings  
by symmetry  for each edge  u  v  we
use m u  v   resp  m v  u   to refer to m  u  v   
an
agent v is fully matched  resp  matched  under m if
�
u∈ng v  m v  u  = 1  resp  �
u∈ng v  m v  u  > 0   m
is perfect if each agent is fully matched  m is integral  resp 
half-integral  if m e  ∈  0  1   resp  m e  ∈  0  0 5  1  
for each edge e  by the birkhoff-von neumann theorem a
fractional matching in a bipartite graph can be decomposed
into a convex combination of integral matchings  horn and
johnson  1991  theorem 3 2 6  
proposition 2 1  let m be a fractional matching of a bipar-
tite graph g with n vertices  there is an integer k ∈ o n2  
positive coefficients x1          xk ∈ r>0  and integral match-
ings m1          mk of g such that �
j∈ k  xj = 1 and for each
edge e ∈ e it holds that m e  = �
j∈ k  xj · mj e  
the integral matchings  mj j∈ k  constitute a support of the
matching m  there may be multiple supports of m 
the acronyms csm  osm  and lsm stand for cardinally
stable  ordinally stable  and linearly stable fractional match-
ing  respectively  see section 1 for the definitions  
we focus on two classes of decision problems  one aim-
ing for maximizing the number of fully matched agents  and
the other for maximizing social welfare  let g =  v  e 
be a graph  sat  v × v
→ q≥0 a satisfaction function 
and m a fractional matching in g  denote #fully m   =
| x ∈ v | �
y∈ng x  m x  y  = 1 | and welfaresat m   =
�
v∈v usat m v   if sat is clear from the context then we
drop it in welfaresat  the problems are defined as follows 
where π ∈  osm  csm 1  
1we omit linear stability since both problems for linear stabil-
ity can be formulated as linear programs and are hence solvable in
polynomial time 
proceedings of the thirtieth    ijcai-21 
91
 algorithm 1  compute an osm for  g  sat  
1 compute the preference lists p from sat
2
ˆ
sat ← break ties in sat arbitrarily
3 compute π and m π for  g  ˆ
sat   cf  def  3 2 
4 return m π
full π matching  full-π 
input 
g =  v  e   sat  v × v → q≥0  and τ ∈ n 
question  does  g sat  admit a π m with #fully m ≥τ 
welfare π matching  welfare-π 
input 
g= v  e   sat  v × v → q≥0  and γ ∈ r≥0 
question  does  g sat  admit a π m with welfare m ≥γ 
all problems are in np since they reduce in polynomial time
to a very restricted variant of integer linear programs  ⋆  
3
structural properties
we now discuss relations among  see figure 2  and existence
of fractional matchings regarding the three stability concepts 
observation 3 1  ⋆    i  every osm is an lsm and a csm 2
 ii  there exists a graph g with strict preferences sat s t 
 g  sat  admits an lsm which is neither an osm nor a csm
and admits a csm which is neither an lsm nor an osm 
the following concept  tan  1991  turns out to be very use-
ful for showing the existence of ordinally stable matchings 
a stable partition of  g =  v  e   sat  with sat being strict
is a permutation π  v → v on the vertices  which satisfies
the following for each vi ∈ v    1  if π vi  ̸= π−1 vi  
then  vi  π vi     vi  π−1 vi   ∈ e and sat vi  π vi   >
sat vi  π−1 vi     2  for each vj ∈ ng vi   if π vi  = vi
or sat vi  vj  > sat vi  π−1 vi    then sat vj  π−1 vj   >
sat vj  vi   we call vi a singleton if π vi  = vi  a stable
partition π can be decomposed into cycles  singletons  and
transpositions  i e   disjoint edges  
we define a fractional matching for a stable partition 
definition 3 2  let π be a stable partition of  g
=
 v  e   sat   define a matching m π for g corresponding
to π as follows   a  for each vi ∈ v with π vi  ̸= vi  if
π vi =π−1 vi   then let m π vi  π vi    = 1  otherwise let
m π vi  π vi   = m π vi  π−1 vi    = 0 5   b  for each re-
maining edge e  let m π e   = 0 
⋄
example 1  π =  a  b  c  d  e  f  is the only stable partition
for the instance in figure 1  since π contains  a  b  c  as
an odd cycle of length three this instance does not admit a
stable integral matching  the matching m π defined for π
according to definition 3 2 is exactly m1  recall that it is
ordinally stable  and hence cardinally and linearly stable 
we will see that each matching as defined by definition 3 2
is ordinally stable  note that the case without ties is observed
by aharoni and fleiner  bir o et al   2003  2008  
proposition 3 5  ⋆   each graph on n vertices and with car-
dinal preferences  and possibly ties  admits an osm  and
2the result for perfect matchings in the marriage case was ob-
served independently in parallel by caragiannis et al   2020  
hence a csm  that is half-integral and matches each matched
agent fully  algorithm 1 finds such a matching in o n2  time 
4
algorithmic results
the structural properties from section 3 give rise to efficient
algorithms for finding optimal stable matchings  for bipartite
graphs  we utilize the fact that supports of osms consist of
stable integral matchings  aziz and klaus  2019  theorem 3  
lemma 4 1  let g be a bipartite graph with satisfaction sat 
m an osm for  g  sat   and  mj j∈ k  a support for m 
then  each mj  j ∈  k   is  integrally  stable 
we show that the welfare and the number of fully matched
agents of a fractional matching are a linear combination of
the corresponding values of the matchings in the support 
lemma 4 2  ⋆   let g be a bipartite graph with satisfac-
tions sat  m be a matching for  g  sat   and  mj j∈ k  be a
support of m with the coefficients x1          xk ∈ r>0  then 
the following inequalities hold  welfare m  = �
j∈ k 
�
xj ·
welfare mj 
�
and #fully m  ≤ maxj∈ k  #fully mj  
from lemma 4 2 it follows that there is an optimal
ordinally stable matching that is also integral since we
may swap out matchings in the support of a fractional
matching for integral matchings with maximum welfare or
with maximum number of fully matched agents in order
to decrease the number of matchings in the support until
only one matching remains in the support  since finding an
optimal stable integral matching for bipartite graphs with
strict preferences is polynomial-time solvable  irving et al  
1987   we immediately obtain the same for ordinal stability 
theorem 4 3  ⋆   for bipartite graphs with strict prefer-
ences  welfare-osm and full-osm are polynomial-
time solvable 
the above tractability result heavily utilizes the fact that
each fractional matching of a bipartite graph is a convex com-
bination of integral matchings  this fact  however  does not
hold for non-bipartite graphs  nevertheless  we can extend
the polynomial-time result to the non-bipartite case  the cor-
rectness is based on the following 
lemma 4 4  ⋆   let g =  v  e  be a graph with cardinal
and strict preferences sat  and let m be an osm of  g  sat  
the following statements hold for each agent y ∈ v  
 1  m x  ⪰y  = 1  where x is the most preferred agent of y 
 2  the following are equivalent   i  y is matched in m 
 ii  y is not a singleton in a stable partition of  g  sat  
 iii  y is fully matched in m 
proof sketch  to show statement  1   suppose to get a con-
tradiction that m x  ⪰y  < 1  where x is the most-preferred
agent of y 
this implies m y  ⪰x  = m y  x  < 1 
a contradiction to m being ordinally stable regarding
edge  x  y  
the equivalence of the statements in  2  is
based on statement  1  
we can perform the first phase
of irving s algorithm  irving  1985   see algorithm 2  to
guarantee that after phase 1   a  an agent is a singleton  in any
stable partition  iff  her preference list is empty  and  b  every
 fully  matched agent in m has non-empty preference list 
proceedings of the thirtieth    ijcai-21 
92
 algorithm 2  irving s phase-1 algo  on input  g  sat 
1 compute the preference lists p from sat
2 while ∃y∈v  g  w  non-empty pref 
s t  lastp 1stp y  ̸=y do
3
d ←   1stp y   z  | 1stp y  prefers y to z in p 
4
p ← p − d
5 return  v ∈ v  g  | v has empty pref  list in p 
note 
in algorithm 2  we use 1stp x  and lastp x  to
refer to the most-preferred and least-preferred agents in the
list ≻x∈ p of x  respectively  we then derive the equivalence
from the properties of algorithm 2 and stable partitions 
using lemma 4 4 we can show that the osm returned from
algorithm 1 achieves the maximum number of fully matched
agents whenever no ties are present 
proposition 4 5  ⋆   for n-vertex graphs with strict prefer-
ences  full-osm is solvable in o n2  time 
we close this section by observing that the osm that we
obtain from algorithm 1 is also a 2-approximate solution for
both cardinal stability and ordinal stability  even with ties 
proposition 4 6  ⋆   algorithm 1 is a 2-approx  algorithm for
the maximization variants of full-osm and full-csm 
proof sketch  let g =  v  e  denote a graph with cardinal
preferences sat with ties  we only show the case of cardi-
nal stability  let m c be a csm of  g  sat  with #fully m c 
being maximum  by proposition 3 5  algorithm 1 returns
an osm m π on input  g  sat  and the strict preference
lists p that are used to compute the corresponding sta-
ble partition π  see lines  2 – 3   
recall that in m π ev-
ery matched agent is fully matched 
let aπ denote the
set of  fully  matched agents in m π 
to show that al-
gorithm 1 is a 2-approx  algorithm for cardinal stability 
we observe that at least one agent of each pair of e must
come from aπ because otherwise this pair is ordinally block-
ing m π 
thus  #fully m c  ≤ �
x∈aπ 
y∈ng x 
m c x  y   
�
x∈v \aπ 
y∈ng x ∩aπ m c x  y  ≤ 2|aπ| 
5
hardness results
optimal ordinally stable matchings 
by lemmas 4 1
and 4 2  full-osm is equivalent to finding a stable integral
matching with maximum cardinality  and welfare-osm
is equivalent to finding a stable integral matching with
minimum egalitarian cost  since both problems are known to
be np-hard  manlove et al   2002   we obtain the following 
theorem 5 1  ⋆   when ties are allowed  full-osm and
welfare-osm are np-complete  even for bipartite graphs 
feder  1994  showed that finding a maximum-welfare stable
integral matching in non-bipartite graphs is apx-hard  even
for no ties  his idea can be adapted to the ordinal stability 
theorem 5 2  ⋆   the maximization variant of welfare-
osm is apx-hard and welfare-osm is np-complete 
even if no ties are present 
eℓ
ei
ℓ
gℓ
ej
ℓ
hℓ
fℓ
ui
uj
2m2 8
1
2m2 5
4
2m2 2
7
2m2 4
5
2m2
9
2m2 7
2
2m2 6
3
2m2 5
47
5
eℓ   hℓ ≻ei
ℓ ≻ej
ℓ 
fℓ   ei
ℓ ≻ej
ℓ 
gℓ   ei
ℓ ≻hℓ ≻ej
ℓ 
ei
ℓ   eℓ ≻ui ≻fℓ ≻gℓ 
ej
ℓ   eℓ ≻uj ≻gℓ ≻fℓ 
hℓ   gℓ ≻eℓ 
figure 3  the edge-gadget for eℓ ∈  vi  vj  ∈ e with i < j  
left  the acceptability graph and the card  preferences of the 6 edge-
agents eℓ  fℓ  gℓ  hℓ  ei
ℓ  and ej
ℓ  when constructing a matching from
an independent set v ′  we integrally match the pairs corresponding
to the green edges if vi ∈ v ′  right  the induced preference lists 
the instance constructed in theorem 5 2 has incomplete
cardinal preferences  each of value at least one  by assigning
distinct cardinal preferences of value less than one to each
unmentioned pair of agents we obtain complete preferences 
corollary 5 3  ⋆   for complete preferences without ties 
the maximization variant of
welfare-osm remains
apx-hard and welfare-osm remains np-complete 
optimal cardinally stable matchings 
we now prove
that welfare-csm and full-csm are np-complete even
when the underlying acceptability graph g is bipartite and sat
has no ties  for both problems we give a polynomial-time
reduction from the np-complete problem independent
set  is   garey and johnson  1979   wherein we are given a
graph g and an integer k and ask to find an k-vertex subset x
in g that is independent  that is  g x  is edgeless  both re-
ductions use the same edge-gadgets  which we now describe 
let  g =  v  e   k  be an instance of is  where v =
 v1          vn  is the vertex set and e =  e1          em  the edge
set  for each edge eℓ ∈ e we let  vi  vj  = eℓ where i < j
and we construct an edge-gadget which consists of a bipartite
graph gℓ with preference function sat as shown in figure 3 
the edge-gadget assumes that two vertex-agents ui and uj
are already present  which will be ensured by the full con-
struction later  the preference function sat of the agents ui
and uj from the vertex gadgets towards the edge-agents ei
ℓ
and ej
ℓ are bounded by 5m and will be defined later  the ver-
tex set v  gℓ  of the edge gadget is the union of the sets uℓ =
 eℓ  fℓ  gℓ  and wℓ =  hℓ  ei
ℓ  ej
ℓ   we call the vertices in gℓ
edge-agents to distinguish them from the vertices in g 
let ge = ∪ℓ∈ m gℓ  i e   the union of the graphs in all
edge-gadgets  we now prove the essential property of the
edge-gadgets  for each edge eℓ ∈ e with eℓ =  vi  vj  at
least one of the edge-agents from ei
ℓ  ej
ℓ  is unsatisfied with
every csm with sufficiently large social welfare  this asserts
that not both vi and vj are in an independent set 
lemma 5 4  ⋆   let m be a csm for ge and ω denote
the welfare of m induced by the edge-agents 
then   i 
ω ≤ 3m 2m2   9   and  ii  if there is an edge eℓ ∈ e
with eℓ =  vi  vj  such that um ui  < sat ui  ei
ℓ  and
um uj  < sat uj  ej
ℓ   then ω < 3m 2m2   9  − n 
using the above we can give the full reduction 
proceedings of the thirtieth    ijcai-21 
93
 ui
wi
xi
yi
 e vi  
3n 3
1
1
3n 4
2
1
1
2
3n
3n 1
3n 2
1
3n 4
1
2
ui   wi ≻ e vi  ≻yi 
xi   yi ≻wi 
wi   xi ≻ui 
yi   ui ≻xi 
figure 4  the vertex-gadget for vertex vi ∈ v used in the proof
of theorem 5 7 
left  the acceptability graph and the cardi-
nal preferences of agents ui  xi  wi  yi associated with vi  here 
e vi  =  ei
ℓ | eℓ ∈ e and vi is incident to eℓ  and  e vi   denotes
the order of the edge-agents e vi  by increasing indices  the red
edges indicate the matching that signifies that vi is in the indepen-
dent set  right  the induced preference lists of the vertex-gadget 
theorem 5 7  ⋆   welfare-csm is np-complete  even for
bipartite graphs with strict preferences 
proof  let  g  k  be an instance of is  where g =  v  e  
v
=
 v1          vn  and e
=
 e1          em  
we in-
deed reduce from is in cubic graphs  i e   each vertex
in g has degree three  as the problem remains np-hard
for cubic graphs  alimonti and kann  2000  
we con-
struct an instance  g′  sat  γ  of welfare-csm where
γ =  3n   7 n   k   3m 2m2   9  and g′ =  u ∪ w  e′ 
is a bipartite graph with partite sets u and w 
– for each vi ∈ v   create 4 vertex-agents ui  xi  wi  yi  and
add ui  xi to u and wi  yi to w 
– for each eℓ ∈ e  add the edge-agents in uℓ  resp  wℓ 
to u  resp  w   and add the acceptable edges of ge to e′ 
– the remaining edges in e′ and the sat function are
described in figure 4  in particular  for each vertex vi ∈ v
and each incident edge eℓ ∈ e  i e   vi ∈ eℓ  the cardinal
preference of ui towards ei
ℓ is some value from  3n  3n  
1  3n   2   recall that each vertex in g has degree three 
for each vertex vi ∈ v we call the subgraph of g′ together
with the cardinal preferences  induced by  ui  wi  xi  yi  the
vertex-gadget for vertex vi  note that g′ is a bipartite graph
because all the introduced edges are between u and w  this
completes the construction of  g′  sat  γ  which clearly takes
polynomial time  in total  |u| = |w| = 6m   4n 
we construct the cardinal preferences for the vertex-agents
to ensure the following  when combined with lemma 5 4 
there are essentially two possible ways of fractionally match-
ing the vertex agents ui  xi  wi  yi corresponding to the same
vertex vi ∈ v   the first one will have a higher welfare than
the second one  but it is not possible to use the first one for two
adjacent agents as this will induce a cardinally blocking pair 
next  we prove  g  k  is a yes-instance of independent
set iff   g′  sat  γ  is a yes-instance of welfare-csm 
the  if  direction amounts to a straightforward check of a
somewhat peculiar matching and is available in the long ver-
sion  chen et al   2020   for the  only if  direction  let m be
a cardinally stable matching for  g′  sat  with welfare m  ≥
γ 
we show that the following vertex subset v ′ with
v ′ =  vi ∈ v | m ui  yi  ≥ 1/n  is an independent set in g
and |v ′| ≥ k  we first show |v ′| ≥ k  for each i∈ n   define
muw
i
 =m ui  wi   mue
i  =�
e∈e vi 
m ui  e   muy
i  =m ui  yi  
mxw
i
 =m xi  wi   mxy
i  =m xi  yi   then 
n�
i=1
�
z∈ ui wi xi yi 
um z  ≤
n�
i=1
�
 3n 4  muw
i
 mue
i  muy
i  
  3 mxw
i
 mxy
i  
�
 
n�
i=1
muy
i
≤  3n   7 n   �n
i=1 muy
i    1 
the last inequality holds since since the total matching val-
ues of the edges incident to ui and xi sum up to at most 1 
respectively  we show that ⌊�n
i=1 muy
i ⌋ ≤ |v ′|  define
k1  = | ui | i ∈  n  and muy
i
< 1/n |  then we have
�n
i=1 muy
i
< k1/n   |v ′|  since k1 ≤ n  it follows that
|v ′| ≥ ⌊�n
i=1 muy
i ⌋  to see that |v ′| ≥ k it thus suffices to
show �n
i=1 muy
i
≥ k  out of welfare m  at most 3m 2m2 
9  stems from the edge-agents  see lemma 5 4 i    hence  at
least  3n 4 n 3n k must stem from the vertex-agents  by
the upper bound on the welfare of the vertex-agents derived
in eq   1   thus indeed �n
i=1 muy
i
≥ k  as required 
it remains to show that v ′ is an independent set 
towards a contradiction  suppose that there is an edge
eℓ
∈
e with eℓ
=
 vi  vj  such that vi  vj
∈
v ′ 
by definition of v ′ we have for both ν
∈
 i  j  that
um uν  ≤ sat uν  yν ·muy
ν  sat uν  wν · 1−muy
ν   < 3n 
that is  um uν  < sat uν  eν
ℓ    by lemma 5 4 i   the total
welfare received from m by vertices of the edge gadgets
is at most 3m 2m2   9  − n  by eq   1   the total welfare
received from the vertex-agents is at most  3n   8 n and
thus welfare m  < γ  a contradiction 
the preferences constructed in theorem 5 7 can be com-
pleted by assigning to each  unacceptable  pair of agents a
sufficiently small but distinct value  such small satisfaction
values will not have any effect on a maximum-welfare csm
as the sum of those utilities will never exceed one 
proposition 5 8  ⋆   welfare-csm is np-complete  even
for bipartite graphs with complete and strict preferences 
next  we turn to full-csm  the hardness construction uses
the same edge gadgets as before  but with a different analysis 
theorem 5 9  ⋆   full-csm is np-complete  even for bi-
partite graphs with strict preferences 
the construction also implies that full-csm is w 1 -hard
wrt  parameter  #fully m −#fully m π  where m is a per-
fect csm and m π is as defined in definition 3 2 
6
conclusion and outlook
studying optimal stable fractional matchings using the frame-
work of parameterized algorithmics  niedermeier  2006 
cygan et al   2015  may provide more insights into the
fine-grained complexity of the problem  promising param-
eters are the number of fully matched agents and the social
welfare of the fractional matchings in the solution  finally 
regarding preference restrictions  bredereck et al   2020  
it would be interesting to know whether assuming a special
preference structure can help in finding tractable cases for
optimal fractional stable matchings 
acknowledgments
jc and sr supported by the wwtf research grant vrg18-
012  ms supported by the alexander von humboldt founda-
tion  significant work of sr done while with imsc  chennai 
india 
proceedings of the thirtieth    ijcai-21 
94
 references
 abeledo and rothblum  1994  hern an g  abeledo and
uriel g  rothblum  stable matchings and linear inequali-
ties  discrete applied mathematics  54 1  1–27  1994 
 aharoni and fleiner  2003  ron
aharoni
and
tam as
fleiner  on a lemma of scarf  journal of combinatorial
theory  series b  87 72–80  2003 
 alimonti and kann  2000  paola
alimonti
and
viggo
kann  some apx-completeness results for cubic graphs 
theoretical computer science  237 1-2  123–134  2000 
 aziz and klaus  2019  haris aziz and bettina klaus  ran-
dom matching under priorities  stability and no envy con-
cepts  social choice and welfare  53 2  213–259  2019 
 bir o et al   2008  p eter bir o  katarina cechl arova  and
tam as fleiner  the dynamics of stable matchings and half-
matchings for the stable marriage and roommates prob-
lems  international journal of game theory  36 3  333–
352  2008 
 bredereck et al   2020  robert bredereck  jiehua chen 
ugo p  finnendahl  and rolf niedermeier  stable room-
mate with narcissistic  single-peaked  and single-crossing
preferences 
autonomous agents and multi-agent sys-
tems  34 2  1–29  2020 
 caragiannis et al   2020  ioannis caragiannis  aris filos-
ratsikas  panagiotis kanellopoulos  and rohit vaish  sta-
ble fractional matchings  artificial intelligence  295 1–26 
2020 
 chen et al   2020  jiehua chen  sanjukta roy  and manuel
sorge  fractional matchings under preferences  stability
and optimality  technical report  arxiv 2011 12259  2020 
 cygan et al   2015  marek cygan  fedor v  fomin  lukasz
kowalik 
daniel lokshtanov 
d aniel marx 
marcin
pilipczuk  michal pilipczuk  and saket saurabh  parame-
terized algorithms  springer  2015 
 do˘gan and yıldız  2016  battal do˘gan and kemal yıldız 
efficiency and stability of probabilistic assignments in
marriage problems 
games and economic behavior 
95 47–58  2016 
 feder  1994  tom as
feder 
network
flow
and
2-
satisfiability  algorithmica  11 3  291–319  1994 
 gale and shapley  1962  d  gale and l  s  shapley  col-
lege admissions and the stability of marriage  the ameri-
can mathematical monthly  120 5  386–391  1962 
 garey and johnson  1979  michael r  garey and david s 
johnson  computers and intractability  a guide to the
theory of np-completeness  w  h  freeman  1979 
 gusfield and irving  1989  dan gusfield and robert w 
irving  the stable marriage problem–structure and al-
gorithms  foundations of computing series  mit press 
1989 
 horn and johnson  1991  roger a  horn and charles r 
johnson  topics in matrix analysis  cambridge university
press  1991 
 irving et al   1987  robert w  irving  paul leather  and
dan gusfield  an efficient algorithm for the  optimal  sta-
ble marriage  journal of the acm  34 3  532–543  1987 
 irving  1985  robert w  irving  an efficient algorithm for
the  stable roommates  problem  journal of algorithms 
6 4  577–595  1985 
 ishizuka and kamiyama  2018  takashi
ishizuka
and
naoyuki kamiyama 
on the complexity of stable frac-
tional hypergraph matching  in wen-lian hsu  der-tsai
lee  and chung-shou liao  editors  proceedings of
the 29th international symposium on algorithms and
computation  isaac  18   volume 123 of lipics  pages
11 1–11 12  2018 
 kesten and ¨unver  2015  onur kesten and m  utku ¨unver 
a theory of school-choice lotteries 
theoretical eco-
nomics  10 2  543–595  2015 
 kintali et al   2013  shiva kintali  laura j  poplawski  raj-
mohan rajaraman  ravi sundaram  and shang-hua teng 
reducibility among fractional stability problems  siam
journal on computing  42 6  2063–2113  2013 
 manlove et al   2002  david manlove  robert w  irving 
kazuo iwama  shuichi miyazaki  and yasufumi morita 
hard variants of stable marriage  theoretical computer
science  276 1-2  261–279  2002 
 manlove  2013  david f  manlove  algorithmics of match-
ing under preferences  volume 2 of series on theoretical
computer science  world scientific  2013 
 niedermeier  2006  rolf niedermeier  invitation to fixed-
parameter algorithms  oxford university press  2006 
 roth et al   1993  alvin e  roth  uriel g  rothblum  and
john h  vande vate  stable matchings  optimal assign-
ments  and linear programming  mathematics of opera-
tions research  18 4  803–828  1993 
 tan  1991  jimmy j m  tan 
a necessary and sufficient
condition for the existence of a complete stable matching 
journal of algorithms  12 1  154–178  1991 
 teo and sethuraman  1998  chung-piaw
teo
and
jay
sethuraman  the geometry of fractional stable matchings
and its applications  mathematics of operations research 
23 4  874–891  1998 
 vande vate  1989  john h  vande vate  linear program-
ming brings marital bliss  operations research letters 
8 3  147–153  1989 
proceedings of the thirtieth    ijcai-21 
95
 "
None,2021,https-www-ijcai-org-proceedings-2021-0014-pdf,Temporal Induced Self-Play for Stochastic Bayesian Games,"Weizhe Chen, Zihan Zhou, Yi Wu, Fei Fang",None,https://www.ijcai.org/proceedings/2021/0014.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0014-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0014-pdf.pdf,"temporal induced self-play for stochastic bayesian games
weizhe chen1∗   zihan zhou2∗   yi wu2 3 and fei fang4
1shanghai jiao tong university
2shanghai qi zhi institute
3tsinghua university
4carnegie mellon university
chenweizhe@sjtu edu cn   footoredo  jxwuyi @gmail com  feif@cs cmu edu
abstract
one practical requirement in solving dynamic
games is to ensure that the players play well from
any decision point onward  to satisfy this require-
ment  existing efforts focus on equilibrium refine-
ment  but the scalability and applicability of exist-
ing techniques are limited  in this paper  we pro-
pose temporal-induced self-play  tisp   a novel
reinforcement learning-based framework to find
strategies with decent performances from any de-
cision point onward  tisp uses belief-space rep-
resentation  backward induction  policy learning 
and non-parametric approximation  building upon
tisp  we design a policy-gradient-based algorithm
tisp-pg  we prove that tisp-based algorithms
can find approximate perfect bayesian equilibrium
in zero-sum one-sided stochastic bayesian games
with finite horizon  we test tisp-based algorithms
in various games  including finitely repeated secu-
rity games and a grid-world game  the results show
that tisp-pg is more scalable than existing math-
ematical programming-based methods and signifi-
cantly outperforms other learning-based methods 
1
introduction
many real-world problems involve multiple decision-makers
interacting strategically  over the years  a significant amount
of work has focused on building game models for these prob-
lems and designing computationally efficient algorithms to
solve the games  serrino et al   2019  nguyen et al   2019  
while nash equilibrium  ne  is a well-accepted solution con-
cept  the players  behavior prescribed by an ne can be irra-
tional off the equilibrium path  one player can threaten to play
a suboptimal action in a future decision point to convince the
other players that they would not gain from unilateral devia-
tion  such  non-credible threats  restrict the practical appli-
cability of these strategies as in the real world  one may make
mistakes unexpectedly  and it is hard to enforce such threats 
thus it is important to find strategy profiles such that each
player s strategy is close to optimal  in expectation  from any
point onward given the other players  strategies 
∗equal contribution
to find such strategy profiles  researchers have proposed
equilibrium refinement concepts such as subgame perfect
equilibrium and perfect bayesian equilibrium  pbe   cho
and kreps  1987  and studied the computational complex-
ity  an et al   2011  etessami et al   2014  hansen and
lund  2018   however  existing methods for computing re-
fined equilibria have limited scalability and often require
full access to the game environment  thus can hardly apply
to complex games and real-world problems  as detailed in
section 2  
on the other hand  deep reinforcement learn-
ing  rl  has shown great promise in complex sequential
decision-making problems for single-agent and multi-agent
settings  mnih et al   2015  silver et al   2018   deep rl
leverages a compact representation of the game s state and
the players  action space  making it possible to handle large
games that are intractable for non-learning-based methods 
despite the promise  to our knowledge  no prior work has ap-
plied deep rl to equilibrium refinements 
in this paper  we focus on two-player stochastic bayesian
games with finite horizon as they can be used to model
various long-term strategic interactions with private in-
formation  albrecht and ramamoorthy  2013  
we pro-
pose temporal-induced self-play  tisp   the first rl-based
framework to find strategy profiles with decent performances
from any decision point onward  there are several crucial
challenges in using rl for this task  first  in these games 
a player s action at a decision point should be dependent on
the entire history of states and joint actions  as the num-
ber of histories grows exponentially  a tabular approach that
enumerates all the histories is intractable  although recurrent
neural networks  rnns  can be used to encode the history 
rnns are typically brittle in training and often fail to cap-
ture long-term dependency in complex games  second  using
standard rl algorithms with self-play suffers from limited
exploration  hence  it is extremely hard to improve the per-
formance on rarely visited decision points  our framework
tisp tackles these two challenges jointly  we use a belief-
based representation to address the first challenge  so that
the policy representation remains constant in size regardless
of the number of rounds  besides  we use backward induc-
tion to ensure exploration in training  tisp also uses non-
parametric approximation in the belief space  building upon
tisp  we design tisp-pg approach that uses policy gradi-
ent  pg  for policy learning  tisp can also be combined
proceedings of the thirtieth    ijcai-21 
96
 with other game-solving techniques such as counterfactual
regret minimization  cfr   zinkevich et al   2007  
fur-
ther  we prove that tisp-based algorithms can find approx-
imate pbe in zero-sum stochastic bayesian games with one-
sided incomplete information and finite horizon  we evalu-
ate tisp-based algorithms in different games  we first test
them in finitely repeated security games with unknown at-
tacker types whose pbe can be approximated through mathe-
matical programming  mp  under certain conditions  nguyen
et al   2019   results show that our algorithms can scale to
larger games and apply to more general game settings  and
the solution quality is much better than other learning-based
approaches  we also test the algorithms in a two-step ma-
trix game with a closed-form pbe  our algorithms can find
close-to-equilibrium strategies  lastly  we test the algorithms
in a grid-world game  and the experimental results show that
tisp-pg performs significantly better than other methods 
2
related work
the study of equilibrium refinements is not new in eco-
nomics  kreps and wilson  1982   in addition to the back-
ward induction method for perfect information games  math-
ematical programming  mp -based methods  nguyen et al  
2019  farina and gatti  2017  miltersen and sørensen  2010 
have been proposed to compute refined equilibria  however 
the mps used are non-linear and often have an exponential
number of variables or constraints  resulting in limited scala-
bility  a few works use iterative methods  farina et al   2017 
kroer et al   2017  but they require exponentiation in game
tree traversal and full access to the game structure  which lim-
its their applicability to large complex games 
stochastic bayesian games have been extensively studied
in mathematics and economics  forges  1992  sorin  2003 
chandrasekaran et al   2017  albrecht and ramamoorthy 
2013    albrecht et al   2016  discussed the advantage of
using type approximation to approximate the behaviors of
agents to what have already been trained  to reduce the com-
plexity in artificial intelligence  ai  researches  we focus on
equilibrium refinement in these games and provide an rl-
based framework 
various classical multi-agent rl algorithms  littman 
1994  hu et al   1998  are guaranteed to converge to an ne 
recent variants  heinrich et al   2015  lowe et al   2017 
iqbal and sha  2019  leverage the advances in deep learn-
ing  mnih et al   2015  and have been empirically shown to
find well-performing strategies in large-scale games  such as
go  silver et al   2018  and starcraft  vinyals et al   2019  
we present an rl-based approach for equilibrium refinement 
algorithms for solving large zero-sum imperfect informa-
tion games like poker  moravˇc ık et al   2017  brown and
sandholm  2018  need to explicitly reason about beliefs 
many recent algorithms in multi-agent rl use belief space
policy or reason about joint beliefs  these works assume a
fixed set of opponent policies that are unchanged  shen and
how  2019   or consider specific problem domains  serrino
et al   2019  woodward et al   2020   foerster et al  2019 
uses public belief state to find strategies in a fully cooperative
partial information game  we consider stochastic bayesian
games and use belief over opponents  types 
3
preliminaries
3 1
one-sided stochastic bayesian game
for expository purposes  we will mainly focus on what we
call one-sided stochastic bayesian games  ossbg   which
extends finite-horizon two-player stochastic games with type
information  in particular  player 1 has a private type that
affects the payoff function  hence  in a competitive setting 
player 1 needs to hide this information  while player 2 needs
to infer the type from player 1 s actions 
our algorithms
can be extended to handle games where both players have
types  as we will discuss in section 6  formally  an ossbg
is defined by a 8-tuple γ = ⟨ω  µ0  λ  p0  a  p   uλ
i    l  γ⟩ 
ω is the state space 
µ0 is the initial state distribution 
λ =  1          |λ|  is the set of types for player 1  p0 is the
prior over player 1 s type  a = �
i ai is the joint action
space with ai the action space for player i  p   ω × a →
∆|ω| is the transition function where ∆|ω| represents the |ω|-
dimensional probability simplex  uλ
i   ω × a → r is the
payoff function for player i given player 1 s type λ  l de-
notes the length of the horizon or number of rounds  γ is the
discount factor 
one play of an ossbg starts with a type λ sampled from
p0 and an initial state s0 sampled from µ0  then  l rounds
of the game will rollout  in round l  players take actions al
1 ∈
a1 and al
2 ∈ a2 simultaneously and independently  based
on the history hl  =  s0   a0
1  a0
2            al−1
1
  al−1
2
   sl   the
players will then get payoff uλ
i  st  al
1  al
2   note that the pay-
off uλ
i  sl  a1  a2  at every round l will not be revealed until
the end of every play on the game to prevent type information
leakage  the states transit w r t  p sl 1|sl  al
1  al
2  across
rounds 
let hl denote the set of all possible histories in round l and
h = �
l hl  let π1   λ × h → ∆a1  π2   h → ∆a2 be the
players  behavioral strategies  given the type λ  the history
hl and the strategy profile π =  π1  π2   player i s discounted
accumulative expected utility from round l onward is
vλ
i  π  hl  =
�
a1 a2
�
π1 a1|λ  hl π2 a2|hl 
�
uλ
i  sl  a1  a2 
  γ
�
s′
p s′|sl  a1  a2  vλ
i  π  hl ∪   a1  a2   s′  
��
   1 
similarly  we can define the q function by qλ
i  π  hl  a  =
uλ
i  sl  a1  a2    γes′ �
v λ
i  π  hl ∪   a1  a2   s′  
�
 
an ossbg can be converted into an equivalent extensive-
form game  efg  with imperfect information where each
node in the game tree corresponds to a  type  history  pair  see
appendix f   however  this efg is exponentially large  and
existing methods for equilibrium refinement in efgs  kroer
et al   2017  are not suitable due to their limited scalability 
3 2
equilibrium concepts in ossbg
let πi denote the space of all valid strategies for player i 
proceedings of the thirtieth    ijcai-21 
97
 definition 3 1  ϵ-ne  a strategy profile π =  π1  π2  is an ϵ-
ne if for i = 1  2  and all visitable history hl corresponding
to the final policy 
max
π′
i∈πi vi πi|hl→π′
i  π−i  hl  − vi π  hl  ≤ ϵ
 2 
where πi|hl→π′
i means playing πi until hl is reached  then
playing π′
i onwards 
definition 3 2  ϵ-pbe  a strategy profile π =  π1  π2  is an
ϵ-pbe if for i = 1  2 and all histories hl 
max
π′
i∈πi vi πi|hl→π′
i  π−i  hl  − vi π  hl  ≤ ϵ
 3 
where πi|hl→π′
i means playing πi until hl is reached  then
playing π′
i onwards 
it is straightforward that an ϵ-pbe is also an ϵ-ne 
4
temporal-induced self-play
our tisp framework  alg  1  considers each player as an
rl agent and trains them with self-play  each agent main-
tains a policy and an estimated value function  which will
be updated during training  tisp has four ingredients  it
uses belief-based representation  sec  4 1   backward induc-
tion  sec  4 2   policy learning  sec  4 3  and belief-space
approximation  sec  4 4   we discuss test-time strategy and
show that tisp converges to ϵ-pbes under certain conditions
in sec  4 5 
4 1
belief-based representation
instead of representing a policy as a function of the history 
we consider player 2 s belief b ∈ ∆|λ| of player 1 s type and
represent πi as a function of the belief b and the current state
sl in round l  i e   π1 l ·|b  sl  λ  and π2 l ·|b  sl   the belief b
represents the posterior probability distribution of λ and can
be obtained using bayes rule given player 1 s strategy 
bl 1
λ
=
π1 l
�
al
1|sl  bl
λ  λ
�
bl
λ
�
λ′∈λ π1 l
�
al
1|sl  bl
λ′  λ′�
bl
λ′
 4 
where bl
λ is the probability of player 1 being type λ given all
its actions up to round l − 1  this belief-based representation
avoids the enumeration of the exponentially many histories 
although it requires training a policy that outputs an action
for any input belief in the continuous space  it is possible to
use approximation as we show in sec  4 4  we can also define
the belief-based value function for agent i in round l by
v λ
i l π  bl  sl  = ea1 a2 sl 1
�
uλ
i  sl  a1  a2 
  γv λ
i l 1 π  bl 1  sl 1 
�
 
 5 
the q-function qλ
i l π  bl  sl  al  can be defined similarly 
we assume the policies and value functions are parameterized
by θ and φ respectively with neural networks 
4 2
backward induction
standard rl approaches with self-play train policies in a top-
down manner  it executes the learning policies from round
0 to l − 1 and only learns from the experiences at visited
decision points  to find strategy profiles with decent per-
formances from any decision point onward  we use back-
ward induction and train the policies and calculate the value
functions in the reverse order of rounds  we start by train-
ing πi l−1 for all agents and then calculate the corresponding
value functions v λ
i l−1  and then train πi l−2 and so on 
the benefit of using backward induction is two-fold  in
the standard forward-fashioned approach  one needs to roll
out the entire trajectory to estimate the accumulative reward
for policy and value learning  in contrast  with backward in-
duction  when training πi l  we have already obtained v λ
i l 1 
thus  we just need to roll out the policy for 1 round and di-
rectly estimate the expected accumulated value using v λ
i l 1
and eq   5   hence  we effectively reduce the original l-
round game into l 1-round games  which makes the learn-
ing much easier  another important benefit is that we can
uniformly sample all possible combinations of state  belief
and type at each round to ensure effective exploration  more
specifically  in round l  we can sample a belief b and then
construct a new game by resetting the environment with a
uniformly randomly sampled state and a type sampled from
b  implementation-wise  we assume access to an auxiliary
function from the environment  called sub reset l  b  that pro-
duces a new game as described  this function takes two pa-
rameters  a round l and a belief b  as input and produces a
new game by drawing a random state from the entire state
space ω with equal probability and a random type according
to the belief distribution b  this function is an algorithmic re-
quirement for the environment  which is typically feasible in
practice  for example  most rl environments provides a re-
set function that generates a random starting state  so a simple
code-level enhancement on this reset function can make exist-
ing testbeds compatible with our algorithm  we remark that
even with such a minimal environment enhancement require-
ment  our framework does not utilize the transition informa-
tion  hence  our method remains nearly model-free compar-
ing to other methods that assume full access to the underly-
ing environment transitions — this is the assumption of most
cfr-based algorithms  furthermore  using customized reset
function is not rare in the rl literature  for example  most
automatic curriculum learning algorithms assumes a flexible
reset function that can reset the state of an environment to a
desired configuration 
4 3
policy learning
each time a game is produced by sub reset l  b   we perform a
1-round learning with self-play to find the policies πi l  tisp
allows different policy learning methods  here we consider
two popular choices  policy gradient and regret matching 
policy gradient
pg method directly takes a gradient step over the ex-
pected utility  for notational conciseness  we omit the su-
per/subscripts of i  l  λ in the following equations and use s 
proceedings of the thirtieth    ijcai-21 
98
 b and s′  b′ to denote the state and belief at current round and
next round 
theorem 4 1 in the belief-based representation  the policy
gradient derives as follows 
∇θv λ π  b  s  =
�
a∈a
∇θ
�
πθ a|b  s qλ π  b  s  a 
�
 6 
= ea s′
�
qλ π  b  s  a ∇θ ln πθ a|b  s 
  γ∇θb′∇b′v λ π  b′  s′ 
�
 
comparing to the standard policy gradient theorem  we
have an additional term in eq  6   the second term   intu-
itively  when the belief space is introduced  the next belief b′
is a function of the current belief b and the policy πθ in the
current round  eq  4    thus  the change in the current pol-
icy may influence future beliefs  resulting in the second term 
the full derivation can be found in appendix e  we also show
in the experiment section that when the second term is ig-
nored  the learned policies can be substantially worse  we
refer to this pg variant of tisp framework as tisp-pg 
regret matching
regret matching is another popular choice for imper-
fect information games 
we take inspirations from deep
cfr  brown et al   2019  and propose another variant of
tisp  referred to as tisp-cfr  specifically  for each training
iteration t  let rt s  a  denote the regret of action a at state s 
πt a|s  b  denote the current policy  qt πt  s  b  a  denote the
q-function and v t
φ πt  s  b  denote the value function corre-
sponding to πt  then we have
πt 1 a|s  b 
=
 rt 1 s  b  a   
�
a′ rt 1 s  b  a′     
where rt 1 s  b  a  = �t
τ=1 qτ πτ  s  b  a  − v τ
φ  πτ  s  b 
and  ·    = max ·  0   since the policy can be directly com-
puted from the value function  we only learn v t
φ here  be-
sides  most regret-based algorithms require known transition
functions  which enables them to reset to any infomation-
set node in the training 
we use the outcome sampling
method  lanctot et al   2009   which samples a batch of tran-
sitions to update the regret  this is similar to the value learn-
ing procedure in standard rl algorithms  this ensures our
algorithm to be model-free  although tisp-cfr does not re-
quire any gradient computation  it is in practice much slower
than tisp-pg since it has to learn an entire value network in
every single iteration 
4 4
belief-space policy approximation
a small change to the belief can drastically change the pol-
icy  when using a function approximator for the policy  this
requires the network to be sensitive to the belief input  we
empirically observe that a single neural network often fails to
capture the desired belief-conditioned policy  therefore  we
use an ensemble-based approach to tackle this issue 
at each round  we sample k belief points  b1  b2       bk 
from the belief space ∆|λ|  for each belief bk  we use self-
play to learn an accurate independent strategy πθk a|s  bk 
algorithm 1 temporal-induced self-play
1  for l = l − 1          0 do
2 
for k = 1  2        k do
▷ run in parallel
3 
for t = 1          t do
4 
initialize replay buffer d =    and π0
5 
for j = 1          batch size do
▷ parallel
6 
s ← sub reset l  bk  
7 
a ← πt−1
θl k  s  bk  
8 
get next state s′ and utility u from env 
9 
d ← d    s  a  s′  u  
10 
update v t
φl k and πt
θl k using d 
11 
vφl k ← v n
φl k  πθl k ← πn
θl k
12  return  πθl k  vφl k 0≤l<l 1≤k≤k 
algorithm 2 compute test-time strategy
1  function getstrategy hl  πθ1          πθl 
2 
b0 ← p0
3 
for j ← 0          l − 1 do
4 
update bj 1 using bj  sj  aj and πθj with eq  4 
5 
return π a|bl  sl  with eq  7 
and value vφk π  s  bk  over the state space but specifically
conditioning on this particular belief input bk  when query-
ing the policy and value for an arbitrary belief b different from
the sampled ones  we use a distance-based non-parametric
method to approximate the target policy and value  specifi-
cally  for any two belief b1 and b2  we define a distance metric
w b1  b2  =
1
max ϵ ∥b−b′∥2  and then for the query belief b  we
calculate its policy π a|b  s  and value v  π  b  s  by
π a|b  s 
=
�k
k=1 πθk a|s  bk w b  bk 
�k
k=1 w b  bk 
 7 
v  π  b  s 
=
�k
k=1 vφk π  s  bk w b  bk 
�k
k=1 w b  bk 
 8 
we introduce a density parameter d to ensure the sam-
pled points are dense and has good coverage over the be-
lief space  d is defined as the farthest distance between any
point in ∆|λ| and its nearest sampled points  or formally
d = sup min ∥b  bi∥ | i = 1          k  | b ∈ ∆|λ|   a
smaller d indicates a denser sampled points set 
note that the policy and value networks at different belief
points at each round are completely independent and can be
therefore trained in perfect parallel  so the overall training
wall-clock time remains unchanged with policy ensembles 
additional discussions on belief sampling are in appx  a 
4 5
test-time strategy
note that our algorithm requires computing the precise be-
lief using eq  4  which requires the known policy for player
1  which might not be feasible at test time when competing
against an unknown opponent  therefore  at test time  we up-
date the belief according to the training policy of player 1 
proceedings of the thirtieth    ijcai-21 
99
 regardless of its actual opponent policy  that is  even though
the actions produced by the actual opponent can be com-
pletely different from the oracle strategies we learned from
training  we still use the oracle policy from training to com-
pute the belief  note that it is possible that we obtain an
infeasible belief  i e   the opponent chooses an action with
zero probability in the oracle strategy  in this case  we simply
use a uniform belief instead  the procedure is summarized
in alg  2  we also theoretically prove in thm  4 2 that in
the zero-sum case  the strategy provided in alg  2 provides
a bounded approximate pbe and further converges to a pbe
with infinite policy learning iterations and sampled beliefs 
the poof can be found in appendix f 
theorem 4 2 when the game is zero-sum and ω is finite  the
strategies produced by alg  2 is ϵ-pbe  where ϵ = l du  c·
t −1/2   d is the distance parameter in belief sampling  u =
l·
�
maxi s a1 a2 ui s  a1  a2 −mini s a1 a2 ui s  a1  a2 
�
  n
is the number of iterations in policy learning and c is a posi-
tive constant associated with the particular algorithm  tisp-
pg or tisp-cfr  details in appendix f   when t → ∞ and
d → 0  the strategy becomes a pbe 
we remark that tisp is nearly-model-free and does not uti-
lize the transition probabilities  which ensures its adaptability 
5
experiment
we test our algorithms in three sets of games  while very few
previous works in rl focus on equilibrium refinement  we
compare our algorithm with self-play pg with rnn-based
policy  referred to as rnn  and provide ablation studies for
the tisp-pg algorithm  bpg uses only belief-based policy
without backward induction or belief-space approximation 
bi adopt backward induction and belief-based policy but does
not use belief-space approximation  full experiment details
can be found in appx  d 
5 1
finitely repeated security game
game setting
we consider a finitely repeated simultaneous-move security
game  as discussed in  nguyen et al   2019   specifically  this
is an extension of a one-round security game by repeating it
for l rounds  each round s utility function can be seen as
a special form of matrix game and remains the same across
rounds  in each round  the attacker can choose to attack one
position from all a positions  and the defender can choose
to defend one  the attacker succeeds if the target is not de-
fended  the attacker will get a reward if it successfully at-
tacks the target and a penalty if it fails  correspondingly  the
defender gets a penalty if it fails to defend a place and a re-
ward otherwise  in the zero-sum setting  the payoff of the
defender is the negative of the attacker s  we also adopt a
general-sum setting described in  nguyen et al   2019  where
the defender s payoff is only related to the action it chooses 
regardless of the attacker s type 
evaluation
we evaluate our solution by calculating the minimum ϵ so
that our solution is an ϵ-pbe  we show the average result of
5 different game instances 
tisp-pg
rnn
bpg
bi
mean ϵ
0 881
15 18
101 2
27 51
worst ϵ
1 220
31 81
111 8
42 54
 a  zero-sum result for model-free methods  with |λ| = 2 
tisp-pg
rnn
bpg
bi
mean ϵ
0 892
34 62
89 21
83 00
worst ϵ
1 120
57 14
182 1
111 9
 b  general-sum result for model-free methods  with |λ| = 2 
zero-sum
general-sum
tisp-pg
tisp-cfr
tisp-pg
tisp-cfr
mean ϵ
0 446
0 474
0 608
0 625
worst ϵ
1 041
1 186
1 855
1 985
 c  result for known model variants  with |λ| = 2 
tisp-pg
rnn
bpg
bi
mean ϵ
1 888
18 20
79 74
40 75
worst ϵ
3 008
28 15
97 67
49 74
 d  zero-sum result  with |λ| = 3 
table 1  the result for finitely repeated security game  the less the
number  the better the solution is  these results are evaluated with
l = 10  |a| = 2  and uniform prior distribution 
l
2
4
6
8
10
mp
≈ 10−8
≈ 10−6
≈ 10−5
n/a
n/a
tisp-pg
0 053
0 112
0 211
0 329
0 473
tisp-cfr
0 008
0 065
0 190
0 331
0 499
 a  |a| = 2
l
2
4
6
8
10
mp
≈ 10−6
≈ 10−6
≈ 10−3
n/a
n/a
tisp-pg
0 120
0 232
0 408
0 599
0 842
tisp-cfr
0 002
0 049
0 285
0 525
0 847
 b  |a| = 5
table 2  comparing mathematical-programming and our methods 
i e   tisp-pg and tisp-cfr  with known model 
these results
are averaged over 21 starting prior distributions of the attacker
  0 00  1 00    0 05  0 95            1 00  0 00   
results
we first experiment with the zero-sum setting where we have
proved our model can converge to an ϵ-pbe  the compar-
ison are shown in table 1a 1c  we use two known model
variants  tisp-pg and tisp-cfr  and a model-free version
of tisp-pg in this comparison  tisp-pg achieves the best
results  while tisp-cfr also has comparable performances 
we note that simply using an rnn or using belief-space pol-
icy performs only slightly better than a random policy 
then we conduct experiments in general-sum games with
results shown in table 1b 1c 
we empirically observe
that the derived solution has comparable quality with the
zero-sum setting  we also compare our methods with the
mathematical-programming-based method  mp  in  nguyen
et al   2019   which requires full access to the game transition 
the results are shown in table 2  although when l is small 
the mp solution achieves superior accuracy  it quickly runs
out of memory  marked as  n/a   since its time and mem-
ory requirement grows at an exponential rate w r t  l  again 
our tisp variants perform the best among all learning-based
methods  we remark that despite of the performance gap be-
proceedings of the thirtieth    ijcai-21 
100
 tween our approach and the mp methods  the error on those
games unsolvable for mp methods is merely 0 1  compar-
ing to the total utility 
in our experiments  we do not observe orders of magni-
tudes difference in running time between our method and
baselines  tisp-pg and tisp-cfr in the tagging game uses
20 hours with 10m samples in total even with particle-based
approximation  200k samples per belief point  while rnn
and bpg in the tagging game utilizes roughly 7 hours with
2m total samples for convergence 
regarding the scalability on the number of types  as the
number of types increases  the intrinsic learning difficulty in-
creases  this is a challenge faced by all the methods  the
primary contribution of this paper is a new learning-based
framework for pbne  while we primarily focus on the case
of 2 types  our approach generalizes to more types naturally
with an additional experiment conducted for 3 types in ta-
ble  1d  advanced sampling techniques can potentially be
utilized for more types  which we leave for future work 
5 2
exposing game
game setting
we also present a two-step matrix game  which we call ex-
posing  in this game  player 2 aims to guess the correct type
of player 1 in the second round  there are two actions avail-
able for player 1 and three actions available for player 2 in
each round  specifically  the three actions for player 2 means
guessing player 1 is type 1  type 2 or not guessing at all  the
reward for a correct and wrong guess is 10 and −20 respec-
tively  the reward for not guessing is 0  player 1 receives a
positive 5 reward when the player 2 chooses to guess in the
second round  regardless of which type player 2 guesses  in
this game  player 1 has the incentive to expose its type to en-
courage player 2 to guess in the second round  we further
add a reward of 1 for player 1 choosing action 1 in the first
round regardless of its type to give player 1 an incentive to not
exposing its type  with this reward  a short-sighted player 1
may pursue the 1 reward and forgo the 5 reward in the second
round  the payoff matrices for this game are in appx  d 
the equilibrium strategy for player 2 in the second round
w r t  different types of player 1 is 
strategy  =
�
�
�
guessing type 1
if pr 1|h  > 1
3
guessing type 2
if pr 2|h  > 1
3
not guessing
else
in this game  the equilibrium values in the second round
for both types of player 1 are highly discontinuous with re-
gard to player 2 s belief  as shown in fig  1a  which makes
the belief-space gradient term in eq  6 ineffective  however 
the approximation introduced in sec  4 4 can serve as a soft
representation of the true value function  as shown in fig  1b 
this soft representation provides an approximated gradient
in the belief space  which allows for belief-space exploration 
we will show later that this belief-space exploration cannot
be achieved otherwise 
1the optimal solution refers to the pareto-optimal pbe in this
game  note that there are two symmetric optimal solutions  we
choose to only show one here for easy comparison and simplicity 
 a  ground truth
 b  approximation
figure 1  ground truth and approximated value of player 1 in
the second round of exposing game  the x−axis corresponds to
pr 1|h   the y−axis corresponds to the equilibrium value 
p1 s type
action 1
action 2
reward
tisp-pg
type 1
0 985
0 015
5 985
type 2
0 258
0 742
5 258
tisp-cfr
type 1
1 000
0 000
1 000
type 2
1 000
0 000
1 000
tisp-pg−
type 1
0 969
0 031
0 969
type 2
0 969
0 031
0 969
optimal
type 1
1 000
0 000
6 000
type 2
0 333
0 667
5 333
table 3  detailed first round policy in exposing game  tisp-pg is
the only algorithm that separates the two player-1 types  strategies
and yields a result very close to the optimal solution 1
results
we compare the training result between tisp-pg and tisp-
cfr to exhibit the effectiveness of our non-parametric ap-
proximation  we further add an ablation study that removes
the belief-space gradient term in tisp-pg  which we call
tisp-pg−  the results are shown in table 3  we can see
that tisp-pg is the only algorithm that successfully escapes
from the basin area in fig  1 as it is the only algorithm that is
capable of doing belief-space exploration  we also show the
obtained policies table 3  the training curves can be found
in appx  d  note that the policies trained from tisp-cfr
and tisp-pg− are also close to a pbe where player 1 takes
action 1 regardless of its type in the first round  and player 2
chooses not to guess in the second round  although it is not
pareto-optimal 
5 3
tagging game
game setting
we test our method in a gridworld game tagging  as illus-
trated in fig  2  the game is inspired by  shen and how 
2019   specifically  the game is on an 8 × 8 square  and
player 1 has two types  i e   ally and enemy  and each type
corresponds to a unique target place  each player will re-
ceive distance-based reward to encourage it to move towards
its target place  there is a river in the top half part of the grids
which player 2 cannot enter  player 1 starts from the bottom
middle of the map and player 2 starts from a random posi-
tion under the river  both players can choose to move in one
of the four directions   up u   down d   left l   right r    by
one cell  player 2 has an additional action  tag  to tag player
1 as the enemy type  the tag action is only available when
player 1 has not entered the river and the euclidean distance
between the two players is less than 2 5  the attackers get
proceedings of the thirtieth    ijcai-21 
101
 figure 2  an illustration of the tagging game 
p1 s type
u
d
r
l
tisp-pg
ally
0 839
0 001
0 001
0 159
enemy
0 932
0 001
0 001
0 066
rnn
ally
0 248
0 237
0 238
0 274
enemy
0 599
0 067
0 077
0 255
bpg
ally
0 000
0 000
0 000
1 000
enemy
1 000
0 000
0 000
0 000
tisp-cfr
ally
0 000
0 000
0 000
1 000
enemy
1 000
0 000
0 000
0 000
table 4  the policy at one of the starting states in tagging game 
where player 2 is two cells above the fixed starting point of player 1 
higher rewards for getting closer to their type-specified tar-
get  and the defenders get higher rewards for getting closer
to the attacker  moreover  if the defender chooses to tag  it
will get a reward of 10 if the attacker is of the enemy type and
a reward of −20 if the attacker is of the ally type  while the
attacker will get a reward of −10 for being tagged no matter
what its type is  more detail is provided in appx  d 
based on the game s rule  an enemy-typed player 1 is likely
to go to its own target immediately to get a higher reward 
however  such a strategy reveals its type straight away  which
can be punished by being tagged  a more clever strategy of
an enemy-typed player 1 is to mimic the behavior of the ally-
typed player 1 in most situations and never let player-2 s be-
lief of enemy type be larger than 2
3  so that player 2 has no
incentive to tag it  the ally-typed player 1 may simply go up
in most states in order to get closer to its target for a reward
while player 2 should learn to tag player 1 if its belief of en-
emy type is high enough and try to move closer to player 1 in
other cases 
evaluation
although it is computationally intractable to calculate the ex-
act exploitability in this gridworld game  we examine the re-
sults following  gray et al   2021  by evaluating the perfor-
mances in induced games  we choose 256 induced games
among all the induced games after the second round and
check their exploitability  we get the best response in each in-
duced game in two ways  in the first round of each game  we
enumerate all the possible actions and manually choose the
best action  we also train a new bpg player-2 from scratch 
this new bpg-based player is trained in a single-agent-like
environment and does not need to consider the change in the
player-1 policy  we check how much reward agents can get
after the learning process finishes  a high reward from player
2 would indicate that player 1 fail to hide its type  we also
provide the detailed strategies from different baselines for the
first round of the game for additional insight 
tisp-pg
rnn
bpg
tisp-cfr
p2 reward
-1 90
-1 67
-0 98
-1 82
p1 reward  ally 
-2 55
-2 87
-3 26
-3 17
p1 reward  enemy 
-2 41
-2 71
-9 29
-4 49
table 5  the average exploitability result of 256 induced games in
the tagging game  the lower player 2 s reward  the better the algo-
rithm 
results
we show the derived policy in the very first step in table 4 
the policy learned by our method successfully keeps the be-
lief to be less than 1
3  and keeps a large probability of going to
the target of each type  the rnn policy shows no preference
between different actions  resulting in not being tagged but
also not getting a larger reward for getting closer to the tar-
get  the bpg policy simply goes straight towards the target
and is therefore punished for being tagged  the exploitabil-
ity results are shown in table 5  from the training reward
achieved by the new exploiter player 2  tisp-pg performs the
best among all baselines and tisp-cfr also produces a ro-
bust player-1 policy  we remark that relative performances of
different methods in the gridworld game are consistent with
what we have previously observed in the finitely repeated se-
curity games  which further validates the effectiveness of our
approach 
6
discussion and conclusion
we proposed tisp  an rl-based framework to find strate-
gies with a decent performance from any decision point on-
ward  we provided theoretical justification and empirically
demonstrated its effectiveness  our algorithms can be eas-
ily extended to a two-sided stochastic bayesian game  the
tisp framework still applies  and the only major modifica-
tion needed is to add a for-loop to sample belief points for
player 2  this extension will cost more computing resources 
but the networks can be trained fully in parallel  the full ver-
sion of the extended algorithm is in appendix c 
acknowledgements
we would like to thank ryan shi for some help in writing the
early workshop version of this paper  co-author fang is sup-
ported in part by nsf grant iis- 1850477  a research grant
from lockheed martin  and by the u s  army combat capa-
bilities development command army research laboratory
cooperative agreement number w911nf-13-2-0045  arl
cyber security cra   the views and conclusions contained
in this document are those of the authors and should not be in-
terpreted as representing the official policies  either expressed
or implied  of the funding agencies 
references
 albrecht and ramamoorthy  2013  stefano v albrecht and
subramanian ramamoorthy  a game-theoretic model and
best-response learning method for ad hoc coordination in
multiagent systems  in aamas  2013 
proceedings of the thirtieth    ijcai-21 
102
  albrecht et al   2016  stefano v albrecht  jacob w cran-
dall  and subramanian ramamoorthy  belief and truth in
hypothesised behaviours  artificial intelligence  2016 
 an et al   2011  bo an  milind tambe  fernando ordonez 
eric shieh  and christopher kiekintveld  refinement of
strong stackelberg equilibria in security games  in aaai 
2011 
 brown and sandholm  2018  noam brown and tuomas
sandholm  superhuman ai for heads-up no-limit poker 
libratus beats top professionals  science  2018 
 brown et al   2019  n  brown  a  lerer  s  gross  and
t  sandholm 
deep counterfactual regret minimization 
icml  2019 
 chandrasekaran et al   2017  muthukumaran
chan-
drasekaran  yingke chen  and prashant doshi 
on
markov games played by bayesian and boundedly-rational
players  in aaai  2017 
 cho and kreps  1987  in-koo cho and david m kreps 
signaling games and stable equilibria  qje  1987 
 etessami et al   2014  kousha etessami  kristoffer arnsfelt
hansen  peter bro miltersen  and troels bjerre sørensen 
the complexity of approximating a trembling hand perfect
equilibrium of a multi-player game in strategic form  in
sagt  2014 
 farina and gatti  2017  gabriele farina and nicola gatti 
extensive-form perfect equilibrium computation in two-
player games  in aaai  2017 
 farina et al   2017  gabriele farina  christian kroer  and
tuomas sandholm  regret minimization in behaviorally-
constrained zero-sum games  in icml  2017 
 foerster et al   2019  jakob foerster  francis song  edward
hughes  neil burch  iain dunning  shimon whiteson 
matthew botvinick  and michael bowling  bayesian ac-
tion decoder for deep multi-agent reinforcement learning 
in icml  2019 
 forges  1992  francoise forges  repeated games of incom-
plete information  non-zero-sum  handbook of game the-
ory with economic applications  1992 
 gray et al   2021  jonathan gray 
adam lerer 
anton
bakhtin  and noam brown  human-level performance in
no-press diplomacy via equilibrium search  iclr  2021 
 hansen and lund  2018  kristoffer arnsfelt hansen and
troels bjerre lund  computational complexity of proper
equilibrium  in ec  2018 
 heinrich et al   2015  johannes heinrich  marc lanctot 
and david silver  fictitious self-play in extensive-form
games  in icml  2015 
 hu et al   1998  junling hu  michael p wellman  et al  mul-
tiagent reinforcement learning  theoretical framework and
an algorithm  in icml  1998 
 iqbal and sha  2019  shariq iqbal and fei sha 
actor-
attention-critic for multi-agent reinforcement learning  in
icml  2019 
 kreps and wilson  1982  david m kreps and robert wil-
son  sequential equilibria  econometrica  1982 
 kroer et al   2017  christian kroer  gabriele farina  and
tuomas sandholm  smoothing method for approximate
extensive-form perfect equilibrium  arxiv  2017 
 lanctot et al   2009  marc lanctot  kevin waugh  martin
zinkevich  and michael bowling  monte carlo sampling
for regret minimization in extensive games  in nips  2009 
 littman  1994  michael l littman 
markov games as a
framework for multi-agent reinforcement learning  in ma-
chine learning proceeding  1994 
 lowe et al   2017  ryan lowe  yi i wu  aviv tamar  jean
harb  openai pieter abbeel  and igor mordatch  multi-
agent actor-critic for mixed cooperative-competitive envi-
ronments  in nips  2017 
 miltersen and sørensen  2010  peter
bro
miltersen
and
troels bjerre sørensen  computing a quasi-perfect equi-
librium of a two-player game  economic theory  2010 
 mnih et al   2015  volodymyr mnih  koray kavukcuoglu 
david silver  andrei a rusu  joel veness  marc g belle-
mare  alex graves  et al  human-level control through
deep reinforcement learning  nature  2015 
 moravˇc ık et al   2017  matej moravˇc ık  martin schmid 
neil burch  viliam lis y  dustin morrill  nolan bard 
trevor davis  et al  deepstack  expert-level artificial in-
telligence in heads-up no-limit poker  science  2017 
 nguyen et al   2019  thanh h  nguyen  yongzhao wang 
arunesh sinha  and michael p  wellman 
deception in
finitely repeated security games  aaai  2019 
 serrino et al   2019  jack serrino  max kleiman-weiner 
david c parkes  and josh tenenbaum  finding friend and
foe in multi-agent games  in neurips  2019 
 shen and how  2019  macheng shen and jonathan p how 
robust opponent modeling via adversarial ensemble rein-
forcement learning in asymmetric imperfect-information
games  arxiv  2019 
 silver et al   2018  david silver  thomas hubert  julian
schrittwieser  ioannis antonoglou  matthew lai  et al 
a general reinforcement learning algorithm that masters
chess  shogi  and go through self-play  science  2018 
 sorin  2003  sylvain sorin  stochastic games with incom-
plete information  in stochastic games and applications 
2003 
 vinyals et al   2019  oriol vinyals  igor babuschkin  woj-
ciech m czarnecki  micha¨el mathieu  andrew dudzik 
junyoung chung  david h choi  richard powell  timo
ewalds  et al  grandmaster level in starcraft ii using multi-
agent reinforcement learning  nature  2019 
 woodward et al   2020  mark woodward  chelsea finn 
and karol hausman  learning to interactively learn and
assist  aaai  2020 
 zinkevich et al   2007  martin zinkevich  michael johan-
son  michael bowling  and carmelo piccione  regret min-
imization in games with incomplete information  nips 
2007 
proceedings of the thirtieth    ijcai-21 
103
 "
None,2021,https-www-ijcai-org-proceedings-2021-0015-pdf,Cooperation in Threshold Public Projects with Binary Actions,"Yiling Chen, Biaoshuai Tao, Fang-Yi Yu",None,https://www.ijcai.org/proceedings/2021/0015.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0015-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0015-pdf.pdf,"cooperation in threshold public projects with binary actions∗
yiling chen1   biaoshuai tao2 and fang-yi yu1†
1harvard university
2john hopcroft center for computer science  shanghai jiao tong university
yiling@seas harvard edu  bstao@sjtu edu cn  fangyiyu@seas harvard edu
abstract
when can cooperation arise from self-interested
decisions in public goods games  and how can we
help agents to act cooperatively  we examine these
classical questions in a pivotal participation game 
a variant of public good games  where heteroge-
neous agents make binary participation decisions
on contributing their endowments  and the public
project succeeds when it has enough contributions 
we prove it is np-complete to decide the exis-
tence of a cooperative nash equilibrium such that
the project succeeds  we also identify two natu-
ral special scenarios where this decision problem is
tractable  we then propose two algorithms to help
cooperation in the game  our first algorithm adds
an external investment to the public project  and our
second algorithm uses matching funds  we show
that the cost to induce a cooperative nash equilib-
rium is near-optimal for both algorithms  finally 
the cost of matching funds can always be smaller
than the cost of adding an external investment  in-
tuitively  matching funds provide a greater incen-
tive for cooperation than adding an external invest-
ment does 
1
introduction
consider a town that seeks donations of collectibles from its
residents with the goal to open a public museum if enough
collectibles are received  or countries deciding whether to
participate in an environmental agreement  e g  kyoto pro-
tocol   kaul et al   1999  finus  2002  battaglini and harstad 
2016  to collectively reduce greenhouse gas emission  these
settings have the nature of public goods games—the non-
exclusiveness of a public good may lead to free ride but the
success of the project requires a certain level of participation 
can cooperative behavior arise from self-interested decisions
to lead to success in the project  how can we help agents to
act cooperatively 
∗a full version of this paper is available at  https //arxiv org/abs/
2105 08572 
†yiling chen and fang-yi yu are supported by the national sci-
ence foundation under grants iis 2007887 
we propose a variant of public goods games  pivotal par-
ticipation game  to answer these two classic questions  each
agent has an endowment and decides whether to contribute
to a public project  if the total contribution is enough for the
project to succeed  everyone regardless of their contribution
receives rewards from the project 
our pivotal participation game has two characteristics 
first  participants make binary decisions on participation
 contributing their endowment or not   this allows us to cap-
ture the indivisibility of contributions in collectible donation
and participation agreement  restriction to binary actions is
also suitable for other public goods domains such as vaccina-
tion  brito et al   1991   adoption of innovations  dybvig and
spatt  1983   public health insurance  goldstein and pauly 
1976   or even practicing social distancing  cato et al   2020  
second  participants have heterogeneous endowments and re-
wards  many well-studied public goods games are symmetric
among agents  agents have symmetric endowments  van de
kragt et al   1983  palfrey and rosenthal  1984  and the re-
ward is uniformly distributed among agents  rapoport  1988 
or only depends on the number of contributing agents  hir-
shleifer  1983  jackson  2010   in our setting  agents  en-
dowments  value of collectibles  cost of reducing greenhouse
gas emissions  are heterogeneous  and their reward from the
project s success  values of visiting museum or benefits from
clean air  can also be different 
we show that successful cooperation is always possible
when informally agents  endowments are small or the reward
levels are large enough  theorem 6   however  in general  we
prove that it is np-complete to decide whether there exists a
nash equilibrium such that the project succeeds  theorem 5  
this result suggests large groups may struggle to cooperate in
public projects  which is supported in the literature   olson 
2009 
then we develop algorithms to help achieving cooperation 
we consider two natural interventions  the algorithms can 1 
add an external investment δ to the public project  or 2  com-
mit to a matching fund so that for every 1 value of investment
from agents  the algorithms add ρ to the project  both in-
terventions are common in practice   baker ii et al   2009 
karlan and list  2020  we want to minimize the additional
cost due to those interventions  we first show that it is np-
hard to approximate the optimal cost under both interventions
to within any finite multiplicative factors  then  we design
proceedings of the thirtieth    ijcai-21 
104
 two algorithms with near-optimal cost in the additive sense 
 theorem 13 and 19  finally  we compare these two interven-
tions and prove that matching funds can promote cooperation
with no more cost than adding an external investment can 
 proposition 16  this provides a theoretical explanation for
the efficacy of matching funds in the field   karlan and list 
2007 
related works 
our work considers the computational is-
sue of searching nash equilibria of public goods games  and
designs algorithms to help cooperation  our model falls in
the category of threshold public goods with binary actions 
however  for most of the existing models in this category 
computational issue has seldom been considered and suc-
cessful cooperation can be found efficiently  one pioneer-
ing work  palfrey and rosenthal  1984  considers partici-
pation games where agents have homogeneous unit endow-
ment  thus  participation by any subset of sufficient num-
ber of agents is an equilibrium  rapoport  1988  and bolle
 2014  consider that agents  rewards only depend on whether
the project succeeds or not  while ours also depends on the
project s total value of contributions  as a result  successful
cooperation can be computed efficiently in their games  an-
other important category of public goods games is network
public goods game  bramoull e et al   2007   for this cate-
gory  recent works also consider the computational complex-
ity of finding equilibria and design algorithms to help coop-
eration  yu et al   2020  kempe et al   2020   however  the
main interest of their games are network structures instead of
heterogeneity of agents  endowments and reward levels 
2
model
we consider the pivotal participation game where agents
have heterogeneous endowment and binary actions deciding
whether to invest all her endowment or none  formally  a
group of n agents wants to fund a project which has a thresh-
old τ ∈ r≥0 for success  each agent i ∈  n  has an indivisi-
ble endowment that has an equivalent value of ei ∈ r≥0  and
she can decide whether to participate by contributing all her
endowment or free ride  ai ∈  0  1   thus  agents  strategy
profile can be denoted by s  =  i   ai = 1  ⊆  n  which
is the set of agents who participate  let e s   = �
j∈s ej
be the total value of contributions made by agents in s  the
project succeeds if e s  ≥ τ  when the project succeeds 
each agent s reward depends on her reward level 0 < mi < 1 
specifically  given a strategy profile s  agent i s utility is
ui s  = ei1 i /∈ s    mie s 1  e s  ≥ τ   
 1 
we use  ⃗e  ⃗m  τ  to denote a pivotal participation game in-
stance  where ⃗e =  e1          en  encodes each agent s en-
dowment and ⃗m =  m1          mn  encodes each agent s re-
ward level 
a strategy profile s is a nash equilibrium if
no one would unilaterally deviate  if i invests  i e   i ∈ s 
ui s  ≥ ui s \  i    if i /∈ s  ui s  ≥ ui s ∪  i    a
strategy profile s is a cooperative nash equilibrium if it is a
nash equilibrium and the project succeeds  e s  ≥ τ 
3
best response and nash equilibria
first note that  fixing other agents  actions  an agent i will
free ride if the project succeeds without her investment or
cannot succeed with her investment  to see this  let s−i =
 j ̸= i   aj = 1  be other agents  action  if agent i s action
does not affect whether the project succeeds  ui s−i ∪ i  −
ui s−i  ≤ −ei   miei < 0  that is  agent i will invest only
if her investment can change the project from unsuccessful to
successful  e s−i  < τ ≤ e s−i    ei  however  the follow-
ing example shows this is just a necessary condition 
example 1  let ⃗e =  2  2  2  9   ⃗m =  0 2  0 2  0 2  0 5  
and τ = 10  the project s success requires agent 4 to par-
ticipate  however  agent 4 will not participate  because even
if everyone participates  the total investment is 15 and agent
4 s reward is at most 15m4 = 7 5 which is smaller than her
endowment 9 
the above example shows that even with enough endow-
ments the agents cannot cooperate due to their heterogeneity 
the following proposition shows that the best response de-
pends on not only whether the project succeeds but also how
large her endowment ei and reward level mi are 
proposition 2  given the other agents  actions s−i  agent i s
best response is participating if and only if
e s−i  < τ ≤ e s−i    ei  and
 2 
1 − mi
mi
ei ≤ e s−i  
 3 
proof  if both  2  and  3  are true 
ui s−i ∪  i  
=mie s−i ∪  i  1 e s−i ∪  i   ≥ τ 
 by eqn   1  
=mie s−i ∪  i  
 by the second part of eqn   2  
=mie s−i    miei
≥ 1 − mi ei   miei
 by eqn   3  
=ui s−i 
 by eqn   2  
therefore  agent i s best response is participating 
conversely  suppose eqn   2  does not hold  agent i s ac-
tion does not affect whether the project succeeds  by eqn   1  
ui s−i ∪  i   − ui s−i  ≤ −ei   miei < 0  thus  agent
i s best response is not participating  finally  if eqn   3  does
not hold 
ui s−i ∪  i   ≤mie s−i    miei
 may not succeed 
< 1 − mi ei   miei
 eqn   3  is false 
=ui s−i  
so agent i s best response is not participating  this completes
the proof 
with proposition 2  we can show that an agent will not
participate if her endowment is very large 
corollary 3  if ei ≥ τ  agent i will not participate 
proof  suppose ei ≥ τ and agent i participates  other agent
will free ride because the project already succeeds  however 
agent i does not want to participate by himself/herself  be-
cause mi < 1 
proceedings of the thirtieth    ijcai-21 
105
 3 1
nash equilibria
by proposition 2  we have the following characterization of
a successful cooperation s which is a nash equilibrium that
makes the project successful 
proposition 4  given a pivotal game  ⃗e  ⃗m  τ   s is a coop-
erative nash equilibrium if and only if for all i ∈ s
max
�
τ  ei
mi
�
≤ e s  < τ   ei 
 4 
we show deciding if there is a cooperative nash equilib-
rium is np-complete  this implies that searching such an co-
operation among a large group of agents is computationally
difficult 
theorem 5  deciding if a pivotal participation game
 ⃗e  ⃗m  τ  has a cooperative nash equilibrium is np-complete 
proof  this decision problem is clearly in np  the set of
agents s ̸= ∅ that invest can be served as a certificate  and
proposition 4 can decide if s is a nash equilibrium in poly-
nomial time  it remains to show that the problem is np-hard 
we reduce the problem from a well-known np-complete
problem  the partition problem  garey and johnson  1979  
given a set s of 2t positive integers c1          c2t   decide if
there exists a subset t of t integers whose sum is exactly
1
2
�2t
i=1 ci  we assume without loss of generality that c1 ≤
· · · ≤ c2t  
we construct a pivotal participation game instance
 ⃗e  ⃗m  τ  as follows 
let m
= 100 �2t
i=1 ci and n
=
100mt  the instance contains n = 2t   2 agents  with
ei = n   m   2ci for i = 1          2t  and e2t  1 = n   1
and e2t  2 = n  it is straightforward to see that e2t  2 <
e2t  1 < e1 ≤ · · · ≤ e2t   the parameter τ is set to τ = 1  
e2t  1   1
2
�2t
i=1 ei = 1
2
�2t
i=1 2ci   n  m t  n  2  fi-
nally  ⃗m is set to the followings  for each i = 1          n  mi =
ei
τ e2t  2−1  for each i = 1          n  we have max  ei
mi   τ  =
τ   e2t  2 − 1 = 1
2
�2t
i=1 2ci    n   m t   2n   1  which
must be a lower bound to e s  by proposition 4 
suppose the partition instance is a yes instance  and let t
be the subset of t integers such that �
i∈t ci = 1
2
�2t
i=1 ci 
by slightly abuse of the notation  let t be the subset of the
first 2t agents that corresponds to the set of t selected inte-
gers  we show that s = t ∪  2t   1  2t   2  is a valid
nash equilibrium  to see this  the total investment is e s  =
2 ·
��
i∈t ci
�
   m   n t   2n   1 = 2 ·
�
1
2
�2t
i=1 ci
�
 
 m   n t   2n   1 = τ   e2t  2 − 1 = max τ  ei
mi   for
each i = 1          n  moreover  for each i = 1          n  by notic-
ing that e2t  2 ≤ ei  we have e s  ≤ τ   ei − 1 < τ   ei 
by proposition 4  s is a nash equilibrium 
suppose the partition instance is a no instance  we aim to
show that the only nash equilibrium is s = ∅  to derive a
contradiction  suppose s ̸= ∅ is a nash equilibrium  and we
consider two cases  2t   2 ∈ s and 2t   2 /∈ s 
suppose 2t   2 ∈ s  by proposition 4  we must have
e2t  2
m2t  2 = τ   e2t  2 − 1 ≤ e s  < τ   e2t  2  since all
ei s are integers  this implies e s  = τ   e2t  2 − 1  and it
must be that �
i∈s\ 2t  2  ei = τ −1 = e2t  1   1
2
�2t
i=1 ei 
by our construction  each of e1          e2t is an even number 
while e2t  1 is an odd number  thus  e2t  1   1
2
�2t
i=1 ei
is an odd number  note that �2t
i=1 ei is a multiple of 4   by
the parity of the equation  we must have 2t   1 ∈ s  this
implies �
i∈s\ 2t  1 2t  2  ei =
1
2
�2t
i=1 ei  let t = s \
 2t   1  2t   2   we have �
i∈t ei = 1
2
�2t
i=1 ei 
next  it is easy to see that |t | = t  if |t | < t  �
i∈t ei ≤
 m  n  t −1  �
i∈t 2ci <  m  n  t −1   1
50m <
 m   n t < 1
2
�2t
i=1 ei  if |t | > t  �
i∈t ei >  m  
n  t   1  >  m   n t   1
50m > 1
2
�2t
i=1 ei 
knowing that |t | = t  by canceling the  m   n  terms
on both sides of the equation �
i∈t ei = 1
2
�2t
i=1 ei and then
divide the both sides by 2  we have �
i∈t ci = 1
2
�2t
i=1 ci 
which contradicts to that the partition instance is a no in-
stance 
it remains to derive a contradiction for the case 2t  2 /∈ s 
firstly  we show that |s| ≥ t   2  if |s| ≤ t   1  we
have e s  = �
i∈s ei <  n   m  t   1   
1
50m   1 <
 m   n t   1 1n < τ   e2t  2 − 1 =
ei
mi   which implies
s cannot be a nash equilibrium by proposition 4 
having shown that |s| ≥ t   2  we discuss two sub-cases 
2t  1 /∈ s and 2t  1 ∈ s  for the first sub-case 2t  1 /∈ s 
since ei > m   n for all i = 1          2t  we have e s  =
�
i∈s ei >  t   2  m   n   on the other hand  for each
i = 1          2t  we have τ  ei = 1
2
�2t
i=1 2ci   m  n t  
n   2    m   n    ci <  m   n  t   1    n   1
25m  
2 <  m   n  t   2   therefore  e s  > τ   ei for each
i = 1          2t  since s ⊆  1          2t   s cannot be a nash
equilibrium by proposition 4 
consider the second sub-case 2t   1 ∈ s  there are at
least t   1 agents in  1          2t   so e s  ≥  m   n  t  
1    n   1 =  m   n t   2n   m   1  on the other
hand  τ   e2t  1 = 1
2
�2t
i=1 2ci    m   n t   2n   3 <
 m   n t   2n   m < e s   by proposition 4  s cannot
be a nash equilibrium  and we derive a contradiction again 
we have derive contradictions for all possible cases for
s ̸= ∅  therefore  the only nash equilibrium is s = ∅ when
the partition instance is a no instance  we conclude the the-
orem 
while cooperative equilibria need not in general exist  ex-
ample 1  and are hard to compute  theorem 5   in the follow-
ing theorem we show that a cooperative nash equilibrium al-
ways exists and can be computed efficiently when the ratio of
endowment to reward level is smaller than τ for each agents
 as long as the sum of all agents  endowments exceeds τ  
intuitively  our result shows that cooperation becomes easy 
if agents  endowments are small or the reward level are large
enough  in contrast to example 1 
theorem 6  given a pivotal participation game  ⃗e  ⃗m  τ   if
ei/mi ≤ τ for all i  there exists a successful cooperation if
and only if �n
i=1 ei ≥ τ  moreover  we can find a coopera-
tive nash equilibrium s in polynomial time 
we will show that every minimal subset of agents s  de-
fined below  is a nash equilibrium 
proceedings of the thirtieth    ijcai-21 
106
 definition 7  given a pivotal participation game  ⃗e  ⃗m  τ   a
subset of agents s is minimal if 1  e s  ≥ τ  and 2  for any
j ∈ s  e s \  j   < τ 
proposition 8  given a pivotal participation game  ⃗e  ⃗m  τ  
if ei/mi ≤ τ for all i  every minimal subset of agents s is a
nash equilibrium 
proof  we prove this by showing that every minimal subset
of agents s satisfies eqn   4  in proposition 4  given an arbi-
trarily minimal subset of agents s  since ei/τ ≤ mi  the left
part of  4  holds due to 1  of definition 7  suppose the right
part of  4  fails for some agent j ∈ s  we have e s  ≥ τ  ej 
which implies e s \  j   ≥ τ  which contradicts to 2  of
definition 7  thus  the right part of  4  also holds for any
i ∈ s 
finally  theorem 6 can be shown by constructing a mini-
mal subset of agents s 
proof of theorem 6  suppose �n
i=1 ei ≥ τ  the following
simple algorithm finds a minimal subset of agents s  ini-
tialize s = ∅  iteratively add an arbitrary agent i to s  and
terminate the algorithm when e s  ≥ τ  the algorithm will
terminates with e s  ≥ τ since �n
i=1 ei ≥ τ  it is easy to
see that the algorithm finds a minimal subset of agents s  and
by proposition 8  s is a nash equilibrium 
suppose �n
i=1 ei < τ  the left part of  4  in proposition 4
will always fail  therefore  there does not exist a cooperative
nash equilibrium 
in the full version of this paper  we consider another spe-
cial case where the success of the project always requires the
same number of agents  and show that the problem of decid-
ing if a cooperative nash equilibrium exists can be solved in
polynomial time 
4
interventions
here we consider two possible interventions to promote
agents to cooperate  we can add an external investment or
commit to a matching fund  we call an intervention valid if
there is a cooperative nash equilibrium after the the interven-
tion  in both interventions  we want to find a valid interven-
tion that minimizes the additional cost 
we first show that it is np-hard to approximate the optimal
cost within any finite factor under both interventions  the-
orem 11   then  we design two algorithms  algorithms 1
and 2  which take parameters of the game  ⃗e  ⃗m  τ  and out-
put a valid intervention  we show that the cost of each algo-
rithm s intervention is close to the optimal with small additive
errors  theorems 13 and 19   finally  we compare these two
interventions and prove that matching fund is more powerful
than adding an external investment in proposition 16 
4 1
external investment
in this section  we consider mechanisms that add investment
δ to the public project in addition to agents  investment  thus 
agent i s utility  ui s  becomes
ei1 i /∈ s    mi e s    δ 1  e s    δ ≥ τ   
 5 
by a similar analysis  we can show the following propo-
sition similar to proposition 4  we leave the details to the
readers 
proposition 9  given a pivotal participation game instance
 ⃗e  ⃗m  τ  with external investment δ  s is a cooperative nash
equilibrium if and only if for all i ∈ s
max
�
τ  ei
mi
�
≤ e s    δ < τ   ei 
 6 
thereafter  we will assume τ   ei >
ei
mi for each agent
i  for otherwise  i will never be a part of a cooperative nash
equilibrium by proposition 9  and we can remove i from con-
sideration 
we say a solution  s  δ  is valid if s is a nash equilibrium
under external investment δ  the following theorem shows
that the optimal solution to this minimization problem always
exists  we defer the proof to the full version 
theorem 10  given a pivotal participation game  ⃗e  ⃗m  τ  
let ∆ ⊆  0  ∞  be the set of all valid external investment δ 
we have inf ∆ ∈ ∆ 
firstly  theorem 5 straightforwardly implies that the prob-
lem is np-hard to approximate to any finite multiplicative fac-
tor 
theorem 11  given a pivotal participation game instance
 ⃗e  ⃗m  τ   letting δ∗ ≥ 0 be the minimum valid external in-
vestment  for any f > 0 that may depend on  ⃗e  ⃗m  τ   it is
np-hard to approximate δ∗ to within factor f 
proof  theorem 5 implies that it is np-complete to decide if
δ∗ = 0  this theorem concludes immediately 
fortunately  this minimization problem has an additive
term approximation algorithm  with the additive term be-
ing the maximum endowments among the agents 
e =
maxi 1≤i≤n ei   the algorithm is described in algorithm 1 
the algorithm works as follows  it considers n possible
values l1          ln for e s  δ  for each possibility e s  δ =
li  it iteratively adds an agent k with lk ≤ li < uk to s
until either no more agent can be added  when the for-loop
at line 7 terminates without reaching line 9  or e s  ≤ li
cannot be maintained  when the for-loop at line 7 exits at
line 9   the algorithm finds a solution for e s    δ = li by
setting δ = li − e s  for s found by the above step  finally 
the algorithm compares the n solutions and output the optimal
one  it is straightforward to check that the algorithm runs in
polynomial time 
remark 12  our algorithm has a desirable fairness property 
 richer people contribute first   list and price  2009   in each
of the n solutions the algorithm outputs  line 6 of the algo-
rithm guarantees that agents with larger endowments invest
first  whenever possible  the larger the index i is  the better
the solution  si  δi  preserves this property  in particular  for
i = n   sn  δn  strictly preserves this property  by line 5
and the fact that uk is larger whenever ek is larger   when
implementing algorithm 1  we can compare the n solutions
and trade off between the investment δ and the said fairness
property 
proceedings of the thirtieth    ijcai-21 
107
 algorithm 1 approximation algorithm for pivotal participa-
tion game with external investment
input  a pivotal participation game instance  ⃗e  ⃗m  τ 
output  a set of agent s that invest  the amount of external
investment δ
1  for each i ∈  n   let ui = τ   ei and li = max τ  ei
mi  
2  sort agents such that l1 ≤ l2 ≤ · · · ≤ ln
3  for i = 1          n do
4 
initialize si = ∅
5 
let ki =  k ∈  n    lk ≤ li < uk 
6 
sort agents in ki so that ek1 ≥ ek2 ≥ · · · ≥ ek|ki|
7 
for j = 1          |ki| do
8 
if e si ∪  kj   > li then
9 
break
10 
end if
11 
update si = si ∪  kj 
12 
end for
13 
set δi = li − e si 
14  end for
15  find io = arg mini δi
16  return  sio  δio 
theorem 13  given a pivotal participation game instance
 ⃗e  ⃗m  τ   letting δ∗ ≥ 0 be the minimum valid external in-
vestment and e = maxi 1≤i≤n ei   algorithm 1 finds a solu-
tion  s  δ  with δ ≤ max e  δ∗  
proof  we first show that the solution output by algorithm 1
is valid  we show that the solution  si  δi  found in each
iteration of the for-loop is valid  we have e si    δi = li and
each k ∈ si satisfies lk ≤ li < uk  guaranteed by line 13 and
5 of the algorithm   proposition 9 implies that si is a nash
equilibrium  it remains to prove the approximation guarantee
δ ≤ max e  δ∗  
suppose agents are ordered such that l1 ≤ · · · ≤ ln  let
 s  δ  be the solution output by the algorithm  let  si  δi  be
the solution output at i-th iteration of the for-loop at line 3 
let  s∗  δ∗  be the optimal solution 
firstly  if the inner for-loop at line 7 exits at line 9 for
certain iteration i of the for-loop at line 3  then δ < e  in
which case the approximation guarantee is proved  to see
this  line 8 and 13 ensure that δi = li − e si  < ekj ≤ e 
since the final solution output by the algorithm is no worse
than  si  δi   we have δ ≤ δi < e  from now on  we assume
that the  break  statement at line 9 has never been executed
for all iterations 
next  we consider the optimal solution  s∗  δ∗   let i†
be the agent with the largest index such that e s∗    δ∗ ≥
li†  we show that each j ∈ s∗ satisfies lj ≤ li† < uj 
suppose there exists j ∈ s∗ with lj > li†  we first know
i† < n  by proposition 9  we must have e s∗    δ∗ ≥ lj ≥
li† 1 to make the solution valid  however  this contradicts
to our assumption that i† is the agent with the largest index
satisfying e s∗  δ∗ ≥ li†  suppose there exists j ∈ s∗ with
uj ≤ li†  since we assumed li† ≤ e s∗    δ∗  proposition 9
implies that  s∗  δ∗  should not have been valid 
in addition  our assumption that the  break  statement at
line 9 has never been executed implies that e s∗    δ∗ =
li†  suppose otherwise e s∗    δ∗ > li†  we have δ∗ = 0 
for otherwise we can always decrease the value of δ∗ while
maintaining e s∗    δ∗ ≥ li†  which contradicts to that δ∗
is optimal  as a result  e s∗    δ∗ > li† implies e s∗  >
li†  since we have proved that each j ∈ s∗ satisfies lj ≤
li† < uj  at iteration i† of our algorithm  we must have s∗ ⊆
ki†  therefore  e ki†  ≥ e s∗  > li†  the  break  statement
will be executed before all the |ki†| agents are added to si† 
which contradicts to our assumption 
finally  we have proved that e s∗    δ∗ = li†  and we
also have s∗ ⊆ ki† at iteration i† of our algorithm  since the
 break  statement has not been executed  we have si† = ki† 
and δi† = li† − e si†  ≤ li† − e s∗  = δ∗  therefore  the
solution output at i†-th iteration of our algorithm is already
optimal  and the final output of our algorithm is no worse
than this 
4 2
matching funds
in this section  we consider another intervention—matching
funds  the mechanism can commit to a rate ρ ≥ 0  and in-
crease the investment from e s  to  1   ρ e s   thus  agent
i s utility ui s  becomes
ei1 i /∈ s    mi 1   ρ e s 1   1   ρ e s  ≥ τ   
 7 
assumption 14  we assume that the rate of matching funds
ρ has a budget constraint ρ < ¯ρ where ¯ρ =
1
maxi∈ n  mi − 1 
this assumption ensures  1   ρ mi < 1 for each agent i 
to justify this assumption  the total reward level �
i mi can
be seen as the return on investment of the public project  and
is around 1 in practice  so each agent s reward level is much
less than 1  e g   1/n  the rate of matching fund ρ is often a
small constant  e g   1-to-1  2-to-1  and 3-to-1   this makes
mi 1   ρ  significantly less than 1  secondly  the behavior of
an agent with mi 1 ρ  ≥ 1 is fundamentally and unnaturally
different from an agent in a normal public goods game  from
eqn   7  and some simple calculations  this agent will always
invest as long as the project is successful  even if the project
can succeed without him/her 
similar to proposition 4 and 9 we have the following char-
acterization of cooperative nash equilibrium  the details are
left to the readers 
proposition 15  given a pivotal participation game instance
 ⃗e  ⃗m  τ  with matching funds ρ < ¯ρ  s is a cooperative nash
equilibrium if and only if for all i ∈ s
max
�
τ  ei
mi
�
≤  1   ρ e s  < τ    1   ρ ei 
 8 
we also have a minimization problem here  the objective
of this problem can be either formulated by the rate ρ or the
cost ρ·e s  where s is a cooperative nash equilibrium under
 7   we say a solution  s  ρ  is valid if s is a nash equilib-
rium under the rate of matching funds ρ 
first  we want to compare the power of these two interven-
tions  the following result shows that  for any valid external
investment δ  there is a valid matching funds with some ρ that
has less or equal cost  intuitively  this shows that matching
funds is more powerful than adding external investment 
proceedings of the thirtieth    ijcai-21 
108
 proposition 16  for all  ⃗e  ⃗m  τ   for any valid solution
 s  δ  where the external investment δ is not prohibitively
large δ < ¯ρ · e s   s is also a cooperative nash equilib-
rium with matching funds ρ = δ/e s   moreover  the cost of
matching funds ρ · e s  is exactly δ 
proof  if adding external δ endowment makes cooperation
successful  setting ρ = δ/e s   s is also a successful coop-
eration because of proposition 15 and τ   ei ≤ τ    1   ρ ei
for all i ∈ s  moreover  the cost ρ · e s  is δ when agents in
s cooperate 
the following theorem shows that the solution with opti-
mal rate and the solution with optimal cost always exist  as
long as a cooperation is possible  the proof is deferred to the
full version of this paper 
theorem 17  given a pivotal participation game  ⃗e  ⃗m  τ  
let ∆ ⊆  0  ∞  be the set of all valid rates of matching funds
ρ  suppose ∆ ̸= ∅  we have inf ∆ ∈ ∆  moreover  there
exists a valid solution  s∗  ρ∗  such that ρ∗ ·e s∗  ≤ ρ·e s 
for all possible solutions  s  ρ  
again  theorem 5 straightforwardly implies that the prob-
lem is np-hard to approximate to any finite multiplicative fac-
tor for both objectives  the rate ρ and the cost ρ·e s    there-
fore  a theorem similar to theorem 11 can be concluded  we
defer the theorem statement and proof to the full version 
we show that we can achieve additive approximation to
both objectives by adaption of algorithm 1  under the very
mild assumption ¯ρ ≥ 1  it is straightforward to check that
algorithm 2 runs in polynomial time 
remark 18  the  richer people contribute first  property for
algorithm 1 mentioned in remark 12 also holds for algo-
rithm 2 
theorem 19  given a pivotal participation game  ⃗e  ⃗m  τ 
with ¯ρ ≥ 1 such that a cooperative nash equilibrium exists
under certain ρ ∈  0  ¯ρ   letting  s∗  ρ∗  be a valid solution
with minimum cost ρ∗·e s∗  and e = maxi 1≤i≤n ei   algo-
rithm 2 finds a collaboration  s  ρ  with cost upper-bounded
by ρ · e s  ≤ max e  ρ∗ · e s∗   and rate upper-bounded by
ρ ≤ max 1  ρ∗  
although being more complex  the main ideas of the proof
are the same as the proof of theorem 13  the proof is avail-
able in the full version of this paper 
remark 20  in theorem 19  we set ρ∗ be the optimal so-
lution in terms of the cost ρ∗ · e s∗   if we consider ρ∗ be
the optimal solution in terms of the minimum rate  then al-
gorithm 2 can still obtain guarantee ρ ≤ max 1  ρ∗   with
line 19 modified to  find io = arg mini ρi   the proof of
this is similar to the proof of theorem 19 
however  we note that the optimal solution in terms of the
cost is not always identical to the optimal solution in terms of
the rate  consider example 1  the solution with optimal cost
is  s =  1  2  3   ρ = 2
3  and the solution with optimal rate
is  s =  1  4   ρ =
7
11  
algorithm 2 approximation algorithm for pivotal participa-
tion game with matching funds
input  a pivotal participation game instance  ⃗e  ⃗m  τ 
output  a set of agent s that invest  the rate of matching
funds ρ
1  for each i ∈  n   let li = max τ  ei
mi  
2  compute ¯ρ =
1
maxi∈ n  mi − 1
3  sort agents such that l1 ≤ l2 ≤ · · · ≤ ln
4  for i = 1          n do
5 
initialize si = ∅
6 
let ki =  k   lk ≤ li  //different to algorithm 1 here
7 
sort agents in ki so that ek1 ≥ ek2 ≥ · · · ≥ ek|ki|
8 
for j = 1          |ki| do
9 
if e si ∪  kj   > li then
10 
break
11 
end if
12 
let ρtemp =
li
e si∪ kj   − 1
13 
if li ≥ τ    1   ρtemp ekj then
14 
break
15 
end if
16 
update si = si ∪  kj   ρi = ρtemp
17 
end for
18  end for
19  find io = arg mini ρi · e si  
20  if ρio ≥ ¯ρ then
21 
return no solution exists
22  end if
23  return  sio  ρio 
5
discussion and conclusion
in the paper  we study a variant of public goods games  the
pivotal participation game  and examine when cooperation
can happen in the game  first  we show that it is np-complete
to decide the existence of cooperation  then we consider two
interventions to help agents to cooperate  external investment
and matching fund  we propose two algorithms that can help
agents to cooperate with near minimum cost 
finally  we
show that matching fund can be more powerful than an ex-
ternal investment 
there are several interesting directions for future work 
the first is considering more fine-grained interventions  for
instance  we may change each agent s endowment or re-
ward level by taxes or subsidies  however  these interven-
tions require more information  and the objective is not as
well-defined 
alternatively  we can consider the informa-
tion aspect of the interventions  in the paper  we know the
game s parameter and want to design algorithms with rea-
sonable computational complexity  those parameters may be
unknown and private to agents  and agents may not report
them truthfully  however  we believe the computational issue
is fundamental and will also arise in the unknown parameter
setting  finally  some open problems are related to our ap-
proximation algorithms  e g   hardness results about additive
approximation for the optimal external investment or match-
ing fund  our current construction does not directly extend to
these settings 
proceedings of the thirtieth    ijcai-21 
109
 references
 baker ii et al   2009  ronald j baker ii  james m walker 
and arlington w williams  matching contributions and
the voluntary provision of a pure public good  experimen-
tal evidence  journal of economic behavior   organiza-
tion  70 1-2  122–134  2009 
 battaglini and harstad  2016  marco battaglini and b˚ard
harstad 
participation and duration of environmental
agreements  journal of political economy  124 1  160–
204  2016 
 bolle  2014  friedel bolle  on a class of threshold public
goods games  with applications to voting and the kyoto
protocol  technical report  discussion paper  2014 
 bramoull e et al   2007  yann bramoull e  rachel kranton 
et al 
public goods in networks 
journal of economic
theory  135 1  478–494  2007 
 brito et al   1991  dagobert l brito  eytan sheshinski  and
michael d intriligator  externalities and compulsary vac-
cinations 
journal of public economics  45 1  69–90 
1991 
 cato et al   2020  susumu cato  takashi iida  kenji ishida 
asei ito  kenneth mori mcelwain  and masahiro shoji 
social distancing as a public good under the covid-19 pan-
demic  public health  188 51–53  2020 
 dybvig and spatt  1983  philip h  dybvig and chester s 
spatt 
adoption externalities as public goods 
journal
of public economics  20 2  231 – 247  1983 
 finus  2002  michael finus 
game theory and interna-
tional environmental cooperation  any practical applica-
tion 
controlling global warming  perspectives from
economics  game theory and public choice  pages 9–104 
2002 
 garey and johnson  1979  michael r garey and david s
johnson  computers and intractability  volume 174  free-
man san francisco  1979 
 goldstein and pauly  1976  gerald s goldstein and mark v
pauly  group health insurance as a local public good  in
the role of health insurance in the health services sector 
pages 73–114  nber  1976 
 hirshleifer  1983  jack hirshleifer 
from weakest-link to
best-shot  the voluntary provision of public goods  public
choice  41 3  371–386  1983 
 jackson  2010  matthew o jackson  social and economic
networks  princeton university press  2010 
 karlan and list  2007  dean karlan and john a list  does
price matter in charitable giving  evidence from a large-
scale natural field experiment  american economic re-
view  97 5  1774–1793  2007 
 karlan and list  2020  dean karlan and john a list  how
can bill and melinda gates increase other people s dona-
tions to fund public goods  journal of public economics 
191 104296  2020 
 kaul et al   1999  inge kaul  i grungberg  and marc a
stern  global public goods  global public goods  450 
1999 
 kempe et al   2020  david kempe  sixie yu  and yevgeniy
vorobeychik 
inducing equilibria in networked pub-
lic goods games through network structure modification 
arxiv preprint arxiv 2002 10627  2020 
 list and price  2009  john a list and michael k price  the
role of social connections in charitable fundraising  ev-
idence from a natural field experiment  journal of eco-
nomic behavior   organization  69 2  160–169  2009 
 olson  2009  mancur olson  the logic of collective ac-
tion  public goods and the theory of groups  second
printing with a new preface and appendix  volume 124 
harvard university press  2009 
 palfrey and rosenthal  1984  thomas
r
palfrey
and
howard rosenthal 
participation and the provision of
discrete public goods  a strategic analysis 
journal of
public economics  24 2  171–193  1984 
 rapoport  1988  amnon rapoport  provision of step-level
public goods  effects of inequality in resources  journal
of personality and social psychology  54 3  432  1988 
 van de kragt et al   1983  alphons
jc
van
de
kragt 
john m orbell  and robyn m dawes 
the minimal
contributing set as a solution to public goods problems 
the american political science review  pages 112–122 
1983 
 yu et al   2020  sixie yu  kai zhou  jeffrey brantingham 
and yevgeniy vorobeychik  computing equilibria in bi-
nary networked public goods games  proceedings of the
aaai conference on artificial intelligence  34 02  2310–
2317  apr  2020 
proceedings of the thirtieth    ijcai-21 
110
 "
None,2021,https-www-ijcai-org-proceedings-2021-0016-pdf,Learning in Markets: Greed Leads to Chaos but Following the Price is Right,"Yun Kuen Cheung, Stefanos Leonardos, Georgios Piliouras",None,https://www.ijcai.org/proceedings/2021/0016.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0016-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0016-pdf.pdf,"learning in markets  greed leads to chaos but following the price is right
yun kuen cheung1   stefanos leonardos2   georgios piliouras2
1royal holloway university of london
2singapore university of technology and design
yunkuen cheung@rhul ac uk  stefanos leonardos  georgios @sutd edu sg
abstract
we study learning dynamics in distributed produc-
tion economies such as blockchain mining  peer-to-
peer file sharing and crowdsourcing  these econ-
omies can be modelled as multi-product cournot
competitions or all-pay auctions  tullock contests 
when individual firms have market power  or as
fisher markets with quasi-linear utilities when ev-
ery firm has negligible influence on market out-
comes  in the former case  we provide a formal
proof that gradient ascent  ga  can be li-yorke
chaotic for a step size as small as θ 1/n   where
n is the number of firms  in stark contrast  for the
fisher market case  we derive a proportional re-
sponse  pr  protocol that converges to market equi-
librium  the convergence result of the pr dynam-
ics is obtained in full generality  in the sense that it
holds for fisher markets with any quasi-linear util-
ity functions  conversely  the chaos results for the
ga dynamics are established in the simplest pos-
sible setting of two firms and one good  and hold
for a wide range of price functions with different
demand elasticities  our findings suggest that as
multi-agent interactions grow larger  the ensuing
market  instead of game-theoretic  conditions al-
low us to formally derive natural and stable learn-
ing protocols which converge to effective outcomes
rather than being chaotic 
1
introduction
multi-agent learning in production economies is an important
yet underexplored domain  production economies are classi-
cally modelled as cournot competitions  varian  2010  or im-
perfectly discriminating all-pay auctions  tullock contests 
 dipalantino and vojnovic  2009   in these models  partic-
ipating firms have market power  and they can significantly
influence aggregate outcomes  prices or total exerted effort 
with their decisions  however  the advancement of the inter-
net has prompted a rapid paradigm shift in economic com-
petition  blockchain mining  arnosti and weinberg  2018 
fiat et al   2019   peer-to-peer file sharing  levin et al   2008 
and crowdsourcing  horton and chilton  2010   among oth-
ers  all constitute distributed production economies with large
numbers of small competitors  individuals or firms   in con-
trast to the classic cournot or tullock models  firms in these
economies typically engage in multiple concurrent competi-
tions  moreover  due to their relative small sizes  each firm
has negligible influence on prices and hence becomes price-
taker  as a result  this form of competition more closely re-
sembles the economic model of fisher markets in which firms
take prices as independently given signals  and purchase opti-
mal bundles of goods  or invest on optimal portfolios to pro-
duce goods  given their budget  or capital  constraints 
the question of which adaptive or learning protocols be-
have well in these economies is largely open and actively
researched  in both cournot competition1 and fisher mar-
kets  firms repeatedly observe the aggregate production  and
adjust their production outputs over time to improve their
own profits  however  empirical results regarding cournot
competition suggest that standard adaptive algorithms  e g  
best response  can lead to unstable and irregular adjust-
ments  even in very simple instances  e g   when there are
only two firms and one good   theocharis  1960  puu  1991 
w¨arneryd  2018   in contrast  when firms ignore their mar-
ket power and act as price-takers  the outcomes can be
more stable  a line of recent works  wu and zhang  2007 
zhang  2011  birnbaum et al   2011  cheung et al   2012 
cheung et al   2020  cheung et al   2018  brˆanzei et al   2019 
cheung et al   2019  gao and kroer  2020  showed that nat-
ural adaptive algorithms  including tˆatonnement and propor-
tional response  pr   lead to stable adjustments in different
markets  where they converge to market equilibria 2
1 1
model and contribution
motivated by the above  our aim is to study the behavior of
learning dynamics in production economies from a theoreti-
cal perspective  our research goals are 1  to establish formal
1the mathematical equivalence between cournot competition
with isoelastic demand and imperfectly discriminating all-pay auc-
tions with proportional success functions or simply tullock contests
is documented in  szidarovszky and okuguchi  1997  w¨arneryd 
2018   among others   we elaborate on this relation in section 2 
2another relevant and interesting result suggests that when firms
trade resources using pr  the underlying production economy grows
in the long term under mild conditions  brˆanzei et al   2018  
proceedings of the thirtieth    ijcai-21 
111
 mathematical arguments that explain the irregular behavior of
greedy learning rules  such as gradient ascent and best re-
sponse dynamics  and 2  to seek protocols that behave well
under general conditions 
concerning the first goal  we present the first rigorous
mathematical proof that the constant step-size gradient as-
cent  ga  algorithm can exhibit li-yorke chaos  li and
yorke  1975  in cournot competition  equivalently  in all-
pay auctions or tullock contests  even when the firms are
homogeneous  this provides a formal explanation for the
unpredictable evolution of these systems that is frequently
observed in practice 
to derive this result  we leverage
sharkovsky s theorem which provides a tractable way to ver-
ify the conditions in li-yorke s characterization of chaos
 palaiopanos et al   2017   in the case of ga  our findings
are robust in two aspects  first  chaos emerges for a large
family of price functions induced by different demand elas-
ticities  and second  chaos emerges even when the step-size is
as small as θ  1/n   our results in this direction contribute to
the growing literature that studies various forms of chaos in
game dynamics  sato et al   2002  galla and farmer  2013 
cheung and piliouras  2019  cheung and piliouras  2020 
cheung and tao  2021  chotibut et al   2021  leonardos and
piliouras  2021  
informally  a dynamical system is li-yorke chaotic if
there are uncountably many pairs of trajectories which get ar-
bitrarily close together  but never intersect  and move apart
indefinitely  when two trajectories are very close to each
other  they become essentially indistinguishable due to the
precision limitation inherent with the environment or com-
puter  in other words  we cannot tell which of the two tra-
jectories will be realized in the future — this is exactly what
unpredictable means  a primary reason for the chaos to arise
is that each firm uses its own market power to strategically
influence the price  when all firms make such strategic ma-
nipulations simultaneously  they aggregately drive prices up
and down without proper control 
while the previous technique does not lead to a formal
proof of li-yorke chaos in the case of best response  br 
dynamics  we formalize the  in -stability properties of the lat-
ter via eigenvalue analysis of the non-linear dynamical sys-
tem  here  instability refers to abrupt changes in the long
term behavior of the dynamics in response to small perturba-
tions of the systems  parameters  e g   firms costs  3
since robustness is an essential property in distributed
production economies both from a normative and a descrip-
tive perspective  the above results provide a convincing ar-
gument against the use of game-theoretically motivated pro-
tocols  this brings us to our second goal which is to seek
learning protocols that result in stable outcomes 
our main result in this direction is to propose a market-
motivated proportional response  pr  algorithm and show
that it is stable and robust  from any initial condition  the
3this formalization closely mirrors existing empirical results on
br dynamics  puu  1991  w¨arneryd  2018   hence  we only present
some indicative visualizations  figure 3   and defer the formal state-
ment to the full version  https //arxiv org/abs/2103 08529  
pr update rule converges to the market equilibrium of an
ensuing fisher market that captures production economies 
namely fisher market with quasi-linear utility functions  the
protocol is simple and can be run by each firm independently
using only local and observable  market level  information 
which makes it particularly suitable for these distributed set-
tings  it can be interpreted as a naturally motivated adaptive
algorithm from a firm s perspective  in each round  each firm
appropriates a certain amount of money  and invests it to the
productions of different goods in proportion to the revenues
received from selling them in the previous round 
one necessary assumption to establish this result is that
as economies grow larger  firms have a negligible influence
on aggregate outputs  however  we formally argue that in
the distributed production economy setting  market equilib-
ria are approximate nash equilibria  this finding is in line
with the largeness concept in  cole and tao  2016   who
showed that when markets grow large  they become asymp-
totically efficient even under agents  strategic behaviors  this
implies that the assumption of diminished influence on out-
comes does not significantly affect the equilibrium outcome
of the system  however  it does have important implications
from a technical perspective  in particular  by modeling pro-
duction economies as fisher markets  we can leverage their
eisenberg-gale convex-program formulation  eisenberg and
gale  1959  to draw a direct analogue between our pr algo-
rithm and standard optimization methods like mirror descent 
this allows us to apply tools from optimization theory and
provides a principled approach to derive convergence proofs 
paper outline  in section 2  we present our three models 
cournot competition with multiple-goods  tullock contests
and fisher markets  and discuss their mathematical connec-
tions  section 3 contains our main results  convergence of pr
dynamics and chaos and instabilities of ga and br dynam-
ics  we discuss the techniques we use in sections 4 and 5 
detailed proofs can be found in the full version 
2
models and definitions
in this section  we describe the cournot competition and
fisher market models  in their classical descriptions  quan-
tities of goods produced are used as the driving variables
to define the notions of nash and market equilibria  how-
ever  it will be more convenient to use spendings/investments
on the production of a good as the driving variables here 
since this is the domain of the pr algorithm  in all mod-
els  n
=  1  2  · · ·   n  is the set of firms  agents  and
m =  1  2  · · ·   m  is the set of goods 
multi-good cournot competition  cc  with isoelastic de-
mands  each firm i invests an amount bij ≥ 0 on producing
good j  we write bi  =  bij j∈m and b  =  bi i∈n  each
firm i has only finite amount of capital  ki  to invest  thus it
is subject to a capital constraint �
j bij ≤ ki  we assume
that the marginal cost of producing good j is the same for all
firms  which we denote by αj  thus  the quantity of good
j produced by firm i is bij/αj  each good j has isoelas-
tic demand  i e   the total sales revenue of the good is con-
proceedings of the thirtieth    ijcai-21 
112
 stant  denoted by vj  thus  the price function4 for good j is
pj b 
 =
vj/  �
i bij/αj   and the revenue of firm i re-
ceived from the sales of good j is pj b · bij/αj   = vj ·yij 
where yij denotes the market share of firm i on good j 
yij  = bij/
�
k bkj 
 1 
the profit of firm i is its revenue from the sales of all goods
minus its total investment  �
j vjyij − �
j bij 
tullock contest  tc   the above setting admits a correspon-
dence to multiple tullock contests  according to this inter-
pretation  each firm i invests an amount of bij ≥ 0 on pro-
ducing good j  but now the goods are considered as prizes 
and the probability that firm i wins good j is yij as defined
in eqn   1   this probabilistic interpretation is natural in the
applications of blockchain mining and imperfectly discrimi-
nating all-pay auctions  crowdsourcing   now  different firms
can have different valuations on the prize  so the parameter vj
in cc may be distinct for different firms  we let vij denote the
valuation of firm i on good j  the expected profit of firm i is
ui bi   =
�
j vijyij −
�
j bij 
 2 
while cc and tc have differences in their rationales  they
admit a correspondence in mathematical terms  by replacing
deterministic profit in cc with expected profit in tc  and vj
with vij for different firms i  accordingly  we will henceforth
refer to this model as cc/tc or simply tc 
definition 1  nash equillibrium   for any δ ≥ 0  we say
that b∗ is a δ-nash equilibrium  δ-ne  of a cc/tc if for
each agent i ∈ n  maxbi �
j bij≤ki ui bi  b∗
−i  ≤  1   δ  ·
ui b∗
i   b∗
−i   in other words  agent i cannot improve her util-
ity by more than an δ fraction at b∗ by unilaterally changing
her own investment portfolio  we call a 0-ne simply a ne 
fisher market  fm   in a fisher market  each good j has
a supply which is normalized to one unit  again  bij de-
notes the spending of firm i on good j  and each firm i has
a budget of ki  so the constraint �
j bij ≤ ki applies  let
p =  pj j∈m  where pj denotes the price of good j  at bi 
firm i gets bij/pj units of good j and has a quasi-linear utility
function  ui  bi | p   which takes the form
ui bi | p  = �
j vij ·  bij/pj  − �
j bij 
 3 
where vij denotes firm i s valuation of one unit of good j  at
price vector p  each firm i select an optimal budget alloca-
tion b#
i in arg maxbi ui bi | p  which maximizes its utility
subject to the constraint �
j bij ≤ ki  at an optimal budget
vector b#
i   a vector x#
i
 =  b#
ij/pj j∈m is called a produc-
tion bundle of agent i at price vector p 
definition 2  market equilibrium   a price vector p# =
 p#
j  j∈m is a market equilibrium  me  if there exists an op-
timal budget allocation b# =  b#
i  i∈n at p#  such that for
4we also consider more general price functions induced by dif-
ferent demand elasticities in section 5 
each good j  �
i b#
ij = p#
j   the vector b# is called a market
equilibrium spending 5
2 1
connection between tc and fm
the crucial difference between tc and fm is that in tc 
prices are determined endogenously as a function of b 
whereas in fm  prices are viewed as independent inputs that
do not explicitly depend on b  thus  while both models re-
quire each firm i to make an allocation bi that is subject to
the same budget constraint �
j bij ≤ ki  the methods to de-
termine outcomes differ 
however  if  p  b  are market equilibrium and mar-
ket equilibrium spending respectively of an fm  then
�
i bij/pj = 1 for each good j 
thus  we can translate
bij/pj  which is the quantity of good j that firm i gets at the
market equilibrium  to the probability that firm i wins good
j in the corresponding tc  under this translation  the out-
come in the fm is the same as the outcome in the tc  due to
the well-known properties of fisher markets  this outcome is
pareto-optimal  and it is envy-free if ki is identical for all i 
the above suggest that if there is an algorithm that con-
verges to the market equilibrium spending  our theorem 4
establishes this  of the fm  then it yields a feasible solution
of the corresponding tc  the remaining question is the qual-
ity of this feasible solution  i e   how close it is to a nash
equilibrium of the tc  it turns out that if the underlying
distributed production economy satisfies a natural largeness
property  then the market equilibrium spending is also a δ′-
ne for some small δ′ > 0  in particular  as we show in
proposition 3 below  this is the case if the budget of each
firm is small compared to any market equilibrium price  i e  
if maxi j ki/p#
j   ≤ δ for a small δ > 0  we may view δ
as a parameter that describes the largeness of the economy 
the smaller δ is  the larger the economy is   we also need the
bang-per-buck ratio βi  = maxj vij/p#
j   to be sufficiently
high for all firms i  because otherwise a firm might invest
nothing thus attain zero utility  forcing δ′ to be  ∞  
proposition 3  suppose that b# is a market equilibrium
spending vector of a quasi-linear fm  and p# is the corre-
sponding market equilibrium price vector  for every i ∈ n 
let βi  = maxj vij/p#
j    if maxi j ki/p#
j   ≤ δ  then b#
is also a δ′-ne of the corresponding tc  where
δ′ = max
i βi>1
�� βi
1 − δ − 1
�
/  βi − 1 
�
− 1 
provided that there is no firm i with 1 − δ < βi < 1 
it is easy to see that if mini βi  grows  then δ′ tends to-
ward δ/ 1 − δ  
3
our main results
we present our two main results here  we discuss the method-
ology of proving them in sections 4 and 5 
5the last condition is same as �
i b#
ij/p#
j
= 1  which is the
classical definition of market equilibrium 
proceedings of the thirtieth    ijcai-21 
113
 algorithm 1 pr-qlin learning protocol
input   ki  vi1  vi2          vim  b◦
i   for each firm i
output  market equilibrium spending b# 
1  for t = 0  1  2        do
2 
for every firm i and good j do
3 
yt
ij ← bt
ij/ �
k bt
kj
4 
for every firm i do
5 
st
i ← �
j vijyt
ij
6 
if st
i > ki then
7 
for every good j do
8 
bt 1
ij
←  vijyt
ij/st
i  · ki
9 
else for every good j do
10 
bt 1
ij
← vijyt
ij
// same as  vijyt
ij/st
i  · st
i
3 1
proportional response in quasi-linear fm
in a quasi-linear fisher market  our pr protocol starts with
each firm i ∈ n investing an arbitrary portfolio b◦
i which is
positive  i e   b◦
ij > 0 for all j ∈ m  in each round  firms
update their portfolios simultaneously according to the pr-
qlin protocol in algorithm 1 
the pr-qlin protocol can be naturally interpreted  af-
ter all firms update their investment portfolios in round t  one
unit of each good j is allocated to the firms in proportion to
their investments on the good  thus  firm i gets yt
ij units of
good j  line 3   then each firm i computes its attained utility 
st
i  without subtracting investment cost  line 5   if st
i > ki 
then firm i will appropriate all of its capital  ki  for invest-
ment in round t   1  otherwise it will only appropriate an
amount of st
i for investment  then each firm invests its ap-
propriated capital on each good in proportion to the utility at-
tained from that good in the previous round  i e   firm i invests
a fraction of vijyt
ij/st
i of its appropriated capital on good j 
our main result is stated below 
theorem 4  given any positive starting point b◦  the algo-
rithm pr-qlin converges to the set of market equilibrium
spending vectors of the quasi-linear fisher market 
3 2
gradient ascent  ga  and li-yorke chaos
to establish our chaos results of the ga dynamics in cc
 hence  also in tc   we consider a cc with one good and
n firms 
since there is only one good  we omit the sub-
script j = 1 and use the shorthand α ≡ α1 to denote the
marginal cost of producing the good  recall from section 2
that this is equal for all firms   in this setting  it is more
convenient to use the quantities of the good produced  i e  
the variables xi = bi1/α  as the driving variables  without
loss of generality  let v1 = 1  then the utility of firm i is
ui x  = xi/ �
k xk  − αxi  the gradient ascent  ga  up-
date rule is given by xt 1
i
← xt
i   η · ∇iui  xt   where η is
the step-size 
assuming that the initial point is symmetric  i e   that x◦
i
is identical for all i  then in each round t > 0  the xt
i s remain
identical for all i  thus  a symmetric ga dynamic is essen-
tially one-dimensional  and its trajectory can be represented
by the sequence  xt
1 t≥0 generated by the ga update rule 
xt 1
1
← xt
1   η ·
�
n−1
n2xt
1 − α
�
 
 4 
our main result states that even for such an apparently simple
one-dimensional dynamical system  chaos occurs with step-
size η as small as θ 1/n   here  we refer to li-yorke chaos
which is formally defined below 
definition 5  li-yorke chaos   a discrete time dynamical
system  xt t∈n such that xt  = f t  x◦  for a continuous up-
date rule f   x → x on a compact set x ⊆ r is called
li-yorke chaotic  if  i  for each k ∈ n  there exists a peri-
odic point ˆx ∈ x with period k  and  ii  there is an uncount-
ably infinite set s ⊂ x that is scrambled  i e   if for each
x ̸= x′ ∈ s it holds that lim inft→∞ |f t  x  − f t  x′  | =
0 < lim supt→∞ |f t  x  − f t  x′  | 
theorem 6  li-yorke chaos in n-player cc/tc   consider
a symmetric ga dynamic with n firms and marginal cost α >
0  then for any step-size η ≥ 3 n−1 /n2α2  the essentially-
one-dimensional dynamical system  4  is li-yorke chaotic 
this theorem applies with isoelastic price function  in
section 5  we consider a larger family of price functions and
show that li-yorke chaos also occurs in the corresponding
symmetric ga dynamics  we also present theoretical and
empirical evidences that instability arises when the ga rule
is replaced by the best response rule 
remark  in practice  firms may choose to use a large step-size
in a myopic  greedy approach to profit maximization  given
that chaos occurs with a vanishingly small step-size θ  1/n 
as the number of firms increases  cf  theorem 6   our result
is practically relevant for distributed production economies in
which many small firms are involved  stability results should
be possible for smaller step sizes  however  such step sizes
are not particularly interesting from a practical perspective 
finally  the presence of a centralised planner who may en-
force small step sizes is a rather unnatural assumption for the
settings and applications that we consider 
4
proportional response  pr  dynamics
our proof of theorem 4 consists of two major steps 
in
the first step  we derive a convex program that captures
the market equilibrium  me  spending of the quasi-linear
fisher market via the approach of  birnbaum et al   2011 
cole et al   2017  cheung et al   2018   in the second step 
we show that a general mirror descent  md  algorithm con-
verges to the optimal solution of this convex program  pr-
qlin is an instantiation of this md algorithm 
convex program framework  we first utilize a convex op-
timization framework to derive a convex program that cap-
tures the me spendings of any quasi-linear fm  the ensuing
framework is summarized in figure 1  in short  via duality
and variable transformations  the market equilibria of a fm
can be captured by various convex programs  each with a dif-
ferent domain 6 our starting point is a convex program pro-
6for linear fisher markets  i e  markets in which each agent has a
proceedings of the thirtieth    ijcai-21 
114
  eg 
 d 
 sh 
 td 
duality
qj =ln pj
duality
program
description
variables
 eg 
eisenberg-gale
xij = allocations i ∈ n  j ∈ m
 d 
dual
pj
= prices
j ∈ m
 td 
transformed dual
qj
= ln  pj 
j ∈ m
 sh 
shmyrev-type
bij = spending
i ∈ n  j ∈ m
figure 1  derivation of the pr-qlin protocol via the mirror descent  md  protocol  starting from the convex program  d   which is the
dual of a generalized eisenberg-gale  eg  program  we move to the transformed dual  td  and by convex duality to a shmyrev-type primal
program  sh  which is  hence  equivalent to the initial program  eg   the objective function of  sh  for quasi-linear utilities is 1-bregman
convex which implies convergence of the md protocol 
posed by  cole et al   2017  that captures me prices of quasi-
linear fisher market  which belongs to type  d  in figure 1  
from this  we derive a new convex program with captures the
me spendings of the market  which belongs to type  sh   
see the full version for the details  the convex program is
min
b w p f b  w  p 
s t 
�n
i=1 bij = pj 
∀j ∈ m 
�m
j=1 bij   wi = ki  ∀i ∈ n 
 sh 
bij  wi ≥ 0 
∀i ∈ n  j ∈ m 
where f b  w  p   = − �n
i=1
�m
j=1 bij ln vij   �n
i=1 wi  
�m
j=1 pj ln pj  for brevity  we will write f z   observe that
the first and second constraints determine the values of w  p
in terms of bij s  thus  we can rewrite the convex program
to have variables b only  and the remaining constraints are
bij ≥ 0 and �m
j=1 bij ≤ ki 
4 1
from mirror descent to pr
after having the convex program with variables b only  we
can compute a me spending by the optimization algorithm
of mirror descent  md   to begin  we recap a general result
about md  chen and teboulle  1993  birnbaum et al   2011  
definition 7  kl-divergence and l-bregman convexity   let
c be a compact and convex set and let h be a convex function
on c  then  for any z′ ∈ c  z ∈ rint c  where rint c  is
the relative interior of c  the bregman divergence  dh  z′  z  
generated by h is defined by
dh z′  z   = h z′  −  h z    ⟨∇h z   z′ − z⟩   
the kullback-leibler  kl  divergence between z′ and z is
defined by kl z′∥z   = �
j z′
j·ln
z′
j
zj −�
j z′
j �
j zj  which
is the same as the bregman divergence dh with regularizer
h  z   = �
j zj · ln zj − zj   a function f is l-bregman
convex w r t  the bregman divergence dh if for any z′ ∈ c
and z ∈ rint c   f z    ⟨∇f z   z′ − z⟩ ≤ f z′  ≤ f z   
⟨∇f z   z′ − z⟩   l · dh z′  z  
utility similar to a quasi-linear utility  but without the subtraction of
investment cost   eisenberg and gale  1959  derived a convex pro-
gram which captures the me allocation  where the driving variables
are quantities of goods allocated to the agents  subsequent works
established that by considering suitable duals and transformations
of eisenberg and gale s convex program  new convex programs can
be derived which capture the me prices and me spendings 
algorithm 2 md protocol w r t  kl-divergence
input  a convex set c  a function f defined on c  a param-
eter γ and a point z◦ ∈ c 
output  z∗ = arg minz∈c f z  
1  for t = 0  1  2        do
2 
g  z  zt  ← ⟨∇f zt   z − zt⟩   γ · kl z∥zt 
3 
zt 1 ← arg minz∈c g  z  zt  
for the problem of minimizing a convex function f z 
subject to z ∈ c  the md protocol w r t  the kl divergence
is presented in algorithm 2  in the protocol  1/γ is the step-
size  which may vary with t  and typically diminishes with t  
however  in the current application of distributed dynamics 
a time-varying step-size is undesirable or even impracticable 
since it requires firms to keep track of a global clock 
theorem 8  suppose f is an l-bregman convex function
w r t  the bregman divergence dh  and zt is the point reached
after t applications of the md update rule in algorithm 2 with
parameter γ = l  then f zt  − f z∗  ≤ l · d z∗  z◦ /t 
where z∗ = arg minz∈c f z  
proof sketch  we first prove lemma 9 below 
then we
show that pr-qlin is an instantiation of algorithm 2 with
γ = 1  this is achieved by identifying the variables b in
pr-qlin as the variables z in algorithm 2  and the domain
 b | bij ≥ 0 and �m
j=1 bij ≤ ki  as the convex set c in
algorithm 2  thus  theorem 8 guarantees the updates of
pr-qlin converge to an optimal solution of the convex pro-
gram  sh   and hence theorem 4 follows 
lemma 9  the objective function f z  of  sh  is a 1-
bregman convex function w r t  the kl-divergence 
5
ga and best response dynamics
to establish theorem 6 about the ga dynamics in eqn   4 
for n = 2  the technique is similar for any n > 2   let
f  x   = x η
� 1
4x − α
�
  note that xt 1
1
= f xt
1  by eqn   4  
to prove that li-yorke chaos occurs  we use a seminal theo-
rem of  li and yorke  1975   which states that if f has two
easy-to-verify properties  then the dynamical system is li-
yorke chaotic  the two properties are   i  an invariant set of
f that includes a fixed point x∗  i e   an interval i =  l  u 
such that f  i  ⊆ i with a point l < x∗ < u satisfying
f x∗  = x∗  and  ii  a point x′ ∈ i other than x∗ with pe-
riod 3  i e   f  3   x′  = x′  where f  3   x   =  f ◦ f ◦ f   x  
proceedings of the thirtieth    ijcai-21 
115
 figure 2  li-yorke chaos of the gradient ascent  ga  dynamics with constant step-size in n-firm cournot competition with isoelastic inverse
demand function  equivalently  tullock contest with proportional success function   first panel  chaotic trajectories  light to dark lines  and
their planar projections  blue dots  of the output pairs of two firms  second panel  chaotic aggregate output in a market with n = 104 firms
with randomly selected costs in  10−5  1  and step-size η = 5 · 10−4  third panel  minimum step-size for which chaos provably occurs in a
2-firm cournot competition with inverse demand function  x1   x2 −γ   γ > 0  chaotic behavior is more likely when demand is inelastic 
figure 3  best response dynamics  firms  outputs
�
xt  yt�
 horizontal planes  with respect to time t ∈  10  250   vertical axis  for different
values of the cost asymmetry parameter  r  between the two firms  in line with the theoretical predictions  see full version   the attractors of
the dynamics may change significantly even for small perturbations in the system parameters 
these properties are formally established in the full version a
visualization of theorem 6 is provided in the first two panels
of figure 2  it can be seen that chaos may emerge even for
small step-size and for asymmetric marginal costs 
general price functions  the two conditions that are re-
quired in the theorem of li and yorke can be also verified
numerically  via computer software  in the case of the para-
metric price function x−γ  where x  = �
i xi and γ > 0 is
the inverse of the demand elasticity ε⟨p⟩  see e g    l opez and
vives  2019   the lower bound of the step-size η at which
chaos emerges  in the symmetric case  is decreasing as de-
mand becomes more elastic  cf  third panel of figure 2 
best response dynamics 
we conclude by revisiting the
well-studied best response  br  dynamics and formally es-
tablish that they can be unstable even in the simplest setting
of two firms and one good  the general br update rule is
xt 1
i
← arg maxxi ui xi  xt
−i   for tc with isoelastic de-
mand  the br dynamics take the form xt 1
i
←  xt
−i/αi 1/2−
xt
−i  for i = 1  2  where αi is the marginal cost of firm i 
br dynamics in cournot duopoly with isoelastic functions
have been studied by  puu  1991  and  in the framework of
contests  by  w¨arneryd  2018   both papers suggest that the
stability of the unique fixed point   x∗
1  x∗
2   depends on the
degree of asymmetry between the two firms  captured by the
ratio r  = α1/α2 with instabilities emerging as the asymme-
try increases  while our previous technique does not lead to
a formal proof of li-yorke chaos in br dynamics  we for-
malize the  in -stability properties of the latter via eigenvalue
analysis of the non-linear system  cf  full version  the result
is visualized in figure 3 which shows how the trajectories of
the dynamics may change dramatically in response to even
small perturbations of the model parameters  firms  costs  
6
conclusions
the current work brings together multi-agent learning with
optimization  market theory and chaos theory  our findings
suggest that by considering production economies from a
market rather than a game-theoretic perspective  we can for-
mally derive a natural learning protocol  pr  which is stable
and converges to effective outcomes rather than being chaotic
 ga   due to its simple form and mild informational require-
ments  pr can be used to study real-world multi-agent set-
tings from an ai perspective  since distributed production
economies capture many important applications  blockchain 
peer-to-peer networks  crowdsourcing   our contributions are
significant both for theoretical and practical purposes 
acknowledgements
this research is supported in part by nrf2019-nrf-
anr095 alias grant  grant pie-sgp-ai-2018-01  nrf
2018 fellowship nrf-nrff2018-07  ame programmatic
fund  grant no  a20h6b0151  from the agency for sci-
ence  technology and research  a star  and the national
research foundation  singapore under its ai singapore pro-
gram  aisg award no  aisg2-rp-2020-016  
proceedings of the thirtieth    ijcai-21 
116
 references
 arnosti and weinberg  2018  n  arnosti and s  m  wein-
berg  bitcoin  a natural oligopoly  in avrim blum  edi-
tor  10th itcs  volume 124  pages 5 1–5 1  2018 
 birnbaum et al   2011  b  birnbaum  n  r  devanur  and
l  xiao  distributed algorithms via gradient descent for
fisher markets  in ec 11  pages 127–136  acm  2011 
 brˆanzei et al   2018  s  brˆanzei  r  mehta  and n  nisan 
universal growth in production economies  in neurips
2018  volume 31  pages 1973–1973  2018 
 brˆanzei et al   2019  s  brˆanzei  n  r  devanur  and y  ra-
bani 
proportional dynamics in exchange economies 
corr  abs/1907 05037  2019 
 chen and teboulle  1993  g  chen and m  teboulle  con-
vergence analysis of a proximal-like minimization al-
gorithm using bregman functions 
siam j  optim  
3 3  538–543  1993 
 cheung and piliouras  2019  y  k  cheung and g  piliouras 
vortices instead of equilibria in minmax optimization 
chaos and butterfly effects of online learning in zero-
sum games  in colt  pages 807–834  2019 
 cheung and piliouras  2020  y  k  cheung and g  piliouras 
chaos  extremism and optimism  volume analysis of
learning in games  in neurips  pre-proceedings   2020 
 cheung and tao  2021  y  k  cheung and y  tao  chaos of
learning beyond zero-sum and coordination via game
decompositions  in iclr  2021 
 cheung et al   2012  y  k  cheung  r  cole  and a  ras-
togi  tatonnement in ongoing markets of complementary
goods  in ec 12  pages 337–354  2012 
 cheung et al   2018  y  k  cheung  r  cole  and y  tao 
dynamics of distributed updating in fisher markets  in
ec 18  pages 351–368  2018 
 cheung et al   2019  y 
k 
cheung 
m 
hoefer 
and
p  nakhe  tracing equilibrium in dynamic markets via dis-
tributed adaptation  in aamas  pages 1225–1233  2019 
 cheung et al   2020  y  k  cheung  r  cole  and n  r  de-
vanur  tatonnement beyond gross substitutes  gradient
descent to the rescue 
games and economic behavior 
123 295–326  2020 
 chotibut et al   2021  t  chotibut  f  falniowski  m  misi-
urewicz  and g  piliouras  family of chaotic maps from
game theory  dynamical systems  36 1  48–63  2021 
 cole and tao  2016  r  cole and y  tao 
large market
games with near optimal efficiency 
in ec 16  pages
791–808  new york  ny  usa  2016  acm 
 cole et al   2017  r  cole  n  r  devanur  v  gkatzelis 
k  jain  t  mai  v  v  vazirani  and s  yazdanbod  convex
program duality  fisher markets  and nash social wel-
fare  in ec 17  pages 459–460  2017 
 dipalantino and vojnovic  2009  d 
dipalantino
and
m  vojnovic  crowdsourcing and all-pay auctions  in
ec  09  pages 119–128  2009 
 eisenberg and gale  1959  e  eisenberg and d  gale  con-
sensus of subjective probabilities 
the pari-mutuel
method  ann  math  statist   30 1  165–168  1959 
 fiat et al   2019  a  fiat  a  karlin  e  koutsoupias  and
c  papadimitriou 
energy equilibria in proof-of-work
mining  in ec 19  pages 489–502  2019 
 galla and farmer  2013  t  galla and j  d  farmer  com-
plex dynamics in learning complicated games  pnas 
110 4  1232–1236  2013 
 gao and kroer  2020  yuan gao and christian kroer  first-
order methods for large-scale market equilibrium compu-
tation  in neurips 2020  2020 
 horton and chilton  2010  j  j  horton and l  b  chilton 
the labor economics of paid crowdsourcing  in ec 10 
pages 209–218  2010 
 leonardos and piliouras  2021  s  leonardos and g  pil-
iouras  exploration-exploitation in multi-agent learning 
catastrophe theory meets game theory  in aaai  2021 
 levin et al   2008  d  levin  k  lacurts  n  spring  and
b  bhattacharjee  bittorrent is an auction  analyzing and
improving bittorrent s incentives 
sigcomm comput 
commun  rev   38 4  243–254  2008 
 li and yorke  1975  t -y  li and j  a  yorke  period three
implies chaos 
the american mathematical monthly 
82 10  985–992  1975 
 l opez and vives  2019   a  l  l opez and x  vives  over-
lapping ownership  r d spillovers  and antitrust policy 
journal of political economy  127 5  2394–2437  2019 
 palaiopanos et al   2017  g  palaiopanos  i  panageas  and
g  piliouras  multiplicative weights update with constant
step-size in congestion games  convergence  limit cy-
cles and chaos  in nips 17  pages 5874–5884  2017 
 puu  1991  t  puu  chaos in duopoly pricing  chaos  soli-
tons   fractals  1 6  573–581  1991 
 sato et al   2002  y  sato  e  akiyama  and j  d  farmer 
chaos in learning a simple two-person game  pnas 
99 7  4748–4751  2002 
 szidarovszky and okuguchi  1997  f 
szidarovszky
and
k  okuguchi  on the existence and uniqueness of pure
nash equilibrium in rent-seeking games 
games and
economic behavior  18 1  135–140  1997 
 theocharis  1960  r  d  theocharis  on the stability of the
cournot solution on the oligopoly problem1  the review
of economic studies  27 2  133–134  02 1960 
 varian  2010  h  r  varian  intermediate microeconomics 
a modern approach 
w w  norton   co   new york 
eighth edition  2010 
 w¨arneryd  2018  k  w¨arneryd  chaotic dynamics in con-
tests  economic inquiry  56 3  1486–1491  2018 
 wu and zhang  2007  f  wu and l  zhang 
proportional
response dynamics leads to market equilibrium 
in
stoc  07  pages 354–363  2007 
 zhang  2011  l  zhang  proportional response dynamics in
the fisher market 
theor  comput  sci   412 24  2691–
2698  2011 
proceedings of the thirtieth    ijcai-21 
117
 "
None,2021,https-www-ijcai-org-proceedings-2021-0017-pdf,Identifying Norms from Observation Using MCMC Sampling,"Stephen Cranefield, Ashish Dhiman",None,https://www.ijcai.org/proceedings/2021/0017.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0017-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0017-pdf.pdf,"identifying norms from observation using mcmc sampling
stephen cranefield1∗ and ashish dhiman2
1department of information science  university of otago  dunedin  new zealand
2department of aerospace engineering  indian institute of technology  kharagpur  india
stephen cranefield@otago ac nz  ashish1610dhiman@gmail com
abstract
to promote efficient interactions in dynamic and
multi-agent systems  there is much interest in tech-
niques that allow agents to represent and reason
about social norms that govern agent interactions 
much of this work assumes that norms are pro-
vided to agents  but some work has investigated
how agents can identify the norms present in a so-
ciety through observation and experience  how-
ever  the norm-identification techniques proposed
in the literature often depend on a very specific and
domain-specific representation of norms  or require
that the possible norms can be enumerated in ad-
vance  this paper investigates the problem of iden-
tifying norm candidates from a normative language
expressed as a probabilistic context-free grammar 
using markov chain monte carlo  mcmc  search 
we apply our technique to a simulated robot manip-
ulator task and show that it allows effective identi-
fication of norms from observation 
1
introduction
the presence of social norms is a significant factor in the be-
haviour exhibited in human societies  while norms govern
the behaviour of individuals  they have the emergent effect
of making the society as a whole more predictable and effec-
tive  in multi-agent systems  mas   software agents are often
modelled with traits borrowed from humans  and norms are
no exception  normative agents  andrighetto et al   2013  
like people  have autonomy  but are equipped with compu-
tational means to reason about norms and weigh up the nor-
mative consequences of different courses of action  e g  the
risk of being sanctioned   when norms are known to be fol-
lowed to a sufficient degree in the mas  they can also help
predict the behaviour of other agents  thus  when norms and
norm-aware agents are present  a multi-agent system can be
expected to operate more efficiently 
this leads to the question of how agents come to know
the norms that govern them  early work on agent societies
mostly assumed that codification of norms would be done
by humans  as a step in the design of a society of software
∗contact author
agents  dellarocas and klein  2000   the problem of norm
identification considers open multi-agent systems in which no
central authority imposes or proposes norms  and considers
how agents can identify norms that are already prevalent in
a society or group  or are exhibited by a role model  through
their own experience and/or observations of others  as agents
learn norms from each other  norms can spread and evolve in
the society  savarimuthu and cranefield  2011  
a variety of techniques have been applied to this prob-
lem  including association rule-mining  savarimuthu et al  
2010  savarimuthu et al   2013   plan recognition  oren
and meneguzzi  2013   bayesian learning  cranefield et al  
2016   dempster-shafer theory  sarathy et al   2017  and
inductive logic programming  tan et al   2019   scenarios
adressed in these studies include socially disapproved be-
haviour such as littering and failure to tip in a restaurant  nor-
mative constraints governing movement on a transport net-
work  appropriate actions in a library vs  a boardroom  and a
social robotics application 
much of this work proposes mechanisms that are specific
to a particular representation of norms and the sources of in-
formation available in the targeted application domain  how-
ever  bayesian and dempster-shafer learning offer promise
as generic approaches that can be adapted to different appli-
cation domains  do not a priori limit the expressiveness of
norms  and do not impose restrictions such as reinforcement
learning s usual markov assumption 
norm identification differs from the problem of norm syn-
thesis  campos et al   2010  morales et al   2013  morales et
al   2015   which considers the automated adaptation or de-
sign of norms for a multi-agent system  in order to suppress
undesired states  the approach aims to provide trusted ad-
visor agents or a central authority to monitor the mas  de-
tect when norms should be changed  generate improved ones 
and broadcast these to the agents  it thus makes strong as-
sumptions about the mas structure  which are not realistic in
open agent societies with a peer-to-peer architecture  norm
identification is also distinct from the use of multi-agent re-
inforcement learning to learn coordinated strategies for so-
cial dilemmas  sen and airiau  2007  wang et al   2019 
zhang et al   2019  chaudhuri et al   2019   as it aims
to identify symbolic representations for norms and is per-
formed prior to any attempt to validate the norms through the
learner s own behaviour 
proceedings of the thirtieth    ijcai-21 
118
 a limitation of prior work on bayesian norm identifica-
tion is that it requires a finite set of candidate norms to be
determined in advance  cranefield et al   2016   this limits
the expressiveness of the norm language  as recursively de-
fined terms may not appear unless a finite depth is imposed 
in this paper  we remove this restriction by adapting a tech-
nique used in program synthesis  i e  the generation of com-
puter programs that satisfy a given specification  gulwani et
al   2017   to norm identification  in particular  our work is
based on the bayesian program synthesis method of saad et
al   2019   which was developed to synthesize probabilistic
programs that model observed data sets  the method mod-
ifies markov chain monte carlo search  widely used with
numeric data  to produce a posterior probability distribution
over a language generated by a probabilistic grammar 
this paper makes the following contributions  first  we
recast the method of saad et al  as an application of the well-
known metropolis-hastings mcmc algorithm  we then pro-
pose a modification of the algorithm to ensure that norms
that are relevant to an observed task are favoured over irrel-
evant ones  as convergence was not addressed in the prior
work  we propose the use of a vector representation of trees
to allow the standard ˆr convergence statistic to be applied
to mcmc search over symbolic expressions  we then eval-
uate the approach through norm identification experiments in
a simulated robot task  and find that it correctly identifies the
real norm underlying the simulated behaviour  therefore  we
overcome the prior limitation of bayesian norm identifica-
tion by providing a generic method that can learn norms from
a countably infinite language  our code and supplementary
material can be found online 1
2
mcmc sampling
markov chain monte carlo  mcmc  methods use a ran-
dom search process to sample from a probability distribution 
they are commonly used in bayesian inference to generate
the posterior distribution of a model parameter θ given an ob-
served set obs of instances of model variables  i e  p θ|obs  
algorithm 1 shows the metropolis-hastings algorithm  gel-
man et al   2013  that is used in this work  this creates a
 chain  of samples  θi   1 ≤ i ≤ n  such that the distribu-
tion of sample values converges to p θ|obs   an initial value
θ0 is sampled from a selected starting distribution p0 θ   such
that p θ0|obs  > 0  line 3   the chain is then generated by an
iterative process  in each iteration i  a proposed new value θ∗
is sampled from a jumping distribution j θ∗|θi−1   line 5  
an acceptance rate r is then calculated  line 6  in terms of the
prior p θ   likelihood p obs|θ  and the jumping distribution 
the proposal θ∗ is chosen to be the next element of the chain
with probability min r  1   otherwise θi = θi−1  line 7  
in practice  after the chain is generated  an initial  warm-
up  segment is discarded to reduce the influence of the start-
ing value on the generated sample 
the efficiency of the
mcmc search is greatly affected by the choice of the starting
and jumping distributions 
1https //git io/jsvuf
algorithm 1 the metropolis-hastings algorithm
1  procedure metropolis-hastings obs  n 
2  obs  observed data  n  num  samples desired
3 
sample θ0 ∼ p0 θ  such that p θ0|obs  > 0
4 
for i = 1  · · ·   n do
5 
sample θ∗ ∼ j θ∗|θi−1 
6 
r =
p θ∗|obs /j θ∗|θi−1 
p θi−1|obs /j θi−1|θ∗ 
7 
θi =
�
θ∗
with probability min r  1 
θi−1
otherwise
8 
end for
9 
return ⟨θ1       θn⟩
10  end procedure
3
mcmc over a probabilistic grammar
mcmc search is usually applied to a numeric domain  in
contrast  saad et al   2019  used mcmc search to sample
from a space of symbolic expressions  programs that are gen-
erated by a grammar  given a set of data that the programs
should generate  they defined a new type of probabilistic
context-free grammar  pcfg   tagged probabilistic context-
free grammars with random symbols  in these grammars 
each production rule must generate an s-expression begin-
ning with a  phrase tag  unique to that production  there is
a designated start symbol selected from the grammar s non-
terminal symbols  a probability distribution is defined over
the production rules for each non-terminal symbol  and for
 non-recursive  rules  those with no non-terminal symbols
following the phrase tag   an s-expression is produced con-
taining the tag followed by a terminal symbol sampled from
an associated probability distribution 
figure
1
shows
the
grammar
used
in
our
norm-
identification experiment described in section 5  we annotate
the    =  and  |  symbols with the probabilities of the associ-
ated productions  these annotations are suppressed where the
probability is 1  the meanings of the expressions generated
by this grammar are discussed later 
saad et al  define an mcmc search over expressions 
which  although not presented that way  is a metropolis-
hastings algorithm with the following choices  the gram-
mar s probabilities on production rules and non-terminal
symbol values define a prior distribution over expressions 
this is used as the mcmc starting distribution  i e  a chain s
start value is generated from the start symbol using weighted
random choice to select production rules and terminal sym-
bols  ensuring that the posterior probability of this value is
non-zero  line 3  reduces to checking that the likelihood is
non-zero  as the prior has already been used to generate the
initial value and is therefore non-zero 
the jumping distribution is defined as follows 
• a node n in the current expression θ is chosen by uni-
form random selection  with probability 1/|θ| where |θ|
is the size of θ 
• the non-terminal symbol that was used to generate the
selected node is determined 
• a new sub-expression is randomly generated in a similar
proceedings of the thirtieth    ijcai-21 
119
 norms
0 5
  =  no-norm t 
0 25
|
 norm norm1 
0 25
|
 norms norm1 norm2 
norm1
0 5
  =  obl cond zone 
0 5
|
 pro act col shape zone 
norm2   =  per act col shape perzone 
cond
0 ˙3
  =  moved col shape zone cond 
0 ˙6
|
 next-move col shape 
perzone   =  per-zone pz 
zone   =  zone z 
act   =  action a 
col   =  colour c 
shape   =  shape s 
where
p t = true  = 1
p c ∈  r  g  b   = 1
6
p c = any  = 1
2
p s ∈  triangle  square  circle   = 1
6
p s = any  = 1
2
p a = putdown  = 1
p z ∈  1  2  3   = 1
3
p pz ∈  1  2  3   = 1
6
p pz = any  = 1
2
figure 1  a pcfg grammar for a language of norms
way to the initial expression  but starting with the non-
terminal identified in the previous step 
• θ is modified to create θ∗ by replacing the subtree at n
with the new sub-expression 
having chosen the jumping distribution  it is necessary to
find a computationally efficient formula for the acceptance
rate r  saad et al   2019  propose a computational formula for
r  and prove its correctness  in the supplementary material 
we show how this formula can be derived from line 6 in the
metropolis-hastings algorithm  algorithm 1  
as we are applying mcmc-based norm identification to
a scenario in which the performance of a specific task is be-
ing observed  see section 5   we are specifically interested in
norm expressions θ that are relevant to the task  i e  those for
which p obs|θ  > p obs|no-norm   where no-norm is the
assumption that there is no norm  expressions that do not sat-
isfy this condition carry no explanatory power  formally  we
are interested in the posterior with an extra task condition t 
i e  p θ|obs  t  
we take the observed task executions as proxies for
knowedge of the task  and define an irrelevance relation 
irrel θ  obs  ≡ p obs|θ  ≤ p obs|no-norm 
we modify the saad et al  definition of r as follows for a
selected α  0 < α < 1  where 1 is the indicator function that
maps a proposition to 0 or 1  we have added the two powers
of α  essentially  this down-scales the prior probabilities for
irrelevant expressions 
r = |θi−1| α1 irrel θ∗ obs   p obs|θ∗ 
|θ∗| α1 irrel θi−1 obs   p obs|θi−1 
 1 
it remains to define the likelihood p obs|θ  of the observed
data given an expression generated by the grammar  this is
domain dependent  in our case of identifying norms  it is the
likelihood of a sequence of observed agent actions given a
norm expression  we discuss this in the context of our exam-
ple norm-identification scenario in section 5 
4
convergence testing
when using mcmc search  it is good practice to produce
multiple chains  which can be examined visually in a trace
plot  lee and wagenmakers  2014  or statistically  gelman
et al   2013  for evidence that the chains have converged to
the same  stationary  distribution  techniques for doing this
with numerical data are well established 
however  saad
et al   2019  do not address convergence testing for their
mcmc search through expressions in a language generated
by a grammar  the gelman-rubin convergence diagnostic
 gelman et al   2013  involves generating a number of in-
dependent chains from separate runs of an mcmc sampling
algorithm  starting from  overdispersed  starting values  the
first half of each chain is discarded to reduce the influence
of the starting values  each chain is then split into two  a
comparison of the between-chain and within-chain variances
results in a statistic ˆr that should decrease to 1 as the chain
size increases to infinity  thus  ˆr is computed for increas-
ingly long initial subsequences of the chains  if the value is
high  then there is reason to believe that further increasing the
chain length is worthwhile  gelman et al   2013  
as this diagnostic test is based on the variances of sample
sets  it is necessary to have a distance metric defined over the
sample space  symbolic expressions in our case   we adopt
the inner product on trees that underlies the tree kernel of
collins and duffy  2002   this is based on a vector represen-
tation h t  = ⟨h1 t   h2 t   · · · hn t ⟩ where the indices
of the vector h are all the tree fragments appearing in t  and
each element hi t  is the number of times the tree fragment
i appears in t  we then define the distance between two trees
as dist t1  t2  =
�
h t1 − t2  · h t1 − t2   in practice 
we represent the tree vector for t as a python counter ob-
ject initialised with a list of all subtrees of t  and only use
complete  non-truncated  subtrees as our tree fragments 
we also use this vector representation of expressions to
generate overdispersed starting expressions for the chains  10
times the required number of starting expressions are ran-
domly generated  and the distances between each expres-
sion s vector and the mean vector are calculated  the can-
didate starts are then sorted by descending order of distance 
and the top ten are chosen as the start elements of the chains 
proceedings of the thirtieth    ijcai-21 
120
 figure 2  an example task to clear a region of the workspace  best
viewed in colour 
 norms
 obl  moved  colour  any    shape  circle    zone  2  
 moved  colour  g    shape  square    zone  2  
 next-move  colour  b    shape  triangle     
 zone  3   
 per action  putdown  
 colour  g    shape  triangle    per-zone  1    
figure 3  an expression generated from the grammar in figure 1
5
example domain
in this section we describe the simulated scenario used to
evaluate our norm identification approach  loosely based on
the scenario of tan et al   2019   we consider a robot arm
given a task to clear a user-specified region of a workspace
 which may be shared with a human   figure 2 shows an
example state of the workspace and task 
the workspace
is divided into three zones  indicated by colours in the fig-
ure   numbered 1 to 3 from left to right 
the workspace
contains blocks with varying shapes  square  circular or tri-
angular prisms  and colours  red  blue and green   to per-
form an instance of the task  for each block b in the region 
the robot must perform the action pickup b  followed by
putdown b  r  for some zone r  the order in which blocks
are moved is not specified by the task  and nor are the new
locations of the moved blocks  however  these may be con-
strained by a norm 
an agent observing one or more robots attempts to iden-
tify the norm  if any  governing the task performance  under
the assumption that the norm is generated by the grammar
in figure 1  there is a true norm that the robots are aware
of  and that they  mostly  comply with  the proportion of
non-normative task executions is an experimental parameter 
which we assume the observer knows  or has estimated accu-
rately  
each task execution is a sequence of pickup-putdown ac-
tion pairs  one pair for each block to be moved  the ob-
server applies the metropolis-hastings algorithm given the
observed task executions to produce a sample of expressions 
the frequency distribution of expressions in this sample ap-
proximates the posterior distribution over the norm language 
provided that the mcmc chains have converged to a station-
ary distribution  see section 4   it then extracts the norm ex-
pression with the highest posterior probability  or can use the
posterior sample for posterior predictive inference 
5 1
the grammar for norms
the grammar in figure 1 generates expressions that contain
one or two norms  or an expression meaning that there is no
norm  in the one-norm case  expressions may contain an obli-
gation or a prohibition  and the two-norm case allows one of
these to be combined with a permission  we use the strong
notion of permission  royakkers  1997   where permissions
represent exceptions to obligations or prohibitions 
figure 3 shows an example expression containing an obli-
gation and a permission  the obligation contains a nested
sequence of three conditions 
the permission states that it is permitted to put green tri-
angles down in zone 1  in this case  the permission is super-
fluous  as the obligation does not apply to green triangles 
there is no restriction for the permission to override  and thus
it is logically equivalent to a single-norm expression contain-
ing only the obligation  this non-redundant version of the
expression has a higher prior probability than the redundant
version  because the latter requires applying more production
rules  each with their own probabilities to be factored into the
prior  given that the likelihood of any observed task execu-
tion will be the same given either expression as the true norm 
the posterior probability of the non-redundant version will be
higher  and it should be preferred by any bayesian norm iden-
tification mechanism 
if the grammar had generated a prohibition for the
first norm 
rather than an obligation 
it would have
the form
 pro  action a   colour c   shape s   zone
pz    this states  unconditionally2  that it is prohibited to
apply action a to a block of colour c  shape s  and zone pz
 for  prohibition zone    the bottom of figure 1 shows the
possible values for the variables a  c  s and pz  with their
probabilities  the specified colour  shape and  within per-
missions  zone values may be given as any  meaning there is
no constraint  note that norms only need to govern put-down
actions  as each block is necessarily picked up immediately
before its put-down action 
the probabilites in the grammar express prior beliefs that
 a  the absence of a norm should be given a higher prior than
any other potential norm  the first production rule has prob-
ability 0 5    b  shorter obligation conditions are more prob-
able than longer ones  note the probabilities for the rules for
the cond non-terminal symbol   and  c  generic norms are
preferred over specific ones  the any non-terminal symbol
has a higher probability than other colour  shape and zone
symbols  
5 2
observation likelihood
we first define the likelihood under the assumption that the
observation was norm-compliant  p obs|θ  comp  
given
an estimated proportion pnn of non-normative executions
 where an agent chooses not to be constrained by norms  
the likelihood without the assumption of compliance is then
p obs|θ  = pnn p obs|no-norm   1−pnn  p obs|θ  comp 
 cranefield et al   2016  
2to allow experimentation with both simple and more complex
norms  we chose to only include conditions in obligations 
proceedings of the thirtieth    ijcai-21 
121
 the calculation of p obs|θ  comp  is necessarily domain-
and grammar-specific  for our scenario  this is done as fol-
lows  when a set of observed task executions and a candidate
norm expression are passed to the likelihood function  for
each execution  each block b is considered in execution order 
the set of compliant zones for b to be put down in is com-
puted  in the no-norm case  there are three zones in which the
block can be put down  but if the norm expression contains
a prohibition or obligation  this may restrict the options  a
permission can override this restriction and increase the op-
tions  in the case of an obligation for which b s colour and
shape match those specified in the obligation s next-move
condition  it is always compliant to put the block down in
the zone specified by the obligation  however  placing it in
the other two zones is not compliant if the obligation s se-
quence of moved expressions matches the task execution his-
tory  these considerations result in a set cm of compliant
moves  the likelihood for the observed move of b is then 0
if its destination zone is not in cm  otherwise the likelihood
is
1
|cm|  finally the likelihoods for all the moves in the exe-
cution are multiplied to give the execution likelihood  and the
execution likelihoods are multiplied to give the likelihood of
the observed data  in practice  we work in log space 
6
experiments
we first evaluated our method using the norm identifica-
tion scenario and evaluation framework of cranefield et
al   2016 3  to compare the performance of our method with
their application of bayes  rule to maintain the odds of a fi-
nite set of norm hypotheses compared to the hypothesis that
there is no norm  their scenario involved norm-constrained
travel tasks  specifying start and end nodes  on a directed
graph  they considered six types of norm that constrain the
sequence of nodes traversed  instantiating these given the
graph used in their experiments  actually a tree  resulted in
1932 norms  and seven of them are chosen to be the real
norms known by the travelling agent but not the observer  ex-
perimental settings include a probability of non-compliance
 which we  more precisely  refer to as non-normative be-
haviour in the previous section   and  high  probabilities of
norm-violating behaviour being observed  and being sanc-
tioned 
using a behavioural measure of precision and recall  sim-
ilar to that described below  but more complex due to the
presence of multiple norms   they reported the following pre-
cision p and recall r for their bayesian norm inference
method  with standard deviation over 50 runs given in brack-
ets   p = 64 76  12 24   r = 95 54  7 16  for pnn = 0 01 
and p = 67 36  10 12   r = 85 14  9 54  for pnn = 0 3 
these were vastly better than the results for two techniques
they evaluated that use data mining  savarimuthu et al   2010 
savarimuthu et al   2013  and plan recognition  cranefield
et al   2016   our method achieved slight better precision
and worse recall for pnn = 0 01  p
= 67 83  15 42  
r = 89 92  10 34   for pnn = 0 3  our approach was around
7  worse on precision and 5  worse on recall  compared
3their
code
is
available
at
https //github com/mir-pucrs/
norm-detect
to their bayesian approach  but still far better than the other
techniques 
we next applied our method to the five-block robot region-
clearing task shown in figure 2 and the norm grammar in
figure 1  the bayesian approach described above cannot be
used with a complex and recursive norm language such as this
without restricting norms to a finite subset of the language 
the mcmc search technique has no such constraint  we
evaluated its performance in identifying an unknown  true
norm  that governs an observed agent s repeated execution
of the task  we chose a single true norm expression 
  norms     obl     moved     colour    r   
  shape    any      zone    1      next-move  
  colour    any      shape    any        zone  
 2       per     action    putdown      colour  
 any      shape    square      perzone    3     
this is the combination of  a  an obligation to place a
block in zone 2 if the move follows the placement of a red
block in zone 1  and  b  the permission to put square blocks
in zone 3  note that the permission partially overrides the obli-
gation  
we considered values of pnn between 0 and 0 55  in incre-
ments of 0 05  for each pnn  we ran three trials of the follow-
ing experiment  we generated a sequence of  observed  ran-
dom task executions that were intentionally compliant with
the norm with probability 1 − pnn  these executions var-
ied in terms of the order of blocks moved and the zones to
which the blocks were moved  our metropolis-hastings al-
gorithm  with the modified acceptance from equation 1  and
α = 0 1  was run to generate ten chains of length 4800  af-
ter discarding the first half of each chain  and splitting the
remaining chain into two  the chain convergence metric ˆr
was iteratively calculated over subsequences of the resulting
20 chain segments that doubled in length until the end of the
segments  the segments were then combined to form a sam-
ple of the posterior distribution over expressions  observa-
tion likelihoods  for each of the expressions featuring in the
chain  were calculated as part of the algorithm  and these were
combined with the expression s prior probabilities  from the
grammar  to calculate the  log  posterior probabilities  these
were stored along with the expressions in the posterior sam-
ple  thus  our approach allows selecting candidate norms
either through their frequency in the posterior sample or by
using their posterior probabilities 
figure 4 shows the log posterior of expressions in the pos-
terior sample  and their rank by frequency  for all trials  plot-
ted against pnn  the subplots use shapes to distinguish differ-
ent trials  in the top plot  pink shapes show the maximum log
posterior within the posterior sample for that trial  and green
ones show the log posterior of the true norm  green above
pink for the same shape indicates that the true norm was not
within the posterior sample  pink above green occurs in some
cases where pnn ≥ 0 25  this indicates that an expression
in the sample has a posterior higher than the true norm  and
therefore is a better explanation of the observed behaviour
due to the high rates of non-normative behaviour  in all such
cases  this expression was the  no-norm  expression 
proceedings of the thirtieth    ijcai-21 
122
 figure 4  expression log posteriors and ranks by frequency within
the posterior sample
pnn
precision
recall
pnn
precision
recall
0 00
0 920
0 974
0 30
0 898
0 974
0 05
0 896
0 974
0 35
0 773
0 878
0 10
0 977
0 977
0 40
0 894
0 909
0 15
0 919
0 941
0 45
0 815
0 938
0 20
0 976
0 977
0 50
0 881
0 924
0 25
0 839
0 939
0 55
0 816
0 938
table 1  precision and recall for the most frequent norm in the pos-
terior  averaged over three trials
the lower plot shows the rank in the posterior sample of the
true norm and the highest ranked equivalent norm  if present  
for higher values of pnn  some trials found neither the true
norm nor an equivalent one  the variation in rank across tri-
als increases with pnn  showing that selecting a norm by log
posterior rather than by rank in the sample  is a better ap-
proach in these cases 
we now consider the precision and recall of the identified
norm  when selected by frequency rank  we do not use a stan-
dard definition of these concepts based on a simple identity
test between true and identified expressions  this is because 
given a particular task  two or more norm expressions may
be equivalent in terms of the constraints they apply to execu-
tions of the task  for example  consider a prohibition against
putting down green squares in zone 1  for the task in fig-
ure 2  the logically more general prohibition against putting
down any green block in zone 1 is  in fact  equivalent to the
former expression  because the only green block to be moved
is square  therefore  we use behavioural interpretations of
precision and recall  cranefield et al   2016   these measure
how well an agent governed by the candidate norm can gen-
erate task executions that are compliant with the true norm
expression  we generated two sets of 100 000 random norm-
compliant task executions  for the true norm and the candi-
date norm expression  we treated the former set as it were the
complete set of true-norm-compliant executions when count-
ing  true  and  false  positives in the latter set  note that as
we did not generate all possible true-norm-compliant task ex-
ecutions  the results give approximations to the behavioural
precision and recall 
table 1 shows precision and recall for different values of
pnn  assuming that the most frequent norm in the posterior
sample is used to govern the observer s own behaviour  even
though the most frequent norm may not be the true norm 
or even an equivalent  high precision and recall are seen in
almost all cases 
finally  we consider the convergence of the chains in each
experiment  we find that  on average across the trials and
values of pnn  the ˆr statistic increased from 1 05 to 1 24
 rather than decreasing towards 1  as the initial segments of
the chains evaluated increased in length from 50 to 1200 
there were no notable differences across the cases  this indi-
cates a lack of convergence  and points to a possible need for
longer chains  however  if the aim of the observer is solely
to adopt the expression with the highest log posterior prob-
ability as the norm  rather than create an accurate posterior
sample to use for posterior predictive inference  then the use
of multiple mcmc chains is a successful search mechanism 
7
conclusion
this paper presents an adaptation of the prior work of saad et
al   2019  to the problem of norm identification from obser-
vations  we have presented their method as an application of
the metropolis-hastings algorithm  and modified it to favour
norms that are relevant to the task being observed  we also
highlighted the importance of analysing the convergence of
the mcmc chains generated  not considered  to our knowl-
edge  in prior research on mcmc search over symbolic ex-
pressions   we propose the use of a vector representation of
trees  based on the tree kernel of collins and duffy  2002   to
define a metric over expressions and allow the ˆr convergence
statistic to be applied in our work  unlike previous work on
bayesian methods in norm identification  our approach does
not require selecting a pre-determined finite set of candidate
norms  the recursive norm language may be defined to al-
low arbitrarily complex norms  as illustrated by the obligation
norms used in this work 
our experiments showed that for our experimental sce-
nario  when the probability of non-normative behaviour does
not exceed 0 25  mcmc search allowed the true norm expres-
sion  or an equivalent one  to be identified as the expression
with the highest log posterior probability  norm identifica-
tion based on the most frequent expression in the posterior
sample can also be a successful means of generating compli-
ant behaviour  based on our precision and recall results  even
if the identified norm is not the true one 
futher research is needed on improving the efficiency of
mcmc search for norms  and determining an ˆr threshold for
 good enough  convergence  it would also be useful to inves-
tigate other forms of probabilistic grammar that are more apt
for encoding norms  and to adapt the approach used in this
paper for incremental learning 
proceedings of the thirtieth    ijcai-21 
123
 references
 andrighetto et al   2013  giulia andrighetto  guido gov-
ernatori  pablo noriega  and leendert w  n  van der
torre  editors  normative multi-agent systems  volume 4
of dagstuhl follow-ups 
schloss dagstuhl - leibniz-
zentrum f¨ur informatik  2013 
 campos et al   2010  jordi campos  maite l opez-s anchez 
and marc esteva  a case-based reasoning approach for
norm adaptation  in international conf  on hybrid artifi-
cial intelligence systems  pages 168–176  springer  2010 
 chaudhuri et al   2019  ritwik chaudhuri  kushal mukher-
jee  ramasuri narayanam  rohith dwarakanath vallam 
ayush kumar  antriksh mathur  shweta garg  sudhanshu
singh  and gyana r  parija  collaborative reinforcement
learning model for sustainability of cooperation in sequen-
tial social dilemmas  in proceedings of the 18th interna-
tional conference on autonomous agents and multiagent
systems  pages 1877–1879  ifaamas  2019 
 collins and duffy  2002  michael collins and nigel duffy 
convolution kernels for natural language 
in advances
in neural information processing systems 14  pages 625–
632  mit press  2002 
 cranefield et al   2016  stephen
cranefield 
felipe
meneguzzi  nir oren  and bastin tony roy savarimuthu 
a bayesian approach to norm identification 
in 22nd
european conference on artificial intelligence  pages
622–629  ios press  2016 
 dellarocas and klein  2000  chrysanthos dellarocas and
mark klein 
civil agent societies  tools for inventing
open agent-mediated electronic marketplaces 
in agent
mediated electronic commerce ii  pages 24–39  springer 
2000 
 gelman et al   2013  andrew gelman 
john b  carlin 
hal s  stern  david b  dunson  aki vehtari  and donald b 
rubin  bayesian data analysis  chapman   hall/crc
texts in statistical science  taylor   francis  third edi-
tion  2013 
 gulwani et al   2017  sumit gulwani  oleksandr polozov 
and rishabh singh  program synthesis  foundations and
trends in programming languages  4 1-2  1–119  2017 
 lee and wagenmakers  2014  michael d  lee and eric-jan
wagenmakers  bayesian cognitive modeling  a practical
course  cambridge university press  2014 
 morales et al   2013  javier
morales 
maite
l opez-
s anchez 
juan
a 
rodr ıguez-aguilar 
michael
j 
wooldridge  and wamberto weber vasconcelos 
auto-
mated synthesis of normative systems 
in international
conference on autonomous agents and multi-agent
systems  pages 483–490  ifaamas  2013 
 morales et al   2015  javier
morales 
maite
l opez-
s anchez  juan antonio rodr ıguez-aguilar  wamberto we-
ber vasconcelos  and michael j  wooldridge 
online
automated synthesis of compact normative systems  acm
transactions on autonomous and adaptive systems 
10 1  2 1–2 33  2015 
 oren and meneguzzi  2013  nir
oren
and
felipe
meneguzzi 
norm identification through plan recog-
nition 
15th international workshop on coordination 
organizations  institutions  and norms in agent systems 
arxiv 2010 02627  2013 
 royakkers  1997  lamber m  m  royakkers  giving per-
mission implies giving choice  in proceedings of the 8th
international conference on database and expert systems
applications  pages 198–203  ieee  1997 
 saad et al   2019  feras a  saad  marco f  cusumano-
towner 
ulrich schaechtle 
martin c  rinard 
and
vikash k  mansinghka  bayesian synthesis of probabilis-
tic programs for automatic data modeling  proceedings
of the acm on programming languages  3  37 1–37 32 
2019 
 sarathy et al   2017  vasanth sarathy  matthias scheutz 
and bertram f  malle  learning behavioral norms in un-
certain and changing contexts  in proceedings of the 8th
ieee international conference on cognitive infocommu-
nications  coginfocom   pages 301–306  2017 
 savarimuthu and cranefield  2011  bastin
tony
roy
savarimuthu and stephen cranefield 
norm creation 
spreading and emergence  a survey of simulation models
of norms in multi-agent systems 
multiagent and grid
systems  7 1  21–54  2011 
 savarimuthu et al   2010  bastin tony roy savarimuthu 
stephen cranefield  maryam purvis  and martin k  purvis 
obligation norm identification in agent societies  journal
of artificial societies and social simulation  13 4   2010 
 savarimuthu et al   2013  bastin tony roy savarimuthu 
stephen cranefield  maryam purvis  and martin k  purvis 
identifying prohibition norms in agent societies  artificial
intelligence and law  21 1  1–46  2013 
 sen and airiau  2007  sandip sen and st ephane airiau 
emergence of norms through social learning  in 20th inter-
national joint conference on artificial intelligence  pages
1507–1512  2007 
 tan et al   2019  zhi-xuan tan  jake brawer  and brian
scassellati  that s mine  learning ownership relations and
norms for robots  in proceedings of the the thirty-third
aaai conference on artificial intelligence  pages 8058–
8065  aaai press  2019 
 wang et al   2019  jane x  wang  edward hughes  chrisan-
tha fernando  wojciech m  czarnecki  edgar a  du e˜nez
guzm an  and joel z  leibo  evolving intrinsic motivations
for altruistic behavior  in proceedings of the 18th interna-
tional conference on autonomous agents and multiagent
systems  pages 683–692  ifaamas  2019 
 zhang et al   2019  chengwei zhang  xiaohong li  jianye
hao  siqi chen  karl tuyls  wanli xue  and zhiyong
feng 
sa-iga  a multiagent reinforcement learning
method towards socially optimal outcomes  autonomous
agents and multi-agent systems  33 403–429  2019 
proceedings of the thirtieth    ijcai-21 
124
 "
None,2021,https-www-ijcai-org-proceedings-2021-0018-pdf,Improving Multi-agent Coordination by Learning to Estimate Contention,"Panayiotis Danassis, Florian Wiedemair, Boi Faltings",None,https://www.ijcai.org/proceedings/2021/0018.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0018-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0018-pdf.pdf,"improving multi-agent coordination by learning to estimate contention
panayiotis danassis   florian wiedemair and boi faltings
artificial intelligence laboratory   ecole polytechnique f ed erale de lausanne  epfl   switzerland
 panayiotis danassis  florian wiedemair  boi faltings @epfl ch
abstract
we present a multi-agent learning algorithm 
alma-learning  for efficient and fair allocations
in large-scale systems 
we circumvent the tra-
ditional pitfalls of multi-agent learning  e g   the
moving target problem  the curse of dimension-
ality  or the need for mutually consistent actions 
by relying on the alma heuristic as a coordi-
nation mechanism for each stage game  alma-
learning is decentralized  observes only own ac-
tion/reward pairs  requires no inter-agent communi-
cation  and achieves near-optimal  < 5  loss  and
fair coordination in a variety of synthetic scenar-
ios and a real-world meeting scheduling problem 
the lightweight nature and fast learning constitute
alma-learning ideal for on-device deployment 
1
introduction
one of the most relevant problems in multi-agent systems is
finding an optimal allocation between agents  i e   comput-
ing a maximum-weight matching  were edge weights corre-
spond to the utility of each alternative  many multi-agent
coordination problems can be formulated as such 
exam-
ple applications include role allocation  e g   team formation
 gunn and anderson  2013    task assignment  e g   smart
factories  or taxi-passenger matching  danassis et al   2019b 
varakantham et al   2012    resource allocation  e g   park-
ing/charging spaces for autonomous vehicles  geng and cas-
sandras  2013    etc  what follows is applicable to any such
scenario  but for concreteness we focus on the assignment
problem  bipartite matching   one of the most fundamental
combinatorial optimization problems  munkres  1957  
a significant challenge for any algorithm for the assign-
ment problem emerges from the nature of real-world applica-
tions  which is often distributed and information-restrictive 
sharing plans  utilities  or preferences creates high overhead 
and there is often a lack of responsiveness and/or communi-
cation between the participants  stone et al   2010   achiev-
ing fast convergence and high efficiency in such information-
restrictive settings is extremely challenging 
a recently proposed heuristic  alma  danassis et al  
2019a   was specifically designed to address the aforemen-
tioned challenges  alma is decentralized  completely un-
coupled  agents are only aware of their own history   and re-
quires no communication between the agents  instead  agents
make decisions locally  based on the contest for resources
that they are interested in  and the agents that are interested
in the same resources 
as a result  in the realistic case
where each agent is interested in a subset  of fixed size  of
the total resources  alma s convergence time is constant in
the total problem size  this condition holds by default in
many real-world applications  e g   resource allocation in ur-
ban environments   since agents only have a local  partial 
knowledge of the world  and there is typically a cost asso-
ciated with acquiring a resource  this lightweight nature of
alma coupled with the lack of inter-agent communication 
and the highly efficient allocations  danassis et al   2019b 
danassis et al   2019a  danassis et al   2020   make it ideal
for an on-device solution for large-scale intelligent systems
 e g   iot devices  smart cities and intelligent infrastructure 
industry 4 0  autonomous vehicles  etc   
despite alma s high performance in a variety of domains 
it remains a heuristic  i e   sub-optimal by nature  in this
work  we introduce a learning element  alma-learning 
that allows to quickly close the gap in social welfare com-
pared to the optimal solution  while simultaneously increas-
ing the fairness of the allocation  specifically  in alma 
while contesting for a resource  each agent will back-off with
probability that depends on their own utility loss of switching
to some alternative  alma-learning improves upon alma
by allowing agents to learn the chances that they will actually
obtain the alternative option they consider when backing-off 
which helps guide their search 
alma-learning is applicable in repeated allocation
games  e g   self organization of intelligent infrastructure  au-
tonomous mobility systems  etc    but can be also applied as
a negotiation protocol in one-shot interactions  where agents
can simulate the learning process offline  before making their
final decision  a motivating real-world application is pre-
sented in section 3 2  where alma-learning is applied to
solve a large-scale meeting scheduling problem 
1 1
our contributions
 1  we introduce alma-learning  a distributed algorithm
for large-scale multi-agent coordination  focusing on scala-
bility and on-device deployment in real-world applications 
 2  we prove that alma-learning converges 
proceedings of the thirtieth    ijcai-21 
125
  3  we provide a thorough evaluation in a variety of syn-
thetic benchmarks and a real-world meeting scheduling prob-
lem  in all of them alma-learning is able to quickly  as
little as 64 training steps  reach allocations of high social wel-
fare  less than 5  loss  and fairness  up to almost 10  lower
inequality compared to the best performing baseline  
1 2
discussion and related work
multi-agent coordination can usually be formulated as a
matching problem 
finding a maximum weight matching
is one of the best-studied combinatorial optimization prob-
lems  see  su  2015  lov asz and plummer  2009    there is a
plethora of polynomial time algorithms  with the hungarian
algorithm  kuhn  1955  being the most prominent centralized
one for the bipartite variant  i e   the assignment problem   in
real-world problems  a centralized coordinator is not always
available  and if so  it has to know the utilities of all the partic-
ipants  which is often not feasible  decentralized algorithms
 e g    giordani et al   2010   solve this problem  yet they re-
quire polynomial computational time and polynomial number
of messages – such as cost matrices  ismail and sun  2017  
pricing information  zavlanos et al   2008   or a basis of the
lp  b¨urger et al   2012   etc   see also  kuhn et al   2016 
elkin  2004  for general results in distributed approximabil-
ity under only local information/computation  
while the problem has been  solved  from an algorithmic
perspective – having both centralized and decentralized poly-
nomial algorithms – it is not so from the perspective of multi-
agent systems  for two key reasons   1  complexity  and  2 
communication  the proliferation of intelligent systems will
give rise to large-scale  multi-agent based technologies  al-
gorithms for maximum-weight matching  whether centralized
or distributed  have runtime that increases with the total prob-
lem size  even in the realistic case where agents are interested
in a small number of resources  thus  they can only handle
problems of some bounded size  moreover  they require a sig-
nificant amount of inter-agent communication  as the num-
ber and diversity of autonomous agents continue to rise  dif-
ferences in origin  communication protocols  or the existence
of legacy agents will bring forth the need to collaborate with-
out any form of explicit communication  stone et al   2010  
most importantly though  communication between partici-
pants  sharing utility tables  plans  and preferences  creates
high overhead  on the other hand  under reasonable assump-
tions about the preferences of the agents  alma s runtime is
constant in the total problem size  while requiring no message
exchange  i e   no communication network  between the par-
ticipating agents  the proposed approach  alma-learning 
preserves the aforementioned two properties of alma 
from the perspective of multi-agent learning  mal   the
problem at hand falls under the paradigm of multi-agent rein-
forcement learning  where for example it can be modeled as
a multi-armed bandit  mab  problem  auer et al   2002  
or as a markov decision process  mdp  and solved using a
variant of q-learning  busoniu et al   2008   in mab prob-
lems an agent is given a number of arms  resources  and at
each time-step has to decide which arm to pull to get the
maximum expected reward  in q-learning agents solve bell-
man s optimality equation  bellman  2013  using an iterative
approximation procedure so as to maximize some notion of
expected cumulative reward  both approaches have arguably
been designed to operate in a more challenging setting  thus
making them susceptible to many pitfalls inherent in mal 
for example  there is no stationary distribution  in fact  re-
wards depend on the joint action of the agents and since all
agents learn simultaneously  this results in a moving-target
problem  thus  there is an inherent need for coordination in
mal algorithms  stemming from the fact that the effect of an
agent s action depends on the actions of the other agents  i e 
actions must be mutually consistent to achieve the desired re-
sult  moreover  the curse of dimensionality makes it difficult
to apply such algorithms to large scale problems  alma-
learning solves both of the above challenges by relying on
alma as a coordination mechanism for each stage of the
repeated game  another fundamental difference is that the
aforementioned algorithms are designed to tackle the explo-
ration/exploitation dilemma  a bandit algorithm for example
will constantly explore  even if an agent has acquired his most
preferred alternative  in matching problems  though  agents
know  or have an estimate of  their own utilities  alma-
learning in particular  requires the knowledge of personal
preference ordering and pairwise differences of utility  which
are far easier to estimate than the exact utility table   the lat-
ter gives a great advantage to alma-learning  since agents
do not need to continue exploring after successfully claiming
a resource  which stabilizes the learning process 
2
proposed approach  alma-learning
2 1
the assignment problem
the assignment problem refers to finding a maximum weight
matching in a weighted bipartite graph  g =  n ∪ r  v  
in the studied scenario  n =  1          n  agents compete to
acquire r =  1          r  resources  the weight of an edge
 n  r  ∈ v represents the utility  un r  ∈  0  1   agent n
receives by acquiring resource r  each agent can acquire at
most one resource  and each resource can be assigned to at
most one agent  the goal is to maximize the social welfare
 sum of utilities   i e   maxx≥0
�
 n r ∈v un r xn r  where
x =  x1 1          xn r   subject to �
r| n r ∈v xn r = 1  ∀n ∈
n  and �
n| n r ∈v xn r = 1  ∀r ∈ r 
2 2
learning rule
we begin by describing  a slightly modified version of  the
alma heuristic of  danassis et al   2019a   which is used
as a subroutine by alma-learning  the pseudo-codes for
alma and alma-learning are presented in algorithms 1
and 2  respectively  both alma and alma-learning are
run independently and in parallel by all the agents  to im-
prove readability  we have omitted the subscript n  
we make the following two assumptions  first  we as-
sume  possibly noisy  knowledge of personal utilities by each
agent  second  we assume that agents can observe feedback
from their environment to inform collisions and detect free
resources  it could be achieved by the use of sensors  or by a
single bit  0 / 1  feedback from the resource  note that these
messages would be between the requesting agent and the re-
source  not between the participating agents themselves  
proceedings of the thirtieth    ijcai-21 
126
 resources
agents
r1
r2
r3
n1
1
0
0 5
n2
0
1
0
n3
1
0 9
0
table 1  motivating adversarial example  inaccurate loss estimate 
agent n3 backs-off with high probability when contesting for re-
source r1 assuming a good alternative  only to find resource r2 oc-
cupied 
resources
agents
r1
r2
r3
n1
1
0 9
0
n2
0
1
0 9
n3
1
0 9
0
table 2  motivating adversarial example  inaccurate reward expec-
tation  agents n1 and n3 always start by attempting to acquire re-
source r1  reasoning that it is the most preferred one  yet each of
them only wins r1 half of the times 
resources
agents
r1
r2
r3
n1
1
0
0 5
n2
0
1
0
n3
1
0 9
0
table 1  motivating adversarial example  inaccurate loss estimate  agent n3 backs-off with high
probability when contesting for resource r1 assuming a good alternative  only to find resource r2
occupied 
resources
agents
r1
r2
r3
n1
1
0 9
0
n2
0
1
0 9
n3
1
0 9
0
table 2  motivating adversarial example  inaccurate reward expectation  agents n1 and n3 always
start by attempting to acquire resource r1  reasoning that it is the most preferred one  yet each of
them only wins r1 half of the times 
algorithm 2 alma-learning
require  sort resources  rn ⊆ r  in decreasing order of utility r0          rrn−1 under ≺n
require  rewardhistory r  l   reward r   loss r 
1  procedure alma-learning
2 
for all r ∈ r do
initialization
3 
rewardhistory r  add u r  
4 
reward r  ← rewardhistory r  getmean  
5 
loss r  ← u r  − u rnext 
6 
rstart ← ar
maxr reward r 
7 
8 
for t ∈  1         
  do
  time horizon
9 
rwon ← alma rstart  loss   
run alma
10 
11 
rewardhistory rstart  add u rwon  
12 
reward rstart  ← rewardhistory rstart  getmean  
13 
if u rstart  − u rwon  > 0 then
14 
loss rstart  ←
15 
 1 − α loss rstart 
α  u rstart  − u rwon  
16 
17 
if rstart = rwon then
18 
rstart ← ar
maxr reward r 
table 2 presents the second example  agents n1 and n3 always start by attempting to acquire resource
168
r1  reasoning that it is the most preferred one  yet  in a repeated game  each of them only wins r1
169
half of the times  achieving social welfare 2  28 5  worse than the optimal 2 8   thus  in expectation 
170
resource r1 has utility 0 5  alma-learning solves this problem by learning an empirical estimate of
171
the reward of each resource  in this case  after learning  either agent n1 or n3  or both   will start from
172
resource r2  agent n2 will back-off since he has a good alternative  and the result will be the optimal
173
allocation where agents n1  n2  n3 are matched with resources r2  r3  r1  or r1  r3  r2   respectively 
174
2 1 2
alma-learning  a multi-agent  meta- learning algorithm
175
alma-learning uses alma as a sub-routine  specifically as a coordination mechanism for each
176
stage of the repeated game  over time  alma-learning learns which resource to select first  rstart 
177
when running alma  and an accurate empirical estimate on the loss it will incur by backing-off
178
 loss     by learning these two values  agents take more informed decisions  specifically   1  if
179
an agent often loses the contest of his starting resource  the expected reward of that resource will
180
5
 a 
resources
agents
r1
r2
r3
n1
1
0
0 5
n2
0
1
0
n3
1
0 9
0
table 1  motivating adversarial example  inaccurate loss estimate  agent n3 backs-off with high
probability when contesting for resource r1 assuming a good alternative  only to find resource r2
occupied 
resources
agents
r1
r2
r3
n1
1
0 9
0
n2
0
1
0 9
n3
1
0 9
0
table 2  motivating adversarial example  inaccurate reward expectation  agents n1 and n3 always
start by attempting to acquire resource r1  reasoning that it is the most preferred one  yet each of
them only wins r1 half of the times 
algorithm 2 alma-learning
require  sort resources  rn ⊆ r  in decreasing order of utility r0          rrn−1 under ≺n
require  rewardhistory r  l   reward r   loss r 
1  procedure alma-learning
2 
for all r ∈ r do
initialization
3 
rewardhistory r  add u r  
4 
reward r  ← rewardhistory r  getmean  
5 
loss r  ← u r  − u rnext 
6 
rstart ← ar
maxr reward r 
7 
8 
for t ∈  1         
  do
  time horizon
9 
rwon ← alma rstart  loss   
run alma
10 
11 
rewardhistory rstart  add u rwon  
12 
reward rstart  ← rewardhistory rstart  getmean  
13 
if u rstart  − u rwon  > 0 then
14 
loss rstart  ←
15 
 1 − α loss rstart 
α  u rstart  − u rwon  
16 
17 
if rstart = rwon then
18 
rstart ← ar
maxr reward r 
table 2 presents the second example  agents n1 and n3 always start by attempting to acquire resource
168
r1  reasoning that it is the most preferred one  yet  in a repeated game  each of them only wins r1
169
half of the times  achieving social welfare 2  28 5  worse than the optimal 2 8   thus  in expectation 
170
resource r1 has utility 0 5  alma-learning solves this problem by learning an empirical estimate of
171
the reward of each resource  in this case  after learning  either agent n1 or n3  or both   will start from
172
resource r2  agent n2 will back-off since he has a good alternative  and the result will be the optimal
173
allocation where agents n1  n2  n3 are matched with resources r2  r3  r1  or r1  r3  r2   respectively 
174
2 1 2
alma-learning  a multi-agent  meta- learning algorithm
175
alma-learning uses alma as a sub-routine  specifically as a coordination mechanism for each
176
stage of the repeated game  over time  alma-learning learns which resource to select first  rstart 
177
when running alma  and an accurate empirical estimate on the loss it will incur by backing-off
178
 loss     by learning these two values  agents take more informed decisions  specifically   1  if
179
an agent often loses the contest of his starting resource  the expected reward of that resource will
180
5
 b 
figure 1  adversarial examples  1a inaccurate loss estimate  agent
n3 backs-off with high probability when contesting for resource r1
assuming a good alternative  only to find resource r2 occupied  1b
inaccurate reward expectation  agents n1 and n3 always start by
attempting to acquire resource r1  reasoning that it is the most pre-
ferred one  yet each of them only wins r1 half of the times 
source will decrease  thus in the future the agent will switch
to an alternative starting resource  and  2  if an agent backs-
off from contesting resource r expecting low loss  only to
find that all his high utility alternatives are already occupied 
then his expected loss of resource r  loss r   will increase 
making him more reluctant to back-off in some future stage
game  in more detail  alma-learning learns and maintains
the following information1 
 i  rewardhistory r  l   a 2d array  for each r ∈ r
it maintains the l most recent reward values received by
agent n  i e   the l most recent un rwon   where rwon ←
alma r  loss     see line 11 of alg  2  the array is initial-
ized to the utility of each resource  line 3 of alg  2  
 ii  reward r  
a 1d array 
for each r
∈
r it
maintains an empirical estimate on the expected reward re-
ceived by starting at resource r and continue playing ac-
cording to alg 
1 
it is computed by averaging the re-
ward history of the resource  i e   ∀r ∈ r   reward r  ←
rewardhistory r  getmean    see line 12 of alg  2 
 iii  loss r   a 1d array  for each r ∈ r it maintains an
empirical estimate on the loss in utility agent n incurs if he
backs-off from the contest of resource r  the loss of each
resource r is initialized to loss r  ← un r  − un rnext  
1we have omitted the subscript n from all the variables and ar-
rays  but every agent maintains their own estimates 
algorithm 2 alma-learning
require  sort resources  rn ⊆ r  in decreasing order of utility
r0          rrn−1 under ≺n
require  rewardhistory r  l   reward r   loss r 
1  procedure alma-learning
2 
for all r ∈ r do
▷ initialization
3 
rewardhistory r  add u r  
4 
reward r  ← rewardhistory r  getmean  
5 
loss r  ← u r  − u rnext 
6 
rstart ← arg maxr reward r 
7 
8 
for t ∈  1          t  do
▷ t  time horizon
9 
rwon ← alma rstart  loss   
▷ run alma
10 
11 
rewardhistory rstart  add u rwon  
12 
reward rstart  ← rewardhistory rstart  getmean  
13 
if u rstart  − u rwon  > 0 then
14 
loss rstart  ←
15 
 1 − α loss rstart    α  u rstart  − u rwon  
16 
17 
if rstart  = rwon then
18 
rstart ← arg maxr reward r 
where rnext is the next most preferred resource to r  accord-
ing to agent n s preferences ≺n  see line 5 of alg  2   sub-
sequently  for every stage game  agent n starts by selecting
resource rstart  and ends up wining resource rwon  the loss
of rstart is then updated according to the following averaging
process  where α is the learning rate 
loss rstart  ←  1 − α loss rstart    α  u rstart  − u rwon  
finally  the last condition  lines 17-18 of alg  2  ensures
that agents who have acquired resources of high preference
stop exploring  thus stabilizing the learning process 
2 3
convergence
convergence of alma-learning does not translate to a fixed
allocation at each stage game  the system has converged
when agents no longer switch their starting resource  rstart 
the final allocation of each stage game is controlled by
alma  which means that even after convergence there can
be contest for a resource  i e   having more than one agent
selecting the same starting resource 
as we will demon-
strate later  this translates to fairer allocations  since agents
with similar preferences can alternate between acquiring their
most preferred resource  due to luck of space we only pro-
vide a sketch of the proof  please refer to the supplement 
theorem 1  there exists time-step tconv such that ∀t >
tconv   rn
start t  = rn
start tconv   where rn
start t  denotes
the starting resource rstart of agent n at the stage game of
time-step t 
proof   sketch  theorem 2 1 of  danassis et al   2019a 
proves that alma  called at line 9 of alg  2  converges
in polynomial time  in fact  under some assumptions  it con-
verges in constant time  i e   each stage game converges in
constant time   in alma-learning agents switch their start-
ing resource only when the expected reward for the current
starting resource drops below the best alternative one  i e  
 a 
resources
agents
r1
r2
r3
n1
1
0
0 5
n2
0
1
0
n3
1
0 9
0
table 1  motivating adversarial example  inaccurate loss estimate 
agent n3 backs-off with high probability when contesting for re-
source r1 assuming a good alternative  only to find resource r2 oc-
cupied 
resources
agents
r1
r2
r3
n1
1
0 9
0
n2
0
1
0 9
n3
1
0 9
0
table 2  motivating adversarial example  inaccurate reward expec-
tation  agents n1 and n3 always start by attempting to acquire re-
source r1  reasoning that it is the most preferred one  yet each of
them only wins r1 half of the times 
resources
agents
r1
r2
r3
n1
1
0
0 5
n2
0
1
0
n3
1
0 9
0
table 1  motivating adversarial example  inaccurate loss estimate  agent n3 backs-off with high
probability when contesting for resource r1 assuming a good alternative  only to find resource r2
occupied 
resources
agents
r1
r2
r3
n1
1
0 9
0
n2
0
1
0 9
n3
1
0 9
0
table 2  motivating adversarial example  inaccurate reward expectation  agents n1 and n3 always
start by attempting to acquire resource r1  reasoning that it is the most preferred one  yet each of
them only wins r1 half of the times 
algorithm 2 alma-learning
require  sort resources  rn ⊆ r  in decreasing order of utility r0          rrn−1 under ≺n
require  rewardhistory r  l   reward r   loss r 
1  procedure alma-learning
2 
for all r ∈ r do
initialization
3 
rewardhistory r  add u r  
4 
reward r  ← rewardhistory r  getmean  
5 
loss r  ← u r  − u rnext 
6 
rstart ← ar
maxr reward r 
7 
8 
for t ∈  1         
  do
  time horizon
9 
rwon ← alma rstart  loss   
run alma
10 
11 
rewardhistory rstart  add u rwon  
12 
reward rstart  ← rewardhistory rstart  getmean  
13 
if u rstart  − u rwon  > 0 then
14 
loss rstart  ←
15 
 1 − α loss rstart 
α  u rstart  − u rwon  
16 
17 
if rstart = rwon then
18 
rstart ← ar
maxr reward r 
table 2 presents the second example  agents n1 and n3 always start by attempting to acquire resource
168
r1  reasoning that it is the most preferred one  yet  in a repeated game  each of them only wins r1
169
half of the times  achieving social welfare 2  28 5  worse than the optimal 2 8   thus  in expectation 
170
resource r1 has utility 0 5  alma-learning solves this problem by learning an empirical estimate of
171
the reward of each resource  in this case  after learning  either agent n1 or n3  or both   will start from
172
resource r2  agent n2 will back-off since he has a good alternative  and the result will be the optimal
173
allocation where agents n1  n2  n3 are matched with resources r2  r3  r1  or r1  r3  r2   respectively 
174
2 1 2
alma-learning  a multi-agent  meta- learning algorithm
175
alma-learning uses alma as a sub-routine  specifically as a coordination mechanism for each
176
stage of the repeated game  over time  alma-learning learns which resource to select first  rstart 
177
when running alma  and an accurate empirical estimate on the loss it will incur by backing-off
178
 loss     by learning these two values  agents take more informed decisions  specifically   1  if
179
an agent often loses the contest of his starting resource  the expected reward of that resource will
180
5
 a 
resources
agents
r1
r2
r3
n1
1
0
0 5
n2
0
1
0
n3
1
0 9
0
table 1  motivating adversarial example  inaccurate loss estimate  agent n3 backs-off with high
probability when contesting for resource r1 assuming a good alternative  only to find resource r2
occupied 
resources
agents
r1
r2
r3
n1
1
0 9
0
n2
0
1
0 9
n3
1
0 9
0
table 2  motivating adversarial example  inaccurate reward expectation  agents n1 and n3 always
start by attempting to acquire resource r1  reasoning that it is the most preferred one  yet each of
them only wins r1 half of the times 
algorithm 2 alma-learning
require  sort resources  rn ⊆ r  in decreasing order of utility r0          rrn−1 under ≺n
require  rewardhistory r  l   reward r   loss r 
1  procedure alma-learning
2 
for all r ∈ r do
initialization
3 
rewardhistory r  add u r  
4 
reward r  ← rewardhistory r  getmean  
5 
loss r  ← u r  − u rnext 
6 
rstart ← ar
maxr reward r 
7 
8 
for t ∈  1         
  do
  time horizon
9 
rwon ← alma rstart  loss   
run alma
10 
11 
rewardhistory rstart  add u rwon  
12 
reward rstart  ← rewardhistory rstart  getmean  
13 
if u rstart  − u rwon  > 0 then
14 
loss rstart  ←
15 
 1 − α loss rstart 
α  u rstart  − u rwon  
16 
17 
if rstart = rwon then
18 
rstart ← ar
maxr reward r 
table 2 presents the second example  agents n1 and n3 always start by attempting to acquire resource
168
r1  reasoning that it is the most preferred one  yet  in a repeated game  each of them only wins r1
169
half of the times  achieving social welfare 2  28 5  worse than the optimal 2 8   thus  in expectation 
170
resource r1 has utility 0 5  alma-learning solves this problem by learning an empirical estimate of
171
the reward of each resource  in this case  after learning  either agent n1 or n3  or both   will start from
172
resource r2  agent n2 will back-off since he has a good alternative  and the result will be the optimal
173
allocation where agents n1  n2  n3 are matched with resources r2  r3  r1  or r1  r3  r2   respectively 
174
2 1 2
alma-learning  a multi-agent  meta- learning algorithm
175
alma-learning uses alma as a sub-routine  specifically as a coordination mechanism for each
176
stage of the repeated game  over time  alma-learning learns which resource to select first  rstart 
177
when running alma  and an accurate empirical estimate on the loss it will incur by backing-off
178
 loss     by learning these two values  agents take more informed decisions  specifically   1  if
179
an agent often loses the contest of his starting resource  the expected reward of that resource will
180
5
 b 
figure 1  adversarial examples  1a inaccurate loss estimate  agent
n3 backs-off with high probability when contesting for resource r1
assuming a good alternative  only to find resource r2 occupied  1b
inaccurate reward expectation  agents n1 and n3 always start by
attempting to acquire resource r1  reasoning that it is the most pre-
ferred one  yet each of them only wins r1 half of the times 
source will decrease  thus in the future the agent will switch
to an alternative starting resource  and  2  if an agent backs-
off from contesting resource r expecting low loss  only to
find that all his high utility alternatives are already occupied 
then his expected loss of resource r  loss r   will increase 
making him more reluctant to back-off in some future stage
game  in more detail  alma-learning learns and maintains
the following information1 
 i  rewardhistory r  l   a 2d array  for each r ∈ r
it maintains the l most recent reward values received by
agent n  i e   the l most recent un rwon   where rwon ←
alma r  loss     see line 11 of alg  2  the array is initial-
ized to the utility of each resource  line 3 of alg  2  
 ii  reward r  
a 1d array 
for each r
∈
r it
maintains an empirical estimate on the expected reward re-
ceived by starting at resource r and continue playing ac-
cording to alg 
1 
it is computed by averaging the re-
ward history of the resource  i e   ∀r ∈ r   reward r  ←
rewardhistory r  getmean    see line 12 of alg  2 
 iii  loss r   a 1d array  for each r ∈ r it maintains an
empirical estimate on the loss in utility agent n incurs if he
backs-off from the contest of resource r  the loss of each
resource r is initialized to loss r  ← un r  − un rnext  
1we have omitted the subscript n from all the variables and ar-
rays  but every agent maintains their own estimates 
algorithm 2 alma-learning
require  sort resources  rn ⊆ r  in decreasing order of utility
r0          rrn−1 under ≺n
require  rewardhistory r  l   reward r   loss r 
1  procedure alma-learning
2 
for all r ∈ r do
▷ initialization
3 
rewardhistory r  add u r  
4 
reward r  ← rewardhistory r  getmean  
5 
loss r  ← u r  − u rnext 
6 
rstart ← arg maxr reward r 
7 
8 
for t ∈  1          t  do
▷ t  time horizon
9 
rwon ← alma rstart  loss   
▷ run alma
10 
11 
rewardhistory rstart  add u rwon  
12 
reward rstart  ← rewardhistory rstart  getmean  
13 
if u rstart  − u rwon  > 0 then
14 
loss rstart  ←
15 
 1 − α loss rstart    α  u rstart  − u rwon  
16 
17 
if rstart  = rwon then
18 
rstart ← arg maxr reward r 
where rnext is the next most preferred resource to r  accord-
ing to agent n s preferences ≺n  see line 5 of alg  2   sub-
sequently  for every stage game  agent n starts by selecting
resource rstart  and ends up wining resource rwon  the loss
of rstart is then updated according to the following averaging
process  where α is the learning rate 
loss rstart  ←  1 − α loss rstart    α  u rstart  − u rwon  
finally  the last condition  lines 17-18 of alg  2  ensures
that agents who have acquired resources of high preference
stop exploring  thus stabilizing the learning process 
2 3
convergence
convergence of alma-learning does not translate to a fixed
allocation at each stage game  the system has converged
when agents no longer switch their starting resource  rstart 
the final allocation of each stage game is controlled by
alma  which means that even after convergence there can
be contest for a resource  i e   having more than one agent
selecting the same starting resource 
as we will demon-
strate later  this translates to fairer allocations  since agents
with similar preferences can alternate between acquiring their
most preferred resource  due to luck of space we only pro-
vide a sketch of the proof  please refer to the supplement 
theorem 1  there exists time-step tconv such that ∀t >
tconv   rn
start t  = rn
start tconv   where rn
start t  denotes
the starting resource rstart of agent n at the stage game of
time-step t 
proof   sketch  theorem 2 1 of  danassis et al   2019a 
proves that alma  called at line 9 of alg  2  converges
in polynomial time  in fact  under some assumptions  it con-
verges in constant time  i e   each stage game converges in
constant time   in alma-learning agents switch their start-
ing resource only when the expected reward for the current
starting resource drops below the best alternative one  i e  
 b 
table 1  adversarial examples   1a  inaccurate loss estimate  agent
n3 backs-off with high probability when contesting for resource r1
assuming a good alternative  only to find resource r2 occupied 
 1b  inaccurate reward expectation  agents n1 and n3 always start
by attempting to acquire resource r1  reasoning that it is the most
preferred one  yet each of them only wins r1 half of the times 
for both alma  and alma-learning  each agent sorts
his available resources  possibly rn ⊆ r  in decreasing util-
ity  r0          ri          rrn−1  under his preference ordering ≺n 
alma  altruistic matching heuristic
alma converges to a resource through repeated trials  let
a =  y  ar1          arrn   denote the set of actions  where
y refers to yielding  and ar refers to accessing resource r 
and let g denote the agent s strategy  as long as an agent has
not acquired a resource yet  at every time-step  there are two
possible scenarios  if g = ar  strategy points to resource
r   then agent n attempts to acquire that resource  if there is
a collision  the colliding parties back-off  set g ← y   with
some probability  otherwise  if g = y   the agent chooses
another resource r for monitoring  if the resource is free  he
sets g ← ar 
the back-off probability  p ·   is computed individually
and locally based on each agent s expected loss  if more than
one agent compete for resource ri  step 8 of alg  1   each
of them will back-off with probability that depends on their
expected utility loss  the expected loss array is computed by
alma-learning and provided as input to alma  the actual
back-off probability can be computed with any monotonically
decreasing function on loss  see  danassis et al   2019a    in
this work we use p loss  = f loss β  where β controls the
aggressiveness  willingness to back-off   and
f loss  =
�
�
�
�
�
1 − ϵ 
if loss ≤ ϵ
ϵ 
if 1 − loss ≤ ϵ
1 − loss 
otherwise
 1 
agents that do not have good alternatives will be less likely
to back-off and vice versa  the ones that do back-off select an
alternative resource and examine its availability  the resource
selection is performed in sequential order  starting from the
most preferred resource  see step 3 of alg  1  
sources of inefficiency 
alma is a heuristic  i e   sub-
optimal by nature  it is worth understanding the sources of
inefficiency  which in turn motivated alma-learning  to
do so  we provide a couple of adversarial examples 
in the original alma algorithm  all agents start attempt-
ing to claim their most preferred resource  and back-off with
probability that depends on their loss of switching to the
immediate next best resource  specifically  in the simplest
case  the probability to back-off when contesting resource
ri would be given by p loss i   = 1 − loss i   where
loss i  = un ri  − un ri 1  and ri 1 is the next best re-
source according to agent n s preferences ≺n 
the first example is given in table 1a  agent n3 backs-off
with high probability  higher than agent n1  when contesting
for resource r1 assuming a good alternative  only to find re-
source r2 occupied  thus  n3 ends up matched with resource
r3 
the social welfare of the final allocation is 2  which
is 20  worse than the optimal  where agents n1  n2  n3 are
matched with resources r3  r2  r1  respectively  achieving a
social welfare of 2 5   alma-learning solves this problem
by learning an empirical estimate of the loss an agent will in-
cur if he backs-off from a resource  in this case  agent n3 will
learn that his loss is not 1−0 9 = 0 1  but actually 1−0 = 1 
and thus will not back-off in subsequent stage games  result-
ing in an optimal allocation 
in another example  table 1b  agents n1 and n3 always
start by attempting to acquire resource r1  reasoning that it is
the most preferred one  yet  in a repeated game  each of them
only wins r1 half of the times  for a social welfare 2  which
is 28 5  worse than the optimal 2 8   thus  in expectation 
resource r1 has utility 0 5  alma-learning solves this by
learning an empirical estimate of the reward of each resource 
in this case  after learning  either agent n1 or n3  or both   will
start from resource r2  agent n2 will back-off since he has a
good alternative  and the result will be the optimal allocation
where agents n1  n2  n3 are matched with resources r2  r3  r1
 or r1  r3  r2   respectively 
alma-learning
alma-learning uses alma as a sub-routine  specifically
as a coordination mechanism for each stage of the repeated
game  over time  alma-learning learns which resource to
select first  rstart  when running alma  and an accurate em-
pirical estimate on the loss the agent will incur by backing-off
 loss     by learning these two values agents take more in-
formed decisions  specifically   1  if an agent often loses the
contest of his starting resource  the expected reward of that re-
source will decrease  thus in the future the agent will switch
to an alternative starting resource  and  2  if an agent backs-
off from contesting resource r expecting low loss  only to
find that all his high utility alternatives are already occupied 
then his expected loss of resource r  loss r   will increase 
making him more reluctant to back-off in some future stage
game  in more detail  alma-learning learns and maintains
the following information1 
 i  rewardhistory r  l   a 2d array  for each r ∈ r
it maintains the l most recent reward values received by
agent n  i e   the l most recent un rwon   where rwon ←
alma r  loss     see line 11 of alg  2  the array is initial-
ized to the utility of each resource  line 3 of alg  2  
 ii  reward r  
a 1d array 
for each r
∈
r it
maintains an empirical estimate on the expected reward re-
ceived by starting at resource r and continue playing ac-
cording to alg 
1 
it is computed by averaging the re-
ward history of the resource  i e   ∀r ∈ r   reward r  ←
rewardhistory r  getmean    see line 12 of alg  2 
1we have omitted the subscript n from all the variables and ar-
rays  but every agent maintains their own estimates 
proceedings of the thirtieth    ijcai-21 
127
 algorithm 1 alma  altruistic matching heuristic 
require  sort resources  rn ⊆ r  in decreasing order of utility
r0          rrn−1 under ≺n
1  procedure alma rstart  loss r  
2 
initialize g ← arstart
3 
initialize current ← −1
4 
initialize converged ← false
5 
while  converged do
6 
if g = ar then
7 
agent n attempts to acquire r
8 
if collision r  then
9 
back-off  set g ← y   with prob  p loss r  
10 
else
11 
converged ← true
12 
else  g = y  
13 
current ←  current   1  mod r
14 
agent n monitors r ← rcurrent 
15 
if free r  then set g ← ar
16 
return r  such that g = ar
 iii  loss r   a 1d array  for each r ∈ r it maintains an
empirical estimate on the loss in utility agent n incurs if he
backs-off from the contest of resource r  the loss of each
resource r is initialized to loss r  ← un r  − un rnext  
where rnext is the next most preferred resource to r  accord-
ing to agent n s preferences ≺n  see line 5 of alg  2   sub-
sequently  for every stage game  agent n starts by selecting
resource rstart  and ends up winning resource rwon  the loss
of rstart is then updated according to the following averaging
process  where α is the learning rate 
loss rstart  ←  1 − α loss rstart    α  u rstart  − u rwon  
finally  the last condition  lines 17-18 of alg  2  ensures
that agents who have acquired resources of high preference
stop exploring  thus stabilizing the learning process 
2 3
convergence
convergence of alma-learning does not translate to a fixed
allocation at each stage game  the system has converged
when agents no longer switch their starting resource  rstart 
the final allocation of each stage game is controlled by
alma  which means that even after convergence there can
be contest for a resource  i e   having more than one agent
selecting the same starting resource 
as we will demon-
strate later  this translates to fairer allocations  since agents
with similar preferences can alternate between acquiring their
most preferred resource 
theorem 1  there exists time-step tconv such that ∀t >
tconv   rn
start t  = rn
start tconv   where rn
start t  denotes
the starting resource rstart of agent n at the stage game of
time-step t 
proof   sketch  see  danassis et al   2021   theorem 2 1 of
 danassis et al   2019a  proves that alma  called at line 9
of alg  2  converges in polynomial time  in fact  under some
assumptions  it converges in constant time  i e   each stage
game converges in constant time   in alma-learning agents
switch their starting resource only when the expected reward
for the current starting resource drops below the best alterna-
tive one  i e   for an agent to switch from rstart to r′
start  it
algorithm 2 alma-learning
require  sort resources  rn ⊆ r  in decreasing order of utility
r0          rrn−1 under ≺n
require  rewardhistory r  l   reward r   loss r 
1  procedure alma-learning
2 
for all r ∈ r do
▷ initialization
3 
rewardhistory r  add u r  
4 
reward r  ← rewardhistory r  getmean  
5 
loss r  ← u r  − u rnext 
6 
rstart ← arg maxr reward r 
7 
8 
for t ∈  1          t  do
▷ t  time horizon
9 
rwon ← alma rstart  loss   
▷ run alma
10 
11 
rewardhistory rstart  add u rwon  
12 
reward rstart  ← rewardhistory rstart  getmean  
13 
if u rstart  − u rwon  > 0 then
14 
loss rstart  ←
15 
 1 − α loss rstart    α  u rstart  − u rwon  
16 
17 
if rstart ̸= rwon then
18 
rstart ← arg maxr reward r 
has to be that reward rstart  < reward r′
start   given that
utilities are bounded in  0  1   there is a maximum  finite num-
ber of switches until rewardn r  = 0  ∀r ∈ r  ∀n ∈ n  in
that case  the problem is equivalent to having n balls thrown
randomly and independently into n bins  since r = n  
since both r  n are finite  the process will result in a distinct
allocation in finite steps with probability 1 
3
evaluation
we evaluate alma-learning in a variety of synthetic bench-
marks and a meeting scheduling problem based on real data
from  romano and nunamaker  2001   error bars represent-
ing one standard deviation  sd  of uncertainty 
fairness 
the usual predicament of efficient allocations is
that they assign the resources only to a fixed subset of agents 
which leads to an unfair result  consider the simple exam-
ple of table 2  both alma  with higher probability  and
any optimal allocation algorithm will assign the coveted re-
source r1 to agent n1  while n3 will receive utility 0  but 
using alma-learning  agents n1 and n3 will update their
expected loss for resource r1 to 1  and randomly acquire it
between stage games  increasing fairness  recall that con-
vergence for alma-learning does not translate to a fixed
allocation at each stage game  to capture the fairness of this
 mixed  allocation  we report the average fairness on 32 eval-
uation time-steps that follow the training period 
to measure fairness  we used the gini coefficient  gini 
1912   an allocation x =  x1          xn ⊤ is fair iff g x  = 0 
where  g x  =  �n
n=1
�n
n′=1 |xn − xn′| / 2n �n
n=1 xn 
3 1
test case #1  synthetic benchmarks
setting 
we present results on three benchmarks 
 a  map  consider a cartesian map on which the agents and
resources are randomly distributed  the utility of agent n
proceedings of the thirtieth    ijcai-21 
128
 resources
agents
r1
r2
r3
n1
1
0 5
0
n2
0
1
0
n3
1
0 75
ϵ → 0
table 2  adversarial example  unfair allocation  both alma  with
higher probability  and any optimal allocation algorithm will assign
the coveted resource r1 to agent n1  while n3 will receive utility 0 
greedy
alma
alma-learning
 a  map
1 51  − 18 71 
0 00  − 9 57 
0 00  − 0 89 
 b  noisy
8 13  − 12 86 
2 96  − 10 58 
1 34  − 2 26 
 c  binary
0 10  − 14 70 
0 00  − 16 88 
0 00  − 0 39 
table 3  range of the average loss     in social welfare compared
the the  centralized  optimal for the three different benchmarks 
for acquiring resource r is proportional to the inverse of their
distance  i e   un r  = 1/dn r  let dn r denote the manhattan
distance  we assume a grid length of size
√
4 × n 
 b  noisy common utilities 
this pertains to an anti-
coordination scenario  i e   competition between agents with
similar preferences 
we model the utilities as  ∀n  n′ ∈
n  |un r −un′ r | ≤ noise  where the noise is sampled from
a zero-mean gaussian distribution  i e   noise ∼ n 0  σ2  
 c  binary utilities  this corresponds to each agent being
indifferent to acquiring any resource amongst his set of de-
sired resources  i e   un r  is randomly assigned to 0 or 1 
baselines 
we compare against   i  the hungarian algo-
rithm  kuhn  1955   which computes a maximum-weight
matching in a bipartite graphs   ii  alma  danassis et al  
2019a   and  iii  the greedy algorithm  which goes through
the agents randomly  and assigns them their most preferred 
unassigned resource 
results 
we begin with the loss in social welfare  figure
1a depicts the results for the map test-case  while table 3 ag-
gregates all three test-cases2  alma-leaning reaches near-
optimal allocations  less than 2 5  loss   in most cases in just
32−512 training time-steps  the exception is the noisy com-
mon utilities test-case  where the training time was slightly
higher 
intuitively we believe that this is because alma
already starts with a near optimal allocation  especially for
r > 256   and given the high similarity on the agent s utility
tables  especially for σ = 0 1   it requires a lot of fine-tuning
to improve the result 
moving on to fairness  alma-leaning achieves the most
fair allocations in all of the test-cases  as an example  figure
1b depicts the gini coefficient for the map test-case  alma-
learning s gini coefficient is −18  to −90  lower on av-
erage  across problem sizes  than alma s  −24  to −93 
lower than greedy s  and −0 2  to −7  lower than hungar-
ian s 
2for the the noisy common utilities test-case  we report results
for σ = 0 1  which is the worst performing scenario for alma-
learning  similar results were obtained for σ = 0 2 and σ = 0 4 
2
4
8 16 32 64
256
1024
#resources
-5
-10
-15
-20
relative difference in sw    
greedy
alma
alma-learning
 a  relative difference in sw
4
8
16 32 64
256
1024
#resources
0 1
0 2
0 3
0 4
0 5
gini coefficient
hungarian
greedy
alma
alma-learning
 b  gini index  lower is better 
figure 1  map test-case  results for increasing number of resources
  2  1024   x-axis in log scale   and n = r  alma-learning was
trained for 512 time-steps 
3 2
test case #2  meeting scheduling
motivation 
the problem of scheduling a large number of
meetings between multiple participants is ubiquitous in ev-
eryday life  nigam and srivastava  2020  ottens et al   2017 
zunino and campo  2009  maheswaran et al   2004  ben-
hassine and ho  2007  hassine et al   2004  crawford and
veloso  2005  franzin et al   2002   the advent of social
media brought forth the need to schedule large-scale events 
while the era of globalization and the shift to working-from-
home require business meetings to account for participants
with diverse preferences  e g   different timezones  
meeting scheduling is an inherently decentralized prob-
lem  traditional approaches  e g   distributed constraint opti-
mization  ottens et al   2017  maheswaran et al   2004   can
only handle a bounded  small number of meetings  interde-
pendences between meetings  participants can drastically in-
crease the complexity  while there are many commercially
available electronic calendars  e g   doodle  google calen-
dar  microsoft outlook  apple s calendar  etc    none of these
products is capable of autonomously scheduling meetings 
taking into consideration user preferences and availability 
while the problem is inherently online  meetings can
be aggregated and scheduled in batches  similarly to the
approach for tackling matchings in ridesharing platforms
 danassis et al   2019b   in this test-case  we map meeting
scheduling to an allocation problem and solve it using alma
and alma-learning  this showcases an application were
alma-learning can be used as a negotiation protocol 
modeling 
let e =  e1          en  denote the set of events
and p =  p1          pm  the set of participants  to formulate
the participation  let part   e → 2p  where 2p denotes the
power set of p  we further define the variables days and
slots to denote the number of days and time slots per day
of our calendar  e g   days = 7  slots = 24   in order to
add length to each event  we define an additional function
len   e → n  participants  utilities are given by 
pref   e×part e × 1          days × 1          slots  →  0  1  
mapping the above to the assignment problem of section
2 1  we would have the set of  day  slot  tuples to correspond
to r  while each event is represented by one event agent  that
aggregates the participant preferences   and the set of which
would correspond to n 
proceedings of the thirtieth    ijcai-21 
129
 10
15 20
50
100
#events
-15
-10
-5
0
5
10
relative difference in sw    
cplex
upper bound
greedy
msrac
alma
alma-learning
 a  relative difference in sw
70
140
210
280
#events
-30
-20
-10
0
10
relative difference in sw    
cplex
upper bound
greedy
msrac
alma
alma-learning
 b  relative difference in sw
70
140
210
280
#events
0 06
0 08
0 1
0 12
0 14
0 16
gini coefficient
cplex
greedy
msrac
alma
alma-learning
 c  gini coefficient  lower is better 
10
15 20
50
100
#events
-15
-10
-5
0
5
10
relative difference in sw    
cplex
upper bound
greedy
msrac
alma
alma-learning
figure 2  meeting scheduling  results for 100 participants  p  and increasing number of events  x-axis in log scale   alma-learning was
trained for 512 time-steps 
baselines 
we compare against four baselines   a  we used
the ibm ilog cp optimizer  laborie et al   2018  to formu-
late and solve the problem as a csp3  an additional benefit of
this solver is that it provides an upper bound for the optimal
solution  which is infeasible to compute    b  a modified ver-
sion of the msrac algorithm  benhassine and ho  2007  
and finally   c  the greedy and  d  alma  as before 
designing large test-cases 
as the problem size grows 
cplex s estimate on the upper bound of the optimal solu-
tion becomes too loose  see figure 2a   to get a more accu-
rate estimate on the loss in social welfare for larger test-cases 
we designed a large-instance by combining smaller problem
instances  making it easier for cplex to solve which in turn
allowed for tighter upper bounds as well  see figure 2b  
we begin by solving two smaller problem instances with
a low number of events  we then combine the two in a cal-
endar of twice the length by duplicating the preferences  re-
sulting in an instance of twice the number of events  agents 
and calendar slots  resources   specifically  in this case we
generated seven one-day long sub-instances  with 10  20  30
and 40 events each   and combined then into a one-week long
instance with 70  140  210 and 280 events  respectively  the
fact that preferences repeat periodically  corresponds to par-
ticipants being indifferent on the day  yet still have a prefer-
ence on time  
these instances are depicted in figure 2b and in the last
line of table 4 
results 
figures 2a and 2b depict the relative difference
in social welfare compared to cplex for 100 participants
 |p| = 100  and increasing number of events for the reg-
ular  |e| ∈  10  100   and larger test-cases  |e| up to 280  
respectively  table 4 aggregates the results for various val-
ues of p  alma-learning is able to achieve less than 5 
loss compared to cplex  and this difference diminishes
as the problem instance increases  less than 1 5  loss for
|p| = 100   finally  for the largest hand-crafted instance
 |p| = 100  |e| = 280  last line of table 4 and figure 2b  
alma-learning losses less than 9  compared to the possi-
ble upper bound of the optimal solution 
moving on to fairness  figure 2c depicts the gini coeffi-
3computation time limit 20 minutes 
greedy
msrac
alma
alma-learning
|p| = 20
6 16  − 18 35 
0 00  − 8 12 
0 59  − 8 69 
0 16  − 4 84 
|p| = 30
1 72  − 14 92 
1 47  − 10 81 
0 50  − 8 40 
0 47  − 1 94 
|p| = 50
3 29  − 12 52 
0 00  − 15 74 
0 07  − 7 34 
0 05  − 1 68 
|p| = 100
0 19  − 9 32 
0 00  − 8 52 
0 15  − 4 10 
0 14  − 1 43 
|e| = 280
0 00  − 15 31 
0 00  − 22 07 
0 00  − 10 81 
0 00  − 8 84 
table 4  range of the average loss     in social welfare compared to
the ibm ilog cp optimizer for increasing number of participants 
p  |e| ∈  10  100    the final line corresponds to the loss compared
to the upper bound for the optimal solution for the large test-case
with |p| = 100  |e| = 280  figure 2b  
cient for the large  hand-crafted instances  |p| = 100  |e|
up to 280   alma-learning exhibits low inequality  up to
−9 5  lower than alma in certain cases  it is worth noting 
though  that the fairness improvement is not as pronounced
as in section 3 1  in the meeting scheduling problem  all of
the employed algorithms exhibit high fairness  due to the na-
ture of the problem  every participant has multiple meetings
to schedule  contrary to only being matched to a single re-
source   all of which are drawn from the same distribution 
thus  as you increase the number of meetings to be sched-
uled  the fairness naturally improves 
supplementary material 
we refer the reader to  danassis
et al   2021  for a detailed model of the meeting scheduling
problem  implementation details and hyper-parameters  and
additional results for both sections 3 1  3 2 
4
conclusion
the next technological revolution will be interwoven to the
proliferation of intelligent systems  to truly allow for scal-
able solutions  we need to shift from traditional approaches to
multi-agent solutions  ideally run on-device  in this paper  we
present a novel learning algorithm  alma-learning   which
exhibits such properties  to tackle a central challenge in multi-
agent systems  finding an optimal allocation between agents 
i e   computing a maximum-weight matching  we prove that
alma-learning converges  and provide a thorough empiri-
cal evaluation in a variety of synthetic scenarios and a real-
world meeting scheduling problem  alma-learning is able
to quickly  in as little as 64 training steps  reach allocations
of high social welfare  less than 5  loss  and fairness 
proceedings of the thirtieth    ijcai-21 
130
 references
 auer et al   2002  peter auer  nicolo cesa-bianchi  yoav freund 
and robert e schapire 
the nonstochastic multiarmed bandit
problem  siam journal on computing  32 1  48–77  2002 
 bellman  2013  richard bellman  dynamic programming  courier
corporation  2013 
 benhassine and ho  2007  ahlem benhassine and tu bao ho 
an agent-based approach to solve dynamic meeting scheduling
problems with preferences  engineering applications of artifi-
cial intelligence  20 6  857–873  2007 
 b¨urger et al   2012  mathias
b¨urger 
giuseppe
notarstefano 
francesco bullo  and frank allg¨ower 
a distributed simplex
algorithm for degenerate linear programs and multi-agent
assignments  automatica  2012 
 busoniu et al   2008  l  busoniu  r  babuska  and b  de schutter 
a comprehensive survey of multiagent reinforcement learning 
trans  sys  man cyber part c  38 2  156–172  march 2008 
 crawford and veloso  2005  elisabeth
crawford
and
manuela
veloso  learning dynamic preferences in multi-agent meeting
scheduling  in ieee/wic/acm international conference on in-
telligent agent technology  pages 487–490  ieee  2005 
 danassis et al   2019a  panayiotis danassis  aris filos-ratsikas 
and boi faltings 
anytime heuristic for weighted match-
ing through altruism-inspired behavior 
in proceedings of the
twenty-eighth international joint conference on artificial intel-
ligence  ijcai-19  pages 215–222  2019 
 danassis et al   2019b  panayiotis danassis  marija sakota  aris
filos-ratsikas  and boi faltings  putting ridesharing to the test 
efficient and scalable solutions and the power of dynamic vehicle
relocation  arxiv  1912 08066  2019 
 danassis et al   2020  panayiotis danassis  aleksei triastcyn  and
boi faltings  differential privacy meets maximum-weight match-
ing  2020 
 danassis et al   2021  panayiotis danassis  florian wiedemair 
and boi faltings  improving multi-agent coordination by learning
to estimate contention  http //arxiv org/abs/2105 04027  2021 
 elkin  2004  michael elkin  distributed approximation  a survey 
sigact news  35 4  40–57  december 2004 
 franzin et al   2002  maria sole franzin  ec freuder  f rossi  and
r wallace 
multi-agent meeting scheduling with preferences 
efficiency  privacy loss  and solution quality  in proceedings of
the aaai workshop on preference in ai and cp  2002 
 geng and cassandras  2013  yanfeng geng and christos g  cas-
sandras  new  smart parking  system based on resource alloca-
tion and reservations  ieee transactions on intelligent trans-
portation systems  2013 
 gini  1912  corrado gini  variabilit a e mutabilit a  reprinted in
memorie di metodologica statistica  ed  pizetti e  salvemini  t  
rome  libreria eredi virgilio veschi  1912 
 giordani et al   2010  stefano
giordani 
marin
lujak 
and
francesco martinelli  a distributed algorithm for the multi-robot
task allocation problem  in international conference on indus-
trial  engineering and other applications of applied intelligent
systems  springer  2010 
 gunn and anderson  2013  tyler gunn and john anderson  dy-
namic heterogeneous team formation for robotic urban search
and rescue  procedia computer science  2013  the 4th int  conf 
on ambient systems  networks and technologies  ant 2013  
the 3rd int  conf  on sustainable energy information technology
 seit-2013  
 hassine et al   2004  ahlem ben hassine  xavier defago  and
tu bao ho  agent-based approach to dynamic meeting schedul-
ing problems  in proceedings of the third international joint
conference on autonomous agents and multiagent systems - vol-
ume 3  aamas  04  2004 
 ismail and sun  2017  sarah ismail and liang sun  decentralized
hungarian-based approach for fast and scalable task allocation  in
2017 int  conf  on unmanned aircraft systems  icuas   2017 
 kuhn et al   2016  fabian kuhn  thomas moscibroda  and roger
wattenhofer  local computation  lower and upper bounds  j 
acm  63 2  17 1–17 44  march 2016 
 kuhn  1955  harold w  kuhn  the hungarian method for the as-
signment problem  naval research logistics  1955 
 laborie et al   2018  philippe laborie 
j erˆome rogerie 
paul
shaw  and petr vil ım  ibm ilog cp optimizer for scheduling  con-
straints  23 2  210–250  2018 
 lov asz and plummer  2009  l aszl o lov asz and michael d  plum-
mer 
matching theory  volume 367 
american mathematical
soc   2009 
 maheswaran et al   2004  rajiv t  maheswaran  milind tambe 
emma bowring  jonathan p  pearce  and pradeep varakantham 
taking dcop to the real world  efficient complete solutions for
distributed multi-event scheduling  in proceedings of the third
international joint conference on autonomous agents and mul-
tiagent systems - volume 1  aamas  04  2004 
 munkres  1957  james munkres  algorithms for the assignment
and transportation problems  journal of the society for industrial
and applied mathematics  1957 
 nigam and srivastava  2020  archana nigam and sanjay srivas-
tava  oddms  online distributed dynamic meeting scheduler  in
simon fong  nilanjan dey  and amit joshi  editors  ict analysis
and applications  singapore  2020  springer singapore 
 ottens et al   2017  brammert ottens  christos dimitrakakis  and
boi faltings 
duct  an upper confidence bound approach to
distributed constraint optimization problems  acm trans  intell 
syst  technol   8 5   july 2017 
 romano and nunamaker  2001  nicholas c romano and jay f
nunamaker  meeting analysis  findings from research and prac-
tice  in proceedings of the 34th annual hawaii international con-
ference on system sciences  pages 13–pp  ieee  2001 
 stone et al   2010  peter stone  gal a  kaminka  sarit kraus  and
jeffrey s  rosenschein  ad hoc autonomous agent teams  col-
laboration without pre-coordination  in aaai  2010 
 su  2015  hsin-hao su  algorithms for fundamental problems in
computer networks  phd thesis  university of michigan  2015 
 varakantham et al   2012  pradeep
varakantham 
shih-fen
cheng  geoff gordon  and asrar ahmed  decision support for
agent populations in uncertain and congested environments  in
proceedings of the twenty-sixth aaai conference on artificial
intelligence  aaai 12  aaai press  2012 
 zavlanos et al   2008  michael m  zavlanos  leonid spesivtsev 
and george j pappas  a distributed auction algorithm for the as-
signment problem  in decision and control  2008  ieee  2008 
 zunino and campo  2009  alejandro zunino and marcelo campo 
chronos  a multi-agent system for distributed automatic meeting
scheduling  expert systems with applications  2009 
proceedings of the thirtieth    ijcai-21 
131
 "
None,2021,https-www-ijcai-org-proceedings-2021-0019-pdf,Multi-Agent Intention Progression with Black-Box Agents,"Michael Dann, Yuan Yao, Brian Logan, John Thangarajah",None,https://www.ijcai.org/proceedings/2021/0019.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0019-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0019-pdf.pdf,"multi-agent intention progression with black-box agents
michael dann1∗   yuan yao2   brian logan3 and john thangarajah1
1rmit university
2zhejiang university of technology
3utrecht university
 michael dann  john thangarajah @rmit edu au  yaoyuan@zjut edu cn  b s logan@uu nl
abstract
we propose a new approach to intention progres-
sion in multi-agent settings where other agents are
effectively black boxes  that is  while their goals
are known  the precise programs used to achieve
these goals are not known  in our approach  agents
use an abstraction of their own program called a
partially-ordered goal-plan tree  pgpt  to sched-
ule their intentions and predict the actions of other
agents 
we show how a pgpt can be derived
from the program of a bdi agent  and present
an approach based on monte carlo tree search
 mcts  for scheduling an agent s intentions using
pgpts  we evaluate our pgpt-based approach in
cooperative  selfish and adversarial multi-agent set-
tings  and show that it out-performs mcts-based
scheduling where agents assume that other agents
have the same program as themselves 
1
introduction
a key problem for an autonomous intelligent agent with mul-
tiple goals is  what to do next   which goal the agent should
be trying to achieve  and which means it should use to achieve
it 
in the popular belief-desire-intention  bdi  approach
to agents  rao and georgeff  1992   this problem is termed
the intention progression problem  ipp   logan et al   2017  
bdi agents are characterised by the concepts of beliefs  goals
and plans 
beliefs represent the information an agent has
about itself  the environment and about other agents  goals
are states the agent would like to bring about 
plans are
recipes for achieving goals  and are composed of primitive
actions that directly change the state of the environment  and
subgoals which are achieved by their own plans  an intention
is formed when the agent commits to achieving a  top-level 
goal utilising a particular plan  a key feature of bdi agents
is their ability to simultaneously pursue multiple intentions 
in order to do so  at each deliberation cycle  the agent must
select which of its multiple intentions it should progress  i e  
intention selection  and  if the next step within the selected
∗contact author  full source code and an extended version of
this paper containing further experimental details is available at 
https //github com/mchldann/pgpt ijcai 
intention is a subgoal  select the best plan to achieve it  i e  
plan selection   these two choices together form the intention
progression problem 
a number of approaches to various aspects of the inten-
tion progression problem have been proposed in the litera-
ture  including summary-information-based  si   thangara-
jah et al   2003  thangarajah and padgham  2011   coverage-
based  cb   waters et al   2014  waters et al   2015  and
monte-carlo tree search-based  mcts   yao et al   2014 
yao and logan  2016  yao et al   2016c  approaches  much
of this work has focussed on the single agent setting  where
the key challenge is the interleaving of steps in plans in dif-
ferent intentions to avoid conflicts  i e   when the execution
of a step in one plan makes the execution of a step in another
concurrently executing plan impossible  recently  dann et
al   2020  extended the mcts-based approach in  yao and
logan  2016  to a multi-agent setting  in the multi-agent set-
ting  how an agent progresses its intentions has implications
for both the achievement of its own goals and the achieve-
ment of the goals of other agents  e g   if the agent selects
a plan that consumes a resource necessary for another agent
to achieve its goal  while the  intention-aware  approach in
 dann et al   2020  was shown to out-perform non-intention-
aware scheduling such as  yao and logan  2016   it assumes
that agents have access to the plans comprising the other
agents  programs for achieving their goals  this is reason-
able in multi-agent systems where the agents are co-designed 
but is less plausible for agents that are not co-designed  i e  
where each agent may have no information about the plans
used by other agents 
one way of overcoming this limitation is for an agent to
assume that the programs of other agents are the same as its
own when progressing its intentions  however  such  ego-
centric  scheduling can give rise to conflicts if the plans used
by other agents achieve subgoals in a different order  or order
primitive actions differently  for example  an agent a1 whose
plan to achieve the goal of doing the household chores con-
tains subgoals to do the laundry  vacuum  and wash the dishes
 in that order  may assume that another agent  a2  tasked with
doing the chores will wash the dishes last  this may result in
a conflict when a1 tries to use the sink to prepare lunch  if the
program of a2 has washing the dishes as the first subgoal 
a more reasonable assumption to make is that the other
agents use a similar program  but may order some subtasks
proceedings of the thirtieth    ijcai-21 
132
 differently  in this paper  we propose a new approach to in-
tention progression in a multi-agent setting  in which agents
schedule their intentions and predict the actions of other
agents based on an abstraction of their own program called a
partially-ordered goal-plan tree  pgpt   a partially-ordered
goal-plan tree is an alternating and-or tree that captures only
the execution order implied by the dependency relationships
inherent in the agent s program  we show how a pgpt can
be derived from the program of a bdi agent  and how the
mcts-based approach in  dann et al   2020  can be extended
and adapted to schedule an agent s intentions using pgpts
in multi-agent settings  as in  dann et al   2020   we evalu-
ate our approach in cooperative  selfish and adversarial multi-
agent settings  our results indicate that pgpt-based schedul-
ing out-performs mcts-based scheduling where agents as-
sume that other agents behave in the same way as themselves 
2
preliminaries
in this section  we introduce and define the basic elements
of our approach to intention progression  including beliefs 
goals  actions and plans 
beliefs and goals 
the agent s beliefs represent the infor-
mation an agent has about itself  the environment and about
other agents 
the agent s belief base b is a finite set of
ground literals  proposition p or its negation ¬p  
b =  b1          bn 
b is updated at each cycle to incorporate the agent s current
percepts  we assume that b is consistent  i e   there is no
p such that p  ¬p ∈ b  the agent s top-level goals repre-
sent states of affairs that the agent wants to bring about  the
agent s goal base g is a finite set of ground literals 
g =  g1          gm 
g does not need to be consistent  e g   conflicting goals may
be achieved at different times 
actions and plans 
an agent can perform a set of primitive
actions in the environment  a =  a1          ak   the precon-
ditions of an action ai are a set of literals φ = pre ai  that
must be true before the execution of the action  and the post-
conditions of the action are a set of literals ψ = post ai  that
are true after the execution of the action  we assume that ac-
tions are deterministic  if the preconditions of an action hold 
then the postconditions of the action hold after executing the
action  an action is executable given the agent s beliefs b if
b |= φ  if the agent attempts to execute an action whose pre-
conditions do not hold  the action fails  cannot be executed  
to achieve the agent s goals  actions are organised into
plans  each goal g is associated with a set of plans π1          πn
that achieve g 
each plan πi is of the form g   χ ←
s1          sm  where χ = pre πi  is a set of literals specify-
ing the context condition which must be true for πi to begin
execution  and s1          sm is a sequence of steps which are ei-
ther actions or subgoals  a plan can be executed if its context
condition holds  the precondition of each of its action steps
holds when the step is reached  and each of its subgoal steps
has an executable plan when the subgoal is reached  note
that  for many agent plans  it is only necessary that b |= χ
for the plan to be executable  as the postcondition of an ac-
tion step or achievement of a subgoal si may establish the
precondition of an action step sj or the context condition of
plans for a subgoal step sj  i < j  this is termed a p-effect
 preparatory effect  in  thangarajah et al   2003  
a goal g is considered achieved  and any intention with
g as top-level goal is dropped  if  and only if  all the steps
in a plan πi for g are successfully executed  we abuse no-
tation slightly  and define the preconditions of a goal  g  as
the union of the context conditions of the plans to achieve
g  i e   pre g  = �
πi pre πi   this is a technical device and
only one of the plans for g must be executable for g to be
 executable    the postcondition of a goal  g  is g itself  i e  
g = post g   we denote by p the set of plans comprising the
agent s program 
3
partially-ordered goal-plan trees
in much of the work on intention progression in bdi agents 
the relationships between the plans  actions and subgoals that
can be used to achieve a goal are represented by a hierarchical
structure termed a goal-plan tree  gpt   thangarajah et al  
2003  thangarajah and padgham  2011  yao et al   2016a  
the root of a goal-plan tree is a goal-node representing a top-
level goal  and its children are plan nodes representing the
potential plans to achieve the top-level goal  the agent only
needs to execute one of these plans to achieve the goal  hence 
the goal nodes are viewed as or-nodes  the children of a plan
node are the action and subgoal nodes corresponding to the
steps in the plan body  the agent needs to execute all of the
child nodes to achieve the goal  thus  plan nodes are viewed
as ordered and-nodes  each subgoal node has its associated
plans as children  giving rise to a tree structure representing
all possible ways an agent can achieve the top-level goal 
while goal-plan trees have been shown to be effective for
single-agent scheduling  yao et al   2016c  yao and logan 
2016  and multi-agent scheduling where the program s  of
the other agents are known  dann et al   2020   they are less
appropriate in multi-agent settings where the agents are not
co-designed  we therefore propose a new approach to multi-
agent intention progression in which agents schedule their in-
tentions based on abstractions of their own programs which
we call partially-ordered goal-plan trees  pgpt   a partially-
ordered goal-plan tree is an alternating and-or tree that cap-
tures only the execution order implied by the p-effects in the
agent s program  rather than strictly adhering to the textual
order of steps specified by the developer  more precisely 
definition 1  partially-ordered goal-plan tree  a pgpt
t =  g  p  a  g0  children   ≺π  π ∈ p   is an alternat-
ing and-or tree where 
• elements of g∪a are or-nodes  goals and actions 1 and
elements of p are and-nodes  plans  
• g0 ∈ g is the root  top-level goal  
1viewing action nodes as or-nodes without children is a technical
device to simplify the definition 
proceedings of the thirtieth    ijcai-21 
133
 • children   g ∪ p −→ 2g∪p ∪a is a function assigning
a  non-empty  set of children to  non-leaf  nodes in the
tree 
• or-nodes only have children in p 
for g
∈
g 
children g  ⊆ p 
• and-nodes only have children in g ∪ a 
for π
∈
p  children π  ⊆ g ∪ a  and
• the set children π  for each π ∈ p is partially ordered
by ≺π 
an execution of a pgpt is a traversal of the tree starting at
the root  g0  if visiting an or-node  the next step in the traver-
sal is to pick any child and visit it  if in an and-node  visit
each child in an order consistent with ≺π of the children  a
pgpt t is executable if there is a traversal of t that is exe-
cutable  given pre- and post conditions of plans and actions 
from some initial state of the environment  i e   if we start in
this initial state and update it with the postconditions of each
visited action  then the pre-conditions of the next action or
context condition of the next plan in the traversal hold in the
updated state 
a pgpt t for a top-level goal g0 and agent program π =
 π1          πn  can be built recursively as follows  set g0 to be
the root of the tree  or-node  and add as children g0  and-
nodes pi for each plan πi = gi   χi ← si
1          si
m where
gi = g0  for each plan and-node  pi  add as children pi  or-
nodes for the each of the steps of πi  si
1          si
m  to establish
the ordering ≺πi of the or-nodes representing the steps in πi 
we proceed as follows 
• for each pair of steps si
j  si
k  1 ≤ j < k ≤ m  if a
literal l ∈ post si
j  ∩ pre si
k  then si
j ≺πi si
k  i e   if
si
j establishes a precondition for si
k  we add an ordering
constraint that si
j must be executed before si
k  if si
k is a
subgoal  before any step in whichever plan is selected to
achieve si
k  
• if there is a step si
c  1 ≤ c < j  or k < c ≤ m  where the
complementary literal ∼ l ∈ post si
c   we add si
c ≺πi
si
j  respectively si
k ≺πi si
c  to ≺πi to ensure that the
execution of si
c does not clobber l 
finally  for each or-node where the corresponding step sj
is a  sub goal  gj  we recurse  i e   we add as children gj 
and-nodes for each plan to achieve gj  and so on 
for example  given the agent program π =  π0  π1  π2  
π0   g0   χ0 ← g1  a0  a1
π1   g0   χ1 ← a3  a4  a5
π2   g1   χ2 ← a2
where χ0 = c0 ∧ c2  χ1 = c1  χ2 = c2  pre a0  = c0 
pre a1  = c3 ∧ c4  pre a2  = c2  pre a3  = c1  pre a4  =
c1  pre a5  = c6  post a0  = c3  post a1  = c5  post a2  =
c4  post a3  = c6  post a4  = c7  post a5  = c8  we can
generate the pgpt shown in figure 1  in figure 1  solid ar-
rows connect goal nodes to the plan nodes that achieve the
goal  e g   p0 and p1 are two plan nodes to achieve the goal
g0
p0
g1
a0
a1
p2
a2
p1
a4
a3
a5
figure 1  an example of a pgpt 
node g0  dashed arrows connect plan nodes to their execu-
tion steps  e g   g1  a0  a1 are the execution steps of plan node
p0  and double arrows indicate the partial ordering relation-
ship between steps in a plan  e g   action a0 must be executed
before action a1  as one of the preconditions of a1  c3  is es-
tablished by the postcondition of a0 
4
scheduling approach
we now present a new approach to multi-agent intention
scheduling based on pgpts  which we call ib  we adapt and
extend dann et al  s  2020  monte-carlo tree search-based
approach  ia  which was shown to outperform several com-
peting methods in a multi-agent setting  we first briefly recall
the approach of dann et al  before explaining how we adapt
it to handle partial ordering 
4 1
intention scheduling with mcts
the monte carlo tree search  mcts  algorithm is a well-
known heuristic search algorithm which has been shown to be
successful in many multiplayer games  browne et al   2012  
the algorithm works by building a search tree incrementally
through simulation  starting at the root node  a tree policy
is used to navigate to a leaf node  the tree policy strives to
achieve a balance between exploration  traversing nodes that
have rarely been visited  and exploitation  favouring steps
that previously led to strong returns   the leaf node is then
expanded  and a rollout policy is used to simulate steps until
a terminal state is reached  each node visited during the tree
policy phase then has its average return updated based on the
outcome of the simulation 
early work on applying mcts to intention scheduling
 yao et al   2014  yao et al   2016c  yao and logan  2016 
focussed on the single-agent setting  more recently  dann
et al   2020  extended the approach to multi-agent schedul-
ing by introducing a payoff matrix  pij  for each  i  j  pair 
the payoff matrix captures the assumed payoffs that agent i
receives upon the completion of agent j s goals  for exam-
ple  allied agents are modelled by defining positive payoffs
for both the agent s own goals and those of its allies  while
adversarial agents are modelled by defining positive payoffs
for the agent s own goals but negative payoffs for the goals of
other agents  in the scheduler s underlying mcts algorithm 
the payoff matrix is used to calculate the return for each agent
at the end of a rollout 
proceedings of the thirtieth    ijcai-21 
134
 4 2
ib  multi-agent scheduling with pgpts
the scheduling approach taken in this work builds directly
upon the ia scheduler of dann et al   2020   however  in
contrast to ia  we do not assume that the order in which other
agents will execute their plans is known  rather  we assume
that other agents may act in any way that is consistent with
the ordering ≺ implied by the p-effects in the agent s own
program  consequently  we model agents  intentions using
pgpts  rather than gpts 
in the mcts algorithm  this change impacts both node ex-
pansion and the rollout policy  node expansion now adds
branches for all steps that are executable according to the
pgpt s ordering constraints 
similarly  the rollout policy
chooses uniformly from amongst all such steps  this growth
in the branching factor is illustrated in figure 2  which shows
a pgpt  left  and one possible linearisation of it into a gpt
 right   suppose that nodes g0 and p0 have so far been tra-
versed  in the  totally ordered  gpt  the only step now exe-
cutable is a0  providing its pre-conditions hold   however  in
the partially ordered pgpt  both a0 and g1 are executable 
an important consideration here is the amount of time
taken to compute the set of executable steps  since this cal-
culation is performed repeatedly during simulation  in dann
et al  s  2020  gpt-based approach this is straightforward 
since gpts are totally ordered  one can just store a pointer
to the next node in each gpt  however  in our pgpt-based
approach  it is necessary to calculate the set of all steps that
are executable according to the ordering constraints  this can
be achieved by recursing through the tree structure  though
such recursion is relatively expensive  instead  we propose
a more efficient method  first  for each node in each pgpt 
we store a list of its unmet temporal dependencies  i e  the
set of steps that  according to ≺  must be executed before the
node in question  then  each time a node is executed  we
loop through its temporal dependents  i e   nodes that must
come afterwards according to ≺  and update their lists of un-
met dependencies  if all dependencies of a node are now met 
it is added to a list of candidate steps  finally  the candidate
steps are filtered to ensure that all other logical requirements
are met  in particular  to be executable  a candidate step must
have its pre-conditions met  in addition  if the agent previ-
ously executed a plan or goal node  we force it to continue ex-
ecuting children of that node until it executes an action node 
the rationale here is that it makes little sense for an agent to
commit to a plan or goal until it has executed an underlying
action  pseudocode for the computation of candidate steps
can be found in the extended version of the paper 
g0
p0
a0
g1
a2
p2
a1
g0
p0
a0
g1
a2
p2
a1
�
�
figure 2  a pgpt  left  and one possible linearisation  right  
5
evaluation
in this section  we evaluate our approach to multi-agent
scheduling  we compare the performance of the ib pgpt-
based scheduler with ia  the gpt-based approach presented
in  dann et al   2020   and random pgpt and gpt-based
schedulers  as in  dann et al   2020   we consider three set-
tings  fully aware  where agents know all the top-level goals
of other agents  termed  full vision  in  dann et al   2020   
partially aware  where agents know half of the other agents 
top-level goals   partial vision    and unaware  where agents
know none of the other agents  top-level goals   na¨ıve    in
each setting  the agents are assumed to have plans for the top-
level goals they are aware of  however the ia agents sched-
ule on the assumption that the other agents have the same
plans  and hence the same gpts  for these goals as them-
selves  that is  unlike  dann et al   2020   the plans/gpts
of the other agents are not available to the agents  the other
agents are essentially  black boxes  
as in  dann et al   2020   we assume that the agents share
the same model of actions  i e   an action has the same pre-
and postconditions for each agent   we also assume that each
agent has the same set of actions available  while this is not
true in all cases  it holds for a large class of applications  e g  
where the agents interact with their environment via an api 
while pgpts can be derived from agent programs as ex-
plained in section 3  in the interests of generality and sim-
plicity  we implemented a pgpt generator that is capable
of generating  synthetic  pgpts corresponding to agent pro-
grams of varying complexity  and hence multi-agent schedul-
ing problems of varying difficulty   the pgpt generator is
based on the gpt generator developed for the intention pro-
gression competition 2  a detailed description of the pgpt
generator can be found in the extended version of the paper  
to generate the gpts used by the ia agents  for each ia
agent in each trial we generated a random linearisation of the
pgpt used by the pgpt-based agent  similarly to figure 2 
different linearisations will typically achieve subgoals and
execute steps in a different order  but each ordering is con-
sistent with ≺  each linearisation thus corresponds to a gpt
derived from a valid program for the task  e g   written by a
different agent developer  all agents are therefore effectively
using different programs for a given top-level goal  but while
the pgpt agents abstract their programs into pgpts  the ia
agents schedule and predict the next steps of other agents us-
ing the gpts corresponding to the their own programs 
the random pgpt and gpt-based schedulers behave iden-
tically to the mcts rollout policies used by ib and ia  re-
spectively  that is  they select uniformly from the set of all
executable steps  e  the only difference between the pgpt
and gpt-based schedulers is that  for the gpt-based sched-
uler  e is calculated via a linearisation of the agent s pgpts 
similarly to ia  and thus its behaviour is more restricted 
the generated pgpts had a depth of 5  each subgoal had
two corresponding plans  with each plan containing three ac-
tions and one subgoal  except the lowest-level plans  which
contained three actions only   for each trial  12 gpts were
generated  with 6 assigned to each agent  thus  for example 
2available from intentionprogression org 
proceedings of the thirtieth    ijcai-21 
135
 the partially-aware ib schedulers had access to 9 pgpts  6
for their own goals and 3 for the goals of the other agent   the
partially-aware ia schedulers likewise had access to 9 gpts 
but the 3 corresponding to the goals of the other agent were
derived from their own programs for those goals   the full
set of pgpts contained 80 environment variables  where this
figure was chosen to yield enough scheduling clashes that the
tasks were non-trivial  yet not excessively difficult 
we evaluated our approach under the three multi-agent set-
tings considered by dann et al   2020   allied  neutral and
adversarial  in each of these settings there are two agents 
the aim in the allied setting is to maximise the total num-
ber of team goals achieved  in the neutral setting  the aim is
to maximise the agent s own goal attainment and disregard
the number of goals achieved by the external agent  i e  to act
selfishly  in the adversarial setting  the aim is to maximise the
agent s own goal attainment while minimising the number of
goals achieved by the external agent  accordingly  we use the
following scoring methodology 
• allied  we report own goals   ally goals  each agent is
assigned 6 pgpts  so the possible score range is  0  12  
• neutral  we report own goals only  so the possible score
range is  0  6  
• adversarial  we report own goals − opponent goals  so
the possible score range is  -6  6  
the results of these experiments are provided in tables 1 
2 and 3  with scores averaged over 500 randomly generated
pgpt forests  cell values indicate the score achieved by the
agent from that row when partnered with the agent above 
the numeric suffixes to the mcts-based agents  names indi-
cate their level of awareness of the other agent s goals  100 =
fully aware  50 = partially aware  0 = unaware  
a striking feature of the results is their consistency  in each
setting and for each partner agent type  the fully aware ib
scheduler performed best  given that ib is more flexible than
ia  both in terms of its ability to act and its ability to model
the behaviour of other agents  this may seem unsurprising 
however  recall from section 4 2 that the mcts search tree
has a greater branching factor under ib than under ia  since
ia and ib were afforded the same number of simulated roll-
outs this means that the rollouts were spread more thinly un-
der ib  with nodes  average returns calculated from fewer
samples  ib s consistent edge over ia shows that this trade-
off was worthwhile  i e   ib s greater uncertainty about the
return was more than compensated for by its extra flexibility 
note that the significance of certain results is best appre-
ciated by considering the number of goals unachieved  for
example  in the allied setting  the  ia 100  ia 100  partner-
ship averaged 10 157 goals  while  ib 100  ib 100  aver-
aged 11 475  an increase of only ≈1 3 goals  however  since
the best possible score in this setting is 12  this represents a
72  reduction in unachieved goals 
the unaware agents ia 0 and ib 0 have no knowledge of
other agents  goals or the plans used to achieve those goals 
and so are unable to make any predictions about the next ac-
tion of the other agent  as such  they are essentially doing
single-agent scheduling with no consideration of the other
agents  intentions  which is the baseline case in  dann et al  
2020   the small improvement in performance of ib 0 over
ia 0 in the allied and neutral settings  4  increase in goals
achieved by two ib 0 agents over two ia 0 agents in the al-
lied setting  and 3  in neutral  is attributable to the ib agents
having more flexibility in the order in which actions are exe-
ally
rand pgpt
rand gpt
ib 100
ib 50
ib 0
ia 100
ia 50
ia 0
rand pgpt
4 023
3 771
9 103
7 743
5 766
7 744
6 864
5 631
rand gpt
3 771
3 634
8 327
7 400
5 850
7 292
6 649
5 416
ib 100
9 103
8 327
11 475
11 158
10 779
10 904
10 661
10 247
ib 50
7 743
7 400
11 158
10 446
9 342
10 342
9 895
9 204
ib 0
5 766
5 850
10 779
9 342
7 180
9 522
8 673
7 097
ia 100
7 744
7 292
10 904
10 342
9 522
10 157
9 928
9 357
total score
ia 50
6 864
6 649
10 661
9 895
8 673
9 928
9 343
8 466
ia 0
5 631
5 416
10 247
9 204
7 097
9 357
8 466
6 897
table 1  allied setting  the best total team score with each ally type is bolded 
other scheduler
rand pgpt
rand gpt
ib 100
ib 50
ib 0
ia 100
ia 50
ia 0
rand pgpt
2 001
2 070
2 034
1 989
2 017
2 029
2 000
2 102
rand gpt
1 723
1 866
1 793
1 781
1 830
1 840
1 883
1 863
ib 100
5 537
5 211
5 339
5 299
5 548
5 098
5 098
5 282
ib 50
4 677
4 631
4 510
4 419
4 621
4 452
4 468
4 568
ib 0
3 738
3 907
3 510
3 475
3 585
3 621
3 592
3 787
ia 100
4 577
4 538
4 418
4 355
4 643
4 455
4 418
4 562
score
ia 50
4 007
4 171
3 898
3 795
4 025
3 945
3 852
4 175
ia 0
3 457
3 669
3 319
3 115
3 235
3 282
3 296
3 479
table 2  neutral setting  the best results achieved with respect to the other scheduler type are bolded 
proceedings of the thirtieth    ijcai-21 
136
 opponent
rand pgpt
rand gpt
ib 100
ib 50
ib 0
ia 100
ia 50
ia 0
rand pgpt
0 000
0 224
-4 839
-3 001
-1 767
-3 429
-2 274
-1 270
rand gpt
-0 224
0 000
-4 205
-2 951
-2 094
-3 395
-2 605
-1 690
ib 100
4 839
4 205
0 000
2 280
4 317
1 666
2 542
3 735
ib 50
3 001
2 951
-2 280
0 000
2 050
-0 471
0 746
2 058
ib 0
1 767
2 094
-4 317
-2 050
0 000
-2 604
-0 977
0 652
ia 100
3 429
3 395
-1 666
0 471
2 604
0 000
1 280
2 672
net score
ia 50
2 274
2 605
-2 542
-0 746
0 977
-1 280
0 000
1 489
ia 0
1 270
1 690
-3 735
-2 058
-0 652
-2 672
-1 489
0 000
table 3  adversarial setting  the best net score  own goals minus opponent goals  achieved against each opponent type is bolded 
cuted  this allows each ib agent to avoid more conflicts be-
tween its own intentions  however  neither the ib 0 nor the
ia 0 agents can effectively avoid conflicts with the intentions
of the other agent  since these are unknown   as the results
show  as the agents  knowledge of the other agent s goals in-
creases  the performance of both ib and ia increases  but ib
is better able to exploit the additional information  for exam-
ple  in the neutral setting  two ib 100 agents can achieve 20 
more goals than two ia 100 agents because they are better at
avoiding conflicts with the other agent s intentions  indeed
the total number of goals achieved by two ib 100 agents in
the neutral setting is greater than two ia 100 agents in the al-
lied setting  i e   two  selfish  ib 100 agents are more effec-
tive than two cooperating ia 100 agents  a similar pattern is
seen when ib is paired with other schedulers 
the experiments also show that a key result from  dann et
al   2020  holds in the black-box setting  namely  both ia and
ib improve as they are afforded more knowledge of the other
agent s goals  demonstrating that they truly are intention-
aware  in the extended version of the paper  we break the
allied setting scores down into own goals and ally goals 
from this  it is evident that the fully aware ib scheduler was
the most effective at helping its partner achieve goals  similar
to findings in  dann et al   2020  
6
related work
the first mcts-based approach to intention scheduling with
bdi agents was that of yao et al   2014   they used a variant
of mcts called single-player mcts  schadd et al   2012  to
schedule the intentions of a single agent at the level of plans
rather than actions  the work was later extended to schedul-
ing intentions at the action level  yao and logan  2016   with
deadlines  yao et al   2016b  and for exploiting synergies
 yao et al   2016c   this work on single agent scheduling
formed the basis for the work by dann et al   2020  on using
mcts-based scheduling for multi-agent settings 
there have been other approaches to scheduling intentions 
for example  the early work by thangarajah et al   2002 
2003  2011  and clement et al   2007  1999  2000  used the
notion of summary information to look-ahead at the inten-
tion structures and schedule accordingly  whilst thangarajah
et al  focussed on scheduling the intentions of a single agent
in bdi setting using gpts  clement et al  focussed on cen-
trally scheduling the intentions of multiple agents in planning
agents using hierarchical task networks  htns  
another line of work considers incorporating an htn
planner into a bdi agent language  thus providing the ability
to look-ahead and find solutions to ensure the successful exe-
cution of an intention  when necessary  sardi˜na et al   2006 
de silva  2017   whilst these methods focus on finding solu-
tions to achieve a single intention and do not take into account
interactions with other concurrent intentions  it could be pos-
sible to incorporate the work of clement et al   mentioned
above  to centrally schedule intentions of bdi agents 
conversely  de silva  2018  considers incorporating ideas
from the bdi paradigm into htn planning  so as to support
interleaved deliberation  acting  and failure recovery  again 
however  this work focuses only on the pursuit of single goals 
finally  we note the coverage-based approach as used in
 thangarajah et al   2012  waters et al   2014  waters et al  
2015   where the probability of executing plans to achieve
a goal in the different possible states of the environment is
used to schedule intentions  the intuition is to progress the
intention that has the highest probability of becoming non-
executable in future states  in contrast to our work  this ap-
proach has so far been applied only to single-agent settings 
beyond the differences already mentioned  unlike our ap-
proach  all of the above methods require full knowledge of
the agents  intention structures 
7
conclusion
in this paper we proposed an approach to multi-agent inten-
tion progression in environments where the other agents are
not co-designed  and thus their precise program s  are un-
known  we evaluated our approach in allied  neutral and ad-
versarial settings  and showed that it outperformed mcts-
based scheduling where agents assume that other agents will
execute plans in the same order as themselves  a possible
direction for future work is to further relax the assumptions
regarding other agents  e g  by assuming that other agents will
pursue some subset of all known goals in the environment  but
where this subset must be inferred at runtime 
acknowledgments
yuan yao was supported by national natural science foun-
dation of china  61906169  and zhejiang provincial natural
science foundation of china  lq19f030009  
proceedings of the thirtieth    ijcai-21 
137
 references
 browne et al   2012  cameron b browne  edward pow-
ley  daniel whitehouse  simon m lucas  peter i cowl-
ing  philipp rohlfshagen  stephen tavener  diego perez 
spyridon samothrakis  and simon colton  a survey of
monte carlo tree search methods  ieee transactions on
computational intelligence and ai in games  4 1  1–43 
2012 
 clement and durfee  1999  bradley j  clement and ed-
mund h  durfee  theory for coordinating concurrent hi-
erarchical planning agents using summary information  in
proceedings of the sixteenth national conference on arti-
ficial intelligence  aaai 1999   pages 495–502  1999 
 clement and durfee  2000  bradley j  clement and ed-
mund h  durfee 
performance of coordinating concur-
rent hierarchical planning agents using summary informa-
tion  in proceedings of the 4th international conference
on multi-agent systems  pages 373–374  2000 
 clement et al   2007  bradley j  clement  edmund h  dur-
fee  and anthony c  barrett  abstract reasoning for plan-
ning and coordination  journal of artificial intelligence
research  28 453–515  2007 
 dann et al   2020  michael dann  john thangarajah  yuan
yao  and brian logan 
intention-aware multiagent
scheduling 
in b  an  n  yorke-smith  a  el fal-
lah seghrouchni  and g  sukthankar  editors  proceed-
ings of the 19th international conference on autonomous
agents and multiagent systems  aamas 2020   pages
285–293  2020 
 de silva  2017  lavindra de silva 
bdi agent reasoning
with guidance from htn recipes  in proceedings of the
16th conference on autonomous agents and multiagent
systems  aamas 2017   pages 759–767  2017 
 de silva  2018  lavindra de silva  htn acting  a formal-
ism and an algorithm  in proceedings of the 17th interna-
tional conference on autonomous agents and multiagent
systems  aamas 2018   pages 363–371  2018 
 logan et al   2017  brian logan  john thangarajah  and
neil yorke-smith  progressing intention progresson  a
call for a goal-plan tree contest 
in proceedings of the
16th international conference on autonomous agents and
multiagent systems  aamas 2017   pages 768–772  2017 
 rao and georgeff  1992  anand s  rao and michael p 
georgeff  an abstract architecture for rational agents  in
proceedings of the 3rd international conference on prin-
ciples of knowledge representation and reasoning  kr
1992   pages 439–449  1992 
 sardi˜na et al   2006  sebastian sardi˜na  lavindra de silva 
and lin padgham 
hierarchical planning in bdi agent
programming languages  a formal approach 
in pro-
ceedings of the 5th international joint conference on au-
tonomous agents and multiagent systems  aamas 2006  
pages 1001–1008  2006 
 schadd et al   2012  maarten p  d  schadd  mark h  m 
winands  mandy j  w  tak  and jos w  h  m  uiterwijk 
single-player monte-carlo tree search for samegame 
knowledge-based systems  34 3–11  2012 
 thangarajah and padgham  2011  john
thangarajah
and
lin padgham  computationally effective reasoning about
goal interactions 
journal of automated reasoning 
47 1  17–56  2011 
 thangarajah et al   2002  john
thangarajah 
michael
winikoff  lin padgham  and klaus fischer 
avoiding
resource conflicts in intelligent agents  in proceedings of
the 15th european conference on artificial intelligence
 ecai 2002   pages 18–22  2002 
 thangarajah et al   2003  john thangarajah  lin padgham 
and michael winikoff  detecting   avoiding interference
between goals in intelligent agents  in proceedings of the
eighteenth international joint conference on artificial in-
telligence  ijcai-03   pages 721–726  2003 
 thangarajah et al   2012  john thangarajah  sebastian sar-
dina  and lin padgham 
measuring plan coverage and
overlap for agent reasoning  in proceedings of the 11th
international conference on autonomous agents and mul-
tiagent systems  aamas 2012   pages 1049–1056  2012 
 waters et al   2014  max waters  lin padgham  and sebas-
tian sardina  evaluating coverage based intention selec-
tion  in proceedings of the 13th international conference
on autonomous agents and multi-agent systems  aamas
2014   pages 957–964  2014 
 waters et al   2015  max waters  lin padgham  and sebas-
tian sardi˜na  improving domain-independent intention se-
lection in bdi systems  autonomous agents and multi-
agent systems  29 4  683–717  2015 
 yao and logan  2016  yuan yao and brian logan  action-
level intention selection for bdi agents  in proceedings of
the 15th international conference on autonomous agents
and multiagent systems  pages 1227–1236  2016 
 yao et al   2014  yuan
yao 
brian
logan 
and
john
thangarajah 
sp-mcts-based intention scheduling for
bdi agents  in proceedings of the 21st european con-
ference on artificial intelligence  ecai 2014   2014 
 yao et al   2016a  yuan yao  lavindra de silva  and brian
logan 
reasoning about the executability of goal-plan
trees  in proceedings of the 4th international workshop
on engineering multi-agent systems  emas 2016   pages
181–196  singapore  may 2016 
 yao et al   2016b  yuan yao 
brian logan 
and john
thangarajah  intention selection with deadlines  in pro-
ceedings of the 22nd european conference on artificial
intelligence  ecai-2016   pages 1700–1701  2016 
 yao et al   2016c  yuan yao 
brian logan 
and john
thangarajah  robust execution of bdi agent programs by
exploiting synergies between intentions  in proceedings
of the thirtieth aaai conference on artificial intelligence
 aaai 2016   pages 2558–2565  2016 
proceedings of the thirtieth    ijcai-21 
138
 "
None,2021,https-www-ijcai-org-proceedings-2021-0020-pdf,The Parameterized Complexity of Connected Fair Division,"Argyrios Deligkas, Eduard Eiben, Robert Ganian, Thekla Hamm, Sebastian Ordyniak",None,https://www.ijcai.org/proceedings/2021/0020.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0020-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0020-pdf.pdf,"the parameterized complexity of connected fair division
argyrios deligkas1   eduard eiben1   robert ganian2   thekla hamm2   sebastian ordyniak3
1royal holloway  university of london  uk
2tu wien  austria
3university of leeds  uk
 argyrios deligkas eduard eiben @rhul ac uk   rganian  thekla hamm sordyniak @gmail com
abstract
we study the connected fair division problem
 cfd   which generalizes the fundamental problem
of fairly allocating resources to agents by requiring
that the items allocated to each agent form a con-
nected subgraph in a provided item graph g  we
expand on previous results by providing a com-
prehensive complexity-theoretic understanding of
cfd based on new algorithms and lower bounds
while taking into account several well-established
notions of fairness  proportionality  envy-freeness 
ef1 and efx  in particular  we show that to achieve
tractability  one needs to restrict both the agents and
the item graph in a meaningful way  we design xp-
algorithms for the problem parameterized by  1 
clique-width of g plus the number of agents and
 2  treewidth of g plus the number of agent types 
along with corresponding lower bounds  finally 
with respect to the restrictions considered here  we
show that to achieve fixed-parameter tractability
one needs to not only use a more restrictive parame-
terization of g  but also include the maximum item
valuation as an additional parameter 
1
introduction
the task of allocating a set of indivisible resources among
participating agents under a suitably defined notion of  fair-
ness  represents a core research topic in the area of compu-
tational social choice  bouveret and lang  2008  bouveret
et al   2016  brams and taylor  1996  
the classical fair
resource allocation problem that arises from this task  fair
division  has been extensively studied in the literature  and
we now have a fairly good understanding of the problem s
complexity under a variety of notions of fairness  bouveret
and lang  2008  budish  2011  caragiannis et al   2019 
plaut and roughgarden  2020   however  in many settings
it is desirable to ensure that the allocation respects a certain
connectivity restriction on the items allocated to each individ-
ual agent—this is easy to substantiate when the items repre-
sent immovable assets  e g   when allocating rooms in a new
building to university departments  or in case of corporate
split-ups   but can also arise when the items are intangible
 e g   when allocating duties organized in a mind map  
motivated by these considerations  in 2017 bouveret et
al   2017  developed a natural framework designed to cap-
ture this additional aspect of fair resource allocation  given
 1  a set of items represented as vertices of an input graph
g   2  a set a of agents  and  3  a set u of valuation func-
tions specifying the utility of each item for each agent  deter-
mine if there exists an allocation of items to agents which is
 i  fair  under a suitable notion of fairness   and  ii  main-
tains the connectivity of items assigned to each individual
agent  they called this the ϕ-connected fair division
problem  ϕ-cfd   where ϕ specifies the desired notion
of fairness  their initial results inspired a body of follow-
up work on the model involving  e g   the incorporation of
chores  aziz et al   2019   computing so-called maximin
share allocations  greco and scarcello  2020   pareto-optimal
allocations  igarashi and peters  2019  and conditions guaran-
teeing the existence of fair allocations  bil o et al   2019  
in spite of these developments  our understanding of the
precise boundaries of computational tractability of ϕ-cfd
remains somewhat limited to date  on one hand  the prob-
lem is a generalization of the classical ϕ-fair division
problem  bouveret and lang  2008  bouveret et al   2016  
since the problems coincide if g is restricted to the class of
complete graphs  but g will not be complete in the typi-
cal use case of the model—on the contrary  one may often
expect it to be rather sparse  and that is why already the orig-
inal work introducing the model  bouveret et al   2017  ini-
tiated the investigation of the problem under various restric-
tions of the structure of g  unfortunately  the algorithmic
and lower-bound results provided in the original paper as well
as in follow-up works  aziz et al   2019  bil o et al   2019 
igarashi and peters  2019  leave a wide gap between the
known boundaries of tractability and the easiest intractable
cases  this provides a rather unsatisfactory contrast between
ϕ-cfd and other variants of the resource allocation prob-
lem  for which we often already have complete complex-
ity landscapes  bliem et al   2016a  bredereck et al   2018 
eiben et al   2020  
1 1
contribution
we perform a comprehensive and in-depth study of the
complexity of ϕ-cfd with the aim of identifying the pre-
cise cut-off between tractable and intractable classes of in-
stances  in line with previous work on complexity-theoretic
proceedings of the thirtieth    ijcai-21 
139
 aspects of computational social choice  chen et al   2017 
chen et al   2018  eiben et al   2018b  and especially fair
allocation  bliem et al   2016a  eiben et al   2020   we em-
ploy the parameterized complexity paradigm to obtain a more
fine-grained understanding of the  in- tractability of ϕ-cfd
under various restrictions  we focus our analysis on combi-
nations of restrictions on two core components of ϕ-cfd 
the structure of the item graph  g  and the set of agents
 a   moreover  all of our results are designed to take into ac-
count several perspectives on fairness  proportionality  envy-
freeness  and also two prominent relaxations of envy-freeness
called ef1 and efx
 bil o et al   2019  budish  2011 
caragiannis et al   2019  plaut and roughgarden  2020  
we begin by observing that the problem remains hope-
lessly intractable even under extreme restrictions to all other
aspects of the input if the valuation function u is allowed
to use binary encodings  proposition 1  
that is why
we proceed—in line with several previous works in the
field  eiben et al   2020  greco and scarcello  2020 —under
the reasonable assumption that u is encoded in unary 
but even under this assumption  we show that the prob-
lem remains surprisingly difficult when one does not apply at
least some restriction to the set a of agents  indeed  while it
was already known that proportional cfd is polynomial-time
tractable on graphs which are stars  bouveret et al   2017   we
prove that for all other considered notions of fairness cfd
remains np-hard even on stars  theorem 2   moreover  pro-
portional cfd remains np-hard on paths  bouveret et al  
2017   on the other hand  restricting the set of agents alone
does not lead to tractability either—even if we only consider
instances with just two agents  proposition 3   so in order to
achieve tractability  one needs to assume restrictions on g as
well as on a  a single-dimensional approach is not viable 
with the above considerations in mind  we can now pro-
ceed to our main algorithmic contributions  first  if we pa-
rameterize by the number of agents  then we can solve ϕ-
cfd for all considered fairness notions on an extremely
broad range of graphs—not only on trees and more gener-
ally graphs of bounded treewidth  but also on dense graph
classes such as complete graphs  complete bipartite graphs 
cographs  distance-hereditary graphs  and many others  we
formalize this by showing that ϕ-cfd is xp-tractable 1 when
parameterized by |a| plus the clique-width of g  theorem 4  
clique-width is among the most general structural parame-
ters of graphs and has found widespread algorithmic applica-
tions  bliem et al   2016b  eiben et al   2018a  
second  we consider a less severe restriction on a  instead
of parameterizing by the number of agents  we parameterize
only by the number of agent types  which are maximal sets
of agents with identical preferences  agent types have been
considered as a middle-ground between unrestricted agents
and a bounded number of agents in various contexts  eiben
et al   2020  nguyen and rothe  2020   and also in the origi-
nal work that introduced ϕ-cfd  bouveret et al   2017   as
our second algorithmic contribution  we show that ϕ-cfd
is xp-tractable when parameterized by the number of agent
1a problem is xp-tractable when parameterized by k if it can be
solved in polynomial time for every fixed  constant value of k 
types plus the treewidth of g  theorem 6   we justify the
use of treewidth instead of clique-width when parameterizing
by the number of agent types by providing a corresponding
lower bound  theorem 9   furthermore  theorem 6 directly
generalizes the results of bouveret et al   2017   who gave
xp-algorithms for proportional and envy-free cfd on paths
parameterized by the number of agent types 
both theorem 4 and theorem 6 are obtained by dynamic
programming along the respective decompositions  an ap-
proach that is often used for these structural parameters 
while handling proportional and envy-free allocations in this
way is not too difficult  dealing with connectivity in the defi-
nitions of ef1 and efx requires a more careful treatment  in
particular  our algorithms for these two variants require ideas
that are not needed for  e g   solving maximin cfd parame-
terized by treewidth  greco and scarcello  2020  
while both of these algorithmic results are  tight  in the
sense that it is not reasonable to hope for a relaxation of the
requirements on a and or g  the notion of tractability used
here—xp-tractability—is weaker than the one which is typ-
ically hoped for in the parameterized setting  notably fixed-
parameter tractability  as our next result  theorem 7   we not
only rule out the fixed-parameter tractability of the problem
in both considered settings  but even for much more restricted
cases  in particular  even when parameterizing by the number
of agents plus the vertex cover number of g  this essentially
rules out the fixed-parameter tractability of the problem un-
der any even remotely reasonable restriction on a and g  for
unary valuation functions u  surprisingly  the problem ex-
hibits the same complexity-theoretic behavior under extreme
restrictions  |a| plus vertex cover number  as when using pa-
rameterizations that are very relaxed  |a| plus clique-width 
or the number of agent types plus treewidth  
but is it really impossible to obtain non-degenerate fixed-
parameter algorithms for ϕ-cfd  the final part of our paper
focuses on this question and provides a more positive outlook
on the problem s complexity  first of all  one may observe
that theorem 4 provides fixed-parameter algorithms for envy-
free and proportional cfd in the case where |a| is bounded
by a fixed constant  but what happens if—instead of impos-
ing extreme restrictions on the number of agents—we also
parameterize by the maximum valuation in u  in theorem 8
we establish the fixed-parameter tractability of ϕ-cfd pa-
rameterized by the maximum valuation in u  the number of
agent types  and the vertex cover number of g  as our last
contribution  theorem 9  we show that this final algorithmic
result cannot be strengthened to more general graph parame-
ters such as treewidth  or even deletion distance to stars  
overall  our results provide a comprehensive understand-
ing of the precise boundaries of tractability of ϕ-cfd  intro-
duce three novel algorithms for the problem  and show that
the problem exhibits a rather diverse complexity-theoretic be-
havior  an overview is provided in figure 1 
2
preliminaries
for an integer i  we let  i  =  1  2          i   we refer to the
handbook by diestel  2012  for standard graph terminology 
we also refer to the standard books for a basic overview of
proceedings of the thirtieth    ijcai-21 
140
 proposition 1
parameterized by
np-hard
unrestricted
restricted
unrestricted
binary
unary
agents
graph
valuations
theorem 2
np-hard
proposition 3
np-hard
theorem 8
vertex cover   no  of types   max valuation
fpt parameterized by
number of agents
xp parameterized by
cliquewidth   no  of agents
theorem 4
number of agent types
treewidth   no  of types
xp parameterized by
theorem 6
w 1 -hard parameterized by
deletion to stars   no  of agents   max valuation
theorem 9
figure 1  a mind-map of our results 
parameterized complexity theory  cygan et al   2015   and
assume that readers are aware of the complexity classes fpt 
xp and w 1   readers interested in the full details of the-
orem 6 are also expected to have a basic understanding of
treewidth and nice tree-decompositions  cygan et al   2015  
clique-width 
let k be a positive integer  a k-graph is a
graph whose vertices are labeled by  k   we denote by γ v 
the label of the vertex v  we call the k-graph consisting of
exactly one vertex v  say  labeled by α  an initial k-graph
and denote it by α v   the clique-width of a graph g is the
smallest integer k such that g can be constructed from initial
k-graphs by means of repeated application of the following
three operations 
1  disjoint union  denoted ⊕  
2  relabeling  changing all labels α to β  denoted pα→β  
3  edge insertion  adding an edge between each vertex
labeled α and each vertex labeled β  α ̸= β  de-
noted ηα β  
a k-expression tree  courcelle et al   2000  is a rooted tree
representation of how the three operations are used to con-
struct a given graph  specifically  the k-expression tree repre-
sents each α v  as a leaf  each ⊕ operator as an ⊕ node with
two children  and each pα→β or ηβ α operator by a corre-
sponding node with a single child  it is known that an approx-
imately optimal k-expression tree can be computed in fixed-
parameter time  oum and seymour  2006   and that every
graph class of bounded treewidth has bounded clique-width 
3
the connected fair division problem
an instance of the connected fair division problem
 cfd   bil o et al   2019  bouveret et al   2017  consists of
an undirected graph g =  v  e   a set a of n agents  and
a valuation function ui   v → n for every agent i ∈ a 
in this setting  every vertex v ∈ v corresponds to an item 
we follow the standard assumption in the literature  and we
assume that the agents have additive valuations  hence for ev-
ery x ⊆ v and every i ∈ a we have ui x  = �
v∈x ui v  
agents i and j have the same type if for every v ∈ v it holds
ui v  = uj v   we denote the set of all agent types by a 
the type of an agent i is then the agent type a ∈ a such that
i ∈ a  hence for an agent type a ∈ a we denote by ua the
valuation function such that ua = ui for all i ∈ a 
an allocation of items is a tuple π =  πi i∈a such that
 1  for all i ∈ a the set πi ⊆ v and the subgraph g πi 
of g induced by πi is connected   2  �
i∈a πi = v   and  3 
for all i  j ∈ a such that i ̸= j we have πi ∩ πj = ∅  we
also define a partial allocation for a subset a′ of a as a tuple
π =  πi i∈a′ satisfying  3   we say that the bundle πi is
assigned to agent i  we will focus on fair allocations  under
several different fairness notions  bouveret et al   2017  bil o
et al   2019   given a bundle πi  let τi =  v ∈ πi | g πi \
 v   is connected    an allocation π1  π2          πn is 
• proportional  prop  if ui πi  ≥ ui v  
n
  for every i ∈ a 
• envy-free  ef  if ui πi  ≥ ui πj   for every i  j ∈ a 
• envy-free up to one item  ef1  if ui πi  ≥ ui πj  −
maxv∈τj ui v   for every i  j ∈ a 
• envy-free up to any item  efx  if ui πi  ≥ ui πj  −
minv∈τj ui v   for every i  j ∈ a 
for a fairness criterion ϕ ∈ f =  prop  ef  ef1  efx  
ϕ-cfd asks whether there exists an allocation satisfying ϕ 
we remark that here we consider the decision version of the
problem for formal reasons only  each of our algorithms can
also output a suitable allocation if one exists 
as our first course of action  we show that even extremely
restricted instances of ϕ-cfd remain intractable if the valu-
ation functions ui are encoded in binary 
proposition 1  for all ϕ ∈ f  ϕ-cfd is np-hard when val-
uation functions are encoded in binary even when restricted
to instances having treewidth at most 2 and where |a| = 2 
and u1 = u2 
in view of proposition 1  from now on we assume every
valuation to be encoded in unary  which also implies that all
numbers are upper-bounded by the size of the instance  
4
the futility of singular restrictions
since our aim is to determine when exactly ϕ-cfd can be
solved efficiently  the most natural thing to do is consider
whether the problem becomes tractable if either the graph or
the set of agents is restricted  in this section  we show that
such a single-dimensional approach does not lead to tractabil-
ity even on highly restricted classes of instances  note that
np-hardness of ef-cfd on stars was already shown in  bou-
veret et al   2017  using a similar idea  albeit without the re-
striction on the valuations 
theorem 2  for all ϕ ∈ f \  prop   ϕ-cfd is np-hard
even when restricted to instances in which g is a star  with
binary valuations 
proof sketch  for each of the three fairness notions  we give a
reduction from independent set on 4-regular graphs  let
 h  k  be a 4-regular instance of independent set  where
h has n vertices and accordingly m = 2n edges  the vertices
of h are indexed as  v1          vn   and the edges of h are
indexed as  e1          em   we construct an instance of cfd
proceedings of the thirtieth    ijcai-21 
141
 as follows  define g to be a star with m   k leaves  we
denote the center of the star as c  and call the first n leaves of
the star vertex leaves  x =  x1          xn   and the remaining
leaves of the star dummy leaves  d =  d1          dm−n k  
let a =  m   1   to complete the reduction  it suffices to
define the valuation functions  in this exposition we present
only the function for ϕ = ef  let um 1 y  = 1 if y = c
and 0 otherwise  and for each other i ∈  m  let ui y  = 1 if
y ∈ d ∪  vj | vj ∈ ei  and 0 otherwise 
finally  we provide some intuition to help verify the re-
duction 
consider an independent set w of size k in h 
for an arbitrary rooted spanning tree of h  denote for each
v
∈
v  h  the unique edge e
∈
e h  which corre-
sponds to an arc toward v in the rooted spanning tree by ev 
let  f1          fm−n 1 k  be an enumeration of all edges in
e h  \  ev | v ∈ w   this gives rise to a connected re-
source allocation π1          πm 1 for the constructed instance
by letting πm 1 =  c  ∪  xi | vi ∈ w   and for i ∈  m 
πi =
� xj 
if ei = evj for vj ∈ v  h  \ w
dj
if ei = fj 
our second hardness result is considerably easier  and is
obtained by a reduction from a problem called equitable
connected partition  ecp   enciso et al   2009  
proposition 3  for every ϕ ∈ f  ϕ-cfd is np-hard when
restricted to instances where |a| = 2  and u1 = u2 = 1 
5
solving instances with few agents
while proposition 3 rules out the existence of efficient algo-
rithms for all instances with bounded n  here we show that
the situation changes as long as we parameterize by n plus
the clique-width of g  denoted cw g  
theorem 4  for every ϕ ∈ f  ϕ-cfd is in xp parameter-
ized by the clique-width and the number of agents 
proof sketch  it is known that an approximate k-expression
tree with at most k2|v  g | nodes can be computed in fixed-
parameter time  kant e and rao  2013  oum and seymour 
2006   so it suffices to decide ϕ-cfd when such a k-
expression tree t with k = f cw g   for g is provided 
let i =  g  a   ui i∈a  be an instance of ϕ-cfd for
ϕ ∈ f  let t be a node of t  and recall that t is one of
the following four types of nodes  α v   ⊕  ηα β or pα→β 
let tt be the subtree of t rooted at t  and let gt be the k-
graph  which is a subgraph of g  defined by the k-expression
tree tt  for instance  if r is the root of t then gr = g  and
for each leaf t in t it holds that gt is a graph with a single
labeled vertex 
the high-level idea of the algorithm is to compute a set
of records for every node t ∈ v  t  and to compute these
records in a leaf-to-root fashion  each record will represent
one way an allocation of g can intersect with the vertices of
gt  and the information contained in the records at the root
of t is sufficient to determine which of the allocations are
connected and satisfy the considered fairness notion 
formally for each node t of t we define a record
  ρi i∈a   µi i∈a   νi i∈a  consisting for each i ∈ a of the
following components 
 1  ρi
∈
22 k  ×  0  1   such that for each partial
allocation ˜π corresponding to   ρi i∈a   µi i∈a   νi i∈a 
the set ρi 0  contains l
⊆
 k  if and only if gt ˜πi 
contains a connected component labeled precisely by la-
bels in l 
formally 
ρi 0 
=
 �
w∈c λ w  
|
c is a connected component of ˜πi   the number ρi 1  = 1
if and only if ˜πi is connected 
 2  µi
∈
zn is a vector of n integers  in which
µi
j describes the additive valuation under uj of all items
assigned to i by any partial allocation corresponding to
  ρi i∈a   µi i∈a   νi i∈a  
 3  νi is only included when ϕ ∈  ef1  efx   it then for
each agent j ̸= i describes the valuation under uj of an item
v which would be omitted from the bundle of agent i in or-
der to determine whether j envies i in any partial allocation ˜π
corresponding to   ρi i∈a   µi i∈a   νi i∈a   this is neces-
sary to ensure that connectedness is maintained when remov-
ing v from the bundle of i in the root of t  for this purpose
νi   a × 22 k  ×  0  1  → z is a partial function for which
νi j  k  x  describes the valuation under uj of an item v ∈ ˜πi
that j would remove from ˜πi such that k =  �
w∈c λ w   |
c is a connected component of ˜πi \ v   and ˜πi \ v  is con-
nected if and only if x = 1  where ˜π is any partial allocation ˜π
corresponding to   ρi i∈a   µi i∈a   νi i∈a   for a technical
reason  if ˜πi =  v   then νi j   ∅   1  = uj v  
note that the number of records at each node is easily
bounded by 2 2k 1 n · |i|n 1 n22k 1  for ϕ ∈  ef1  efx 
and even 2 2k 1 n · |i|n for ϕ ∈  prop  ef   which is xp
parameterized by cw g  and n  to unify the dealing with
ef1 and efx  we let obj = min if ϕ = efx and obj = max
if ϕ = ef1  we say a record   ρi i∈a   µi i∈a   νi i∈a  is
valid whenever there is an allocation π of v  gt  to a such
that for every i ∈ a  all of the following hold 
 r1  ρi 0  =  �
w∈c λ w   | c is a connected component
of πi  and ρi 1  = 1 if and only if πi is connected 
 r2  for all j ∈  n   µi
j = �
v∈πi uj v  
 r3  for all j ∈ a and all k ⊆ 2 k   it holds that νi j  k  0  =
obj  uj v  | v ∈ πi ∧ k =  �
w∈c λ w   | c ̸=
πi \  v  is a connected component of πi \  v      fur-
thermore  for all j ∈ a and all λ ⊆ 2 k   it holds that
νi j   λ   1  = obj  uj v  | v ∈ πi ∧  πi \  v 
is a connected  ∧ λ
=
�
w∈πi\ v  λ w     and
νi j  k  1  = undefined otherwise 
for a node t ∈ v  t  we denote by r t  the set of all valid
records for t  with this setup there is a ϕ-cfd for  g =
 v  g   a   ui i∈a  if and only if at the root r of t  r r 
contains a valid record   ρi i∈a   µi i∈a   νi i∈a  such that
all of the following hold 
 r 1  for all i ∈ a and for all j ∈ a   a  µi
i ≥
�
v∈v ui v 
n
if we are considering the fairness notion ϕ = prop   b 
µi
i ≥ µj
i if we are considering the fairness notion ϕ =
ef   c  µi
i ≥ µj
i − obj  νj i   λ   1  | λ ⊆ 2 k    if we
are considering a fairness notion ϕ ∈  ef1  efx  
this condition ensures that the allocation satisfies the
desired fairness notion 
proceedings of the thirtieth    ijcai-21 
142
  r 2  for all i ∈ a  ρi =   λ   1  for some λ ∈ 2 k   this
condition ensures that the allocation is connected 
both of these conditions can be checked in o∗ 2k -time for
each record  thus  to complete the proof it suffices to show
how to compute the set of valid records r t  at each node t
of t  given the sets of valid records of the children of t in t 
this can be done by giving a construction for each
case of t 
using this we can compute the set of all valid records r t 
for every node t of t using a leaves-to-root dynamic program 
achieving a final runtime of |i|o n22k   for ef1 and efx and
of 2o 2kn  ·|i|o n  for envy-free and proportional cfd 
corollary 5  if |a| is bounded by a constant  envy-free and
proportional cfd is fpt parameterized by clique-width 
6
instances with few agent types
given the state of the art  the obvious question that arises
from theorem 4 is whether we can relax the parameteriza-
tion by n to a less restrictive parameterization  notably to the
number of agent types  we show later in theorem 9 that this
is not possible  i e   for each ϕ ∈ f  ϕ-cfd is np-hard even
for one agent type and clique-width three 
on the other hand  as the main result for this section 
we show that offsetting the  less restrictive  agent type pa-
rameter by a  more restrictive  graph parameter—notably
treewidth—gives rise to an xp-algorithm for the problem 
theorem 6  for each ϕ ∈ f  ϕ-cfd is in xp when param-
eterized by the treewidth and the number of agent types 
proof sketch  we show the theorem using a bottom-up dy-
namic programming algorithm along a tree decomposition
 t  χ  of the graph g  as usual the main challenge lies in
the definition of the records that we keep for each node t of
t  where each record models an equivalence class of partial
solutions for the sub-instance induced by the items in gt  i e  
the graph g induced by all items contained in bags in the sub-
tree rooted at t  to illustrate the main ideas behind the def-
inition of our records  consider a solution  i e   an allocation
π =  πi i∈a for the whole instance i =  g  a   ui i∈a  of
ϕ-cfd for ϕ ∈ f  then  our records need to keep informa-
tion about all bundles that contain at least some items from
gt  there are two main types of those bundles   1  bundles
that do not contain any items from the current bag χ t   and
 2  bundles that do contain some item from χ t   note that
the former bundles must be completely contained in gt  be-
cause the tree decomposition does not allow any edges from
gt−χ t  to g−gt   while the latter bundles can still contain
items from g − gt and therefore do not even need to be con-
nected inside gt  now  let at be the set of all agents being
assigned a bundle of type  2   let af
t be the set of all agents
being assigned a bundle of type  1   and let ai
t be the set of
all other agents  i e   all agents whose bundles do not intersect
with gt  for the agents in af
t   remember the following 
• the number of agents in af
t of type a for every a ∈
a  this is important to ensure that we do not falsely
assume more agents of a certain type than are present in
the instance 
• we need to ensure that no agent in af
t envies an agent
in at ∪ ai
t   i e   any agent that will be assigned items
at a later stage of the algorithm  for this it suffices to
remember the minimum value w r t  ua of any bundle
assigned to an agent in af
t of type a for every a ∈ a 
note that this is only necessary if ϕ ∈  ef  ef1  efx 
and can be skipped if ϕ = prop 
• we need to ensure that no agent in at ∪ ai
t envies an
agent in af
t   depending on ϕ ∈  ef  ef1  efx   it
will be sufficient to remember the following for every
agent type a ∈ a   1  the maximum value w r t  ua of
any bundle assigned to an agent in af
t  if ϕ = ef   and
 2  the maximum value w r t  ua of any bundle assigned
to an agent in i ∈ af
t after removing an item in π′
i of
maximum/minimum value w r t  ua  if ϕ is ef1/efx  
while the above information for the agents in af
t is still
fairly straightforward  the real challenge arises for the agents
in at  since we additionally have to take into account the
connectivity of their bundles and in the case of ef1 and
efx even the connectivity of their bundles after removing
an item  consider an agent i ∈ at  then  gt πi  is not
necessarily connected  it might only become connected be-
cause of the items in πi \ gt   which means that we have
to remember not only which items of πi are in χ t  but also
the partition of those items into components of gt πi   in
the case of ϕ /∈  ef1  efx   this together with the value
of the partial bundle πi ∩ gt w r t  ua for every agent type
a ∈ a would actually be sufficient information  however  if
ϕ ∈  ef1  efx  this does not suffice since in order to en-
sure that no agent in af
t ∪ ai
t will envy i  we also need to
know the minimum/maximum value of any item that could
potentially be removed from the bundle πi  since whether
or not an item in πi ∩ gt can be removed can really only
be determined once we know the whole bundle πi  we need
to store the minimum/maximum value of any item whose re-
moval results in a certain refinement of the current partition of
πi∩χ t  into components of gt πi   in other words  for every
 refinement  of the current partition of πi ∩ χ t  into compo-
nents of gt πi   we store the minimum/maximum value of
any item r whose removal results in this refinement  defined
by gt πi \  r    
7
towards fixed-parameter tractability
from the perspective of parameterized complexity  the most
obvious question that arises from theorem 4 and 6 is whether
one can obtain fixed-parameter algorithms under these pa-
rameterizations  we firmly answer this question by provid-
ing an involved reduction that establishes the w 1 -hardness
of ϕ-cfd even under significantly stronger restrictions than
those required by either of the two algorithms 
theorem 7  for each ϕ ∈ f  ϕ-cfd is w 1 -hard parame-
terized by the vertex cover number and the number of agents 
even when all agents have identical valuations 
proof sketch  we provide reductions from the w 1 -hard
unary bin packing problem  jansen et al   2013   given a
set of items with unary values and a set of k bins  determine if
it is possible to allocate items to bins so that each bin receives
proceedings of the thirtieth    ijcai-21 
143
 the same total value  which we call b  on a high-level  the re-
duction constructs an instance of ϕ-cfd consisting of k  or 
for technical reasons that arise in the case of ef1  2k  agents
and a complete bipartite graph with k bin-vertices on one side
each representing one bin  and item-vertices on the other side
each representing one item  we then attach one  or  in the
case of ef1  two  leaves to the bin-vertices and set the valua-
tions in a way which ensures that every fair allocation in the
constructed cfd instance will force k agents to each receive
one bin-vertex along with items whose values sum up pre-
cisely to b  this yields a correspondence between solutions
to the ϕ-cfd instance and solutions to the original unary
bin packing instance  completing the reduction 
but given theorem 7  is it really impossible to obtain fixed-
parameter algorithms for ϕ-cfd  corollary 5 noted that if
the number of agents is bounded by a constant  proportional
as well as envy-free cfd becomes fixed-parameter tractable
parameterized by clique-width alone  however  if we do not
wish to restrict the agents or their types in this manner  the
problem can be shown to be fixed-parameter tractable if we
additionally restrict the number of valuations of a vertex  i e  
val = | ui v |i ∈  n   v ∈ v  | 
theorem 8  for each ϕ ∈ f  ϕ-cfd is fixed-parameter
tractable when parameterized by the vertex cover number  the
number of agent types  and val 
proof sketch  let  g =  v  e   a   ui i∈a  be an instance
of ϕ-cfd  we compute a minimum size vertex cover s of g
in time o 2vcn g  · |v |   cygan et al   2015  
since ng v  ⊆ s for each v ∈ v  g \s  there are at most
2|s|val equivalent items where for v  w ∈ v  g  \ s  v ∼ w
if and only if ng v  = ng w  and for all a ∈ a every agent
a ∈ a values v and w equally  an equivalence class under
this relation is completely determined by its neighborhood in
g and its valuations for each agent type  now  the algorithm
proceeds in two steps  in the first step we branch on a possible
structure of the sought solution  as will be described below 
for each leaf of the branching tree  we then construct an in-
stance of ilp with a number of variables bounded in our pa-
rameters  such an instance of ilp can then be solved in fpt
time parameterized by the number of variables by lenstra s
well-known algorithm  lenstra jr   1983  
in the branching step we first branch on which vertices of s
are allocated to which agent  up to identical agent types   and
denote the set of agents that receive at least one item of s as
as  moreover  for each s′ ⊆ s and each possible valuation
q for agent types in val| a |  we branch on whether an agent
in a \ as is allocated an item in the equivalence class deter-
mined by s′ and q  for each a ∈ as we branch on whether
a receives zero  one  or more items in the equivalence class
determined by s′ and q  for each agent type we also branch
on whether any agent of that type receives no items 
at this point  it is not difficult to ensure that each pursued
branch remains connected  to complete the allocation  we
use the aforementioned ilp formulation to ensure  1  the ex-
act number of items of each equivalence class assigned to
each agent a ∈ as  when a is branched to receive at least
two such items and  2  the exact number of agents in a \ as
of each agent type that receive an item in a specific equiva-
lence class  if it is branched that there is at least one agent of
the agent type receiving an item in that equivalence class 
as our last result  we show that even using val as an ad-
ditional parameter does not allow us to lift fixed-parameter
tractability to structural parameters such as treewidth 
theorem 9  for each ϕ ∈ f  ϕ-cfd is w 1 -hard when
parameterized by the deletion distance to stars and the num-
ber of agents even when val = 1  moreover  ϕ-cfd is np
-hard even when val = 1 and the clique-width is at most 3 
proof sketch  we prove our result via a reduction from
unary bin packing  ubp   let  i   si i∈i  k  b  be an
instance of unary bin packing such that �
i∈i si = k·b 
we construct an instance  g =  v  e   a   ui i∈a  of cfd
such that for all i ∈ a and all v ∈ v it holds ui v  = 1
and let u = ui for all i ∈ a 
we let |a| = k 
for
each bin j ∈  k   we create a bin vertex bj  for each item
i ∈ i  we create si many vertices  one  center  vertex ci
and si − 1 many  pendant  vertices p1
i   p2
i           psi−1
i
and
we denote si =  ci  p1
i           psi−1
i
   the center vertex ci
is adjacent to all pendant vertices p1
i           psi−1
i
and all bin
vertices b1          bk  note that each connected component of
g −  bj | j ∈  k   is a star of size si for some i ∈ i 
given a solution  i1  i2          ik  for ubp  we let πi =
 bi  ∪ �
j∈ii sj it is easy to see that u πi  = 1   b and the
allocation is fair  on the other hand  given a fair allocation
π  we can observe that  since |v | = k ·  b   1   π has to be
also prop  to finish the proof  we show that every agent has
to get exactly one bin vertex and if an agent gets the center
vertex ci  then she gets all vertices in the star si 
8
concluding remarks
interestingly  it turns out that the complexity-theoretic behav-
ior of cfd seems to exhibit very little variation between the
different considered notions of fairness  it is also surpris-
ing that while fairly unrestrictive parameterizations suffice
to guarantee xp-tractability  as showcased by theorems 4
and 6   disproportionately stronger restrictions are required to
achieve fixed-parameter tractability  see theorems 7 and 8  
we remark that all of our algorithms can also be straightfor-
wardly extended to handle chores  i e   negative evaluations  
while our results provide a detailed understanding of the
complexity of cfd for several of the most prominent no-
tions of fairness studied in the literature  there remain open
questions that deserve further attention  one such question is
that it is currently not known whether ef1 allocations always
exist on path graphs  bil o et al   2019  
acknowledgments
ganian and hamm gracefully acknowledge support from
the austrian science fund  fwf  projects p31336 and
y1329  
hamm also acknowledges support from fwf
 project w1255-n23   ordyniak acknowledges the support
by the epsrc  ep/v00252x/1  
proceedings of the thirtieth    ijcai-21 
144
 references
 aziz et al   2019  haris aziz  ioannis caragiannis  ayumi
igarashi  and toby walsh  fair allocation of indivisible
goods and chores  in ijcai 2019  pages 53–59  ijcai org 
2019 
 bil o et al   2019  vittorio
bil o 
ioannis
caragiannis 
michele flammini  ayumi igarashi  gianpiero monaco 
dominik peters  cosimo vinci  and william s  zwicker 
almost envy-free allocations with connected bundles  in
itcs 2019  pages 14 1–14 21  dagstuhl  2019 
 bliem et al   2016a  bernhard bliem  robert bredereck 
and rolf niedermeier  complexity of efficient and envy-
free resource allocation  few agents  resources  or utility
levels  in ijcai 2016  pages 102–108  ijcai/aaai press 
2016 
 bliem et al   2016b  bernhard bliem  sebastian ordyniak 
and stefan woltran  clique-width and directed width mea-
sures for answer-set programming  in ecai 2016  pages
1105–1113  ios press  2016 
 bouveret and lang  2008  sylvain bouveret and j erˆome
lang  efficiency and envy-freeness in fair division of in-
divisible goods  logical representation and complexity  j 
artif  intell  res   32 525–564  2008 
 bouveret et al   2016  sylvain bouveret  yann chevaleyre 
and nicolas maudet  fair allocation of indivisible goods 
in handbook of computational social choice  pages 284–
310  cambridge university press  2016 
 bouveret et al   2017  sylvain
bouveret 
katar ına
cechl arov a  edith elkind  ayumi igarashi  and do-
minik peters  fair division of a graph  in ijcai 2017 
pages 135–141  ijcai org  2017 
 brams and taylor  1996  steven j brams and alan d tay-
lor  fair division  from cake-cutting to dispute resolution 
cambridge university press  1996 
 bredereck et al   2018  robert bredereck  andrzej kacz-
marczyk  and rolf niedermeier  envy-free allocations re-
specting social networks  in aamas 2018  pages 283–
291  2018 
 budish  2011  eric budish 
the combinatorial assign-
ment problem 
approximate competitive equilibrium
from equal incomes 
journal of political economy 
119 6  1061–1103  2011 
 caragiannis et al   2019  ioannis
caragiannis 
david
kurokawa  herv e moulin  ariel d procaccia  nisarg
shah  and junxing wang 
the unreasonable fairness
of maximum nash welfare 
acm transactions on
economics and computation  teac   7 3  1–32  2019 
 chen et al   2017  jiehua chen  piotr faliszewski  rolf nie-
dermeier  and nimrod talmon  elections with few vot-
ers  candidate control can be easy  j  artif  intell  res  
60 937–1002  2017 
 chen et al   2018  jiehua chen  rolf niedermeier  and piotr
skowron  stable marriage with multi-modal preferences 
in ec 2018  pages 269–286  acm  2018 
 courcelle et al   2000  bruno
courcelle 
johann
a 
makowsky  and udi rotics 
linear time solvable opti-
mization problems on graphs of bounded clique-width 
theory comput  syst   33 2  125–150  2000 
 cygan et al   2015  marek cygan  fedor v  fomin  lukasz
kowalik 
daniel lokshtanov 
d aniel marx 
marcin
pilipczuk  michal pilipczuk  and saket saurabh  parame-
terized algorithms  springer  2015 
 diestel  2012  reinhard diestel  graph theory  4th edition 
volume 173 of graduate texts in mathematics  springer 
2012 
 eiben et al   2018a  eduard eiben  robert ganian  dusan
knop  and sebastian ordyniak  unary integer linear pro-
gramming with structural restrictions 
in ijcai 2018 
pages 1284–1290  ijcai org  2018 
 eiben et al   2018b  eduard eiben  robert ganian  and se-
bastian ordyniak  a structural approach to activity selec-
tion  in ijcai 2018  pages 203–209  ijcai org  2018 
 eiben et al   2020  eduard eiben  robert ganian  thekla
hamm  and sebastian ordyniak  parameterized complex-
ity of envy-free resource allocation in social networks  in
aaai 2020  pages 7135–7142  aaai press  2020 
 enciso et al   2009  rosa enciso  michael r  fellows  jiong
guo  iyad a  kanj  frances a  rosamond  and ondrej
such y  what makes equitable connected partition easy 
in iwpec 2009  pages 122–133  springer  2009 
 greco and scarcello  2020  gianluigi greco and francesco
scarcello  the complexity of computing maximin share
allocations on graphs  in aaai 2020  pages 2006–2013 
aaai press  2020 
 igarashi and peters  2019  ayumi igarashi and dominik pe-
ters  pareto-optimal allocation of indivisible goods with
connectivity constraints  in aaai 2019  pages 2045–2052 
aaai press  2019 
 jansen et al   2013  klaus jansen  stefan kratsch  d aniel
marx  and ildik o schlotter  bin packing with fixed number
of bins revisited  j  comput  syst  sci   79 1  39–49  2013 
 kant e and rao  2013  mamadou
moustapha
kant e
and
micha¨el rao  the rank-width of edge-coloured graphs 
theory comput  syst   52 4  599–644  2013 
 lenstra jr   1983  hendrik w  lenstra jr  integer program-
ming with a fixed number of variables  math  oper  res  
8 4  538–548  1983 
 nguyen and rothe  2020  trung thanh nguyen and j¨org
rothe  approximate pareto set for fair and efficient al-
location  few agent types or few resource types  in ijcai
2020  pages 290–296  ijcai org  2020 
 oum and seymour  2006  sang-il oum and paul d  sey-
mour  approximating clique-width and branch-width  j 
combin  theory ser  b  96 4  514–528  2006 
 plaut and roughgarden  2020  benjamin plaut and tim
roughgarden  almost envy-freeness with general valua-
tions  siam j  discret  math   34 2  1039–1068  2020 
proceedings of the thirtieth    ijcai-21 
145
 "
None,2021,https-www-ijcai-org-proceedings-2021-0021-pdf,Neural Regret-Matching for Distributed Constraint Optimization Problems,"Yanchen Deng, Runsheng Yu, Xinrun Wang, Bo An",None,https://www.ijcai.org/proceedings/2021/0021.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0021-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0021-pdf.pdf,"neural regret-matching for distributed constraint optimization problems
yanchen deng   runshen yu   xinrun wang and bo an
school of computer science and engineering  nanyang technological university  singapore
ycdeng@ntu edu sg  runshengyu@gmail com   xinrun wang boan @ntu edu sg
abstract
distributed
constraint
optimization
problems
 dcops  are a powerful model for multi-agent
coordination and optimization  where informa-
tion and controls are distributed among multiple
agents by nature 
however  most of incomplete
algorithms for dcops are context-free  i e   agents
make a decision purely based on the state of their
neighbors  which makes them prone to get trapped
in poor local convergence 
on the other hand 
context-based algorithms use tables to exactly
store all the information  e g   costs  confidence
bounds   which limits their scalability  this paper
tackles the limitation by incorporating deep neural
networks in solving dcops for the first time and
presents a neural context-based sampling scheme
built upon regret-matching  in the algorithm  each
agent trains a neural network to approximate the
regret related to its local problem under current
context and performs sampling according to the
estimated regret 
furthermore  to ensure explo-
ration  we propose a regret rounding scheme that
rounds small regret values to positive numbers 
we theoretically show the regret bound of our
algorithm and extensive evaluations indicate that
our algorithm can scale up to large-scale dcops
and significantly outperform the state-of-the-art
methods 
1
introduction
distributed
constraint
optimization
problems
 dcops 
 fioretto et al   2018  modi et al   2005  are a power-
ful model for multi-agent coordination and optimization  in
which agents cooperatively find assignments that maximize
a global objective  due to their ability to model scenarios
where information and controls are distributed among mul-
tiple agents  dcops have been successfully deployed into
many real-world applications including radio channel alloca-
tion  monteiro et al   2012   vessel navigation  hirayama et
al   2019  and resource management  fioretto et al   2017  
most algorithms for dcops generally follow search or in-
ference strategy  the search-based algorithms either perform
an exhaustive distributed backtrack search to guarantee opti-
mality  hirayama and yokoo  1997  litov and meisels  2017 
modi et al   2005  yeoh et al   2010  or iteratively optimize
the solution by using hill-climbing  maheswaran et al   2004 
okamoto et al   2016  zhang et al   2005  
additionally 
some regret-based local search algorithms  chapman et al  
2011  cast a dcop to a potential game and iteratively approx-
imate equilibria via regret-matching  hart and mas-colell 
2000   in contrast  inference-based algorithms use dynamic
programming  petcu and faltings  2005  vinyals et al   2011 
or belief propagation  farinelli et al   2008  to indirectly ex-
plore the solution space  finally  sampling-based techniques
 nguyen et al   2019  ottens et al   2017  are the emerg-
ing state-of-the-art incomplete methods for medium-scale
dcops  which perform sequential sampling on a pseudo tree 
most of incomplete algorithms for dcops are context-
free  i e   agents make a decision purely based on the state
of their neighbors  which makes them prone to get trapped
in poor local convergence since agents communicate their
preferred decision based on the preferred decision of their
neighbors  farinelli et al   2008   while duct  ottens et
al   2017  tries to remedy the problem by exactly storing an
upper confidence bound  i e   an optimistic estimation of the
optimal utility value for the subproblem of an agent  for each
context and assignment  it may need considerable rounds to
make the bounds informative  besides  exactly storing all
confidence bounds requires exponential memory in the worst
case  which severely limits its scalability 
recent advances in deep reinforcement learning  deep rl 
 franc¸ois-lavet et al   2018  have demonstrated the great po-
tential of neural network for function approximation in han-
dling large state space  instead of storing information exactly
in a table  deep rl uses deep neural networks to represent
state or policy compactly and has led to tremendous suc-
cess in various domains  mnih et al   2015  openai  2018 
silver et al   2017   unfortunately  there is no previous work
on employing function approximation to address the scalabil-
ity limitation in the dcop literature 
in this paper  we aim to develop the first scalable and
efficient neural-based sampling algorithm for dcops  we
make the following key contributions   1  we first introduce
a new context-based sampling algorithm for dcops built
upon regret-matching  different from existing regret-based
local search algorithms  our methods perform sampling on
proceedings of the thirtieth    ijcai-21 
146
 a pseudo tree and store regret values for each context sep-
arately  which allows an agent to devise different strategies
for different contexts 
besides  compared to the existing
sampling-based techniques  our method has a higher sample
efficiency since it accumulates regret values according to the
local problem rather than the subproblem of a variable   2 
we present a neural-based scheme to improve the scalability
of the proposed sampling algorithm by using deep neural net-
works to approximate the regret values  to the best of our
knowledge  we are the first to leverage deep neural networks
into solving dcops  to incentivize exploration  we propose
a regret rounding scheme that rounds small regret values to
positive numbers   3  we prove the regret bounds of our algo-
rithms   4  extensive empirical evaluations indicate that our
neural-based scheme can scale up to large-scale dcops and
significantly outperform the state-of-the-art methods  techni-
cal proofs  pseudo codes and additional results are provided
in the appendix  which can be found at https //personal ntu e
du sg/boan/papers/ijcai21 deep dcop appendix pdf 
2
backgrounds
in this section  we briefly introduce dcop  pseudo tree and
regret-matching 
2 1
distributed constraint optimization problems
a distributed constraint optimization problem  dcop   modi
et al   2005  can be defined by a tuple ⟨i  x  d  f⟩ where
i =  1          n  is the set of agents  x =  x1          xm  is
the set of variables  d =  d1          dm  is the set of discrete
domains and f =  f1          fq  is the set of constraint func-
tions  each variable xi takes a value from domain di and
each function fi   di1 ×         ×dik → r≥0 defines the cost
for each possible combination of xi1          xik  finally  the
objective is to find a joint assignment x∗ that minimizes the
total cost  that is 
x∗ = arg minx
�
fi∈f fi 
 1 
for the sake of simplicity  we follow the common assump-
tions that each agent only controls a variable  i e   m = n  and
all constraints are binary  i e   fij   di × dj → r≥0  ∀fij ∈
f   therefore  the term  agent  and  variable  can be used
interchangeably and a dcop can be visualized by a con-
straint graph  fig 1 a  presents a constraint graph of a dcop
instance in which vertices and edges represent the variables
and constraints of the dcop  respectively 
2 2
pseudo tree
a pseudo tree  freuder and quinn  1985  defines a partial or-
dering among variables  which is used to organize the search
space or establish a communication structure  a pseudo tree
can be generated by a depth-first traversal to the constraint
graph which classifies the edges into tree edges and pseudo
edges  consequently  the neighbors of a variable xi are clas-
sified into parent p xi   the direct ancestor which connects
to xi via a tree edge   pseudo parents pp xi   the direct
ancestors which connect to xi via pseudo edges   children
c xi   the direct descendants which connect to xi via tree
edges   and pseudo children pc xi   the direct descendants
 a  the constraint graph
 b  a possible pseudo tree
 c  constraint functions
figure 1  the constraint graph and a derived pseudo tree of a dcop 
which connect to xi via pseudo edges   for succinctness 
we also use ap xi  =  p xi   ∪ pp xi  and ac xi  =
c xi  ∪ pc xi  to denote all direct ancestors and descen-
dants of xi  respectively  finally  the separators sep xi  of
xi are the set of ancestors which connect to xi or its descen-
dants 
fig 1 b  presents a possible pseudo tree corresponding to
the constraint graph in fig 1 a  
the solid edges and the
dotted edge are the tree edges and the pseudo edge  respec-
tively  in the pseudo tree  x2  neighbors n2 =  x1  x3  are
classified into p x2  = x1  pp x2  = ∅  c x2  =  x3 
and pc x2  = ∅ 
accordingly  ap x2  =  x1  and
ac x2  =  x3   since x1 is constrained with x2 and x3 
we have sep x2  =  x1  
2 3
regret-matching
consider a scenario in which an agent chooses a mixed strat-
egy πt ∈ ∆|a|1 and observes a reward vector f t ∈ r|a|
in each round t  where a is the set of actions 
then the
instantaneous regret of action a ∈ a is rt a  = f t a  −
�
a′ πt a′ f t a′  and the accumulated regret is rt a  =
�t
t′=1 rt′ a   to improve the total reward  the agent needs to
minimize the accumulated regret  regret-matching  hart and
mas-colell  2000  is an efficient algorithm for regret mini-
mization  which computes a mixed strategy according to the
positive part of accumulated regret  that is 
πt 1 a  =
�
rt   a 
�
a′∈a rt   a′ 
�
a′∈a rt   a′  > 0
1
|a|
otherwise
 
∀a ∈ a   2 
where rt   a  = max 0  rt a   is the positive part of
rt a   regret-matching has the regret bound of l
�
t|a| 
where l is the largest gap in reward vectors  because the
accumulated regret grows sublinearly w r t  the number of
rounds  regret-matching is a so-called no-regret algorithm
 blackwell  1956  
3
context-based regret-matching for dcops
in this section  we present context-based regret-matching
schemes for dcops  we begin with formally introducing our
1∆|a| is the set of probability distributions over set a
proceedings of the thirtieth    ijcai-21 
147
 proposed sampling algorithm in sect  3 1  then we show that
the vanilla regret-matching could perform poorly and present
the regret rounding scheme in sect  3 2 
3 1
context-based regret-matching scheme
the proposed context-based regret-matching scheme alterna-
tively executes a sampling phase and a backtracking phase
on a pseudo tree  starting from the root agent  each agent
in sampling phase sequentially selects an assignment accord-
ing to the regret vector associated with the received context 
while backtracking phase is a bottom-up procedure to refine
the solution and update regret values for each agent 
let us begin with introducing notations that will be used in
the algorithm  for a variable xi in a pseudo tree  we denote
an assignment to the variables in sep xi   i e   a context  as
xi and an assignment to the variables in ac xi  as yi  re-
spectively  in each round t  after collecting xt
i and y t
i   the
hindsight local cost st
i di  of each assignment di ∈ di is
then computed by
st
i di  =
�
xj∈ap  xi 
fij di  xt
i xj    
�
xk∈ac xi 
fik di  y t
i  xk     3 
where xt
i xj  denotes the assignment of xj in xt
i and
y t
i  xk  denotes the assignment of xk in y t
i   respectively 
given the mixed strategy πt
i of xi  the expected local cost
st
i = �
di∈di πt
i di st
i di   finally  the accumulated regret
of xi in round t is defined as
rt
i xi  di  =
�rt−1
i
 xi  di    st
i − st
i di 
xi = xt
i
rt−1
i
 xi  di 
otherwise    4 
in each round t  the sampling phase is initiated by the root
agent  after receiving the context xt
i from its parent  a non-
leaf variable xi first computes the mixed strategy πt
i by
πt
i di  =
�
�
�
rt−1  
i
 xt
i  di 
�
d′∈di rt−1  
i
 xt
i  d′ 
�
d′∈di rt−1  
i
 xt
i  d′  > 0
1
|di|
otherwise
  ∀di ∈ di   5 
then it samples an assignment dt
i ∼ πt
i and sends the aug-
mented context xt
i ∪  xi = dt
i  to its children c xi   leaf
variables  however  do not have any subproblem and thus di-
rectly select the assignment that minimizes their local cost 
the phase ends when all leaf agents finish sampling 
the backtracking phase is a bottom-up procedure initiated
by leaf agents sending the selected assignment to their direct
ancestors  after collecting all the assignments of its direct
descendants y t
i   a variable xi computes the hindsight local
cost vector st
i and updates the regret rt
i according to eq  3 
and eq  4   respectively  finally  xi refines the solution by
changing its assignment to the one with the lowest hindsight
local cost and sends the assignment to its direct ancestors 
the procedure ends after the root agent updates its regret and
then the next round of sampling starts 
to look deeper into how context-based sampling avoids
poor local convergence  consider the instance shown in fig 1 
in the first round of sampling  all non-leaf agents have no
prior knowledge and sample randomly  assume that x1 as-
signs f  x2 assigns t and thus leaf agent x3 plays the best
response f  if it does not differentiate contexts  x2 would up-
date its regret values by
�s1
2 =  18  16 
s1
2 = 18 × 0 5   16 × 0 5 = 17
�r1
2 t  = 17 − 18 = −1
r1
2 f  = 17 − 16 = 1
which means that x2 cannot assign t in the next round  in
fact  one can easily verify that no matter what value x1 as-
signs  if x2 assigns f and x3 plays the best response  then the
instantaneous regret for t is always negative and x2 cannot
deviate to t  which precludes the possibility of reaching the
optimal solution  t  t  t  in subsequent rounds 
the reason behind such mis-coordination is that in context-
free method each agent fails to adapt the complex behavior
of its lower priority neighbors since it uses the same regret
values to make decision for different contexts  in the above
example  given the fact that x1 assigns f and x3 plays the
best response  x2 would conclude that assigning f is better
than assigning t  which is not true if x1 switches to t  in con-
trast  our context-based sampling scheme explicitly maintains
regret values for each context  which allows agents to adapt
the multi-modal behavior of its descendants  in more detail 
x2 in our method would associate the fact  f is superior over
t  with context  x1 =f   which does not bias the decision-
making procedure under the context  x1=t  
since it contains all assignments of separators  the size of
a context message is proportional to the number of agents 
i e   o |i|   note that in sampling phase  each non-leaf agent
sends a context message to each of its children via tree edges 
therefore  there are |i| − 1 context messages in the sampling
phase  and the total information exchanged is in o |i|2  
backtracking phase  on the other hand  exchanges the assign-
ments among neighbors  which induces |f| messages of size
o 1   therefore  the total size of messages exchanged in each
round is in o |i|2   |f|  = o |i|2  
3 2
regret rounding scheme
regret-matching could perform poorly in the context of solv-
ing dcops due to insufficient exploration  consider the sim-
ple instance in fig 2  assume that x1 selects d1
1 =t and x2
selects d1
2 =r in the first round of sampling  the following
equations show the trace when x1 updates its regret 
�s1
1 =  1  3 
s1
1 = 1 × 0 5   3 × 0 5 = 2
�r1
1 ∅  t  = 2 − 1 = 1
r1
1 ∅  f  = 2 − 3 = −1
according to eq  5  the assignment f cannot be selected by
x1 in the subsequent rounds since its regret is negative  even
though  x1 = f  x2 = l  is the optimal solution  in other
words  negative regret would limit the exploration of the al-
gorithm  although regret-matching   tammelin et al   2015 
mitigates the issue by resetting the negative regret to zero  se-
lecting these assignments still depends on the positive instan-
taneous regret in subsequent rounds  which is highly coupled
with the behavior of other agents 
we trigger the effective exploration by rounding small re-
gret values to positive numbers  this way  all assignments
have a non-zero probability in the mixed strategy and the ex-
ploration is independent of other agents  behavior  specifi-
cally  instead of maintaining regret rt
i for each variable xi 
we maintain the rounded regret ¯rt
i 
¯rt
i xi  di  =
�max
�
δt  ¯rt−1
i
 xi  di    st
i − st
i di 
�
xi = xt
i
¯rt−1
i
 xi  di 
otherwise    6 
where ¯r0
i  ·  ·  = 0 and δt > 0 is a non-decreasing term 
in this example  if set δt = tα  α > 0  then ¯r1
1 ∅  t  =
proceedings of the thirtieth    ijcai-21 
148
  a  the pseudo tree
 b  the constraint function
figure 2  a dcop instance with structured constraint functions
¯r1
1 ∅  f  = 1 and thus x1 still has chance to select assignment
f in subsequent rounds  regardless of the strategy selected by
x2  theorem 1 gives an upper bound of the rounded regret
and theorem 2 provides the no-regret guarantee 
theorem 1  for variable xi  let li
= �
xj∈ni f  
ij −
f −
ij   be the largest gap in its local cost  where f  
ij
=
maxdi maxdj fij di  dj  and f −
ij = mindi mindj fij di  dj 
are the upper bound and lower bound of constraint
fij  respectively 
after xi finishes t rounds of sam-
pling  the rounded regret ¯rt
i  xi  di  is no higher than
�
|di|
�
tl2
i   �t
t=1 δ2
t
�
for all xi  di 
theorem 2  when limt→∞ δt
√
t = 0  the regret rounding
scheme is no-regret  i e   the total regret grows sublinearly 
4
scaling up to large problems
in this section  we first address the memory challenge by us-
ing deep neural networks to approximate high-dimensional
regret tables  then we present a prioritized training scheme
to speed up the proposed algorithm by reducing the number
of non-concurrent training processes in each round 
4 1
neural-based sampling scheme
a prominent issue of the sampling algorithm proposed in
sect 3 is the high memory consumption incurred by exactly
storing regret values for each context  a straightforward way
would be approximating the regret tables by using linear re-
gression  however  due to their limited capacity  linear mod-
els may not be able to capture the complex patterns when the
problem is large  alternatively  regression regret-matching
 rrm   morrill  2016  waugh et al   2015  tries to address
the issue by using regression trees to estimate the accumu-
lated regret  but it still needs to preserve all regret values dur-
ing the solving process  which eliminates the most attractive
advantage of reducing memory consumption  also  since a
regression tree cannot be trained incrementally  rrm needs
to re-train the model on all data after updating regret values 
which could be extremely inefficient  as confirmed in our ex-
perimental results  given a very generous runtime limit  e g  
1000s   rrm can only finish about 500 rounds of sampling
and ends up with poor solutions 
in contrast  deep neural networks have been demonstrated
to be a powerful function approximator and lead to great suc-
cesses in a wide variety of domains in ai  therefore  we aim
to address the scalability challenge by parameterizing the re-
gret tables via neural networks  in our neural-based sampling
scheme  for each non-leaf variable xi we maintain an esti-
mator vi   πxj∈sep xi ∪ xi dj → r and a fifo capacitied
memory mi to estimate regret and store cached regret  re-
spectively  the input of vi is the concatenation of the one-hot
encoding of the assignment to sep xi  and xi and the output
is the estimated regret 
when receiving a context from its parent  a non-leaf vari-
able xi first retrieves the estimated regret ˆrt−1
i
related to the
context from either memory mi or estimator vi  depending
on whether the context-assignment pair ⟨xt
i  di⟩ presents in
the memory  then xi computes the mixed strategy πt
i accord-
ing to ˆrt−1
i
and perform sampling 
in the backtracking phase  after collecting all the assign-
ments of its direct descendants  xi trains neural network vi θi
to minimize the mean squared error  mse  between the esti-
mated regret and cached regret for h steps  for each step  xi
samples a mini-batch b ⊆ mi of regret values and updates
the parameters θi to minimize the mse 
li θi  =
1
|b|
�
⟨xi di⟩∈b  mi xi  di  − vi θi xi  di  2  
 7 
where |b| is the size of the batch  mi xi  di  and vi xi  di 
are the cached regret value and the estimated regret value
for the context-assignment pair ⟨xt
i  di⟩  respectively  then
xi updates the regret according to eq  6  
particularly  a
bootstrapping step is performed if context-assignment pair
⟨xt
i  di⟩ does not present in the memory  theorem 3 presents
the regret bound of the neural-based sampling scheme 
theorem
3 
for
variable
xi
and
round
t 
the
regret
rt  xi  di 
is
no
higher
than
�
li|di|
�
 4
�
|di|δt   li t   4 �t
t=1
�
d′
i ϵt
i xi  d′ 2
�
for all xi  di  where ϵt
i xi  d′
i  = ˆrt
i xi  d′
i  − ¯rt
i xi  d′
i  
4 2
prioritized training scheme
one potential issue of the proposed neural-based sampling
scheme could be the high latency incurred by non-concurrent
training processes in the backtracking phase of each round 
more specifically  agents in a chain structure sequentially
train their neural network  which is not desirable when there
are long chains in a pseudo tree 
unfortunately  since a
pseudo tree is generated by depth-first traversal  it usually
has few branches when the problem is large  which makes
the training quite time-consuming 
therefore  we propose a prioritized training scheme to re-
duce the training latency by selecting several key agents in
each chain structure to perform training procedure in each
round  we confine our training scheme to chain structures
because agents in different branches  1  can perform in par-
allel in real-world scenarios and  2  need additional efforts to
coordinate training process 
in more detail  in preprocessing phase  we first cluster the
agents into different groups according to their position in the
pseudo tree and the similarity of dimensions of their regret
table  that is  starting from an empty group and the first agent
of the chain  we extend the group by adding the current agent
until  1  the agent has more than one child  or  2  there is
an agent whose regret table dimensions differ by b variables
from the union of the ones of remaining agents in the group 
proceedings of the thirtieth    ijcai-21 
149
  a  p1 = 0 25  |di| = 10
 b  50 agents  |di| = 10
 c  50 agents  p1 = 0 25
figure 3  performance comparison on random dcops
 a  scale-free net problems
 b  sensor net problems
figure 4  performance comparison on structured problems
where b is a user-specified difference budget to control the
size of each group  then a new group is created and this
procedure repeats until each agent belongs to a group 
in backtracking phase  we schedule the training processes
of each group g according to the prediction error of each
agent  that is  each agent i maintains a discounted error et
i 
each time agent i backtracks  it performs training with the
probability et
i/ �
j∈g et
j  the discounted error is updated by
the absolute error between the predicted regret and the cached
regret under current context with discount factor γ  that is 
et
i = γet−1
i
   1 − γ 
�
di∈di |mi xt
i  di  − vi θi xt
i  di | 
5
empirical evaluations
we empirically evaluate our proposed neural-based sampling
scheme  neural-rrs  on standard benchmark problems in-
cluding random dcops  scale-free network problems and
sensor network problems  we set δt = t0 45 and consider
each estimator as a neural network with two hidden layers 
each hidden layer has 16 neurons and uses relu as the ac-
tivation function  each time the neural networks are trained
by 2 steps of mini-batch stochastic gradient descent  sgd 
with a batch size of 32  we use adam optimizer  kingma
and ba  2014  with a learning rate of 2 × 10−3 to update pa-
rameters  finally  we set difference budget b = 4  γ = 0 9
and the capacity of the memory to 5000 regret values 
the baselines we consider include dsa-c  zhang et al  
2005   gdba  okamoto et al   2016  as representative lo-
cal search algorithms  mgm-2  maheswaran et al   2004 
as a representative k-opt algorithm  d-gibbs  nguyen et
al   2019  as a representative sampling algorithm and max-
sum advp  zivan et al   2017  as a representative belief
propagation algorithm  besides  we also include regret-based
local search schemes  chapman et al   2011   lsrm and
wrm-i  since they are context-free regret-matching algo-
rithms for dcops  finally  we also consider the variants lr-
rrs and rt-rrs that use linear regression and regression
tree to approximate the regret values  respectively 
we set p = 0 8 for dsa-c and use ⟨m  nm  t⟩ vari-
ant for gdba according to  okamoto et al   2016   finally 
all algorithms terminate after 5000 rounds with a timeout of
1000s and report the anytime normalized cost  i e   the best
solution cost divided by the number of constraints  as the re-
sult  all experiments are conducted on an i7 octa-core work-
station with 32 gb memory  for each experiment  we average
the results over 50 random instances 
results on random dcops  in a random dcop  two agents
randomly establish a constraint with a probability p1  result-
ing a constraint graph with density p1  for each constraint 
we uniformly randomly select costs from  0  100   we vary
the number of agents  density and domain size respectively
and present the results in fig 3  regret-based local search
algorithms explore low-quality convergences and are infe-
rior to dsa  similarly  d-gibbs converges to local optima
quickly and performs just like stochastic search 
on the
other hand  the merits of our proposed context-based regret-
matching scheme are confirmed by the fact lr-rrs and
neural-rrs significantly outperform their context-free coun-
terparts as well as mgm2 and gdba  rt-rrs  however 
fails to strictly dominate gdba when solving the problems
with large domain size  that is because regression tree can-
not be trained incrementally  as a consequence  each agent
in rt-rrs has to fit its model on all cached regret values 
which is extremely inefficient and does not scale up well  in
fact  rt-rrs can only finish about 500 rounds of sampling
and ends up with poor solutions 
results on scale-free network problems  in the experiment 
we use barab asi-albert model  barab asi and albert  1999 
to generate scale-free networks  we consider the problems
with m0 = 10 initially connected vertices  i e   variables   in
proceedings of the thirtieth    ijcai-21 
150
  a  p1 = 0 25  |di| = 10
 b  50 agents  |di| = 10
 c  50 agents  p1 = 0 25
figure 5  runtime results on random dcops
 a  scale-free net problems
 b  sensor net problems
figure 6  runtime results on structured problems
each iteration  a new vertex is connected to m1 vertices with
a probability that is proportional to the degree of each exist-
ing vertex  we set the number of vertices to 50 and uniformly
select costs from  0 100   fig 4 a  presents the results when
varying m1  d-gibbs performs poorly due to the inability of
exploiting different contexts and gets trapped in local optima
quickly  gdba and mgm2 perform better by using gener-
alized breakout mechanism and coordinated moves between
two agents to escape poor convergence  respectively  on the
other hand  our neural-rrs finds significantly better solu-
tions than all the competitors on different m1  in fact  the av-
erage improvement of neural-rrs over gdba is 5 6   that
is due to the fact that our algorithm stores regret for each con-
text  which finds significantly better solutions by allowing an
agent to devise different strategies for different contexts 
results on sensor network problems  in a sensor network
problem  nguyen et al   2012  nguyen et al   2019   sensors
are placed in a 2d grid and each sensor can move along its
four cardinal directions or stay stationary  i e   each sensor
has 5 possible actions   besides  sensors are constrained with
their neighboring sensors and the costs are uniformly selected
from  0 100   we vary the grid size from 6 × 6  i e   36 vari-
ables  to 10×10  i e   100 variables  and present the results in
fig 4 b   interestingly  max-sum advp is quite competitive
and finds the solutions with quality much better than the ones
found by gdba and mgm2 in this set of experiments  this
might be due to the high-structured topology of sensor net-
works  besides  it is worth noting that the performance of lr-
figure 7  convergence analysis on random dcops
rrs is similar to neural-rrs when solving small problems
 i e   the ones with grid size of 6 × 6   but the performance
substantially degenerates w r t  growing grid size  that might
be due to the fact that the limited representational capability
of linear models cannot capture the complex patterns in large
problems  in contrast  neural-rrs leverages powerful deep
neural networks to represent regret tables  leading to the best
performance on all configurations 
runtime results 
we compare the wall clock runtime of
each algorithm and present the results when solving random
problems and structured problems in fig 5 and fig 6  respec-
tively  it can be seen that all traditional methods terminate
very quickly  that is no surprise since they essentially per-
form table lookup  leading to lower overall runtime  in con-
trast  all functional versions of rrs require higher runtime
as they need additional efforts to train estimators  in partic-
ular  rt-rrs is timed out on all test cases  and the runtime
of lr-rrs grows significantly w r t  the growing problem
scales  in contrast  combining with the prioritized training
scheme  our neural-rrs incurs relatively modest runtime re-
quirement than lr-rrs  notably  on the random problems
with different density  i e   fig 5 b   and the scale-free prob-
lems  i e   fig 6 a    our neural-rrs requires significantly
less runtime than other rt-rrs and lr-rrs  which demon-
strates the merits of prioritized training scheme 
to investigate the efficiency of our algorithms  we conduct
a convergence analysis on random dcops with 50 agents 
density of 0 25 and domain size of 15  and present the results
in fig 7  rt-rrs improves slowly and fails to outperform
proceedings of the thirtieth    ijcai-21 
151
  a  p1 = 0 25  |di| = 10
 b  40 variables  |di| = 10
 c  40 variables  p1 = 0 25
figure 8  ablation study on random dcops
gdba in the first 500s  while lr-rrs marginally surpasses
gdba after 350s  finally  combining with the prioritized
training scheme  our neural-rrs improves relatively fast and
steadily  dominating gdba after 150s 
ablation study  to explicitly demonstrate the necessity of
regret rounding scheme and function approximation  we con-
sider the tabular counterpart of neural rm-rrs  namely
rm-rrs  and the one uses vanilla regret-matching  namely
rm   we set the memory capacity to 5000 for neural rm-
rrs and vary the memory capacity from 5000 to 40000 for
tabular counterparts to simulate different memory budgets in
real-world scenarios  fig  8 presents the results on random
dcops 
here we omit the results of rm under different
memory capacities due to their similarity 
it can be clearly seen that rm is inferior to rm-rrs under
the same memory capacity  in fact  given smaller memory
capacity  e g   10000   rm-rrs can still outperform rm in
the most cases  that is because the negative regret values
in rm would restrict exploration and eventually lead to poor
results  in contrast  rm-rrs triggers effective exploration by
actively rounding the negative regret to small positive values 
ensuring that all assignments have a non-zero probability 
on the other side  exploration triggered by rounded regret
could also lead to a large number of different contexts  there-
fore  given limited budget  e g   5000   rm-rrs quickly runs
out of memory before finding a good solution  leading to poor
performance when solving large-scale problems  while neu-
ral rm-rrs with the same memory constraint still achieves
the best performance  therefore  the scalability of rm-rrs
is severely restricted by its tabular nature  which is success-
fully addressed by neural function approximation 
6
conclusion
most of incomplete algorithms for dcops are context-free 
which usually leads to low-quality convergence 
while
context-based methods tries to remedy the problem by explic-
itly storing information for each context  they usually suffer
from low sample efficiency and high memory consumption
which prohibit them from scaling up to large problems  in
this paper  we tackle the issues by proposing neural-rrs  the
first neural context-based algorithm for dcops  built upon
regret-matching  the algorithm overcomes the pathology of
low sample efficiency by accumulating regret according to
the local problem of each variable 
to address the scala-
bility challenge incurred by exactly storing regret for each
context  neural-rrs approximates the regret tables by deep
neural networks  besides  we propose a prioritized training
scheme to reduce the training latency  finally  the algorithm
uses a regret rounding scheme that rounds small regret values
to positive numbers to ensure exploration  we theoretically
show the regret bound and the extensive evaluations indicate
that our algorithm can scale up to large problems and signifi-
cantly outperform the state-of-the-art methods 
acknowledgements
this research was supported by the national research foun-
dation  singapore under its ai singapore programme  aisg
award no 
aisg-rp-2019-0013   national satellite of
excellence in trustworthy software systems  award no 
nsoe-tss2019-01   and ntu 
references
 barab asi and albert  1999  albert-l aszl o
barab asi
and
r eka albert  emergence of scaling in random networks 
science  286 5439  509–512  1999 
 blackwell  1956  david blackwell  an analog of the mini-
max theorem for vector payoffs  pacific journal of math-
ematics  6 1  1–8  1956 
 chapman et al   2011  archie c  chapman  alex rogers 
nicholas r  jennings  and david s  leslie  a unifying
framework for iterative approximate best-response algo-
rithms for distributed constraint optimization problems 
knowledge eng  review  26 4  411–444  2011 
 farinelli et al   2008  alessandro farinelli  alex rogers 
adrian petcu  and nicholas r jennings  decentralised co-
ordination of low-power embedded devices using the max-
sum algorithm  in aamas  pages 639–646  2008 
 fioretto et al   2017  ferdinando fioretto  william yeoh 
enrico pontelli  ye ma  and satishkumar j ranade  a dis-
tributed constraint optimization  dcop  approach to the
proceedings of the thirtieth    ijcai-21 
152
 economic dispatch with demand response 
in aamas 
pages 999–1007  2017 
 fioretto et al   2018  ferdinando fioretto  enrico pontelli 
and william yeoh 
distributed constraint optimization
problems and applications  a survey  journal of artificial
intelligence research  61 623–698  2018 
 franc¸ois-lavet et al   2018  vincent franc¸ois-lavet  peter
henderson  riashat islam  marc g  bellemare  and joelle
pineau 
an introduction to deep reinforcement learn-
ing  foundations and trends in machine learning  11 3-
4  219–354  2018 
 freuder and quinn  1985  eugene c freuder and michael j
quinn  taking advantage of stable sets of variables in con-
straint satisfaction problems  in ijcai  volume 85  pages
1076–1078  1985 
 hart and mas-colell  2000  sergiu hart and andreu mas-
colell  a simple adaptive procedure leading to correlated
equilibrium  econometrica  68 5  1127–1150  2000 
 hirayama and yokoo  1997  katsutoshi
hirayama
and
makoto yokoo  distributed partial constraint satisfaction
problem  in cp  pages 222–236  1997 
 hirayama et al   2019  k hirayama  k miyake  t shiotani 
and t okimoto  dssa   distributed collision avoidance
algorithm in an environment where both course and speed
changes are allowed 
international journal on marine
navigation and safety of sea transportation  13 1  117–
123  2019 
 kingma and ba  2014  diederik p kingma and jimmy ba 
adam 
a method for stochastic optimization 
arxiv
preprint arxiv 1412 6980  2014 
 litov and meisels  2017  omer litov and amnon meisels 
forward bounding on pseudo-trees for dcops and ad-
cops  artificial intelligence  252 83–99  2017 
 maheswaran et al   2004  rajiv t maheswaran  jonathan p
pearce  and milind tambe 
distributed algorithms for
dcop  a graphical-game-based approach 
in isca
pdcs  pages 432–439  2004 
 mnih et al   2015  volodymyr mnih  koray kavukcuoglu 
david silver  andrei a rusu  joel veness  marc g belle-
mare  alex graves  martin riedmiller  andreas k fidje-
land  georg ostrovski  et al  human-level control through
deep reinforcement learning  nature  518 7540  529–533 
2015 
 modi et al   2005  pragnesh jay modi 
wei-min shen 
milind tambe  and makoto yokoo  adopt  asynchronous
distributed constraint optimization with quality guaran-
tees  artificial intelligence  161 1-2  149–180  2005 
 monteiro et al   2012  tˆania l monteiro 
guy pujolle 
marcelo e pellenz  manoel c penna  and richard demo
souza  a multi-agent approach to optimal channel assign-
ment in wlans  in wcnc  pages 2637–2642  2012 
 morrill  2016  dustin morrill 
using regret estimation to
solve games compactly  master s thesis  university of al-
berta  2016 
 nguyen et al   2012  duc thien nguyen  william yeoh 
and hoong chuin lau  stochastic dominance in stochas-
tic dcops for risk-sensitive applications  in aamas  pages
257–264  2012 
 nguyen et al   2019  duc thien nguyen  william yeoh 
hoong chuin lau  and roie zivan  distributed gibbs  a
linear-space sampling-based dcop algorithm  journal of
artificial intelligence research  64 705–748  2019 
 okamoto et al   2016  steven okamoto  roie zivan  and
aviv nahon  distributed breakout  beyond satisfaction 
in ijcai  pages 447–453  2016 
 openai  2018  openai  openai five  https //blog openai 
com/openai-five/  2018 
 ottens et al   2017  brammert
ottens 
christos
dimi-
trakakis  and boi faltings  duct  an upper confidence
bound approach to distributed constraint optimization
problems  acm transactions on intelligent systems and
technology  8 5  69 1–69 27  2017 
 petcu and faltings  2005  adrian petcu and boi faltings  a
scalable method for multiagent constraint optimization  in
ijcai  pages 266–271  2005 
 silver et al   2017  david
silver 
julian
schrittwieser 
karen simonyan  ioannis antonoglou  aja huang  arthur
guez  thomas hubert  lucas baker  matthew lai  adrian
bolton  et al  mastering the game of go without human
knowledge  nature  550 7676  354–359  2017 
 tammelin et al   2015  oskari
tammelin 
neil
burch 
michael johanson  and michael bowling 
solving
heads-up limit texas hold em  in ijcai  pages 645–652 
2015 
 vinyals et al   2011  meritxell vinyals  juan a rodriguez-
aguilar  and jes us cerquides 
constructing a unifying
theory of dynamic programming dcop algorithms via
the generalized distributive law  autonomous agents and
multi-agent systems  22 3  439–464  2011 
 waugh et al   2015  kevin
waugh 
dustin
morrill 
james andrew bagnell 
and michael h  bowling 
solving games with functional regret estimation  in aaai 
pages 2138–2145  2015 
 yeoh et al   2010  william yeoh  ariel felner  and sven
koenig 
bnb-adopt  an asynchronous branch-and-
bound dcop algorithm  journal of artificial intelligence
research  38 85–133  2010 
 zhang et al   2005  weixiong zhang 
guandong wang 
zhao xing  and lars wittenburg  distributed stochastic
search and distributed breakout  properties  comparison
and applications to constraint optimization problems in
sensor networks  artificial intelligence  161 1-2  55–87 
2005 
 zivan et al   2017  roie zivan  tomer parash  liel cohen 
hilla peled  and steven okamoto  balancing exploration
and exploitation in incomplete min/max-sum inference for
distributed constraint optimization 
autonomous agents
and multi-agent systems  31 5  1165–1207  2017 
proceedings of the thirtieth    ijcai-21 
153
 "
None,2021,https-www-ijcai-org-proceedings-2021-0022-pdf,Online Selection of Diverse Committees,"Virginie Do, Jamal Atif, Jérôme Lang, Nicolas Usunier",None,https://www.ijcai.org/proceedings/2021/0022.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0022-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0022-pdf.pdf,"online selection of diverse committees
virginie do1 2∗   jamal atif1   j erˆome lang1 and nicolas usunier2
1lamsade  universit e psl  universit e paris-dauphine  cnrs  france
2facebook ai research
virginiedo@fb com  jamal atif@lamsade dauphine fr  lang@lamsade dauphine fr  usunier@fb com
abstract
citizens  assemblies need to represent subpopula-
tions according to their proportions in the general
population  these large committees are often con-
structed in an online fashion by contacting people 
asking for the demographic features of the volun-
teers  and deciding to include them or not  this
raises a trade-off between the number of people
contacted  and the incurring cost  and the represen-
tativeness of the committee  we study three meth-
ods  theoretically and experimentally  a greedy al-
gorithm that includes volunteers as long as propor-
tionality is not violated  a non-adaptive method that
includes a volunteer with a probability depending
only on their features  assuming that the joint fea-
ture distribution in the volunteer pool is known  and
a reinforcement learning based approach when this
distribution is not known a priori but learnt online 
1
introduction
forming a representative committee consists in selecting a
set of individuals  who agree to serve  in such a way that
every part of the population  defined by specific features  is
represented proportionally to its size  as a paradigmatic ex-
ample  the climate assembly in the uk and the citizens 
convention for climate in france brought together 108 and
150 participants respectively  representing sociodemographic
categories such as gender  age  education level  professional
activity  residency  and location  in proportion to their im-
portance in the wider society  beyond citizens  deliberative
assemblies  proportional representation often has to be re-
spected when forming an evaluation committee  selecting a
diverse pool of students or employees  and so on 
two key criteria for evaluating the committee formation
process are the representativeness of the final selection and
the number of persons contacted  each of these incurring a
cost   the trade-off is that the higher the number of people
contacted  the more proportional the resulting committee 
a first possibility is to use an offline strategy  as for the
uk assembly   invitations are sent to a large number of peo-
∗contact author 
†full version available at https //arxiv org/abs/2105 09295 
ple  30 000   and the final group is selected among the pool of
volunteers  an alternative setting which is common in hiring
is to consider an online process  the decision-maker is given
a stream of candidates and has to decide at each timestep
whether or not to admit the candidate to the final committee 
this work focuses on the latter setting 
a further difficulty is that the distribution of volunteers is
not necessarily known in advance  for example  although
the target is to represent distinct age groups proportionally to
their distribution in the wider population  it may be the case
that older people are predominant among volunteers 
multi-attribute proportional representation in committee
selection in an off-line setting usually assumes full access to
a finite  typically large  database of candidates  this assump-
tion is impractical in a variety of real-world settings  first  the
database does not exist beforehand and constructing it would
require contacting many more people than necessary  sec-
ond  in some domains  the decision to hire someone should
be made immediately so that people don t change their mind
in the meantime  which is typical in professional contexts  
an online strategy must achieve a good trade-off between
sample complexity  i e  the number of timesteps needed to
construct a full committee  and the quality of the final com-
mittee  as measured by its distance to the target distribution 
we focus on the online setting  we introduce a new model
and offer three different strategies  which rely on different as-
sumptions on the input  and the process   the greedy strategy
selects volunteers as long as their inclusion does not jeop-
ardize the size and representation constraints  it does not
assume any prior distribution on the volunteer pool 
the
nonadaptive strategy  based on constrained markov decision
processes  repeatedly chooses a random person  and decides
whether to include or not a volonteer with a probability that
depends only on their features  it assumes the joint distribu-
tion in the volunteer pool is known  it can be parallelised 
finally  the reinforcement learning strategy assumes this dis-
tribution is not known a priori but can be learnt online 
which of these strategies are interesting depends on do-
main specificities  for each  we study bounds for expected
quality and sample complexity  and perform experiments us-
ing real data from the uk citizens  assembly on brexit 
the outline of the paper is as follows  we discuss related
work in section 2  define the problem in section 3  define and
study our three strategies in sections 3 2  4 and 5  analyse our
proceedings of the thirtieth    ijcai-21 
154
 experiments in section 6 and conclude in section 7 
2
related work
diversity and representation in committee  s election 
the problem of selecting a diverse set of candidates from
a candidate database  where each candidate is described by
a vector of attribute values  has been considered in several
places  in  lang and skowron  2018   the goal is to find a
committee of a fixed size whose distribution of attribute val-
ues is as close as possible to a given target distribution  in
 celis et al   2018  bredereck et al   2018   each candidate
has a score  obtained from a set of votes  and some constraints
on the proportion of selected candidates with a given attribute
value are specified  the goal is to find a fixed-size committee
of maximal score satisfying the constraints  in the same vein 
 aziz  2019  considers soft constraints  and  bei et al   2020 
do not require the size of the committee to be fixed 1
our online setting shifts the difficulty of the multi-attribute
representation problem from computational complexity anal-
yses  to the need for probabilistic guarantees on the tradeoffs
between sample complexity and achieved proportionality 
representative and fair sortition 
finding a representa-
tive committee  typically  a panel of citizens  with respect
to a set of attributes  using sortition  is the topic of at least
two recent papers   benad e et al   2019  show that strati-
fication  random selection from small subgroups defined by
attribute values  rather than from the larger group  only helps
marginally   flanigan et al   2020  go further and consider
this three-stage selection process   1  letters are sent to a large
number of random individuals  the recipients    2  these re-
cipients answer whether they agree to participate  and if so 
give their features  those individuals constitute the pool   3  a
sampling algorithm is used to select the final panel from the
pool  as the probability of willingness to participate is differ-
ent across demographic groups  each person is selected with a
probability that depends on their features  so as to correct this
self-selection bias  this guarantees that the whole process be
fair to all individuals of the population  with respect of going
from the initial population to the panel 2
the main differences between this work and ours are   1 
 once again  our process is online   2  we do not consider in-
dividual fairness  only group representativeness   3  we care
about minimizing the number of people contacted  moreover 
unlike off-line processes  our process can be applied in con-
texts where hiring a person just interviewed cannot be de-
layed  this may not be crucial for citizens  assemblies  al-
though someone who volunteers at first contact may change
their mind if the delay until the final selection is long   but
this is definitely so when hiring a diverse team of employees 
1note that diversity and proportional representation are often
used with a different meaning in multiwinner elections  namely  in
the sense that each voter should feel represented in an elected com-
mittee  regardless of attributes  a good entry to this literature is the
survey  faliszewski et al   2017  
2fairness guarantees are pushed further in following  yet unpub-
lished  work by the authors  see https //youtu be/x 1ce1kt7vc 
online selection problems 
generalized secretary prob-
lems  babaioff et al   2008  are optimal stopping problems
where the goal is to hire the best possible subset of persons 
assuming that persons arrive one at a time  their value is ob-
served at that time  and the decision to hire or not them must
be taken immediately  the problem has been generalized to
finding a set of items maximizing a submodular value func-
tion  bateni et al   2013  badanidiyuru et al   2014  while
the latter models do not deal with diversity constraints   stoy-
anovich et al   2018  aims at selecting a group of people ar-
riving in a streaming fashion from a finite pool  with the goal
of optimizing their overall quality subject to diversity con-
straints  the common point with our approach is the online
nature of the selection process 
the main differences are
that they consider only one attribute  the size of the pool is
known  and yet more importantly  what is optimized is the
intrinsic quality values of the candidates and not the number
of persons interviewed  closer to our setting is  panigrahi et
al   2012  who consider diversity along multiple features in
online selection of search results  regardless of item quality 
they only seek to maximise diversity  and do not consider
trade-offs with the number of items observed 
the diverse hiring setting of  schumann et al   2019  is
very different  at each time step  the decision-maker chooses
which candidate to interview and only decides on which sub-
set to hire after multiple rounds  whereas in our setting  candi-
dates arrive one by one and decisions are made immediately 
3
formal setting
3 1
problem definition
let x = x1 ×     × xd be the product space of d finite do-
mains  each of size di = |xi|  and where we identify xi with
 di  =  1       di   each candidate is represented by a char-
acteristic vector x ∈ x with d features  let xi ∈ xi denote
the value of the i-th feature  for each i ∈  d   we consider a
target vector ρi ∈  0  1 di with �di
j=1 ρi
j = 1 
the candidate database is infinite and the horizon as well 
at each timestep t ≥ 1  the agent observes a candidate xt
drawn i i d  from a stationary distribution p over x  i e  xt ∼
p  the decision-maker must immediately decide between two
actions  accept or reject the candidate  which we respectively
denote as at = 1 and at = 0 
the goal is to select a committee c of k candidates that
matches the target vectors as closely as possible  while mini-
mizing the number of candidates screened 
for some set c  let λ c  ∈ �d
i=1 0  1 di be the rep-
resentation profile of c  where λi
j c  =
| x∈c xi=j |
|c|
 
we define the representation loss as ∥λ c  − ρ∥∞
=
maxi∈ d  j∈ di  |λi
j c  − ρi
j| 
we evaluate how much c
matches the target ρ by the ℓ∞ metric  because it is harsher
than ℓ1  ℓ2 on committees that are unacceptable in our appli-
cations  e g  committees with no women that achieve perfect
representation on all other categories than gender  
let ct =  xt′   t′ ≤ t  at′ = 1  denote the set of all
accepted candidates at the end of step t  the agent stops
at τ  where τ is the first time when k candidates have
been accepted  i e  the total number of candidates screened 
proceedings of the thirtieth    ijcai-21 
155
 gender \ age
s
j
m
1/2 − ϵ′
1/4
f
1/4
ϵ′
table 1  example candidate distribution p with 2 binary features 
the agent following a  possibly randomized  algorithm alg
must minimize the sample complexity ep alg τ  
importantly  we consider two settings  whether the candi-
date distribution p is known or unknown 
remark  in this model  we simply ignore non-volunteers 
since the agent only needs to make decisions for volunteers 
which from now on we call candidates  the joint distribution
of characteristic vectors in the population of candidates is p 
3 2
greedy strategy
we describe a first simple strategy  in greedy  the agent
greedily accepts any candidate as long as the number of peo-
ple in the committee with xi = j does not exceed the quota
⌈ρi
jk⌉  
ϵk
 di−1  for any i  j  where ϵ > 0 is some tolerance
parameter for the representation quality 
proposition 1  the representation loss incurred by greedy
is bounded as follows 
∥λ cτ  − ρ∥∞ ≤
a s 
�maxi∈ d  di − 1
k
  ϵ  
this method is simple to interpret and implement  and can
even be used when the candidate distribution p is unknown 
however  in the following example  we see that greedy may
be inefficient because it requires interacting with an arbitrar-
ily large number of candidates to recruit a full committee 
example 1  let ϵ′ > 0  ≪ 1  there are 2 binary features 
gender and age  with domains xgender =  m  f  and xage =
 s  j   the candidates are distributed as p given in table 1 
we want a committee of size k = 4  e g   a thesis committee 
and the target is ρgender =  1/2  1/2  and ρage =  3/4  1/4  
let a be the event that in the first 3 timesteps 
the agent observes candidates with characteristic vectors
 fs  ms  ms  in any order  then greedy accepts all of
them  i e  a =  c3 =  fs  ms  ms    we have  p  a  =
1/4 1/2 − ϵ′ 2 × 3  = 3/2 1/2 − ϵ′ 2 ≥ 3/2
�
1/3
�2 = 1/6 
under event a  greedy can only stop upon finding fj
in order to satisfy the representation constraints  therefore 
τ|a follows a geometric distribution with success probability
ϵ′  hence its expectation is 1/ϵ′  and ep greedy τ  ≥ e  τ|a  ×
p  a  = 1/6ϵ′  therefore  the sample complexity of greedy in
this example is arbitrarily large 
this example shows the limits of directly applying a naive
strategy to our online selection problem  where the diffi-
culty arises from considering multiple features simultane-
ously  even when there are only 2 binary features  we fur-
ther discuss the strengths and weaknesses of greedy  and its
sensitivity to the tolerance ϵ in our experiments in section 6 
the greedy strategy is adaptive  in the sense that decisions
are made based on the current candidate and candidates ac-
cepted in the past  in the following section  we present  with
theoretical guarantees  an efficient yet non-adaptive algorithm
based on constrained mdps for the setting in which the candi-
date distribution is known  we then adapt this approach to the
case when this distribution is unknown  using techniques for
efficient exploration / exploitation in constrained mdps rely-
ing on the principle of optimism in the face of uncertainty 
4
p is known  constrained mdp strategy
in this section  we assume the distribution p is known  and
we place ourselves in the limit where we would select a com-
mittee of infinite size  and aim to maximize the rate at which
candidates are selected  under the constraint that the propor-
tion of accepted candidates per feature value is controlled
by ρ  one advantage of this approximation is that the op-
timal policy is stationary  thus simple to represent  more-
over  as stationary policies can be very well parallelized  in
the case where multiple candidates can be interviewed simul-
taneously  to apply this approach to the finite-size committee
selection problem  one needs to interrupt the agent when k
candidates have been selected  we showcase a high proba-
bility bound of o 
�
1/k  on the representation loss  which
guarantees that for large enough values of k  the resulting
committee is representative 
from now on  we assume that any feature vector can be
observed  i e   p x  > 0 for all x  so that proportional repre-
sentation constraints can be satisfied 
4 1
our model
fundamentally  our problem could be seen as a contextual
bandit with stochastic contexts xt ∼ p and two actions at = 0
or 1  however  the type of constraints incurred by propor-
tional representation are well studied in constrained mdps
 cmdps   altman  1999   whereas the contextual bandits
literature focused on other constraints  e g   knapsack con-
straints  agrawal and devanur  2016    we show how we
can efficiently leverage the cmdp framework for our online
committee selection problem 
formally  we introduce an mdp m =  x  a  p  r   where
the set of states is the d-dimensional candidate space x  the
set of actions is a =  0  1   and the  deterministic  reward is
r x  a  = 1 a=1   the transition kernel p  which defines the
probability to be in state x′ given that the previous state was
x and the agent took action a  is very simple in our case  we
simply have p x′|x  a  = p x′  since candidates are drawn
i i d regardless of the previous actions and candidates 
we consider the average reward setting in which the per-
formance of a policy π   x × a →  0  1  is measured by its
gain gp π  defined as 
gp π x  = lim
t →∞
1
t ep π
� t
�
t=1
r xt  at 
����x1 = x
�
 
we simply write gp π  = gπ when the underlying transition
is p without ambiguity 
we include proportional representation constraints follow-
ing the framework of cmdps  where the set of allowed poli-
cies is restricted by a set of additional constraints specified by
reward functions  in our case  for i ∈  d   j ∈  di   we in-
troduce ri
j x  a  = 1 xi=j a=1   and let ξi
j = ri
j − ρi
jr be the
proceedings of the thirtieth    ijcai-21 
156
 reward function for the constraint indexed by i  j  similarly to
the gain  we define hi
j
π = limt →∞ 1
t eπ ��t
t=1 ξi
j xt  at 
�
 
the cmdp is defined by 
max
π  gπ | ∀i ∈  d   ∀j ∈  di   hi
j
π = 0  
 1 
given the simplicity of the transition kernel  and since the
mdp is ergodic by the assumption p > 0  the gain is constant 
i e  ∀x ∈ x  gπ x  = gπ  and problem  1  is well defined 
from now on  we only write gπ and ξi
j
π  moreover  the opti-
mal policy for the cmdp  1  is denoted π∗ and is stationary
 altman  1999  
lemma 1  gπ is the selection rate under policy π 
gπ =
�
x
p x π x  1  = pp π a = 1 
moreover  if π is feasible for cmdp  1   then 
∀i ∈  d   ∀j ∈  di   pp π xi = j|a = 1  = ρi
j 
lemma 1 implies that  a  π∗ maximises the selection rate
of candidates  and  b  the constraints of  1  force candidates
x with xi = j to be accepted in proportions given by ρi
j 
the cmdp can be expressed as the linear program 
max
π∈rx×a
 
�
x a
π x  a p x r x  a 
u c 
∀x ∈ x 
�
a
π x  a  = 1
∀i  j 
�
x a
π x  a p x ξi
j x  a  = 0 
 2 
notice that problem  2  is feasible by the assumption that
∀x ∈ x  p x  > 0  next we study how well the proportional
selection along features is respected when we shift from infi-
nite to finite-sized committee selection 
4 2
theoretical guarantees
we analyze the cmdp-based strategy where at each timestep 
the agent observes candidates xt ∼ p  decides to accept xt
by playing at ∼ π∗  |xt  and stops when k candidates have
been accepted  we later refer to it as cmdp for brevity 
first  we formally relate the gain gπ that we optimize for
in  1  to the quantity of interest ep π τ  
lemma 2  for any stationary policy π  ep π τ  = k
gπ  
lemma 2 is a direct consequence of the fact that τ  k fol-
lows a negative binomial distribution with parameters k and
1 − gπ  which are respectively the number of successes and
the probability of failure  i e  of rejecting a candidate under
π  note that this is only true because in our case the transition
structure of the mdp ensures constant gain  a quick sanity
check shows that if the agent systematically accepts all can-
didates  i e  gπ = 1  then ep π τ  = k  and that maximizing
gπ is equivalent to minimizing ep π τ  
we exhibit a bound on the representation loss of cmdp
which follows the optimal stationary policy π∗ of cmdp  1  
let ˜d = �d
i=1 di − 1     ˜d = d when all features are binary  
algorithm 1  rl-cmdp algorithm 
input   confidence δ  committee size k  targets ρ
output  committee cτ
1 t ← 0  c0 ← ∅ 
2 while |ct| < k do
3
for episode l = 1  2      do
4
τl = t   1 
5
πl ← sol  of  4  via the extended lp  5  
6
while nt xt  < 2nτl−1 xt  do
7
t ← t   1  execute πl 
8
end
9
end
10 end
11 return ct
proposition 2  let π∗ be an optimal stationary policy for
cmdp  1   let δ > 0  then 
pp π∗
�
�∥λ cτ  − ρ∥∞ ≤
�
log  2 ˜d
δ  
2k
�
� ≥ 1 − δ 
all proofs of this section are available in appendix    
the upper bound on the representation loss of cmdp de-
creases with the committee size in
�
1/k  this shows that
the stationary policy π∗ works well for larger committees 
although it acts independently from previously accepted can-
didates  the intuition is that for larger committees  adding a
candidate has less impact on the current representation vector 
example 2  we take the same attributes and same distribu-
tion as in table 1  with ϵ′ = 1/6  here  the target vectors are
ρgender =  1/2  1/2  and ρage =  1/2  1/2   an ideal committee
contains as many women as men  as many senior as junior 
with the optimal policy for lp  2   each time the current
volunteer is a senior male  we select him with probability 1/2 
all other volunteers are selected with probability 1  the ex-
pected final composition of the pool is 30  of junior male 
30  of senior female  20  of junior female and 20  of se-
nior male  as the policy selects in average 5/6 of the vol-
unteers  the expected time until we select k candidates is
ep π∗ τ  =  6/5 k 
5
p is unknown  optimistic cmdp strategy
we now tackle the committee selection problem when the
candidate distribution p is unknown and must be learned on-
line  let g∗ = gπ∗ be the value of  1   which is the optimal
gain of the cmdp when the distribution p is known  we eval-
uate a learning algorithm by 
1  the performance regret  r t  = �t
t=1 g∗ − r xt  at   
2  the cost of constraint violations 
rc t  = maxi j
�� �t
t=1 ξi
j xt  at 
�� 
we propose an algorithm that we call rl-cmdp  reinforce-
ment learning in cmdp  alg  1   it is an adaptation of the
optimistic algorithm ucrl2  jaksch et al   2010   and it also
builds on the algorithm optcmdp proposed by  efroni et al  
proceedings of the thirtieth    ijcai-21 
157
 2020  for finite-horizon cmdps  learning in average-reward
cmdps involves different challenges  because there is no
guarantee that the policy at each episode has constant gain 
it does not matter in our case  since as we noted in sec  4 
the simple structure of the transition kernel ensures constant
gain  and does not require to use the bellman equation  the
few works on learning in average-reward cmdps make un-
suitable assumptions for our setting  zheng and ratliff  2020 
singh et al   2020  
rl-cmdp proceeds in episodes  which end each time the
number of observations for some candidate x doubles  dur-
ing each episode l  observed candidates xt are accepted on
the basis of a single stationary policy πl 
let τl denote the start time of episode l and el =  τl  τl 1  
let nt x 
=
�t
t′=1 1 xt′=x  and n t 
=
|ct−1|
=
�t−1
t′=1 1 at′=1   let n i
j t  = �t−1
t′=1 1 xi
t′=j at′=1  be the
number of accepted candidates x such that xi = j before t 
at each episode l  the algorithm estimates the true can-
didate distribution by the empirical distribution ˆpl x  =
nτl−1 x 
τl−1
and maintains confidence sets bl on p 
as in
ucrl2  these are built using the inequality on the ℓ1-
deviation of p and ˆpl from  weissman et al   2003  
lemma 3  with probability ≥ 1 − δ
3 
∥ˆpl − p∥1 ≤
�
2|x| log
�
6|x|τl τl − 1 /δ
�
τl − 1
 = βl
 3 
let bl =  ˜p ∈ ∆ x    ∥ˆpl − ˜p∥1 ≤ βl  be the confi-
dence set for p at episode l  the associated set of compatible
cmdps is then   ˜
m =  x  a  ˜p  r  ξ    ˜p ∈ bl   at the
beginning of each episode  rl-cmdp finds the optimum of 
max
π∈π ˜p∈bl g ˜p π | ∀i  j  hi
j
˜p π = 0  
 4 
extended lp 
in order to optimize this problem  we re-
write  4  as an extended lp  following  rosenberg and man-
sour  2019  and the cmdp literature  we introduce the state-
action occupation measure µ x  a  = π x  a p x  and vari-
ables β x  to linearize the ℓ1 constraint induced by the confi-
dence set 
max
µ∈rx×a
β∈rx
�
x a
µ x  a r x  a 
u c 
µ ≥ 0 
�
x a
µ x  a  = 1
∀x 
�
a
µ x  a  ≤ ˆpl x    β x 
∀x 
�
a
µ x  a  ≥ ˆpl x  − β x 
∀x  a 
�
y
β y  ≤ µ x  a βl
∀i  j 
�
x a
µ x  a ξi
j x  a  = 0 
 5 
the last constraint is the proportional representation con-
straint  the second to fourth constraints enforce the com-
patibility of µ with the ℓ1 confidence set  we retrieve the
distribution as ˜pl x  = �
a µ x  a   and the policy as 
πl x  a  =
�
µ x a 
˜pl x 
if ˜pl ̸= 0
1
2
otherwise  
precisely  if some ˜pl x  = 0  we may set the policy πl a|x 
arbitrarily  since the mdp induced by ˜p is still weakly com-
municating  and in particular any policy is unichain  the opti-
mal gain in this cmdp is not affected 
we now provide regret and representativeness guarantees 
theorem 1  with probability ≥ 1 − δ  the regret of rl-cmdp
satisfies 
r t  = o
��
|x|t log |x|t/δ 
�
rc t  = o
��
|x|t log |x|t/δ 
�
 
moreover  with probability 1 − δ  the representation loss of
rl-cmdp at horizon t satisfies 
∥λ ct   − ρ∥∞ = o
�
� 1
g∗
�
|x| log
�
|x|t/δ
�
t
�
�  
it relies on decomposing regret over episodes  bounding
the error on p which decreases over episodes as the confi-
dence sets are refined  and leveraging martingale inequalities
on the cumulative rewards 
since r t  
t
= g∗ − n t  
t
  it means that with high prob-
ability  the difference between the optimal selection rate and
the selection rate of rl-cmdp decreases in
�
log t /t w r t 
the horizon t  the representation loss decreases at the same
speed  meaning that the agent should see enough candidates
to accurately estimate p  and accept candidates at little cost
for representativeness 
compared to the bound from proposition 2  the cost of not
knowing p on representativeness is a
�
|x| log |x|  factor 
this is due to the estimation of p in the worst case  which
is controlled by lemma 3  as we show in our experiments
 sec  6   the impact of |x| on performance regret  and in
turn on sample complexity  is not problematic in our typical
citizens  assembly scenario  since there are only a handful
of features  our algorithm selects candidates quickly in prac-
tice  though representativeness is weakened by not knowing
p   for specific structures of p  we obtain bounds with better
scaling in |x|  by controlling each entry of p with bernstein
bounds  maurer and pontil  2009   instead the ℓ1-norm 
interestingly  the representation loss is also inversely pro-
portional to g∗  the optimal selection rate in the true cmdp 
the reason is that the cmdp constraints do not control the
ratios λi
j ct   =
n i
j t  
n t     but n i
j t  instead  by definition of
rc t  and ξi
j   if n t  is small  i e  due to a small selection
rate g  then ri
j t  = |n i
j t  − ρi
jn t | is small  but not
necessarily |
n i
j t  
n t   − ρi
j|  the committee is too small to be
representative 
proceedings of the thirtieth    ijcai-21 
158
 6
experiments
the goal of these experiments is to answer the following 
 q1  in practice  for which range of committee sizes do our
strategies achieve satisfying sample complexity and represen-
tation loss   q2  what is the cost of not knowing the distri-
bution p for the sample complexity and representation loss 
experimental setting 
to answer these questions  we use
summary data from the 2017 citizens  assembly on brexit 
the participants were recruited in an offline manner  volun-
teers could express interest in a survey  and then 53 citizens
were drawn from the pool of volunteers using stratified sam-
pling  in order to construct an assembly that reflects the di-
versity of the uk electorate  we use summary statistics pub-
lished in the report  renwick et al   2017  to simulate an on-
line recruitment process 
there are d = 6 features  the organisers expressed target
quotas for 2 ethnicity groups  2 social classes  3 age groups 
8 regions  2 gender groups and 2 brexit vote groups  remain 
leave   the report also includes the number of people con-
tacted per feature group  e g   women  or people who voted
to remain  and the volunteering rate for each feature group 
which we use as probability of volunteering given a feature
group  we use bayes  rule to compute the probabilities of fea-
ture groups among volunteers  and use them as the marginal
distributions pr xi = j|volunteers   since we only consider
the population of volunteers   since we only have access to
the marginals  we compute the joint distribution as if the fea-
tures were independent  although our model is agnostic to the
dependence structure of the joint distribution 
we study greedy with tolerance ϵ = 0 02  0 05  we run
experiments for k = 50  100  150  250  500  1000  averaged
over 50 simulations 
 a1  
we compare greedy and cmdp  when the distribution
p is known  figure 1 shows that the greedy strategy with
ϵ = 0 05 requires 10 times more samples than cmdp  and
its representation loss is higher as soon as k ≥ 250  greedy
with lower tolerance ϵ = 0 02 achieves better representation
than cmdp for smaller committees  k ≤ 100   but the margin
quickly decreases with k  however  even for small com-
mittees  it requires about 100 times more samples  which is
prohibitively expensive  figure 1 shows that for cmdp  the
sample complexity grows linearly in the committee size  with
a reasonable slope  we need to find τ ≈ 500 volunteers for a
committee of size k ≈ 200  
 a2  
to corroborate the previously discussed effect of |x|
when p is unknown  we evaluate rl-cmdp on different con-
figurations   1  using only the features ethnicity  social class 
and gender  d = 3  |x| = 8    2  using all features except
regions  d = 5  |x| = 48   fig  2 shows that unlike cmdp
which has full knowledge of p  it is for large committee sizes
that rl-cmdp reaches low representation loss  below 0 05 for
k ≥ 1500 in the configuration 1    this is because rl-cmdp
needs to collect more samples to estimate p  as discussed in
th  1  for known p  the cmdp approach achieves the same
representativeness for middle-sized committees  repr 
loss
≤ 0 05 for k ≈ 250   hence  comparing the cases of known
 fig  1  and unknown distribution p  fig  2   the ignorance
figure 1  effect of committee size k on sample complexity and rep-
resentation loss for different strategies  in the uk brexit assembly
experiment  using all features  p is known 
figure 2  effect of committee size k on sample complexity and rep-
resentation loss for rl-cmdp  on data simulated from the uk brexit
assembly  using 3 and 5 features  p is unknown 
of p is not costly for sample complexity  but rather for the
representation loss which decreases more slowly 
consistently with th  1  we observe that the representation
loss is higher when x is larger  d = 5   for small and middle-
sized committees  the loss of rl-cmdp is much worse than
greedy s which also works for unknown p  for large com-
mittees though  the margin is only 0 05 when k ≳ 2000 and
τ ≈ 3500 for rl-cmdp  which is ×3 more sample efficient
than greedy   in absolute terms  the theoretical regret bounds
have a large constant
�
|x| 
this constant is likely un-
avoidable asymptotically because it comes from lem  3  but
our experiments suggest that in the non-asymptotic regime 
rl-cmdp performs better than the bound suggests 
7
conclusion
we formalised the problem of selecting a diverse committee
with multi-attribute proportional representation in an online
setting  we addressed the case of known candidate distri-
butions with constrained mdps  and leveraged exploration-
exploitation techniques to address unknown distributions 
acknowledgements
this work was funded in part by the french government un-
der management of agence nationale de la recherche as part
of the  investissements d avenir  program anr-19-p3ia-
0001  prairie 3ia institute   we thank matteo pirotta for
his helpful suggestions and feedback 
proceedings of the thirtieth    ijcai-21 
159
 references
 agrawal and devanur  2016  shipra agrawal and nikhil
devanur  linear contextual bandits with knapsacks  in ad-
vances in neural information processing systems  pages
3450–3458  2016 
 altman  1999  eitan altman  constrained markov decision
processes  volume 7  crc press  1999 
 aziz  2019  haris aziz  a rule for committee selection with
soft diversity constraints  group decision and negotia-
tion  28 1193–1200  2019 
 babaioff et al   2008  moshe babaioff  nicole immorlica 
david kempe  and robert kleinberg 
online auctions
and generalized secretary problems  acm sigecom ex-
changes  7 2  1–11  2008 
 badanidiyuru et al   2014  ashwinkumar
badanidiyuru 
baharan mirzasoleiman  amin karbasi  and andreas
krause 
streaming submodular maximization  massive
data summarization on the fly  in proceedings of the 20th
acm sigkdd  pages 671–680  2014 
 bateni et al   2013  mohammadhossein bateni 
moham-
madtaghi hajiaghayi  and morteza zadimoghaddam  sub-
modular secretary problem and extensions  acm transac-
tions on algorithms  talg   9 4  1–23  2013 
 bei et al   2020  xiaohui bei  shengxin liu  chung keung
poon  and hongao wang  candidate selections with pro-
portional fairness constraints  in proceedings of the 19th
international conference on autonomous agents and mul-
tiagent systems  aamas  20  auckland  new zealand 
may 9-13  2020  pages 150–158  2020 
 benad e et al   2019  gerdus
benad e 
paul
g¨olz 
and
ariel d procaccia 
no stratification without represen-
tation  in proceedings of the 2019 acm conference on
economics and computation  pages 281–314  2019 
 bredereck et al   2018  robert
bredereck 
piotr
fal-
iszewski  ayumi igarashi  martin lackner  and piotr
skowron 
multiwinner elections with diversity con-
straints  in thirty-second aaai conference on artificial
intelligence  2018 
 celis et al   2018  l  elisa celis  lingxiao huang  and
nisheeth k  vishnoi 
multiwinner voting with fairness
constraints 
in proceedings of the 27th international
joint conference on artificial intelligence  pages 144–
151  2018 
 efroni et al   2020  yonathan efroni  shie mannor  and
matteo pirotta 
exploration-exploitation in constrained
mdps  arxiv preprint arxiv 2003 02189  2020 
 faliszewski et al   2017  piotr faliszewski  piotr skowron 
arkadii slinko  and nimrod talmon  multiwinner voting 
a new challenge for social choice theory  trends in com-
putational social choice  74 27–47  2017 
 flanigan et al   2020  bailey flanigan  paul g¨olz  anupam
gupta  and ariel d procaccia  neutralizing self-selection
bias in sampling for sortition  in h  larochelle  m  ran-
zato  r  hadsell  m  f  balcan  and h  lin  editors  ad-
vances in neural information processing systems  vol-
ume 33  pages 6528–6539  curran associates  inc   2020 
 jaksch et al   2010  thomas jaksch  ronald ortner  and pe-
ter auer  near-optimal regret bounds for reinforcement
learning  journal of machine learning research  11 4  
2010 
 lang and skowron  2018  j erˆome lang and piotr skowron 
multi-attribute proportional representation  artificial in-
telligence  263 74–106  2018 
 maurer and pontil  2009  andreas maurer and massimil-
iano pontil  empirical bernstein bounds and sample vari-
ance penalization  arxiv preprint arxiv 0907 3740  2009 
 panigrahi et al   2012  debmalya
panigrahi 
atish
das sarma  gagan aggarwal  and andrew tomkins 
online selection of diverse results  in proceedings of the
fifth acm international conference on web search and
data mining  pages 263–272  2012 
 renwick et al   2017  a renwick  s allan  w jennings 
r mckee  m russell  and g smith  a considered pub-
lic voice on brexit  the report of the citizens  assembly on
brexit  2017 
 rosenberg and mansour  2019  aviv rosenberg and yishay
mansour 
online
convex
optimization
in
adver-
sarial markov decision processes 
arxiv preprint
arxiv 1905 07773  2019 
 schumann et al   2019  candice schumann 
samsara n
counts  jeffrey s foster  and john p dickerson  the di-
verse cohort selection problem  in proceedings of the 18th
international conference on autonomous agents and mul-
tiagent systems  pages 601–609  international foundation
for autonomous agents and multiagent systems  2019 
 singh et al   2020  rahul singh 
abhishek gupta 
and
ness b shroff  learning in markov decision processes un-
der constraints  arxiv preprint arxiv 2002 12435  2020 
 stoyanovich et al   2018  julia stoyanovich  ke yang  and
hv jagadish  online set selection with fairness and diver-
sity constraints  in proceedings of the edbt conference 
2018 
 weissman et al   2003  tsachy weissman  erik ordentlich 
gadiel seroussi  sergio verdu  and marcelo j weinberger 
inequalities for the l1 deviation of the empirical distribu-
tion  hewlett-packard labs  tech  rep  2003 
 zheng and ratliff  2020  liyuan
zheng
and
lillian
j
ratliff 
constrained upper confidence reinforcement
learning  arxiv preprint arxiv 2001 09377  2020 
proceedings of the thirtieth    ijcai-21 
160
 "
None,2021,https-www-ijcai-org-proceedings-2021-0023-pdf,Graphical Cake Cutting via Maximin Share,"Edith Elkind, Erel Segal-Halevi, Warut Suksompong",None,https://www.ijcai.org/proceedings/2021/0023.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0023-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0023-pdf.pdf,"graphical cake cutting via maximin share
edith elkind1   erel segal-halevi2 and warut suksompong3
1department of computer science  university of oxford
2department of computer science  ariel university
3school of computing  national university of singapore
elkind@cs ox ac uk  erelsgl@gmail com  warut@comp nus edu sg
abstract
we study the recently introduced cake-cutting set-
ting in which the cake is represented by an undi-
rected graph  this generalizes the canonical inter-
val cake and allows for modeling the division of
road networks  we show that when the graph is a
forest  an allocation satisfying the well-known cri-
terion of maximin share fairness always exists  our
result holds even when separation constraints are
imposed  however  in the latter case no multiplica-
tive approximation of proportionality can be guar-
anteed 
furthermore  while maximin share fair-
ness is not always achievable for general graphs 
we prove that ordinal relaxations can be attained 
1
introduction
cake cutting is an old and famous problem in resource allo-
cation  with the cake serving as a metaphor for a heteroge-
neous divisible resource that is supposed to be fairly divided
among interested agents  while the problem has long enjoyed
substantial attention from mathematicians and economists 
it has also attracted ongoing interest from computer scien-
tists  not least those working in artificial intelligence  balka-
nski et al   2014  li et al   2015  brˆanzei et al   2016 
alijani et al   2017  menon and larson  2017  bei et al  
2018  arunachaleswaran et al   2019  goldberg et al   2020 
hosseini et al   2020   indeed  as procaccia  2013  aptly put
it  cake cutting is more than just child s play 
the cake in cake cutting is typically assumed to be a one-
dimensional interval  even though the linear representation
is appropriate for modeling the division of time  for instance 
usage of a jointly-owned facility   or space in a hallway  it
is too simplistic to capture more complex resources such
as road networks  this consideration has led bei and suk-
sompong  2021  to introduce a more general graphical cake
model  in which the resource comes in the form of a con-
nected undirected graph  in parallel  segal-halevi  2021  ad-
dressed the case of graphs given by a disjoint union of inter-
vals  in contrast to the single interval cake  for general graphs
it is not always possible to find a connected proportional allo-
cation  that is  an allocation that gives every agent a connected
subset of the cake worth at least 1/n of the agent s value for
the entire cake  where n denotes the number of agents among
whom the cake is divided  nevertheless  bei and suksom-
pong showed that more than half of this guarantee can be re-
covered  for any connected graph  it is possible to ensure that
every agent obtains at least 1/ 2n − 1  of her total value  and
this factor is tight in general  but can be improved for certain
graphs   for the union-of-intervals case  segal-halevi estab-
lished an approximation factor of 1/ m   n − 1   where m
denotes the number of intervals 
in this paper  we study graphical cake cutting with respect
to another prominent fairness notion  maximin share fairness
 budish  2011   an allocation satisfies this notion if it assigns
to every agent a bundle worth at least her maximin share  i e  
the largest value that she can get if she is allowed to partition
the cake into n connected parts and take the least valuable
part  maximin share fairness is a robust notion  which can
naturally take into account the features and constraints arising
in various settings  indeed  this robustness enables us to de-
rive positive results in three settings where approximate pro-
portionality fails  first  we allow the graph to be arbitrary—
it may be disconnected  and each of its connected compo-
nents may have an arbitrary topology 
second  we allow
agents to have general monotone valuations—unlike most of
the cake cutting literature  we do not assume that valuations
must be additive  with disconnected graphs or non-additive
valuations  providing an approximate proportionality guaran-
tee solely in terms of n is impossible  third  we also consider
a recently introduced setting of elkind et al   2021c  in which
the shares of different agents should be sufficiently separated
from one another  this allows us to model space between seg-
ments of roads with different owners  for example transition
or buffer zones  in the presence of separation constraints  ob-
taining any multiplicative approximation of proportionality is
again infeasible  as the value of all agents may be entirely
concentrated in the same tiny portion  this observation moti-
vated elkind et al  to use the maximin share benchmark when
separation is imposed  they showed that with separation  a
maximin allocation always exists for a path graph  but not for
a cycle graph 
1 1
our contributions
we begin in section 3 by addressing the basic case where no
separation constraints are imposed  in this case  for propor-
tionality approximations it can be crucial whether pieces of
different agents are allowed to share a finite number of points
proceedings of the thirtieth    ijcai-21 
161
  bei and suksompong  2021   we show that this modeling
choice is also crucial with respect to maximin share fairness 
in particular  if points can be shared  then a maximin allo-
cation may not exist even when the graph is a star  whereas
if sharing is not allowed  the existence of such an allocation
can be guaranteed if the graph is acyclic  i e   a disjoint union
of trees  also known as a forest   our results complement
those of bei and suksompong  who observed that approx-
imate proportionality cannot be ensured even for trees un-
der the no-sharing assumption  moreover  our guarantees de-
grade gracefully for graphical cakes with cycles  we attain a
1-out-of- n   r  maximin allocation  where r is the feedback
vertex set number of the cake  that is  the smallest number of
vertices whose removal would make the cake acyclic  
in section 4  we consider the more general case where the
pieces of any two agents must be separated by distance at
least a given  positive  parameter  our main technical result
shows that a maximin allocation exists whenever the graph is
acyclic—this significantly generalizes the existence result of
elkind et al   2021c  for paths and complements their non-
existence result for cycles  as with paths  our proof uses the
following high-level idea  given the maximin partitions of
the agents  we find a part in one agent s partition such that
allocating the part to that agent rules out at most one part in
each remaining agent s partition  this allows us to recurse on
the remaining agents and cake  while in the case of paths the
desired part can be found by simply scanning the path from
left to right  in an arbitrary forest there is no  left  or  right  
so new techniques are needed  we develop auxiliary lemmas
related to real trees—metric spaces defined by tree graphs—
which may be of independent interest  as in the case of no
separation  we obtain a 1-out-of- n   r  maximin allocation
for general graphs 
for the case of positive separation  we show that  in gen-
eral  the factor n   r cannot be improved  for every r ≥ 0 
if n is sufficiently large  there exists a graph with feedback
vertex set number r and a set of n agents with no 1-out-of-
 n   r − 1  maximin allocation  however  better guarantees
can be attained for smaller n and specific classes of graphs 
1 2
additional related work
as mentioned earlier  cake cutting is a popular topic among
researchers of several disciplines—see the classic books of
brams and taylor  1996  and robertson and webb  1998   as
well as a more recent survey by procaccia  2016  offering a
computer scientist s perspective 
for a discussion of the work relevant to graphical fair divi-
sion and separation constraints  see the related work sections
in the papers of bei and suksompong  2021  and elkind et
al   2021c   we highlight here some important aspects of our
study  first  we assume that each agent must receive a con-
nected piece of cake  this assumption is often made in or-
der to ensure that agents do not end up with a collection of
crumbs—indeed  a bundle made up of tiny stretches of road
in different parts of the network is unlikely to be of much
use  second  the connectivity requirement is imposed not
only on the allocation  but also in the definition of the max-
imin share  this is consistent with previous work on maximin
share fairness in constrained settings  bouveret et al   2017 
biswas and barman  2018  lonc and truszczynski  2020 
bei et al   2021  elkind et al   2021c   bouveret et al   2017 
proved that for indivisible items lying on a tree  a maximin al-
location exists  however  as we discuss in section 5  the  last
diminisher  approach that they used for this proof does not
work in our setting with separation  recently  igarashi and
zwicker  2021  studied envy-freeness in graphical cake cut-
ting under the assumption that agents cannot share individual
points  while elkind et al   2021b  investigated land division
with separation constraints 
in the papers above  as in our paper  the resource to be
divided forms a graph  a complementary line of work stud-
ies fair division scenarios in which the agents  relationship
is captured by a graph  abebe et al   2017  bei et al   2017 
aziz et al   2018  
2
preliminaries
there is a set of agents n =  n   where  k   =  1  2          k 
for any positive integer k  the cake is represented by a finite
undirected graph g =  v  e   which may be connected or
not  each agent has a nonnegative  monotone  and continuous
valuation function vi  which is not necessarily additive  in
particular  continuity implies that the vertices in v have zero
value  this model captures the classic cake cutting setting
as well as the circular cake  a k a  pie  studied by elkind et
al   2021c   an interval cake corresponds to taking g to be a
path graph  while a pie is equivalent to a cycle graph  a piece
of cake is a finite union of intervals from one of more edges
in e  the piece is said to be connected if for any points x  y
in it  one can get from x to y along the graph g while staying
within this piece of cake  we assume that each agent must
receive a connected piece of cake 
there is a separation parameter s ≥ 0  when s > 0  the
edge lengths play an important role  we measure distance
along the edges of g  for any two points x  y ∈ g  we denote
by distg x  y  the length of a shortest path from x to y along
the edges of g  if x and y belong to different connected com-
ponents of g  we set distg x  y  = ∞  for two pieces of
cake x  y ⊆ g  we denote by distg x  y   the shortest dis-
tance between a point in x and a point in y along the edges
of g  i e   distg x  y   = infx∈x y∈y distg x  y   if y
consists of a single point y  we simply write distg x  y  
a partition of the cake is a set p =  p1          pn   where
each pi is a connected piece of cake  and the pieces are pair-
wise disjoint  pi ∩ pj = ∅ for all i ̸= j  when s = 0  we
will consider  in addition to the disjoint-pieces setting  an al-
ternative setting in which pi ∩ pj may contain finitely many
points  an allocation is defined similarly  except that we have
a vector a =  a1          an  instead of a set  where piece ai
is allocated to agent i  a partition p is said to be s-separated
if distg pi  pj  ≥ s for all i ̸= j  an analogous defini-
tion holds for an allocation  we assume that partitions and
allocations are required to be s-separated  observe that for
s > 0  in any s-separated partition or allocation  some of the
cake necessarily remains unallocated  moreover  since any
two pieces are separated by a positive distance  we assume
without loss of generality in this case that the pieces contain
proceedings of the thirtieth    ijcai-21 
162
 closed intervals only  denote by γn s the set consisting of all
s-separated partitions 
the main fairness notion of our paper is the following 
definition 2 1  the maximin share of agent i  denoted by
mmsn s
i
  is defined as supp∈γn s minj∈ n  vi pj  
we omit the superscript s when it is clear from the con-
text  similarly to the interval cake  elkind et al   2021c   the
supremum in definition 2 1 can be replaced with a maximum 
in other words  there is always a maximizing partition  which
we refer to as a maximin partition  an allocation in which
every agent receives at least her maximin share is said to be a
maximin allocation 
all omitted proofs can be found in the full version of our
paper  elkind et al   2021a  
3
no separation
in this section  we address the basic case where there is no
separation constraint imposed on the allocation  i e   s = 0 
when s > 0  the pieces of any two agents cannot be adjacent
to each other  so we can assume without loss of generality
that all pieces consist of closed intervals only and the pieces
have empty intersections  for s = 0  however  this is not true 
there are essential differences between the empty-intersection
setting and the finite-intersection setting  in which pieces may
overlap in finitely many points  this observation was made
by bei and suksompong  2021  with respect to approximate
proportionality for the case of a star graph  specifically  in
the empty-intersection setting  n − 1 agents do not receive
the center of the star and therefore can receive cake from at
most one edge  as a consequence  one obtains strong negative
results  on the other hand  in the finite-intersection setting 
non-trivial welfare guarantees can be obtained 
as we will see  the distinction between empty intersection
and finite intersection is crucial with respect to maximin share
fairness too  note that we use the same constraints when se-
lecting an allocation and when computing the benchmark 
e g   in the finite-intersection setting  when computing the
agents  maximin shares  we optimize over all partitions where
parts may intersect in a finite number of points  thus  allow-
ing intersections results in a more demanding benchmark 
first  we show that in the finite-intersection setting  a max-
imin allocation may not exist 
proposition 3 1  assume that the allocated pieces are al-
lowed to intersect in a finite number of points  there exists
an instance with n = 3 agents and a star cake in which no
maximin allocation exists 
proof  the proof follows the celebrated theorem 2 1 of
kurokawa et al   2018   which shows that a maximin allo-
cation of indivisible objects may not exist for n = 3 agents 
in their instance  there are 12 objects  indexed by j ∈  3 
and k ∈  4   each agent i ∈  3  values each object  j  k  by 
vi j  k  = 1000000   1000 · tj k   e i 
j k 
where t  e 1   e 2   e 3  are carefully chosen 3×4 matrices
with all values smaller than 100  kurokawa et al  proved that
every agent can partition the objects into 3 subsets of 4 objects
each  in such a way that the sum of values in each subset is
exactly 4055000  this value is therefore the maximin share of
all agents  these authors then showed that no allocation gives
every agent at least this value 
in our instance  there is a star graph with 12 edges con-
nected to a single center vertex c  the edges are indexed by
pairs  j  k  with j ∈  3   k ∈  4   agent i ∈  3  has value
vi j  k  for the edge  j  k   and this value is spread uniformly
across the edge  since the pieces may intersect in a finite
number of points  the maximin share of each agent in our in-
stance is also 4055000  and corresponds to partitioning the
set of edges into 3 subsets of 4 edges each  intersecting in c 
if an agent s piece is contained in a single edge  then her
value is clearly less than 2000000  hence  in a maximin allo-
cation  no edge is shared among two or more agents  we may
therefore assume without loss of generality that each agent
receives a piece containing two or more whole edges  but the
same argument as that of kurokawa et al   2018  shows that
no such allocation can be a maximin allocation 
next  we show that in the empty-intersection setting  a
maximin allocation always exists when the cake is a forest 
theorem 3 2  let g be a forest and s = 0  assume that all
allocated pieces must be completely disjoint  for agents with
arbitrary monotone valuations  a maximin allocation exists 
intuitively  given the n maximin partitions of the agents 
we want to choose a part in one agent s partition that overlaps
at most one part in each remaining agent s partition—this will
allow us to recurse on the remaining agents and their leftover
partitions  to this end  we introduce the following definition 
given a graph g and a family x =  x1          xk  of con-
nected pieces of g  we say that a piece xj is 0-good if for
all j1  j2 ∈  k  the following holds  if xj1 ∩ xj ̸= ∅ and
xj2 ∩ xj ̸= ∅  then xj1 ∩ xj2 ̸= ∅ 
lemma 3 3  let g be a tree and let x =  x1          xk  be a
family of connected subsets of g  for some k ∈ n  for some
j∗ ∈  k   the piece xj∗ is 0-good 
in order to prove this lemma  we must handle both open
and closed pieces 1 indeed  for n = 3 and a star graph with
three edges of equal value  a maximin partition contains two
open pieces and one closed piece 2
proof of lemma 3 3  let m be the number of edges in g 
the proof is by induction on m 
for the base case m = 1  g is an interval  assume without
loss of generality that it is the interval  0  1   each xj is also
an interval which may be open  half-open  or closed  for
each j ∈  k   let ℓj and rj be the left and right endpoint of
xj  respectively  choose j∗ ∈  k  such that rj∗ is smallest 
if there is a tie  break it in favor of a piece that is right-open 
i e   does not contain rj∗  if xj∗ contains its right endpoint
1we are grateful to alex ravsky for the proof idea 
2the finite-intersection analogue of lemma 3 3 does not hold 
for example  if g is a star graph with center c and edges e1  e2  e3 
e4  and x =  e1∪c∪e2  e3∪c∪e4  e1∪c∪e3  e2∪c∪e4   there is
no xj with the property that if xj1 ∩ xj is infinite and xj2 ∩ xj is
infinite  then xj1 ∩ xj2 is infinite  this explains why theorem 3 2
does not extend to the finite-intersection case 
proceedings of the thirtieth    ijcai-21 
163
  i e   it is right-closed   then any piece xj intersecting xj∗
must have ℓj ≤ rj∗ and must contain the point rj∗  on the
other hand  if xj∗ does not contain its right endpoint  i e   it
is right-open   then any piece xj intersecting xj∗ must have
ℓj < rj∗ and must contain an interval  rj∗ − ε  rj∗  for some
sufficiently small ε > 0  in both cases  any two such pieces
xj intersect  so xj∗ is 0-good  this concludes the analysis
for base case 
for the inductive step  let m ≥ 2  assume that the statement
holds for graphs with at most m − 1 edges  and consider a
graph g with m edges  since g is a tree  it contains an edge
e with endpoints u and w such that w is a leaf of g  let g−
be the graph g without the vertex w and the internal points of
edge e  note that u is a vertex of g−  we consider two cases 
case 1  at least one piece of x is contained in e  so it is
an interval   we can then view e as the interval  0  1   with
w = 0  u = 1   and use the same approach as for m = 1 
i e   pick the interval xj∗ with the smallest right endpoint 
breaking ties in favor of right-open intervals  then xj∗ is
0-good by the same argument as in the base case m = 1 
case 2  no piece of x is fully contained in e  this means
that all pieces of x intersect g−  let x′  =  x′
1          x′
k  
where x′
j  = xj ∩ g− for each j ∈  k   by the inductive
assumption applied to g−  at least one piece in x′  say x′
j∗ 
is 0-good with respect to x′  it suffices to show that xj∗ is
also 0-good with respect to x 
we claim that if xj∗ intersects some other piece xj  then
x′
j∗ also intersects x′
j  to see this  consider a point z ∈
xj∗ ∩ xj  if z ∈ g−  then x′
j∗ intersects x′
j and we are
done  if z ∈ e  then both xj∗ and xj intersect e  on the other
hand  we assume that all pieces of x intersect g−  thus 
both xj∗ and xj contain the point u  which is the unique
point connecting e and g−  hence u ∈ x′
j∗ ∩ x′
j  so again
x′
j∗ intersects x′
j  this establishes the claim 
we now show that xj∗ is 0-good with respect to x  sup-
pose that xj∗ intersects two other pieces in x  say xj1 and
xj2  by the claim in the previous paragraph  x′
j∗ intersects
both x′
j1 and x′
j2  since x′
j∗ is 0-good with respect to x′  it
must be that x′
j1 intersects x′
j2  in particular  xj1 intersects
xj2  hence  xj∗ is 0-good with respect to x 
with lemma 3 3 in hand  we can now show that  in the
empty-intersection setting  a maximin allocation exists when-
ever the cake is a forest 
proof of theorem 3 2  for each agent  consider her maximin
partition  every part of the partition is contained in some tree
of the forest  let t ⊆ g be a tree that contains at least one
part from the maximin partition of at least one agent 
for every agent i ∈ n  let ki be the number of parts of
i s maximin partition that are contained in t  and denote the
parts by ti 1          ti ki  by lemma 3 3  there exists some
i ∈ n and j ∈  ki  such that ti j is 0-good  allocate the
part ti j to agent i  and divide the remaining cake recursively
among the remaining agents 
the remaining cake is still a forest  by definition of a 0-
good subset  for every other agent  at most one part of her
maximin partition overlaps the allocated piece ti j  hence 
for each of the n−1 remaining agents  at least n−1 parts from
her maximin partition remain intact  therefore the recursive
call indeed returns a maximin allocation 
as we have seen  the seemingly minor distinction of
whether individual points can be shared among allocated
pieces makes a decisive difference in relation to maximin
share fairness  which assumption is more realistic depends
on the use case  for example whether road intersections can
only be owned by one agent or shared by multiple agents 
bei and suksompong  2021  showed that nontrivial egalitar-
ian welfare can be obtained only when sharing is allowed 
thus  our results complement theirs  we establish that  even
when sharing is infeasible  a reasonable fairness guarantee
can still be provided in terms of the maximin share 
we now proceed to general graphs  we consider an ordi-
nal relaxation called 1-out-of-k maximin share  denoted by
mmsk s
i
  or simply mmsk
i when s is clear from the context 
the idea is that instead of taking partitions into n parts as
in the canonical maximin share  we allow partitions into k
parts  where k > n is a given parameter  for each graph g 
let fvsnum g  be the feedback vertex set number of g  that
is  the minimum number of vertices whose removal makes the
graph acyclic 3
theorem 3 4  let s = 0  and assume that all allocated
pieces must be completely disjoint  for any graph g and any
n agents with arbitrary monotone valuations  there exists an
allocation of g in which each agent i receives a connected
piece with value at least mmsn fvsnum g 
i
 
proof  let r  = fvsnum g   pick a subset of r vertices
such that after deleting these vertices the remaining graph is
a forest  and delete them  while keeping their adjacent edges
intact as open intervals   for each agent  consider her 1-out-
of- n r  maximin partition  since all pieces of each partition
are pairwise disjoint  each vertex deletion harms at most one
part in each partition  thus  once the graph becomes a forest 
for every agent  at least n parts remain  by theorem 3 2 
there is an allocation in which every agent i gets at least one
of her n parts  and therefore value at least mmsn r
i
 
for every graph g  let mmsrank g  be the smallest in-
teger r ≥ 0 such that for any integer n ≥ 1 and any n
agents with arbitrary monotone valuations  there exists an
allocation of g in which each agent i receives a connected
piece with value at least mmsn r
i
  theorem 3 4 shows that
mmsrank g  ≤ fvsnum g   we do not know if this in-
equality is tight 
when agents  valuations are additive  theorem 3 4 is not
tight for some graphs  in particular  for the cycle graph c we
have fvsnum c  = 1  but mmsn
i can be guaranteed to all
agents  by transforming c into an interval  for which a pro-
portional allocation exists  
defining mmsrankadd g 
analogously to mmsrank g   but for additive valuations
only  we thus obtain mmsrankadd c  = 0 
3computing fvsnum g  is np-hard  karp  1972   but here we
only use it for existence proofs  note that fvsnum g  is upper-
bounded by the circuit rank of g  that is  the minimum number of
edges whose removal makes the graph acyclic  the circuit rank of a
graph g =  v  e  with c connected components is |e| − |v |   c 
proceedings of the thirtieth    ijcai-21 
164
 4
positive separation
in this section  we consider the case where a separation con-
straint is imposed  that is  s > 0 
4 1
cutting forests
first  we assume that g is a forest  we start with several
lemmas about the distg metric when g is a tree 4
by definition of a tree  for any two points x  y ∈ g  there is
a unique  simple  path between x and y  denote this unique
path by pathg x  y  or x → y  and observe that the length
of this path is distg x  y   we say that two subsets of g are
essentially-disjoint if they intersect in at most a single point 
lemma 4 1  let g be a tree  x ⊆ g a closed connected
subset  and r ∈ g \ x a point  there exists a unique point
x∗ ∈ x  a function of x and r  with the following properties 
 a  the path from any point in x to r passes through x∗ 
that is  for any y ∈ x it holds that x∗ ∈ pathg y  r  
 b  x∗ is closer to r than any other point in x is  that is 
distg x∗  r  < distg y  r  for all y ∈ x \  x∗  
 c  for any y
∈
x it holds that distg y  r 
=
distg y  x∗    distg x∗  r  
denote the unique point x∗ guaranteed by lemma 4 1 by
nearest x  r   5 the lemma can be generalized as follows 
lemma 4 2  let g be a tree and x  r ⊆ g be closed con-
nected subsets with x ∩ r = ∅  there exists a unique point
x∗ ∈ x  a function of x and r  satisfying the following
properties 
 a  the path from any point in x to any point in r passes
through x∗ 
 b  for every point r ∈ r  x∗ is closer to r than any other
point in x is 
for non-intersecting subsets x  r ⊆ g  denote the unique
point x∗ guaranteed by lemma 4 2 by nearest x  r  
note that nearest x  r  ̸= nearest r  x   the former
is in x while the latter is in r  we now define  s-good 
pieces similarly to 0-good pieces in lemma 3 3  given a
graph g and a family x =  x1          xk  of closed connected
pieces of g  a piece xj is called s-good provided that for all
j1  j2 ∈  k  the following holds  if distg xj1  xj  < s and
distg xj2  xj  < s  then distg xj1  xj2  < s 
lemma 4 3  let g be a tree and x =  x1          xk  a family
of closed connected subsets of g  for some integer k ≥ 1  if
s > 0  then for some j∗ ∈  k   the piece xj∗ is s-good 
proof  fix an arbitrary point r ∈ g as the tree root  for every
j ∈  k   let xj  = nearest xj  r  and dj  = distg xj  r  
let j∗ ∈ arg maxj∈ k  dj  so that xj∗ is a piece in x farthest
from r  abusing notation slightly  we refer to this piece as x0
4in this case  the metric space distg is known as a real tree or
an r-tree  bestvina  2001  
5nearest x  r  is closely related to the concept of median in
a tree  given three points x  y  z of a tree graph  there is a unique
point in pathg x  y  ∩ pathg y  z  ∩ pathg z  x   this point is
called the median of x  y  z  more generally  any graph with this
uniqueness property is called a median graph  such graphs have been
studied in voting theory  nehring and puppe  2007  
and let x0  = xj∗  we claim that x0 is s-good  to prove this 
we need several auxiliary claims concerning x0  see the full
version of our paper  elkind et al   2021a  for the proofs 
claim 1  for each j ∈  k   if x0 intersects xj  then x0 ∈ xj 
claim 2  for each j ∈  k   if x0 does not intersect xj  then
x0 = nearest x0  xj  
for every j ∈  k  such that x0 and xj are disjoint  let
yj  = nearest xj  x0  = nearest xj  x0  and zj  =
nearest pathg x0  yj   r   i e   zj is the point at which
the path from x0 to r meets the path from yj to r  our next
auxiliary claim is 
claim 3  for each j ∈  k  such that x0 does not intersect xj 
distg yj  zj  ≤ distg x0  zj  
by claims 1 and 2 and the definition of yj  we get the
following useful formula for the distance between x0 and
xj  for every j ∈  k  
distg x0  xj  = distg x0  xj  = distg x0  yj    1 
where the second equality holds if x0 and xj are disjoint  in
other words  to measure the distance between the sets x0 and
xj  we can consider the distance between the single point
x0 ∈ x0  the point closest to r  and xj  if x0 ∩ xj = ∅  so
that yj is defined  then we can consider the distance between
x0 and the single point yj ∈ xj  the point closest to x0  
we are finally ready to prove that x0 is s-good 
con-
sider two arbitrary pieces of x  say x1 and x2  such that
distg x1  x0  < s and distg x2  x0  < s  we have to
prove that distg x1  x2  < s 
if x0 ∩ x1 ̸= ∅  then x0 ∈ x1 by claim 1  so
distg x1  x2  ≤ distg x0  x2  = distg x0  x2  < s 
where the equality holds by  1   an analogous claim holds
if x0 ∩ x2
̸= ∅ 
if x1 ∩ x2
̸= ∅  then obviously
distg x1  x2  = 0 < s  so from now on suppose that
x0 ∩ x1 = x0 ∩ x2 = x1 ∩ x2 = ∅ 
then y1 and
y2 are defined  and by  1  we have distg y1  x0  < s and
distg y2  x0  < s 
by definition of z1 and z2  the path x0
→
r must
pass through both z1 and z2 
without loss of generality 
suppose that z1 comes no later than z2 on this path  so
distg x0  z1  ≤ distg x0  z2   as in the illustration below 
x0
y1
z1
y2
z2
r
consider the path y1 → z1 → z2 → y2  the length of this
path is at most
distg y1  z1    distg z1  z2    distg z2  y2 
≤ distg x0  z1    distg z1  z2    distg z2  y2 
= distg x0  y2  = distg x0  x2  < s 
proceedings of the thirtieth    ijcai-21 
165
 the first inequality holds by claim 3 and the last equality
by  1   we have demonstrated a path of length shorter than
s from a point y1 ∈ x1 to a point y2 ∈ x2  this proves that
distg x1  x2  < s  it follows that x0 is s-good 
with lemma 4 3 in hand  we can now establish the ex-
istence of a maximin allocation for forests by using similar
arguments as in theorem 3 2  in particular  when we allo-
cate an s-good part ti j to agent i  we remove all portions
of the tree that are within distance s of ti j  and divide the
remaining cake recursively among the remaining agents 
theorem 4 4  let g be a forest and s > 0  for agents with
arbitrary monotone valuations  a maximin allocation exists 
4 2
cutting general graphs
we now proceed to general graphs  even when the graph is
a simple cycle  elkind et al   2021c  showed that a maximin
allocation does not necessarily exist  however  the 1-out-of-
 n   1  maximin share can be guaranteed  we present here
a more general theorem analogous to theorem 3 4  how-
ever  our theorem requires the assumption that the length of
each edge is at least s  we remark that the separation param-
eter s is generally small in our motivating applications such
as transition or buffer zones  so this assumption is realistic 
nevertheless  it is an interesting question whether the result
continues to hold without this assumption 
theorem 4 5  let s > 0  let g be a graph in which the
length of each edge is at least s  for any n agents with arbi-
trary monotone valuations  there exists an s-separated allo-
cation in which each agent i receives a connected piece with
value at least mmsn fvsnum g 
i
 
proof  let r  = fvsnum g   let u1          ur be a set of ver-
tices such that  when they are deleted from g  the remaining
graph is a forest  for each j ∈  r   remove an open interval
of length s/2 from each edge adjacent to uj  consider the
1-out-of- n   r  maximin partition of each agent  for each
j ∈  r   the diameter of the set removed due to the vertex uj
is less than s  hence  each removed set overlaps at most one
part of each agent s partition  therefore  once the graph be-
comes a forest  for every agent  at least n parts remain  by
the argument in the proof of theorem 4 4  there exists an s-
separated allocation in which every agent i gets at least one
of the remaining parts of her s-separated maximin partition 
and therefore value at least mmsn r
i
  then  reconstruct the
original graph by putting back the removed intervals of length
s/2  the allocation remains s-separated 
as in the case s = 0  we do not know whether the factor
n   fvsnum g  is tight in general  below  we present a
class of graphs for which we can obtain a tight bound  in par-
ticular  we consider the family of graphs such that the feed-
back vertex set number of each connected component is at
most 1  that is  every connected component is either a tree 
or can be made acyclic by removing a single vertex   set
n  = min n   fvsnum g   2n − 1  
theorem 4 6  the following statements hold for any real
number s > 0 and integer n ≥ 1 
 a  let g be a vertex-disjoint union of graphs with fvs
number ≤ 1  such that the length of each edge is at least s 
for any n agents with monotone valuations  there is an allo-
cation in which each agent i receives value at least mmsn
i  
 b  for any integer r ≥ 1  there exists a graph g with
fvsnum g  = r  specifically  a union of r cycles and zero
or more trees   and n agents with additive valuations  such
that no allocation gives each agent i at least mmsn−1
i
 
theorem 4 6 shows that theorem 4 5 is tight for unions of
trees and cycles when the number of cycles is less than n 
however  exact bounds for other graphs are not known 
5
discussion
in this work  we have studied the division of a graphical cake
using the maximin share notion  both with and without sep-
aration constraints  our most technically challenging result
shows that a maximin allocation exists for positive separa-
tion whenever the graph is acyclic  a tempting approach to
simplify this proof is by using the  last diminisher  method 
wherein each agent can trim a proposed piece as long as the
value of the piece that remains after trimming is at least the
agent s maximin share  indeed  this method was used by bou-
veret et al   2017  to establish the existence result for trees in
the context of indivisible goods  and the algorithm of elkind
et al   2021c  for interval cakes can also be seen as a version
of last diminisher  we remark here that the approach does not
work in our setting with separation  indeed  consider the sub-
tree in figure 1  where two of alice s parts in her maximin
partition are bold  while one of bob s parts is dashed  the
last diminisher method may allocate bob s part to him  how-
ever  when we take the separation requirement into account 
we cannot allocate either of alice s parts in its entirety  note
that the dashed piece is not s-good  this example precisely
demonstrates why  in the proof of theorem 4 4  we need to
reason carefully about real trees in order to guarantee the ex-
istence of an s-good piece 
s/2
s/2
figure 1  an example subtree in which the last diminisher method
fails to produce a maximin allocation 
throughout the paper  we have formulated a number of
open questions that stem naturally from our work  more gen-
erally  our work builds upon an active line of research that in-
corporates realistic constraints in fair division problems  we
believe that identifying and studying such considerations will
lead to technically intriguing questions as well as practically
useful fairness guarantees 
acknowledgments
this work was partially supported by the israel science foun-
dation under grant number 712/20 and by an nus start-up
grant  we would like to thank the anonymous reviewers for
their valuable comments 
proceedings of the thirtieth    ijcai-21 
166
 references
 abebe et al   2017  rediet abebe  jon m  kleinberg  and david c 
parkes  fair division via social comparison  in proceedings of the
16th conference on autonomous agents and multiagent systems
 aamas   pages 281–289  2017 
 alijani et al   2017  reza alijani  majid farhadi  mohammad gh-
odsi  masoud seddighin  and ahman s  tajik  envy-free mecha-
nisms with minimum number of cuts  in proceedings of the 31st
aaai conference on artificial intelligence  aaai   pages 312–
318  2017 
 arunachaleswaran et al   2019  eshwar ram arunachaleswaran 
siddharth barman  and nidhi rathi  fair division with a secretive
agent  in proceedings of the 33rd aaai conference on artificial
intelligence  aaai   pages 1732–1739  2019 
 aziz et al   2018  haris aziz  sylvain bouveret  ioannis caragian-
nis  ira giagkousi  and j erˆome lang  knowledge  fairness  and
social constraints  in proceedings of the 32nd aaai conference
on artificial intelligence  aaai   pages 4638–4645  2018 
 balkanski et al   2014  eric balkanski  simina brˆanzei  david
kurokawa  and ariel d  procaccia  simultaneous cake cutting 
in proceedings of the 28th aaai conference on artificial intelli-
gence  aaai   pages 566–572  2014 
 bei and suksompong  2021  xiaohui bei and warut suksompong 
dividing a graphical cake  in proceedings of the 35th aaai con-
ference on artificial intelligence  aaai   2021 
 bei et al   2017  xiaohui bei  youming qiao  and shengyu zhang 
networked fairness in cake cutting  in proceedings of the 26th
   ijcai  
pages 3632–3638  2017 
 bei et al   2018  xiaohui bei  guangda huzhang  and warut suk-
sompong  truthful fair division without free disposal  in pro-
ceedings of the 27th international joint conference on artificial
intelligence  ijcai   pages 63–69  2018 
 bei et al   2021  xiaohui bei  ayumi igarashi  xinhang lu  and
warut suksompong  the price of connectivity in fair division 
in proceedings of the 35th aaai conference on artificial intelli-
gence  aaai   2021 
 bestvina  2001  mladen bestvina  r-trees in topology  geometry 
and group theory  in r  j  daverman and r  b  sher  editors 
handbook of geometric topology  chapter 2  pages 55–91  else-
vier  2001 
 biswas and barman  2018  arpita biswas and siddharth barman 
fair division under cardinality constraints  in proceedings of the
27th    ij-
cai   pages 91–97  2018 
 bouveret et al   2017  sylvain bouveret 
katar ına cechl arov a 
edith elkind  ayumi igarashi  and dominik peters  fair division
of a graph  in proceedings of the 26th international joint con-
ference on artificial intelligence  ijcai   pages 135–141  2017 
 brams and taylor  1996  steven j  brams and alan d  taylor  fair
division  from cake-cutting to dispute resolution  cambridge
university press  1996 
 brˆanzei et al   2016  simina brˆanzei  ioannis caragiannis  david
kurokawa  and ariel d  procaccia  an algorithmic framework
for strategic fair division  in proceedings of the 30th aaai con-
ference on artificial intelligence  aaai   pages 418–424  2016 
 budish  2011  eric budish  the combinatorial assignment prob-
lem  approximate competitive equilibrium from equal incomes 
journal of political economy  119 6  1061–1103  2011 
 elkind et al   2021a  edith elkind  erel segal-halevi  and warut
suksompong  graphical cake cutting via maximin share  arxiv
preprint arxiv 2105 04755  2021 
 elkind et al   2021b  edith elkind  erel segal-halevi  and warut
suksompong  keep your distance  land division with separa-
tion  in proceedings of the 30th international joint conference
on artificial intelligence  ijcai   2021 
 elkind et al   2021c  edith elkind  erel segal-halevi  and warut
suksompong  mind the gap  cake cutting with separation  in
proceedings of the 35th aaai conference on artificial intelli-
gence  aaai   2021 
 goldberg et al   2020  paul w  goldberg  alexandros hollender 
and warut suksompong  contiguous cake cutting  hardness re-
sults and approximation algorithms  journal of artificial intelli-
gence research  69 109–141  2020 
 hosseini et al   2020  hadi hosseini  ayumi igarashi  and andrew
searns  fair division of time  multi-layered cake cutting  in pro-
ceedings of the 29th international joint conference on artificial
intelligence  ijcai   pages 182–188  2020 
 igarashi and zwicker  2021  ayumi
igarashi
and
william
s 
zwicker  fair division of graphs and of tangled cakes  arxiv
preprint arxiv 2102 08560  2021 
 karp  1972  richard m  karp  reducibility among combinatorial
problems  in proceedings of a symposium on the complexity of
computer computations  pages 85–103  1972 
 kurokawa et al   2018  david kurokawa  ariel d  procaccia  and
junxing wang  fair enough  guaranteeing approximate maximin
shares  journal of the acm  64 2  8 1–8 27  2018 
 li et al   2015  minming li  jialin zhang  and qiang zhang 
truthful cake cutting mechanisms with externalities  do not
make them care for others too much  in proceedings of the 24th
   ijcai  
pages 589–595  2015 
 lonc and truszczynski  2020  zbigniew
lonc
and
miroslaw
truszczynski  maximin share allocations on cycles  journal of
artificial intelligence research  69 613–655  2020 
 menon and larson  2017  vijay menon and kate larson  deter-
ministic  strategyproof  and fair cake cutting  in proceedings of
the 26th  
 ijcai   pages 352–358  2017 
 nehring and puppe  2007  klaus nehring and clemens puppe 
the structure of strategy-proof social choice — part i  general
characterization and possibility results on median spaces  jour-
nal of economic theory  135 1  269–305  2007 
 procaccia  2013  ariel d  procaccia  cake cutting  not just child s
play  communications of the acm  56 7  78–87  2013 
 procaccia  2016  ariel d  procaccia  cake cutting algorithms  in
felix brandt  vincent conitzer  ulle endriss  j erˆome lang  and
ariel d  procaccia  editors  handbook of computational social
choice  chapter 13  pages 311–329  cambridge university press 
2016 
 robertson and webb  1998  jack robertson and william webb 
cake-cutting algorithms  be fair if you can  peters/crc press 
1998 
 segal-halevi  2021  erel segal-halevi 
fair multi-cake cutting 
discrete applied mathematics  291 15–35  2021 
proceedings of the thirtieth    ijcai-21 
167
 "
None,2021,https-www-ijcai-org-proceedings-2021-0024-pdf,Keep Your Distance: Land Division With Separation,"Edith Elkind, Erel Segal-Halevi, Warut Suksompong",None,https://www.ijcai.org/proceedings/2021/0024.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0024-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0024-pdf.pdf,"keep your distance  land division with separation
edith elkind1   erel segal-halevi2 and warut suksompong3
1department of computer science  university of oxford
2department of computer science  ariel university
3school of computing  national university of singapore
elkind@cs ox ac uk  erelsgl@gmail com  warut@comp nus edu sg
abstract
this paper is part of an ongoing endeavor to bring
the theory of fair division closer to practice by han-
dling requirements from real-life applications  we
focus on two requirements originating from the di-
vision of land estates   1  each agent should re-
ceive a plot of a usable geometric shape  and  2 
plots of different agents must be physically sep-
arated  with these requirements  the classic fair-
ness notion of proportionality is impractical  since
it may be impossible to attain any multiplicative
approximation of it  in contrast  the ordinal max-
imin share approximation  introduced by budish
in 2011  provides meaningful fairness guarantees 
we prove upper and lower bounds on achievable
maximin share guarantees when the usable shapes
are squares  fat rectangles  or arbitrary axes-aligned
rectangles  and explore the algorithmic and query
complexity of finding fair partitions in this setting 
1
introduction
the problem of fairly allocating a divisible resource has a
long history  dating back to the seminal article of polish
mathematician hugo steinhaus  1948   in its basic formula-
tion  the resource  which is metaphorically viewed as a cake 
comes in the form of an interval  the aim is to find a division
satisfying some fairness criteria  e g   proportionality  which
means that if there are n agents  the value that each of them
receives should be at least 1/n of the entire cake  not only
does a proportional allocation always exist  but it can also be
found efficiently  dubins and spanier  1961  
while the interval cake is simple and consequently use-
ful as a starting point  it is often insufficient for modeling
real-world applications  especially when combined with the
common requirement that each agent should receive a con-
nected piece of the cake 1 in particular  when allocating real
estate  geometric considerations play a crucial role  it is hard
to build a house or raise cattle on a thin or highly zigzagged
1as stromquist  1980  memorably wrote  without such con-
nectivity requirements  there is a danger that agents will receive a
 countable union of crumbs  
piece of land even if its total area is large  such considera-
tions have motivated researchers to study fairness in land di-
vision  which also serves to model the allocation of other two-
dimensional objects such as advertising spaces  berliant et
al   1992  ichiishi and idzik  1999  berliant and dunz  2004 
dall aglio and maccheroni  2009  iyer and huhns  2009 
devulapalli  2014  segal-halevi et al   2017  segal-halevi
et al   2020   these studies have uncovered important dif-
ferences between land division and interval division  for in-
stance  when agents must be allocated square pieces  segal-
halevi et al   2017  show that we cannot guarantee the agents
more than 1/ 2n  of their entire value in the worst case  even
when the agents have identical valuations over the land 
a related issue  which frequently arises in practice  is that
agents  pieces may have to be separated from one another  we
may need to leave a space between adjacent pieces of land 
e g   to prevent dispute between owners  provide access to the
plots  avoid cross-fertilization of different crops  or ensure
safe social distancing among vendors in a market  the formal
study of fair division with separation constraints was initiated
by elkind et al   2021c   who focus on the one-dimensional
setting  the goal of our work is to extend this analysis to
two dimensions  i e   to analyze fair division of land under
separation constraints 
1 1
our contribution
we assume that each agent must obtain a contiguous piece
of land  and the shares that any two agents receive must be
separated by a distance of at least s  where s is a given pa-
rameter that is independent of the land value  in the pres-
ence of separation constraints  no multiplicative approxima-
tion of proportionality can be guaranteed  even in one di-
mension  when all of the agents  values are concentrated
within distance s  only one agent can receive a positive
utility 
elkind et al   2021c  therefore consider the well-
known criterion of maximin share fairness  budish  2011 
kurokawa et al   2018 —the value that each agent receives
must be at least her 1-out-of-n maximin share  i e   the best
share that she can guarantee for herself by dividing the re-
source into n bundles and accepting the worst one  elkind
et al   2021c  show that this criterion can be satisfied for an
interval cake  while an ordinal approximation of it can be at-
tained for a one-dimensional circular cake 
we establish that maximin share fairness and relaxations
proceedings of the thirtieth    ijcai-21 
168
 thereof can also provide worst-case guarantees in land allo-
cation with separation  moreover  since full proportionality
cannot always be attained in this setting even in the case of
no separation  s = 0   our results have interesting implica-
tions for that case as well 
our first result is negative  we prove that  when s > 0  it
is impossible to guarantee to each agent a positive fraction
of her 1-out-of-n maximin share  therefore  in the rest of
the paper  we focus on an ordinal notion of approximation 
specifically  we ask for the smallest value of k ≥ n such that
we can guarantee each agent her 1-out-of-k maximin share 
we assume that both the land to be divided and each agent s
piece are axes-aligned rectangles  if we additionally require
that all rectangles  both in agents  maximin partitions and in
the final allocation  are r-fat  i e   the ratio of the length of
the longer side to the length of the shorter side is bounded by
a constant r ≥ 1  then it suffices to set k =  2⌈r⌉   2 n −
 3⌈r⌉   2   in particular  if all land pieces are required to be
squares  r = 1   we obtain k = 4n − 5  without the fatness
assumption  the problem is more difficult  and the technique
we use for fat rectangles no longer works  however  we still
obtain a finite approximation  we show that it suffices to set
k = 2n 2  and provide stronger bounds for small values of n 
in particular  for n = 2 we can set k = 3  which is optimal 
our positive results are constructive  in the sense that 
given each agent s 1-out-of-k maximin partition  i e   a par-
tition into k pieces where the value of each piece is at least
the agent s maximin share   we can divide the land among
the agents so that each agent gets her 1-out-of-k share  using
a natural adaptation of the standard robertson–webb model
 robertson and webb  1998   however  it is not clear how a
1-out-of-k maximin partition can be efficiently computed or
even approximated  to circumvent this difficulty  we focus
on a special class of land partitions known as guillotine par-
titions  intuitively  these are partitions that can be obtained
by a sequence of edge-to-edge cuts  we show that we can
efficiently compute an approximately optimal guillotine par-
tition  and that the loss caused by using guillotine partitions
can be bounded  combining these results with our ordinal ap-
proximation algorithms  we obtain approximation algorithms
for computing a maximin allocation 
1 2
related work
in considering fair division with separation  we build on
the work of elkind et al   2021c   who investigate the one-
dimensional variant of this problem  fair land division with
constraints on the shape of usable pieces has been previ-
ously studied  segal-halevi et al   2017  segal-halevi et al  
2020   we follow these works in considering fat rectangles
and guillotine cuts  however  the fairness notions consid-
ered in these papers are  partial  proportionality and envy-
freeness  whereas our work concerns maximin fairness 
our analysis is also somewhat similar in spirit to several re-
cent works on dividing a cake represented by a general graph 
which generalizes both the interval and the cycle  a k a  pie 
setting  several fairness notions have been studied in this set-
ting  partial proportionality  bei and suksompong  2021  
envy-freeness  igarashi and zwicker  2021   and maximin
share fairness  elkind et al   2021a   in all of these works  the
cake is still one-dimensional—it is a union of a finite num-
ber of intervals  as we show in this work  a two-dimensional
cake is fundamentally different 
2
preliminaries
the land is given by a closed  bounded  and connected sub-
set l of the two-dimensional euclidean plane r2  the land
is to be divided among a set of agents n =  n   where
 k   =  1  2          k  for any positive integer k  there is a
prespecified family u of usable pieces  each agent has an in-
tegrable density function fi   l → r≥0  agent i s value for a
piece of land z is given by vi z   =
��
z fi x  y dxdy 
let s ≥ 0 be the separation parameter  an allocation of
the land is given by a vector a =  a1          an   where each
ai is a single  connected  piece of land allocated to agent i 
we require allocations to be s-separated  i e   any two pieces
ai and aj are separated by distance at least s  where distance
is measured according to the ℓ∞ norm 
d ai  aj  =
inf
 x y ∈ai  x′ y′ ∈aj max |x − x′|  |y − y′|  
partitions and s-separated partitions are defined similarly 
except that instead of a vector a =  a1          an   we have
a set p =  p1          pn   denote by γn s  the set of all s-
separated partitions  an instance consists of the land  agents 
density functions  and the separation parameter 
definition 2 1  the 1-out-of-k maximin share of agent i is
defined as mmsk s
i
 = supp∈γk s  minj∈ k  vi pj   we omit
s if it is clear from the context  and write mmsk
i instead of
mmsk s
i
  we refer to mmsn
i as i s maximin share 
as with cake cutting  elkind et al   2021c   the supremum
in definition 2 1 can be replaced by a maximum  this re-
quires defining a metric on the usable pieces and showing
that u is compact in that metric space—see appendix c in
the work of segal-halevi et al   2017   an s-separated parti-
tion for which this maximum is attained is called a maximin
partition of agent i 
all omitted proofs can be found in the full version of our
paper  elkind et al   2021b  
3
a general impossibility result
we first show that  in contrast to one-dimensional cake cut-
ting with separation  elkind et al   2021c   for land division
there may be no allocation that guarantees to all agents their
maximin share or even any multiplicative approximation of it 
this negative result does not depend on the geometric shape
of the land or the pieces 2
proposition 3 1  for every family u of usable pieces  integer
n ≥ 2  separation parameter s > 0  and real number r > 0 
there exists a land division instance with n agents in which no
s-separated allocation gives every agent i a value of at least
r · mmsn s
i
 
proof sketch  we construct n sets s1          sn consisting of n
points each such that the distance between any two points in
2we are grateful to alex ravsky for the proof idea 
proceedings of the thirtieth    ijcai-21 
169
 the same set is greater than 1  but if we pick one representa-
tive point from each set  then some two representatives are at
distance less than 1 apart  we then construct agents  density
functions so that each agent only values a small  pool  of land
around each of the points in their set  assigning a value of 1
to each such pool  by scaling this construction by approxi-
mately a factor of s  we can ensure that each agent s maximin
share is 1  but there are at most n − 1 agents who can obtain
a positive utility in an s-separated partition 
4
ordinal approximation
since no multiplicative approximation of the maximin share
can be guaranteed  we instead consider an ordinal notion of
approximation  that is  we ask if each agent can be guaran-
teed her 1-out-of-k maximin share for some k > n 
while the negative result of section 3 does not depend on
geometric assumptions  our positive results concern pieces
that have a  nice  geometric shape 
specifically  we first
consider the scenario where u consists of  fat  axes-aligned
rectangles  i e   rectangles whose length-to-width ratio is
bounded by a constant  e g   if this constant is 1  the set u
consists of axes-aligned squares   we then consider the more
general setting where u consists of all axes-aligned rectan-
gles  placing such constraints on the shape of each piece
is useful in land allocation settings  particularly in urban re-
gions  note that when we restrict the shape of the usable
pieces to be a  fat  rectangle  in our definition of the maximin
share we also only consider s-separated partitions in which
each piece is a  fat  rectangle 
4 1
squares and fat rectangles
for a real number r ≥ 1  a rectangle is called r-fat if the ratio
of its longer side to its shorter side is at most r  agarwal et al  
1995  katz  1997   in particular  a 1-fat rectangle is a square 
given a rectangle r  we denote the lengths of its long and
short side by long r  and short r   respectively  we refer to
short r  as the width of r  in what follows  we say that two
pieces of land overlap if their intersection has a positive area 
and that they are disjoint if their intersection has a zero area 
in order to obtain maximin share guarantees  the high-level
idea is to find a sufficiently large k such that if we consider the
agents  1-out-of-k maximin partitions  then it is possible to
select a representative piece from each partition in such a way
that these representatives are s-separated  this will ensure
that  by allocating to each agent her representative  we obtain
an allocation that is s-separated and in which agent i receives
value at least mmsk s
i
  the following theorem shows that
k =  2⌈r⌉   2 n −  3⌈r⌉   2  suffices  for a square  r = 1  
this yields k = 4n − 5  note that our result does not place
any assumptions on the shape of the land 
theorem 4 1  let r ≥ 1 be a real number  for every land
division instance with n agents and separation parameter s
where u is the set of axes-aligned r-fat rectangles  there ex-
ists an allocation in which every agent i receives value at
least mmsk s
i
  where k  =  2⌈r⌉   2 n −  3⌈r⌉   2  
proof  we first consider the following geometric problem 
there are n ≥ 2 sets  each of which contains n ≥
n axes-aligned r-fat rectangles  the rectangles in
each set are pairwise disjoint  we want to choose
a single representative rectangle from each set so
that the representatives are pairwise disjoint  what
is the smallest integer n = nfat r  n  for which
this is always possible 
we first prove that nfat r  2  ≤ ⌈r⌉   2  3 given ⌈r⌉   2
red and ⌈r⌉   2 blue r-fat rectangles  we have to show that
at least one red and one blue rectangle do not overlap each
other  the proof of this statement is left to the full version of
our paper  elkind et al   2021b  
next  we prove that nfat r  n   1  ≤ nfat r  n   
2⌈r⌉   2  we claim that in any arrangement of axes-aligned
r-fat rectangles  there exists a rectangle that overlaps at most
2⌈r⌉   2 pairwise disjoint rectangles  to prove this claim 
let qmin be a minimum-width rectangle  and denote its width
by w  mark all four corners of qmin  moreover  on both of
its longer sides  mark ⌈r⌉ − 1 additional points so that the
distance between any two consecutive marks is at most w 
the total number of marks is 2⌈r⌉   2  any rectangle q that
overlaps qmin must contain at least one of its marks  hence 
if there are more than 2⌈r⌉   2 rectangles overlapping qmin 
some two of them will overlap  this establishes the claim 
combining this with the base case n = 2  we conclude
that  for all n ≥ 2 and r ≥ 1 
nfat r  n  ≤  2⌈r⌉   2  n − 2     ⌈r⌉   2 
=  2⌈r⌉   2 n −  3⌈r⌉   2  
for the special case of a square we get n 1  n  ≤ 4n − 5 
figure 1  the dark rectangles are s-separated if and only if the light
rectangles wrapping them with a rectangle ring of width s/2 are
disjoint 
we can now return to our original problem  given the sep-
aration parameter s  for every rectangle q with side lengths
u and v  define wrap q  s  to be the rectangle with side
lengths u s and v s and the same center as q  i e   wrap q
with a  rectangle ring  of width s/2   note that wrap q  s 
3 this inequality is tight  that is  nfat r  2  = ⌈r⌉   2 for any
r ≥ 1  this can proved by exhibiting two sets of r-fat rectangles 
each of which contains ⌈r⌉   1 pairwise-disjoint rectangles  such
that no two representatives are disjoint  consider the following two
sets of rectangles  the vertical set contains the rectangles  i  i 1 ×
 1 − ε  ⌈r⌉   ε  for i ∈  0          ⌈r⌉   the horizontal set contains
the rectangles  1 − ε  ⌈r⌉   ε  ×  i  i   1  for i ∈  0          ⌈r⌉   for
all rectangles  the ratio between the two side lengths is ⌈r⌉ 2ε−1 
for sufficiently small ε  it is less than r  so all rectangles are r-fat 
it can be verified that each horizontal rectangle overlaps all vertical
rectangles 
proceedings of the thirtieth    ijcai-21 
170
 is r-fat whenever q is  then  two rectangles q1 and q2 are
s-separated if and only if wrap q1  s  and wrap q2  s  do
not overlap  see figure 1  
now  given an n-agent instance  we ask each agent to pro-
duce a 1-out-of-k maximin partition  this is a set of k axes-
aligned rectangles that are s-separated  then  we replace each
rectangle q with wrap q  s   so each agent now has a set
of k non-overlapping rectangles 
since k ≥ nfat r  n  
there is a set of representative rectangles  one per agent 
that are pairwise disjoint 
suppose that these rectangles
are wrap q1  s   wrap q2  s           wrap qn  s   where
wrap qi  s  belongs to agent i s set  we allocate the rect-
angle qi to agent i  the rectangles qi are s-separated  and
every agent i receives value at least mmsk s
i
  as desired 
constructions similar to those in proposition 3 1 show that
nfat r  n  ≥ n   1 for all r  thus the bound 4n − 5 for
squares is optimal for n = 2  but may be suboptimal for n ≥
3  closing the gap between the lower bound n   1 and the
upper bound 4n − 5 seems to require new geometric insights 
4 2
arbitrary rectangles
next  we allow the pieces to be arbitrary axes-aligned rect-
angles  and assume that the land itself is also an axes-aligned
rectangle  without loss of generality  we suppose further that
the land is a square  otherwise  for positive results  a rectan-
gular land can be completed to a square by attaching to it a
rectangle that all agents value at 0   we scale the axes so that
the land is the unit square  0  1  ×  0  1  
the arbitrary rectangle case differs from the fat rectangle
case in two respects  first  without the separation require-
ment  the arbitrary rectangle case is much easier  the land
can be projected onto a one-dimensional interval  for which
full proportionality  and hence mmsn
i   can be achieved  du-
bins and spanier  1961   in contrast  with the separation re-
quirement  the arbitrary rectangle case is much harder  the
representative-selection technique of theorem 4 1  which has
also been used implicitly  in a simpler form  for cake and pie
division by elkind et al   2021c    does not yield a meaning-
ful bound for arbitrary rectangles  an example similar to the
one in footnote 3 shows that  even for an arbitrarily large k 
there exist two size-k sets of pairwise-disjoint rectangles such
that no two representatives are disjoint 
a priori  for n ≥ 2  it is not clear that there is a finite
nrect n  such that an mmsnrect n  allocation among n
agents always exists  below we prove that nrect n  is in-
deed finite for any n ≥ 2  and derive improved upper bounds
on nrect n  for small values of n  towards this goal  we
develop some new tools 
in what follows  for each agent we fix a 1-out-of-k max-
imin partition—see figure 2 for some examples of such par-
titions  for all i ∈ n  we assume without loss of generality
that mmsk
i = 1  and that i s value is 0 outside the k rectan-
gles in her maximin partition  the latter value being positive
can only make it easier to satisfy the agent   hence each agent
has a value of k for the land and should get an axes-aligned
rectangle worth at least 1 
we refer to the k rectangles in the agent s fixed maximin
partition as mms-rectangles  every rectangular piece of land
that is worth at least 1 to the agent is called a value-1 rect-
angle  due to our normalization  every mms-rectangle is a
value-1 rectangle  but the converse is not necessarily true 
definition 4 2  consider an agent with a fixed 1-out-of-k
maximin partition  and integers p  q ≥ 1  a vertical p q-
rectangle cut is a rectangular strip of height 1 and width s
that has at least p whole mms-rectangles on its left and at
least q whole mms-rectangles on its right 
a vertical p-
rectangle stack is a sequence of p rectangles of value 1 such
that each consecutive pair is separated by a vertical distance
of at least s 
horizontal rectangle cuts and stacks are defined similarly 
in figure 2 a   the left vertical cut  the thick red line  is
a 1 2-rectangle cut and the right one is a 2 1-rectangle cut 
in figure 2 c   there is a vertical 3-rectangle stack  in fig-
ure 2 d   the vertical cut is a 2 1-rectangle cut  and there is a
vertical 2-rectangle stack 
the following lemma shows the existence of either a rect-
angle cut or a rectangle stack with appropriate parameters 
lemma 4 3  fix an agent and a 1-out-of-k maximin partition
of this agent  for any integers 1 ≤ p  q ≤ k with p   q ≤
k   1  the agent has a vertical p q-rectangle cut or a vertical
 k − p − q   2 -rectangle stack 
proof  starting from the left end of the cake  move a vertical
knife of width s to the right  stop the knife at the first point
where there are at least p whole mms-rectangles to its left—
the knife may need to move outside the cake in order for this
to happen  as in figure 2 c  for any p  consider two cases 
case 1  there are at least q whole mms-rectangles to the
right of the knife  then  the knife indicates a vertical p q-
rectangle cut  this is the case when p = q = 1 in figures
2 a    b   and  d  
case 2  there are at most q − 1 whole mms-rectangles
to the right of the knife  then  by moving the knife slightly
to the left  we obtain a cut for which there are at most p − 1
mms-rectangles entirely to its left  and at most q − 1 mms-
rectangles entirely to its right  therefore  at least k−p−q 2
mms-rectangles must intersect the knife itself 
since the
knife width is s  these rectangles must lie in order vertically 
with a vertical distance of at least s between consecutive rect-
angles  hence  they form a vertical  k − p − q   2 -rectangle
stack  this is the case when p = q = 1 in figure 2 c  
in the remainder of this section  given y  y′ ∈  0  1  with
y ≤ y′  we write r y  y′   =  0  1  ×  y  y′  
we now prove a positive result for two agents matching the
lower bound implied by proposition 3 1 
theorem 4 4  for any land division instance with a rect-
angular land and n = 2 agents  there exists an allocation
in which each agent i receives an axes-aligned rectangle of
value at least mms3
i  
proof  call the agents alice and bob  take a 1-out-of-3 max-
imin partition of each agent  and consider two cases 
case 1  both agents have a vertical 1 1-rectangle cut  as-
sume without loss of generality that alice s cut lies further to
the left  give the rectangle to its left to alice and the one to its
right to bob  then each agent receives an mms-rectangle 
proceedings of the thirtieth    ijcai-21 
171
  a 
 b 
 c 
 d 
figure 2  four partitions of a rectangular land into three axes-aligned rectangles  each of these partitions can be a 1-out-of-3 maximin
partition of an agent  the partition lines  the thick red lines  have thickness s 
case 2  at least one agent  say alice  has no vertical 1 1-
rectangle cut  by lemma 4 3  she has a vertical 3-rectangle
stack  as in figure 2 c   for the i-th rectangle in this stack
 counting from the bottom   denote the y-coordinates of its
top and bottom sides by ti and bi  respectively  note that
t1   s ≤ b2 and t2   s ≤ b3 
if bob s value for r 0  t2  is at least 1  then give r 0  t2 
to bob and r b3  1  to alice  otherwise  bob values r 0  t2 
less than 1  so his value for r b2  1  is more than 2  give
r b2  1  to bob and r 0  t1  to alice  in both cases alice s
value is 1 and the pieces are s-separated 
for n ≥ 3 agents  the analysis becomes more compli-
cated  as in classic cake-cutting algorithms  e g    dubins
and spanier  1961    we would like to proceed recursively 
give one agent a rectangle worth at least 1  and divide the rest
of the land among the remaining n − 1 agents  in particular 
for n = 3  after allocating a piece to one agent  we would
need to show that  for each of the remaining two agents  the
rest of the land is worth at least 3  so that we can apply the-
orem 4 4  in fact  to apply theorem 4 4  we need an even
stronger condition  each agent should have three s-separated
rectangles of value 1  however  the recursion step might yield
a remainder land made of many pieces of such rectangles 
each of which is worth less than 1  we therefore need to
adapt our definitions and lemmas accordingly 
definition 4 5  a vertical p q-value cut of an agent is a rect-
angular strip of width s such that the agent values the land on
its left at least p and the land on its right at least q 
for any integers p  q  every p q-rectangle cut is also a p q-
value cut  but the converse is not necessarily true 
for the following lemma  it is important that the agent s
value function is normalized as explained earlier  i e   the
value of each mms-rectangle is 1 and the value outside the
mms-rectangles is 0  a land-subset is a subset of the land af-
ter some pieces have possibly been allocated to other agents 
lemma 4 6  consider an agent with a fixed 1-out-of-k max-
imin partition of the land  who takes part in a division of a
rectangular land-subset  let v ≤ k be the agent s value for
the land-subset  for any integers p  q ≥ 1 with p   q ≤ v  
the agent has either a vertical p q-value cut or a vertical
⌈ ⌊v ⌋ − p − q /2⌉-rectangle stack 
the following lemma establishes a weaker bound than
theorem 4 4 does  however  it applies to an arbitrary land-
subset  and hence  unlike theorem 4 4  can be used as part
of a recursive argument  its proof is essentially identical to
the proof of theorem 4 4  the only difference is that we first
look for a vertical 1 1-value cut  and if we fail to find one 
we invoke lemma 4 6 to establish the existence of a vertical
3-rectangle stack 
lemma 4 7  consider a rectangular land-subset and n = 2
agents who value it at least 7 each  there is an allocation in
which each agent receives an axes-aligned rectangle of value
at least 1 
proof  we consider two cases 
case 1  both agents have a vertical 1 1-value cut  take the
cut to the left  give the rectangle to its left to the cutter  and
the rectangle to its right to the other agent 
case 2  at least one agent  say alice  has no vertical 1 1-
value cut  by lemma 4 6  she has a vertical 3-rectangle stack 
so we can proceed as in case 2 of theorem 4 4 
let vreq n  be the smallest value of v such that if each of
n agents values the land-subset at v or higher  then there is
an allocation of this land-subset in which each agent s value
for her share is at least 1  obviously vreq 1  = 1  and by
lemma 4 7 we know that vreq 2  ≤ 7  we can now provide a
finite  exponential  mms approximation for every positive n 
theorem 4 8  for any n ≥ 1  given any land division in-
stance with a rectangular land and n agents  there exists an
allocation in which each agent i receives an axes-aligned
rectangle with value at least mmsk
i   where k = 2n 2 
by adjusting the argument in the proof of theorem 4 8  we
can obtain stronger bounds for n = 3 and n = 4  in particular 
we can guarantee each agent i a piece of value at least mms14
i
and mms24
i   respectively  the details can be found in the full
version of our paper  elkind et al   2021b  
5
computing maximin allocations
the results in section 4 are stated in terms of approximation
guarantees  to convert them into algorithms  we need to for-
mally define our computational model  to do so  we propose
a natural modification of the classic robertson–webb model
 robertson and webb  1998  for the two-dimensional setting 
consider an axes-aligned rectangle l =  a0  a1  ×  b0  b1  
which may be part of a larger land-subset  we adapt the cut
and eval queries of the robertson–webb model to allow
for horizontal and vertical cuts as follows  the cuti |  l  δ 
query returns a value a such that agent i values the rectangle
proceedings of the thirtieth    ijcai-21 
172
  a0  a  ×  b0  b1  at δ  and the cuti −  l  δ  query returns a
value b such that agent i values the rectangle  a0  a1  ×  b0  b 
at δ  we assume that this query returns a1  respectively  b1 
if the agent values the entire rectangle less than δ  simi-
larly  the evali |  l  a  query with a0 ≤ a ≤ a1 returns the
value that i assigns to the rectangle  a0  a  ×  b0  b1   whereas
evali −  l  b  query with b0 ≤ b ≤ b1 returns the value that
i assigns to the rectangle  a0  a1  ×  b0  b  
we can now revisit the proofs of theorems 4 4 and 4 8
and check if they can be converted into algorithms that use
cut and eval queries  one can see that these proofs are
constructive and their basic steps can be expressed in terms
of these queries  a p q-value cut can be implemented by two
cut queries  and agents  values for rectangles of the form
r x  y  can be determined using eval queries 
however  these algorithms use the agents  1-out-of-k max-
imin partitions as their starting points  and it is not clear if
such partitions are efficiently computable  indeed  even in the
1-dimensional case  there is no algorithm that always com-
putes a maximin partition of an agent using finitely many
queries  and the best known solution is a  1 − ε  approxi-
mation in time o n log 1/ε    elkind et al   2021c   for the
2-dimensional case  even a  1−ε  approximation seems chal-
lenging 
to circumvent this difficulty  we focus on maximin par-
titions with a special structure  namely  guillotine partitions
 gonzalez et al   1994  ackerman et al   2006  messaoud
et al   2008  horev et al   2009  asinowski et al   2014 
russo et al   2020   this class of partitions is defined re-
cursively  as follows 
definition 5 1  consider a land-subset l =  a0  a1 × b0  b1  
a set of rectangles p =  p1          pt   where pi ⊆ l for each
i ∈  t   and a separation parameter s  we say that p forms an
s-separated guillotine partition of l if one of the following
three conditions holds 
• t = 1 and p1 ⊆ l 
• there exists an a with a0 < a < a1 − s and a partition of
p into two disjoint collections of rectangles p1 and p2
such that p1 forms an s-separated guillotine partition of
 a0  a  ×  b0  b1  and p2 forms an s-separated guillotine
partition of  a   s  a1  ×  b0  b1  
• there exists a b with b0 < b < b1 − s and a partition of
p into two disjoint collections of rectangles p1 and p2
such that p1 forms an s-separated guillotine partition of
 a0  a1  ×  b0  b  and p2 forms an s-separated guillotine
partition of  a0  a1  ×  b   s  b1  
intuitively  an s-separated guillotine partition is obtained
by a sequence of cuts  where each cut splits a rectangle into
two s-separated rectangles  all partitions in figure 2 are guil-
lotine partitions  while figure 3 provides an example of an
s-separated partition that is not a guillotine partition 
the following theorem shows that we can compute a nearly
optimal s-separated guillotine maximin partition efficiently 
our algorithm proceeds by discretizing the land and finding
an optimal s-separated guillotine partition that is consistent
with this discretization  such a partition can be computed by
dynamic programming 
figure 3  example of an s-separated partition that is not a guillotine
partition  the small space between each pair of  adjacent  rectangles
has length s 
theorem 5 2  consider a rectangular land-subset l  an
agent i who values l at 1  and a separation parameter s > 0 
suppose that there exists an s-separated guillotine partition
of l into k parts such that i s value for each part is at least v  
then  given ε > 0  s  and k  we can compute an s-separated
guillotine partition of l into k parts such that i s value for
each part is at least v − ε  in time polynomial in k and 1/ε 
how much value do we lose by considering guillotine par-
titions instead of general ones  figure 3 illustrates that this
loss is non-trivial  the following theorem provides a crude
 but positive  lower bound on the approximation ratio 
theorem 5 3  let ξ-mmsk s
i
denote the maximin share of
agent i with respect to s-separated guillotine partitions into
k parts  then  it holds that ξ-mmsk s
i
≥ mms4k2 s
i
 
combining theorems 5 2 and 5 3 with 4 8 gives
corollary 5 4  for each ε > 0  we can compute in time poly-
nomial in k and 1/ε an allocation in which each agent i
receives a rectangular piece of land with value at least
mmsk s
i
− ε  where k ≤ 4 ·  22n 2 2 = 24n 6 
6
conclusion and future work
this paper continues the quest of bringing the theory of fair
division closer to practice by investigating fair land alloca-
tion under separation constraints  even though the classic
fairness notion of proportionality is unsuitable for this set-
ting  we establish meaningful bounds on achievable maximin
share guarantees for a variety of shapes and develop a num-
ber of new techniques in the process  in particular  for r-
fat rectangles we derive a polynomial bound on the achiev-
able approximation for any number of agents  while for ar-
bitrary rectangular pieces we obtain a finite but exponential
bound  improving the latter bound to polynomial is a chal-
lenging question which likely requires novel geometric in-
sights  other avenues for future work include testing our al-
gorithms on real land division data  shtechman et al   2020 
and exploring the possibilities of efficient computation with
non-guillotine or other types of cuts 
acknowledgments
this work was partially supported by the european research
council  erc  under grant number 639945  accord   by
the israel science foundation under grant number 712/20 
and by an nus start-up grant  we would like to thank kshi-
tij gajjar for his insights regarding guillotine partitions and
the anonymous reviewers for their valuable comments 
proceedings of the thirtieth    ijcai-21 
173
 references
 ackerman et al   2006  eyal
ackerman 
gill
barequet 
ron y  pinter  and dan romik  the number of guillo-
tine partitions in d dimensions  information processing
letters  98 4  162–167  2006 
 agarwal et al   1995  pankaj k  agarwal  matthew j  katz 
and micha sharir 
computing depth orders for fat ob-
jects and related problems 
computational geometry 
5 4  187–206  1995 
 asinowski et al   2014  andrei asinowski  gill barequet 
toufik mansour  and ron y  pinter  cut equivalence of d-
dimensional guillotine partitions  discrete mathematics 
331 165–174  2014 
 bei and suksompong  2021  xiaohui bei and warut suk-
sompong  dividing a graphical cake  in proceedings of the
35th aaai conference on artificial intelligence  aaai  
2021 
 berliant and dunz  2004  marcus berliant and karl dunz 
a foundation of location theory  existence of equilibrium 
the welfare theorems  and core  journal of mathematical
economics  40 5  593–618  2004 
 berliant et al   1992  marcus berliant  william thomson 
and karl dunz 
on the fair division of a heteroge-
neous commodity  journal of mathematical economics 
21 3  201–216  1992 
 budish  2011  eric budish 
the combinatorial assign-
ment problem 
approximate competitive equilibrium
from equal incomes 
journal of political economy 
119 6  1061–1103  2011 
 dall aglio and maccheroni  2009  marco dall aglio and
fabio maccheroni  disputed lands  games and economic
behavior  66 1  57–77  2009 
 devulapalli  2014  raghuveer devulapalli  geometric par-
titioning algorithms for fair division of geographic re-
sources  phd thesis  university of minnesota  2014 
 dubins and spanier  1961  lester e  dubins and edwin h 
spanier  how to cut a cake fairly  american mathematical
monthly  68 1  1–17  1961 
 elkind et al   2021a  edith elkind  erel segal-halevi  and
warut suksompong  graphical cake cutting via maximin
share  in proceedings of the 30th international joint con-
ference on artificial intelligence  ijcai   2021 
 elkind et al   2021b  edith elkind  erel segal-halevi  and
warut suksompong  keep your distance  land division
with separation  arxiv preprint arxiv 2105 06669  2021 
 elkind et al   2021c  edith elkind  erel segal-halevi  and
warut suksompong  mind the gap  cake cutting with sep-
aration  in proceedings of the 35th aaai conference on
artificial intelligence  aaai   2021 
 gonzalez et al   1994  teofilo f  gonzalez  mohammadreza
razzazi  man-tak shing  and si-qing zheng  on opti-
mal guillotine partitions approximating optimal d-box par-
titions  computational geometry  4 1  1–11  1994 
 horev et al   2009  elad horev 
matthew j  katz 
roi
krakovski  and maarten l¨offler  polychromatic 4-coloring
of guillotine subdivisions  information processing letters 
109 13  690–694  2009 
 ichiishi and idzik  1999  tatsuro ichiishi and adam idzik 
equitable allocation of divisible goods  journal of mathe-
matical economics  32 4  389–400  1999 
 igarashi and zwicker  2021  ayumi igarashi and william s 
zwicker 
fair division of graphs and of tangled cakes 
arxiv preprint arxiv 2102 08560  2021 
 iyer and huhns  2009  karthik iyer and michael n  huhns 
a procedure for the allocation of two-dimensional re-
sources in a multiagent system  international journal of
cooperative information systems  18 3–4  1–34  2009 
 katz  1997  matthew j  katz 
3-d vertical ray shooting
and 2-d point enclosure  range searching  and arc shoot-
ing amidst convex fat objects  computational geometry 
8 6  299–316  1997 
 kurokawa et al   2018  david kurokawa  ariel d  procac-
cia  and junxing wang 
fair enough 
guaranteeing
approximate maximin shares 
journal of the acm 
64 2  8 1–8 27  2018 
 messaoud et al   2008  said ben messaoud  chengbin chu 
and marie-laure espinouse  characterization and mod-
elling of guillotine constraints  european journal of op-
erational research  191 1  112–126  2008 
 robertson and webb  1998  jack robertson and william
webb  cake-cutting algorithms  be fair if you can  pe-
ters/crc press  1998 
 russo et al   2020  mauro russo  maurizio boccia  an-
tonio sforza  and claudio sterle 
constrained two-
dimensional guillotine cutting problem  upper-bound re-
view and categorization  international transactions in op-
erational research  27 2  794–834  2020 
 segal-halevi et al   2017  erel
segal-halevi 
shmuel
nitzan  avinatan hassidim  and yonatan aumann  fair
and square  cake-cutting in two dimensions  journal of
mathematical economics  70 8  1–28  2017 
 segal-halevi et al   2020  erel segal-halevi  avinatan has-
sidim  and yonatan aumann 
envy-free division of
land 
mathematics of operations research  45 3  896–
922  2020 
 shtechman et al   2020  itay shtechman  rica gonen  and
erel segal-halevi  fair cake-cutting algorithms with real
land-value data  in proceedings of the 19th international
conference on autonomous agents and multiagent sys-
tems  aamas   pages 2005–2007  2020 
 steinhaus  1948  hugo steinhaus  the problem of fair divi-
sion  econometrica  16 1  101–104  1948 
 stromquist  1980  walter stromquist 
how to cut a cake
fairly  american mathematical monthly  87 8  640–644 
1980 
proceedings of the thirtieth    ijcai-21 
174
 "
None,2021,https-www-ijcai-org-proceedings-2021-0025-pdf,On a Competitive Secretary Problem with Deferred Selections,"Tomer Ezra, Michal Feldman, Ron Kupfer",None,https://www.ijcai.org/proceedings/2021/0025.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0025-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0025-pdf.pdf,"on a competitive secretary problem with deferred selections
tomer ezra1   michal feldman1 2   ron kupfer3
1tel aviv university
2microsoft research
3the hebrew university of jerusalem
tomer ezra@gmail com  michal feldman@cs tau ac il  ron kupfer@mail huji ac il
abstract
we study the secretary problem in multi-agent en-
vironments  in the standard secretary problem  a
sequence of arbitrary awards arrive online  in a ran-
dom order  and a single decision maker makes an
immediate and irrevocable decision whether to ac-
cept each award upon its arrival  the requirement
to make immediate decisions arises in many cases
due to an implicit assumption regarding competi-
tion  namely  if the decision maker does not take
the offered award immediately  it will be taken by
someone else  we introduce a novel multi-agent
secretary model  in which the competition is ex-
plicit  in our model  multiple agents compete over
the arriving awards  but the decisions need not
be immediate  instead  agents may select previous
awards as long as they are available  i e   not taken
by another agent   if an award is selected by mul-
tiple agents  ties are broken either randomly or ac-
cording to a global ranking  this induces a multi-
agent game in which the time of selection is not
enforced by the rules of the games  rather it is an
important component of the agent s strategy  we
study the structure and performance of equilibria in
this game  for random tie breaking  we character-
ize the equilibria of the game  and show that the
expected social welfare in equilibrium is nearly op-
timal  despite competition among the agents  for
ranked tie breaking  we give a full characterization
of equilibria in the 3-agent game  and show that as
the number of agents grows  the winning probabil-
ity of every agent under non-immediate selections
approaches her winning probability under immedi-
ate selections 
1
introduction
in the classic secretary problem  ferguson  1989  a deci-
sion maker observes a sequence of n non-negative real-valued
awards v1          vn  which are unknown in advance  in a ran-
dom order  at time step t  the decision maker observes award
vt  and needs to make an immediate and irrevocable decision
whether or not to accept it  if she accepts vt  the game termi-
nates with value vt  otherwise  the award vt is gone forever
and the game continues to the next round  the objective of
the decision maker is to maximize the probability of choosing
the maximal award  a tight competitive ratio of 1/e is well
known for this problem  see  e g    ferguson  1989   
this problem  and variants thereof  is an abstraction that
captures many real-life scenarios  such as an employer who
interviews potential workers overtime  renters looking for a
potential house  a person looking for a potential partner for
life  phd students looking for an advisor  and so on  this
problem also has interesting implications to mechanism de-
sign  auctions and pricing  for both welfare and revenue max-
imization  in various markets such as online advertising mar-
kets  see e g   babaioff et al   2008  babaioff et al   2007 
ezra et al   2018  freeman  1983  kesselheim et al   2013 
kleinberg  2005   
in this work  we study the secretary problem in a multi-
agent system by introducing a secretary model with multiple
agents who compete with each other 
1 1
competing agents
competition among agents is a fundamental component in
many real-life scenarios  a recent line of work studies secre-
tary settings with multiple agents  where a set of employers
compete over a set of potential employees  the employees
enter the labor market sequentially  and the employers need
to decide whether to hire them or not  when a potential em-
ployee receives an offer  she accepts it  if she receives multi-
ple offers  she chooses one among them 
immorlica et al   2006  and karlin and lei  2015  con-
sider settings with multiple decision makers who compete
over awards that arrive online  in these studies  as in the
standard setting  decisions are immediate and irrevocable 
one of the justifications for the requirement in the standard
 single agent  secretary setting that decisions must be imme-
diate arises from an implicit assumption about competition 
namely  if the decision maker does not take the current of-
fered award  then it may be taken by someone else and gone
forever  for example  an employer who does not make a job
offer to a potential employee following an interview will lose
her forever  as she will probably be hired by another firm 
in this paper  we introduce a multi-agent model in which
the competition among agents over the arriving awards is ex-
plicit 
since the competition is explicitly captured by the
multiplicity of agents  decisions need no longer be imme-
proceedings of the thirtieth    ijcai-21 
175
 diate  instead  every previously arriving award can be se-
lected as long as it has not been taken by a different agent 
in our model  it is the explicit competition that may drive
agents to make fast selections  rather than the rules of the
game  that is  the time to select an award is part of an agent s
strategy  this model captures many real-life scenarios  where
decisions need not be immediate  rather  the time in which
agents make selections is part of their strategy  given the com-
petition  for example  an apartment remains available in the
market until it is rented by another potential renter  similarly 
a potential employee remains available until she accepts an
offer from another company  in all of these scenarios  a de-
cision need not be immediate  but delaying a decision might
result in losing the object if it is taken by another agent in the
meantime  this is the tension our model captures 
one issue that arises in this model is how to resolve ties
among agents  that is  who gets the award if several agents
select it  we consider two natural tie-breaking rules  namely 
random tie breaking  where ties are broken uniformly at
random  and ranked tie-breaking  where agents are a-priori
ranked by some global order  and ties are broken in favor of
higher ranked agents   random tie breaking fits scenarios
with symmetric agents  whereas ranked tie breaking fits sce-
narios where some agents are preferred over others  according
to some global preference order  for example  it is reason-
able to assume that a higher-position/salary job is preferred
over lower-position/salary job  or that firms in some industry
are globally ordered from most to least desired  random and
ranked tie-breaking rules were considered by immorlica et al 
 2006  and karlin and lei  2015   respectively  in secretary
settings with immediate and irrevocable decisions 
two natural objectives have been considered in settings
with competition 
the first is maximizing the probability
of receiving the maximal award  see  e g    immorlica et al  
2006  karlin and lei  2015    the second is outperforming
the competitors  see  e g   the dueling framework studied by
immorlica et al   2011    we consider an extension of the
latter objective  where an agent wishes to maximize the prob-
ability to win the 1st place  then to win the 2nd place  and so
on 
our goal is to study the structure and quality of equilibria
in these settings 
1 2
our results and techniques
random tie-breaking
for the random tie-breaking rule  we characterize the equi-
libria of the induced game  and show that the expected social
welfare in equilibrium is nearly optimal  despite competition
between the agents  this is cast in theorems 3 1 and 3 2  a
simplified statement follows 
theorem   theorems 3 1 and 3 2  in every k-agent game
with random tie-breaking 
there exists a simple time-
threshold strategy that guarantees each agent a winning prob-
ability of 1
k  regardless of the strategies of the other agents 
the strategy profile where all agents play this strategy is a
subgame perfect equilibrium  spe   moreover  the expected
social welfare of this spe is at least a k−1
k
fraction of the
sum of the top k awards 
in particular  we show that each of the k agents can guar-
antee herself a winning probability of 1
k following a simple
time-threshold strategy that depends only on the current time 
the number of active agents  i e   agents who have not yet re-
ceived an award   and whether the maximal award so far is
available  by symmetry  this is the maximal possible guaran-
tee  this guarantee is then used to fully characterize the set
of subgame perfect equilibria of the game 
we then establish that in equilibrium  the expected social
welfare is at least k−1
k
fraction of the sum of the top k awards
which is the optimal welfare  i e   we bound the price of com-
petition   we do so by using the following two observations 
first  we show that in equilibrium the expected number of
selected awards among the top k awards is high  second 
we observe that the probability of an award to be selected in
equilibrium is monotone in its rank among the awards 
we complement this result with a matching upper bound
 up to a constant factor   which is derived by observing that
in equilibrium there is a constant probability that the first se-
lected award is not one of the top k awards 
ranked tie-breaking
for the ranked tie-breaking rule  we show that for a suffi-
ciently large number of agents  the winning probabilities un-
der immediate- and non-immediate selections are roughly the
same 
theorem   informal theorem 4 2  under the ranked tie-
breaking rule  for every rank i  as the number of agents
grows  the winning probabilities of the ith ranked agent under
non-immediate selections approaches her winning probabil-
ity under immediate selections 
to prove this result  we use observations from  matsui and
ano  2016  karlin and lei  2015  ezra et al   2018  to show
that in the immediate decision model  the probability that the
maximal award is allocated goes to 1 as the number of agents
grows  since an agent in the non-immediate decision model
can always mimic the strategy of an agent in the immedi-
ate decision model  her guarantee for her winning probabil-
ity  which equals to her probability of receiving the maximal
award  in the non-immediate model is at least her guarantee
of receiving the maximal award in the immediate decisions
game 
we therefore deduce that the winning probabilities in the
non-immediate model converge to those in the immediate
model  this claim essentially formalizes the intuition that as
competition grows  the urgency to select awards faster grows 
in addition  we fully characterize the equilibria of the
three-agent game 
theorem   theorem 4 1  in every equilibrium of the 3-agent
game  agent 1 wins with probability
ln 4
2 ln 4 ≈ 0 41 while each
of agents 2  3 wins with probability
1
2 ln 4 ≈ 0 295 
notice that agent 1  the highest-ranked agent  can always
guarantee herself a winning probability of at least e−1 ≈ 0 37
by acting according to the optimal strategy in the classical
secretary problem  the last theorem quantifies the benefit
that agent 1 derives due to her ability to postpone decisions
in a 3-agent setting  as implied by theorem 4 2  this benefit
shrinks as the number of agents grows 
proceedings of the thirtieth    ijcai-21 
176
 1 3
related work
the classical secretary problem and variants thereof have at-
tracted broad interest and have resulted in a vast amount of
literature over the years  for a comprehensive survey  see 
e g    freeman  1983  
competing agents 
the closest papers to our work are the
studies by karlin and lei  2015  and immorlica et al   2006  
who study secretary settings with competing agents  with the
ranked- and random tie breaking rules  respectively 
the
main difference between their models and ours is that they
consider multi-agent settings where agents must make de-
cisions immediately  while in our model the competition is
endogenous  namely  past awards can be selected as long as
they are available  karlin and lei  2015  show that under the
ranked tie-breaking rule  the optimal strategy for each agent
is a time-threshold strategy  which is given in the form of a re-
cursive formula  albeit not in a closed form   immorlica et al 
 2006  characterize the nash equilibria under the random tie-
breaking rule  another related work is the dueling framework
by immorlica et al   2011   who considered  among other set-
tings  a dueling scenario between two secretary algorithms 
whose objective is to outperform the opponent algorithm 
matroid secretaries 
in this paper we derive insights from
studies on secretary variants in which a decision maker
can choose multiple awards  based on some feasibility con-
straints  babaioff et al   2007  introduced the matroid secre-
tary problem  where a decision maker selects multiple awards
under a matroid constraint  it has been shown that a constant
competitive ratio can be achieved for some matroid struc-
tures  but the optimal competitive ratio for arbitrary matroids
is still open  an interesting special case  which was also stud-
ied in earlier works such as  kleinberg  2005  and  gilbert
and mosteller  1966   is one where the decision maker may
choose up to k awards  also known as a k-uniform matroid
constraint  
previous works  gilbert and mosteller  1966 
sakaguchi  1978  matsui and ano  2016  ezra et al   2018 
studied secretary models in which a decision maker wishes
to maximize the probability of getting the highest award  but
may choose up to k awards  in section 4 we draw interesting
connections between these models and the ours 
non-immediate or revocable decisions 
other relax-
ations of the requirement to select immediately have been
considered in the literature  ho and krishnan  2015  consider
a sliding-window variant  where decisions may be delayed for
a constant amount of time  a similar model is considered by
kesselheim et al   2019   where decisions may be delayed for
a randomized  not known in advance  amount of time  ezra
et al   2018  study settings where the irrevocability assump-
tion is relaxed  specifically  they consider a setting where the
decision maker can select up to ℓ elements immediately and
irrevocably  but her performance is measured by the top k el-
ements in the selected set  this work is complementary to
ours in the sense that it relaxes the irrevocability assumption 
while our work relaxes the immediacy assumption 
1 4
paper s structure
our model is presented in section 2  in sections 3 and 4 we
present our results with respect to the random- and ranked
tie-breaking rules  respectively  we conclude this paper in
section 5  where we discuss future directions  all missing
proofs are deferred to the full version  ezra et al   2020  
2
model
we consider a variant of the classical secretary setting  where
a set of n arbitrary awards are revealed online in a uniformly
random order  let vt denote the award revealed at time t 
unlike the classical secretary problem that involves a single
decision maker  in our setting there are k agents who com-
pete over the awards  upon the revelation of award vt  every
agent who has not received an award yet may select one of
the awards v1          vt that is still available  an award that is
selected by a single agent is assigned to this agent  an award
that is selected by more than one agent is assigned to one
of these agents either randomly  hereafter  random tie break-
ing   or according to a predefined ranking  hereafter  ranked
tie breaking   agents who received awards are no longer ac-
tive  awards that were assigned are no longer available  thus 
at time t  the set of available awards is the subset of awards
v1          vt that have not been assigned yet  the game con-
tinues as long as there are active agents  i e   after time n 
if active agents remain  the agents compete  without newly
arriving awards  on the remaining available awards until all
agents are allocated 
given an instance of a game  the history at time t in-
cludes all the relevant information revealed up to time t  i e  
v1          vt  and the assignments up to time t − 11  a strat-
egy of agent i  denoted by si  is a function from the set of all
possible histories to a selection decision  either selecting one
of the available awards  or passing   a strategy profile is de-
noted by s =  s1          sk   we also denote a strategy profile
by s =  si  s−i   where s−i denotes the strategy profile of
all agents except agent i  every strategy profile s induces a
distribution over assignments of awards to agents  for ranked
tie breaking  the distribution is with respect to the random
order of award arrival  and possibly the randomness in the
agent strategies  for random tie breaking  the randomness is
also with respect to the randomness in the tie breaking 
we say that agent i wins the jth place in the game if she
receives the jth highest award among all allocated awards 
let p =  p1          pk  be a k-dimensional vector  where pj is
the probability to win the jth place  as natural in competi-
tion settings  every agent cares only about her relative per-
formance with respect to her competitors  consequently  we
find the following objective function the most natural in this
setting  every agent wishes to maximize her probability to
win the first place  upon equality she wishes to maximize the
probability to win the second place  and so on  thus  given
two vectors p  ¯p ∈ rk  p is preferred over ¯p  denoted ¯p ≺ p 
if p is lexicographically greater than ¯p  similarly  p is weakly
preferred over ¯p  denoted ¯p ⪯ p  if p is lexicographically
greater or equal to ¯p 
a strategy profile s induces a k-dimensional probability
vector pi s  for each agent i  where pi
j s  is the probability
1in our setting  additional information  such as the history of se-
lections  in contrast to assignments  is irrelevant for future decisions 
proceedings of the thirtieth    ijcai-21 
177
 that agent i wins the jth place under s  agent i derives higher
 respectively  weakly higher  utility from strategy profile s
than strategy profile ¯s  denoted ¯s ≺i s  resp   ¯s ⪯i s   if
pi  ¯s  ≺ pi s   resp   pi  ¯s  ⪯ pi s    we use ¯s ≺i s and
s ≻i ¯s interchangeably  and similarly for p and ¯p 
note that pi
1 s  is the probability that agent i wins the first
place under strategy profile s  we sometimes refer to it as
agent i s winning probability under s 
we consider the following equilibrium notions 
• a strategy profile s =  s1          sk  is a nash equilib-
rium  ne  if for every agent i and every strategy s′
i  it
holds that  s′
i  s−i  ⪯i  si  s−i  
• a strategy profile s =  s1          sk  is a subgame per-
fect equilibrium  spe  if it is a ne for every subgame
of the game  i e  for every initial history h  s is a ne in
the game induced by history h 
every spe is a ne  but not vice versa 
we now illustrate our models in the following example 
example 1  consider a setting with 5 houses for rent and
3 potential renters  the houses  enter the market   i e   be-
come available  in a random order and remain available until
rented by some renter 
random tie-breaking captures scenarios where the house
owners are indifferent between different renters  upon the
entrance of the first house  the renters do not select it since
the probability that this house is the best one among all 5
houses is only 1
5  which is too low  the threshold here is 1/3 
see theorem 3 1   upon the entrance of the second house 
the better among the two houses is the best among all five
houses with probability 2
5 > 1
3  and so all three agents select
it  assume that renter #1 was assigned the selected house
 by the random assignment process   and further assume that
the third house is the highest among the first three houses 
in this case  the two remaining renters will select this house
and it will be assigned to one of them at random  the one
remaining renter will select the maximal available house at
the end of the process  by symmetry  each one of the three
agents wins with probability 1
3 
ranked tie breaking captures scenarios where the house
owners have identical preferences over renters  e g   ranking
according to the credit history of the renters  
upon the entrance of the first house  the renter ranked #3
selects it and guarantees herself a winning probability of 1
5
 one can show that the other renters can guarantee them-
selves a higher winning probability  and that if renter #3
does not select it  then her winning probability in spe is up-
per bounded by 1
6   suppose next that the second house is
worse than the first one  then  it is not selected by any of
the remaining renters  suppose further that the third house
is the best among the first three houses  then  both remain-
ing renters select it  and it is being assigned to renter #1  by
ranked tie-breaking   a full analysis of the spe shows that
the renters  winning probabilities are 31
60  17
60  and 12
60  respec-
tively 
3
random tie-breaking
in this section  we study the setting of the random tie-
breaking rule  we characterize the spes and give simple time
threshold strategies with optimal utility guarantees  we show
that in the spe where all agents play according to this optimal
guarantee strategy  at least k−1
k
of the optimal social welfare
is achieved in expectation 
consider the following strategy σi for agent i  where ℓt de-
notes the number of active agents at time t  agent i included  
• if t ≥ n  then select the maximal available award 
• if n
ℓt < t < n  and the maximal award so far is available 
then select it 
• if t = n
2   ℓt = 2  and the maximal award so far is avail-
able  then select it 
• else  pass  i e   select no award  
we denote by si the set of strategies in which agent i plays
according to σi up to the following cases 
• if ℓt = 2  t = n
2   and both the highest and the second
highest awards so far are available  then the agent can
either pass or select the highest award so far 
• if ℓt = 1 and the highest award so far is available  then
the agent can either pass or select this award 
we next show that strategies in si are the only strategies
that guarantee a utility of at least   1
k          1
k   by symmetry 
there is no strategy σ such that
� 1
k          1
k
�
≺ pi σ  s−i  for
every s−i  thus  the strategy profiles where each agent i
plays according to a strategy in si  are the only spes 
theorem 3 1  for every agent i  σ ∈ si and s−i  it holds
that
� 1
k          1
k
�
⪯ pi σ  s−i    for every σ′ /∈ si there exists
s−i such that
� 1
k          1
k
�
≻ pi σ′  s−i   moreover  the strat-
egy profiles where each agent j plays according to a strategy
in sj  are the only spes 
before proving theorem 3 1  we show the following 
observation 3 1  for every time t < n  selecting an element
that is not the maximal so far cannot guarantee a winning
probability of 1
k 
thus  we can assume that agents do not select elements that
are not the maximal so far up to time t = n  we now give
lower bounds on the probabilities of winning first and second
places in a strategy σ ∈ si given a time t  and whether the
maximal and second maximal awards so far are available  for
every 1 ≤ ℓ ≤ k  let aℓ
t ∈  0  1 2 be an ordered pair denoting
a lower bound on the probabilities of agent i winning first and
second places under strategy profile  σ  s−i   conditioned on
the event that at time t  after observing the award vt  but be-
fore making selections in time t  agent i is active  there are
ℓ active agents  including agent i   and the maximal and sec-
ond maximal awards up to time t are available  similarly  let
bℓ
t be a lower bound on the probabilities of agent i winning
first and second places under strategy profile  σ  s−i   condi-
tioned on the event that at time t  agent i is active  there are ℓ
active agents  i included   and the maximal award up to time
t is available  but the second maximal award is not available 
let cℓ
t be a lower bound on the probabilities of agent i win-
ning first and second places under strategy profile  σ  s−i  
conditioned on the event that after the allocations of time t 
agent i is active  there are ℓ active agents  including agent i  
proceedings of the thirtieth    ijcai-21 
178
 and the maximal award up to time t is not available  but the
second maximal award is available  finally  let dℓ
t be a lower
bound on the probabilities of agent i winning first and sec-
ond places under strategy profile  σ  s−i   conditioned on the
event that after the allocations of time t  agent i is active  there
are ℓ active agents  i included   and none of the maximal and
the second maximal awards up to time t are available 
in lemma 3 1 we lower bound the above terms  the com-
plete proof of the lemma is deferred to the full version 
lemma 3 1  for every t  and every k ≥ ℓ > 1  it holds that 
• aℓ
t ≥
� 1
ℓ   1
ℓ
�
• cℓ
t ≥
�
n−t
nℓ   n2 t2−tn−n
n n−1 ℓ
�
• bℓ
t ≥
�
1
ℓ    n−t  n t−1 
n n−1 ℓ
�
• dℓ
t ≥
� n−t
nℓ   n−t
nℓ
�
proof sketch  we observe that the winning probability of an
agent depends on the time step t  the number of active agents
ℓ  and whether the maximal award so far is available or not 
if at time t an agent receives the maximal award up to time
t  she wins with probability t
n  which is the probability that
this award is the global maximum   if another agent receives
the maximal award up to time t  then by symmetry  each re-
maining active agent can guarantee a winning probability of
n−t
n ℓ−1  
thus  selecting the maximal award so far is bet-
ter whenever
t
n >
n−t
n ℓ−1   and passing is better whenever
t
n <
n−t
n ℓ−1   in cases where t
n =
n−t
n ℓ−1   both passing and
selecting the maximal award so far give a winning probability
of 1
ℓ   and the agents break this tie based on the probability of
winning the second place  for the four states of whether the
maximal and second maximal awards so far are available  we
establish lower bounds on the probabilities of winning first
and second places  by induction on t and ℓ 
we are now ready to prove theorem 3 1 
proof of theorem 3 1  it
follows
from
the
proof
of
lemma 3 1 that for every strategy that is not in si  if
each agent j ̸= i plays according to a strategy in sj  agent
i s utility is smaller than
� 1
k  1
k  0          0  k−2
k
�
  it also shows
that if agent i plays according to a strategy in si  and there
exists an agent j that plays according to a strategy not in sj 
utility is greater than
� 1
k  1
k  k−2
k   0          0
�
 
thus  the only spes are profiles in which each agent j
plays according to a strategy in sj  and by symmetry  the
utility of agent i is exactly
� 1
k          1
k
�
  as desired 
in theorem 3 1 we characterize the structure of all spes 
immorlica et al   2006  prove that in the immediate decisions
model  whenever t
n ≥
1
ℓt   and the current arriving award is
the maximal so far  all active agents select it  however  they
do not provide a full characterization of the cases where t
n <
1
ℓt   indeed  in some cases agents do select the maximal award
so far at such times t  in contrast  we show that in the non-
immediate decisions model  the times where t
n ≥
1
ℓt are the
only times where the agents make selections 
we next study the social welfare  i e   the sum of the awards
received by all agents  obtained in an spe  let yi denote the
ith maximal value among v1          vn  then  the optimal so-
cial welfare is opt = �k
i=1 yi 
the following theorem asserts that despite the competition 
the social welfare of the spe where all agents play according
to σi is at least k−1
k
of the optimal social welfare 
theorem 3 2  the expected sum of the allocated awards in
the spe profile s =  σ1          σk  is at least k−1
k
· opt 
we complement this result by showing an instance of
awards y1        yn where the social welfare in every spe is
at most k−ω 1 
k
· opt for every k > 1 
example 2  suppose y1 =       = yk = 1 and yj = 0 for
every j such that k < j ≤ n  in every spe  the first selection
is made at time no later than t = ⌊ n
k ⌋   1  if none of the
top k awards appeared up to time t  at least one of the agents
gets an award of 0  the probability that none of y1        yk
appeared by time t is approximately   k−1
k  k = ω 1   thus 
the expected social welfare is at most k−ω 1 
k
· opt 
4
ranked tie-breaking
in this section  we study competition under the ranked tie-
breaking rule  we first claim that without loss of generality 
for every agent the winning probability equals to the probabil-
ity of receiving the highest award  to show this  we observe
that whenever exactly one agent is active  she may as well
wait until time t = n and only then select the maximal award
without harming her utility  thus  it can be assumed that the
maximal award is always allocated  and the winning agent
receives it  thus  we may assume that the first-order objec-
tive of every agent is to maximize the probability of receiving
the maximal award  as in the standard secretary problem and
previous multi-agent extensions 
in section 4 1 we present general observations regarding
equilibria in this setting  we then characterize the equilibrium
in the 3-agent game in section 4 2  in section 4 3 we show
that as the number of competing agents goes to infinity  the
agents  probabilities of receiving the highest award  which
equal to the agents  winning probabilities  converge to the
corresponding probabilities in the immediate decisions model
described by karlin and lei  2015  
4 1
general observations
we first make observations about the structure of the subgame
perfect equilibria  spe  of the game 
proposition 4 1  a strategy profile s =  s1          sn  is an
spe if for every agent i  si is described by a set of time
thresholds t ℓ
j for every j  ℓ such that 1 ≤ j ≤ ℓ ≤ k  at
time t  agent i selects the highest award so far if it is avail-
able and t ≥ t ℓ
j   where the current number of active agents
is ℓ and agent i is ranked jth among them 2 in addition  if ℓ
agents are active and t > n − ℓ  then the lowest-ranked ac-
tive agent makes a selection  even if the highest award so far
is not available 
we proceed with several observations about the time
thresholds in the spe of the game  since any agent can al-
ways mimic the strategy of an agent ranked lower than her 
2if t = t ℓ
j   then the agent is indifferent between selecting and
passing 
proceedings of the thirtieth    ijcai-21 
179
 in equilibrium a lower-ranked agent would be willing to re-
ceive any award that a higher-ranked agent would be willing
to receive  in the threshold terminology  it means that 
observation 4 1  for any number of active agents ℓ  for ev-
ery pair of ranks h  j such that h < j ≤ ℓ  without loss of
generality it holds that t ℓ
j ≤ t ℓ
h 
the following observation gives bounds on the time thresh-
old of the lowest-ranked active agent relative to the second-
lowest ranked active agent 
observation 4 2  for any number of active agents ℓ  it holds
that t ℓ
ℓ−1 ≥ t ℓ
ℓ ≥ t ℓ
ℓ−1 − 1 
proof  by observation 4 1 we have that t ℓ
ℓ−1 ≥ t ℓ
ℓ   on
the other hand  the lowest-ranked active agent never makes a
selection before time minj̸=ℓ t ℓ
j − 1  because she can only
benefit from waiting as long as no other active agent makes a
selection  the claim now follows since  by observation 4 1 
minj̸=ℓ t ℓ
j = t ℓ
ℓ−1 
recall that the winning probability of agent i under strat-
egy profile s is denoted by pi
1 s   throughout this section 
we make two simplifications in notation  first  we omit s 
second  we omit the subscript 1  since we consider only the
probability of winning the 1st place  consequently  we de-
note the probability that agent i wins the 1st place in strategy
profile s by pi 
the following observation gives bounds on the winning
probability of the lowest-ranked agent relative to the second-
lowest agent 
observation 4 3  it holds that pk−1 − 1
n ≤ pk ≤ pk−1 
4 2
the 3-agent game
in a 2-agent game observation 4 3 implies that 1
n ≥ p1−p2 ≥
0  that is  both agents win with probability roughly a half 
this symmetry breaks as more agents join the game and the
setting becomes interesting already in the case of 3 agents 
notice that the highest-ranked agent can always guarantee
herself a probability of at least e−1 ≈ 0 37 to receive the
highest award by adopting the optimal strategy in the classi-
cal secretary problem  an interesting question is whether the
opportunity to make non-immediate decisions increases this
probability for the highest-ranked agent 
we show the following 
theorem 4 1  in a setting with 3 agents  in any spe  agent 1
wins with probability ≈ 0 41  while each of agents 2  3 wins
with probability ≈ 0 295 
4 3
immediate vs  non-immediate selections
in this section 
we compare the immediate and non-
immediate models for games with a large number of agents 
let pi k denote the probability that agent i wins in a k-agent
game  with non-immediate selections  and let qi denote the
probability that agent i receives the highest award in a game
with immediate selections  we note that under immediate se-
lections  qi is independent of the number of agents 
the main result here is that agents  winning probabili-
ties in equilibrium under non-immediate selections approach
their winning probabilities under immediate selections  as the
number of agents grows 
theorem 4 2  for every i  limk→∞ pi k = qi 
the full proof of theorem 4 2 is deferred to the full ver-
sion  we give here the high-level idea of the proof  we use the
following theorem by karlin and lei  karlin and lei  2015 
regarding the immediate decision model 
theorem 4 3  karlin and lei  2015    for every n  k and
every i ∈  k   there is a unique ti  independent of k  such
that agent i plays a ti-threshold strategy in spe  namely 
wait until time ti  then make a selection whenever a best-
so-far award appears  it holds that ti−1 ≥ ti  and qi = ti
n  
for all i  moreover  threshold strategy ti guarantees agent i a
winning probability of qi regardless of other agent strategies 
we then show that in the non-immediate model  every
agent i can mimic strategy ti specified in theorem 4 3 and
guarantee herself the same guarantee of qi  thus for all i  k 
it holds that pi k ≥ qi   moreover  using results by  matsui
and ano  2016  and  gilbert and mosteller  1966   it follows
that limk→∞
�
i≤k qi = 1  we show that this implies that
limk→∞ pi k ≤ qi  since otherwise  there exists k such that
�
i pi k > 1 
5
discussion and future directions
we study secretary settings with competing decision makers 
while in previous secretary settings  including ones where
competition among multiple agents are considered  decisions
must be made immediately  we introduce a model where the
time of selection is part of the agent s strategy  and thus the
competition is endogenous  in particular  decisions need not
be immediate  and agents may select previous awards as long
as they are available  these settings capture many real-world
settings  where agents compete over  awards  that may re-
main available until taken by a competitor 
this work suggests open problems and directions for future
research  for the ranked tie-breaking rule  we fully charac-
terize the equilibria of a 3-agent game  and derive the corre-
sponding utilities of the agents  extending this characteriza-
tion to any number of agents is an interesting open problem 
below we list some future directions that we find partic-
ularly natural   1  study competition in additional problems
related to optimal stopping theory  such as prophet and pan-
dora box settings   2  study competition in secretary settings
under additional tie-breaking rules  such as random tie break-
ing with non-uniform distribution  and tie-breaking rules that
allow to split awards among agents   3  study competition in
secretary settings under additional feasibility constraints  for
example  scenarios where agents can choose up to k awards 
or other matroid constraints   4  extend the current study to
additional objective functions 
acknowledgments
this project has received funding from the european re-
search council  erc  under the european union s horizon
2020 research and innovation program  grant agreement no 
866132  740282   and by the israel science foundation  grant
number 317/17  
the full version of this work can be found at  ezra et al  
2020  
proceedings of the thirtieth    ijcai-21 
180
 references
 babaioff et al   2007  moshe babaioff  nicole immorlica 
and robert kleinberg  matroids  secretary problems  and
online mechanisms 
in proceedings of the eighteenth
annual acm-siam symposium on discrete algorithms 
pages 434–443  2007 
 babaioff et al   2008  moshe babaioff  nicole immorlica 
david kempe  and robert kleinberg 
online auctions
and generalized secretary problems  acm sigecom ex-
changes  7 2  1–11  2008 
 ezra et al   2018  tomer ezra  michal feldman  and ilan
nehama  prophets and secretaries with overbooking  in
proceedings of the 2018 acm conference on economics
and computation  pages 319–320  2018 
 ezra et al   2020  tomer ezra  michal feldman  and ron
kupfer  on a competitive secretary problem with deferred
selections  arxiv preprint arxiv 2007 07216  2020 
 ferguson  1989  thomas s  ferguson  who solved the sec-
retary problem  statistical science  4 3   1989 
 freeman  1983  p  r  freeman  the secretary problem and
its extensions  a review  international statistical review /
revue internationale de statistique  51 2  189–206  1983 
 gilbert and mosteller  1966  john p  gilbert and frederick
mosteller  recognizing the maximum of a sequence  jour-
nal of the american statistical association  61 313  35–
73  1966 
 ho and krishnan  2015  shan-yuan ho and abijith krish-
nan  a secretary problem with a sliding window for recall-
ing applicants  arxiv preprint arxiv 1508 07931  2015 
 immorlica et al   2006  nicole immorlica  robert klein-
berg  and mohammad mahdian  secretary problems with
competing employers  in international workshop on in-
ternet and network economics  pages 389–400  springer 
2006 
 immorlica et al   2011  nicole immorlica  adam tauman
kalai  brendan lucier  ankur moitra  andrew postle-
waite  and moshe tennenholtz  dueling algorithms  in
proceedings of the forty-third annual acm symposium on
theory of computing  pages 215–224  acm  2011 
 karlin and lei  2015  anna karlin and eric lei  on a com-
petitive secretary problem  in twenty-ninth aaai confer-
ence on artificial intelligence  2015 
 kesselheim et al   2013  thomas kesselheim  klaus radke 
andreas t¨onnis  and berthold v¨ocking  an optimal online
algorithm for weighted bipartite matching and extensions
to combinatorial auctions  in european symposium on al-
gorithms  pages 589–600  springer  2013 
 kesselheim et al   2019  thomas kesselheim  alexandros
psomas  and shai vardi 
how to hire secretaries with
stochastic departures 
in web and internet economics
- 15th international conference  wine 2019  volume
11920  page 343  2019 
 kleinberg  2005  robert d kleinberg 
a multiple-choice
secretary algorithm with applications to online auctions 
in soda  volume 5  pages 630–631  2005 
 matsui and ano  2016  tomomi matsui and katsunori ano 
lower bounds for bruss  odds problem with multiple stop-
pings  mathematics of operations research  41 2  700–
714  2016 
 sakaguchi  1978  m sakaguchi  dowry problems and ola
policies  rep  stat  appl  res   juse  25 124–128  1978 
proceedings of the thirtieth    ijcai-21 
181
 "
None,2021,https-www-ijcai-org-proceedings-2021-0026-pdf,Relaxed Core Stability in Fractional Hedonic Games,"Angelo Fanelli, Gianpiero Monaco, Luca Moscardelli",None,https://www.ijcai.org/proceedings/2021/0026.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0026-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0026-pdf.pdf,"relaxed core stability in fractional hedonic games
angelo fanelli1   gianpiero monaco2   luca moscardelli3
1cnrs   umr-6211   france
2university of l aquila  l aquila  italy
3university of chieti-pescara  pescara  italy
angelo fanelli@unicaen fr  gianpiero monaco@univaq it  luca moscardelli@unich it
abstract
the core is a well-known and fundamental notion
of stability in games intended to model coalition
formation such as hedonic games  the fact that the
number of deviating agents  that have to coordinate
themselves  can be arbitrarily high  and the fact that
agents may benefit only by a tiny amount from their
deviation  while they could incur in a cost for devi-
ating   suggest that the core is not able to suitably
model many practical scenarios in large and highly
distributed multi-agent systems  for this reason 
we consider relaxed core stable outcomes where the
notion of permissible deviations is modified along
two orthogonal directions  the former takes into ac-
count the size of the deviating coalition  and the
latter the amount of utility gain for each member
of the deviating coalition  these changes result in
two different notions of stability  namely  the q-size
core and k-improvement core  we investigate these
concepts of stability in fractional hedonic games 
that is a well-known subclass of hedonic games for
which core stable outcomes are not guaranteed to
exist and it is computationally hard to decide non-
emptiness of the core  interestingly  the considered
relaxed notions of core also possess the appealing
property of recovering  in some notable cases  the
convergence  the existence and the possibility of
computing stable solutions in polynomial time 
1
introduction
hedonic games  introduced in  drèze and greenberg  1980  
represent the most important game-theoretic approach to the
study of coalition formation problems  an outcome for these
games is a coalition structure  which is a partition of the
agents into coalitions  over which the agents have valuations 
the utility that an agent gets in a coalition structure only de-
pends on the coalition she belongs to  fractional hedonic
games  fhgs   introduced in  aziz et al   2014   see also
 aziz et al   2019    embody a natural and succinct graph
representation subclass of hedonic games  in these games 
each agent has a value for any other agent  and the utility
that an agent gets for a coalition is the sum of the values
she assigns to the members of her coalition divided by the
size of the coalition  fhgs can model natural behavioral
dynamics in social environments  real-world examples in-
clude social networks in which people organize themselves
in groups with the aim of maximizing the fraction of peo-
ple of the same ethnic or with the same interests  politicians
organizing themselves in parties with the goal of maximiz-
ing the fraction of like-minded members  countries organiz-
ing themselves in international groups  employees forming
unions  etc  moreover  simple symmetric fractional hedonic
games  ss-fhgs   where symmetric valuations only take the
values 0 and 1  suitably model a basic economic scenario re-
ferred to in  aziz et al   2019  as bakers and millers 
among other solution concepts  core stability plays a cen-
tral rule in hedonic games  an outcome is core stable if there
is no subset of agents t whose members all prefer t with
respect to the coalition they belong to in the outcome  the set
of agents t is called a blocking coalition for the outcome  
it is worth noticing that the members of a blocking coalition
have to coordinate in order to perform a deviation  moreover 
they could incur a proportional cost for deviating  for these
reasons  in large and highly distributed multi-agent systems 
the fact that the number of deviating agents can be arbitrar-
ily high  and the fact that agents may benefit only by a tiny
amount from their deviation suggest that the core is not able
to suitably model many practical processes of coalition struc-
ture generation  furthermore  it is well known that there are
games that do not always admit core stable outcomes  even
for ss-fhgs  the core may be empty  finally  it is computa-
tionally hard in general to decide non-emptiness of the core
 aziz et al   2019  and  even in games where the existence of
core stable outcomes is guaranteed  these outcomes could be
very inefficient or computationally intractable 
1 1
our contribution
motivated by the downsides of core stability  in this work we
propose a new natural direction of investigation  which con-
sists in relaxing the stability constraints along two orthogonal
directions  in order to enrich the set of admissible solutions 
specifically  our conceptual contributions are the notion of q-
size core stability  in which the size of a blocking coalition
is at most q  and the one of k-improvement core stability  in
which each member of a blocking coalition increases her util-
ity by a factor strictly greater than k  while the former is a
notion of stability related to the one of q-strong nash stabil-
proceedings of the thirtieth    ijcai-21 
182
 ity  with the notable difference that  in the context of q-strong
nash  the deviating agents are not forced to form a coalition
together  and was also considered in the context of hedonic
games  carosi et al   2019   to the best of our knowledge
the latter has never been investigated in the context of non-
cooperative games  more specifically  it is worth noticing
that  in the context of cooperative coalition formation games
in which the valuation of any coalition is not agent-specific
and has to be allocated among the agents belonging to the
considered coalition in some fair way  a related notion is the
one of strong ϵ-core  shapley and shubik  1966   in which a
blocking coalition has a valuation that is at least the sum of
the current allocations of its agents plus ϵ  this definition leads
to the one of least-core  maschler et al   1969   that is the
strong ϵ-core with the smallest value of ϵ that makes the set
of stable solutions non-empty  our notion of k-improvement
core stability differs from the one of strong ϵ-core because  i 
in the spirit of non-cooperative games  in the former the re-
quested gain is for the utility of any agent  as opposed to the
latter in which  in the spirit of cooperative games  the gain
is for the valuation of the whole blocking coalition and  ii 
in the former such a gain is given by a multiplicative factor 
while in the latter by an additive one 
as a case study  we investigate the considered relaxed con-
cepts of stability in fractional hedonic games  in this context 
we can summarize the results as follows  we first focus on ex-
istential and computational aspects  section 3   with a special
focus on the convergence of relaxed core dynamics starting
from any coalition structure  in fact  it is worth remarking that
the convergence of such dynamics is a very appealing prop-
erty in practical scenarios  we show that a 2-size core stable
outcome always exists and can be obtained through a 2-size
core dynamics  theorem 3   for simple games  we strengthen
the previous result by extending it to 3-size core stable out-
comes  also showing that the 3-size core dynamics has poly-
nomial length  theorem 4   on the side of k-improvement
core stability  we show that a k-improvement core stable out-
come always exists for k ≥ 2 and can be obtained through a
k-improvement core dynamics  theorem 5   although we are
not able to show that such dynamics has the desirable prop-
erty of polynomial length  we show that a k-improvement
core stable outcome can be still computed in polynomial time 
for any k ≥ 2 1 − 1/n   where n is the number of agents 
through a simple algorithm  theorem 6   for simple games 
we slightly strengthen the previous result by proving that a
k-improvement core stable outcome can still be computed in
polynomial time  for any k ≥ 3/2  theorem 7   this latter
result has been proven by showing an intriguing relation be-
tween 3-size core stable outcomes and 3
2-improvement core
stable outcomes  specifically  we show that every 3-size core
stable coalition structure is also 3
2-improvement core stable
 theorem 2   we remark that the reason for considering the
settings of q ≤ 3 and k ≥ 3
2 is twofold  on the one hand  they
represent a necessary step for understanding the cases with
higher coalition sizes or smaller improvement factor  see sec-
tion 5 for a more detailed discussion   on the other hand  they
are also practically significant in themselves because  when
considering small values of q  it is easy to obtain coordina-
tion within small-sized coalitions  while the value of k = 3
2
is reasonably small 
finally  we focus on the efficiency of k-improvement core
and q-size core stable outcomes  section 4   we show that 
for every k ≥ 1  in every game the social welfare of an op-
timal outcome can be at most 2k times the social welfare of
any k-improvement core stable outcome  theorem 8  and that
such bound is tight  theorem 9   we also provide similar
analyses for 2-size core and 3-size core stable outcomes 
1 2
related work
hedonic games have been introduced in  drèze and green-
berg  1980  and then further developed in  banerjee et
al   2001  bogomolnaia and jackson  2002  cechlárová and
romero-medina  2001   see  aziz and savani  2016  for a
nice survey on the topic  
fractional hedonic games  fhgs  have been introduced
in  aziz et al   2014   see also  aziz et al   2019   where
it is shown that the core can be empty even for the special
case of simple and symmetric valuations ss-fhg  but that it
is not empty for very specific sub-classes  the authors also
show that it is computationally hard in general to decide the
non-emptiness of the core  various computational results for
core and individual stability have been presented in  brandl
et al   2015   local core stability  where there is a structural
constraint on the blocking coalition  has been addressed in
 carosi et al   2019    bilò et al   2018  study the existence 
efficiency and computational complexity of nash and strong
nash equilibria  it is worth mentioning that a q-strong nash
stable outcome is also q-size core stable  however  in  bilò et
al   2018  it is shown that  for any q ≥ 2  q-strong nash stable
outcomes are not guaranteed to exist even for ss-fhg  no-
tice that this result gives an additional motivation for studying
the existence of 2-size core stable outcomes  improved results
about the nash price of stability can be found in  kaklamanis
et al   2020   fhgs have been also considered under differ-
ent perspectives in  aziz et al   2015  flammini et al   2018 
flammini et al   2021  
modified fractional hedonic games  mfhgs   introduced
in  olsen  2012   are very similar to fractional ones  a com-
parison between the two classes of games can be found in
 monaco et al   2020   the existence and the performance of
natural stable outcomes like nash  strong nash  and core sta-
ble outcomes for mfhgs have been presented in  monaco et
al   2019  monaco et al   2020  
finally  the price of pareto optimality for both mfhgs and
fhgs has been studied in  elkind et al   2020  
2
model and preliminaries
for any n ∈ n  we denote by  n  the set  1  2          n  
a symmetric fractional hedonic game  s-fhg  g =
 n   vi i∈n  is a game in which each agent i ∈ n  where
n =  n   has a valuation vi   n → r≥0  mapping ev-
ery agent to a real non-negative value  we assume that the
number of agents is n ≥ 2  we denote with vmax
i
 g  =
maxj∈n vi j  the maximum valuation of agent i for any
other agent j ∈ n in the game g  we assume that vi i  = 0
for every i ∈ n and that the valuations are symmetric  i e  
vi j  = vj i  for every i  j ∈ n 
proceedings of the thirtieth    ijcai-21 
183
 if it holds that vi j  ∈  0  1  for every i  j ∈ n  we
say that the game is a simple symmetric fractional hedonic
game  ss-fhg  
graph representation 
an s-fhg has a very intuitive
graph representation 
in fact  it can be expressed by a
weighted graph g =  n  e  w   where nodes in n repre-
sent the agents  and undirected edges are associated to non-
null valuations  namely  for any i  j ∈ n  if vi j  > 0 
an edge  i  j  of weight w  i  j   = vi j  = vj i  belongs
to e  analogously  an ss-fhg can be expressed by an un-
weighted graph g =  n  e  in which  for any i  j ∈ n  edge
 i  j  belongs to e if and only if vi j  = 1  given a subset
of agents c ⊆ n  we denote with g c  the subgraph of g
induced by agents in c 
coalitions and utilities 
a coalition is a non-empty sub-
set of n  the set of all agents n is also called the grand
coalition  and a coalition of size 1 is called a singleton coali-
tion  given a coalition c and any agent i ∈ c  let δc i  =
�
j∈c vi j  be the sum of valuations of agent i for every
agent belonging to coalition c  the utility or payoff µi c 
of agent i in coalition c such that c ∋ i is equal to δc i 
divided by the total number of agents in the coalition  that
is µi c  =
δc i 
|c|   notice that µi c  ≤
|c|−1
|c| vmax
i
 g  ≤
n−1
n vmax
i
 g  for any agent i ∈ n and coalition c of a
game g  an outcome of the game is a coalition structure
c =  c1          ch   c is a partition of the agents into h coali-
tions  that is  �
t∈ h  ct = n and ct ∩ cp = ∅ ∀t  p ∈  h  
with t ̸= p  we denote by c i  the coalition agent i belongs
to in coalition structure c  the utility µi c i   of an agent i
in coalition structure c is also denoted by µi c  
core stability 
given a coalition structure c  a blocking
coalition for c is a set of agents c ⊆ n such that  for every
agent i ∈ c  it holds that µi c  > µi c   since vi j  ≥ 0
and vi i  = 0 for every i  j ∈ n  we have that |c| ≥ 2  a
coalition structure c is core stable if it does not admit a block-
ing coalition  we relax the definition of core stability along
two directions   i  given an integer q ≥ 2  a q-size blocking
coalition for c is a blocking coalition in which |c| ≤ q and
 ii  given a real number k ≥ 1  a k-improvement blocking
coalition for c is a set of agents c ⊆ n such that  for ev-
ery agent i ∈ c  it holds that µi c  > kµi c   notice that
a blocking coalition is also a 1-improvement blocking coali-
tion and an n-size blocking coalition  a coalition structure
c is q-size core stable  respectively k-improvement core sta-
ble  if it does not admit a q-size blocking coalition  respec-
tively a k-improvement blocking coalition   we notice that
if a coalition structure is q-size core stable then it is q′-size
core stable for any q′ ≤ q  moreover  if a coalition structure
is k-improvement core stable then it is k′-improvement core
stable for any k′ ≥ k 
dynamics and convergence 
the core  respectively q-size
core and k-improvement core  dynamics d of a s-fhg
is a sequence  possibly infinite  of coalition structures
⟨c0  c1       ⟩ such that for every consecutive pair  ct−1  ct  
with t ≥ 1  there exists a blocking coalition  respectively
q-size blocking coalition and k-improvement blocking coali-
tion  ct for ct−1 =  c1  c2          ch  whose deviation leads
to the coalition structure ct =  ct  c1 \ ct          ch \ ct  \
 ∅   roughly speaking  the coalition structure ct is obtained
by letting all agents in ct form a new coalition together  thus
leaving the coalitions they belonged to in ct−1  we say that a
finite dynamics d = ⟨c0  c1          cℓ⟩ of length ℓ ≥ 1  leads
to coalition structure cℓ starting from the initial coalition
structure c0  a game is core  respectively  q-size core and
k-improvement core  convergent if  for any coalition struc-
ture c  every dynamics starting from c is finite 
social welfare 
the social welfare of a coalition structure
c =  c1          cℓ  is given by the sum of the agent utili-
ties  i e   sw c  = �
i∈n µi c   by extending the previ-
ous definition  given a coalition c  we denote by sw c 
the sum of utilities of the agents belonging to c  notice that
sw c  = �
c∈c sw c  = �
c∈c
�
i∈c µi c  
efficiency 
given a game g  let c∗ g  be the outcome
maximizing the social welfare  and let q-size core g 
and k-impr core g  be the set of coalition structures
that are q-size core stable and k-improvement core sta-
ble  respectively 
the q-size core price of anarchy  re-
spectively k-improvement core price of anarchy  of a sym-
metric fractional hedonic game g is defined as the ra-
tio between the social welfare of the optimal outcome
c∗ g  and the one of the worst q-size core stable  re-
spectively k-improvement core stable  outcome  formally 
q-size cpoa g  = maxc∈q-size core g 
sw c∗ g  
sw c 
 respec-
tively k-impr cpoa g  = maxc∈k-impr core g 
sw c∗ g  
sw c 
  
2 1
preliminary results
we first present an interesting relation between 2-size core
stable and 2-improvement core stable coalition structures 
specifically  we show that  for every s-fhg  any 2-size core
stable coalition structure is 2-improvement core stable 
theorem 1  for every s-fhg  any 2-size core stable coali-
tion structure is 2-improvement core stable 
it is also possible to show that the analysis of theorem 1 is
tight even for ss-fhg 
we also show that  for every ss-fhg  any 3-size core sta-
ble coalition structure is 3
2-improvement core stable 
theorem 2  for every ss-fhg  any 3-size core stable coali-
tion structure is 3
2-improvement core stable 
proof  in this proof we exploit the graph representation intro-
duced in section 2  since we are considering ss-fhg  the re-
lated graph g is unweighted  given an ss-fhg g  let us as-
sume that c is a 3-size core stable coalition structure of g  let
us suppose  by contradiction  that c admits a 3
2-improvement
blocking coalition c  remind that µi c  ≤
n−1
n
for any
i ∈ c  first notice that  for any i ∈ c  it holds that µi c  < 2
3
 because they belong to the 3
2-improvement blocking coali-
tion c and in any coalition structure each agent gets utility of
at most n−1
n    it implies that the subgraph g c  induced by
agents in c does not contain a triangle  in fact  if three agents
of a triangle form a new coalition together  each of them gets
utility of 2
3 and this is a contradiction to the fact that c is a
3-size core stable coalition structure of g 
proceedings of the thirtieth    ijcai-21 
184
 consider any edge  i  j  in g c  
it holds that either
µi c  ≥
1
2 or µj c  ≥
1
2 because otherwise i and j to-
gether form a 2-size blocking coalition for c  and this is a
contradiction to the fact that c is a 3-size core stable coali-
tion structure of g  without loss of generality  let us assume
that µi c  ≥
1
2  then  since i belongs to c  we have that
µi c  >
3
2
1
2 =
3
4  it implies that agent i has more than
three adjacents in g c   we now show an upper bound to
the utility of each agent j adjacent to i in g c   given that
g c  does not contain triangles  any pair of adjacents of i
is not connected by an edge  let x be the number of agents
connected to i in g c   we have that µi c  =
x
|c| >
3
4 
thus  any agent j connected to i in g c  gets utility of at
most |c|−x
|c|
< 1
4  since j is a member of the 3
2-improvement
blocking coalition c  we get that µj c  < 1
6 
by summarizing  there must exist two agents j and z that
together with i form in g a star of three nodes centered in i
such that µj c  < 1
6  µz c  < 1
6 and µi c  < 2
3  therefore 
agents i  j and z together form a 3-size blocking coalition for
c  this is a contradiction to the fact that c is a 3-size core
stable coalition structure of g 
it is possible to show that the analysis of theorem 2 is tight 
as a last remark  it is possible to show that the converses
of theorems 1 and 2 do not hold 
3
existence and computation
in this section  we focus on existence and convergence issues
of relaxed core solutions  we start by showing that any 2-size
dynamics of every s-fhg converges to a stable solution 
theorem 3  every s-fhg is 2-size core convergent 
sketch of proof  we exploit a potential function argument 
consider any 2-size core dynamics d starting from any coali-
tion structure c0  we show that d = ⟨c0  c1      ⟩ has finite
length  i e   that a 2-size core stable coalition structure is even-
tually reached  for any t ≥ 0  let ⃗xt be the vector obtained by
listing the utilities of all agents involved in some of the first t
improvement deviations of d in non-increasing order  notice
that these agents belong to a coalition of cardinality at most 2
in any coalition structure cp with p ≥ t   as usual  given two
n-dimensional vectors ⃗y and ⃗y′  the first one is smaller than
the second one for the lexicographical order  and we write
⃗y ≺ ⃗y′  if either yp is a prefix of y′
p or yp < y′
p for the first
component p such that yp ̸= y′
p  it is possible to show that 
for any t ≥ 1  ⃗xt−1 ≺ ⃗xt 
we are also able to provide a similar result holding for 3-
size dynamics in the context of simple games  i e   games
with valuations in  0  1   
theorem 4  every ss-fhg is 3-size core convergent within
a polynomial number of deviations 
sketch of proof  in this proof  it is convenient to exploit the
graph representation introduced in section 2  since we are
considering ss-fhgs  the related graphs are unweighted 
consider any 3-size core dynamics d starting from any coali-
tion structure c0  we show that d = ⟨c0  c1      ⟩ has finite
length  i e   that a 3-size core stable coalition structure is even-
tually reached  for any t ≥ 1  let ct be the 3-size blocking
coalition for ct−1 whose deviation leads to ct  it is worth
noticing that  for any t ≥ 1  g ct  is  i  either to a trian-
gle  i e   a clique of 3 nodes    ii  a path of 3 nodes  or  iii  a
clique of 2 nodes 
given any coalition structure c  let α c   respectively β c 
and γ c   be the number of coalitions in c being triangles
 respectively path of 3 nodes and cliques of 2 nodes  
for any t
≥
0 
let ⃗xt be the triple defined as
 α ct   β ct    γ ct   β ct   
it is possible to show  by
performing a case-by-case analysis  that  for any t ≥ 0 
⃗xt−1 ≺ ⃗xt  i e   the considered triple always lexicographi-
cally increases after each deviation  since the cardinality of
the set of possible triples polynomial in the number of agents 
the claim directly follows 
our last result concerns the convergence of k-improvement
dynamics  for any k ≥ 2  it is obtained by proving that  in
this case  the social welfare is indeed a potential function for
the game  i e   every deviation of a blocking coalition implies
an increase of the social welfare 
theorem 5  every s-fhg is k-improvement core conver-
gent  for every k ≥ 2 
notice that  by theorem 5  we directly get that every
s-fhg admits a k-improvement core stable coalition struc-
ture  for every k ≥ 2  that can be obtained by running a k-
improvement core dynamics starting from any coalition struc-
ture  analogously  by combining theorem 1 and theorem 3 
we can obtain  for any given s-fhg  a k-improvement core
stable coalition structure  for every k ≥ 2  by running a 2-size
core dynamics starting from any coalition structure  how-
ever  in both cases  we are not guaranteed that the dynamics is
convergent within a polynomial number of deviations  in the
following  we show a polynomial time algorithm that  given
any instance of s-fhg  computes a coalition structure which
is k-improvement core stable  for every k ≥ 2 1 − 1/n  
theorem 6  every s-fhg admits a k-improvement core sta-
ble coalition structure that can be computed in polynomial
time  for every k ≥ 2 1 − 1/n  
proof  we show a simple algorithm that computes in poly-
nomial time a 2 1 − 1/n -improvement core stable coalition
structure  we notice that the same algorithm has been used
to show the existence of core stable outcomes in modified
fractional hedonic games  monaco et al   2020   the algo-
rithm works in phases t = 1  2          let g0 = g  for any
t ≥ 1  let gt =  n t   vi t
i∈n t  be the resulting sub-game
obtained after phase t  in any phase t ≥ 1  a new coali-
tion isomorphic to a clique of size 2 is added to c as fol-
lows  let vt−1
max = vi j  = vj i   for some i  j ∈ n t−1 
be the maximum valuation of two agents in gt−1  that is 
vt−1
max = maxi∈n t−1 vmax
i
 gt−1   we add to c the coalition
formed by agents i and j  i e   c = c ∪  i  j   moreover 
let gt such that n t = n t−1 \  i  j   the algorithm stops
when |n t| ≤ 1  in particular  if |n| mod 2 = 0  resp  |n|
mod 2 = 1   the algorithm ends by returning c  resp  c ∪ i 
where n t =  i    since at each phase  excluding the last 
proceedings of the thirtieth    ijcai-21 
185
 two agents are removed from the sub-game  the algorithm
terminates in at most ⌈|n|/2⌉ phases returning a coalition
structure with all coalitions of cardinality at most 2 
we now show that the returned outcome c is a 2 1 − 1/n -
improvement core stable coalition structure of g  in c  agents
i and j selected at phase t = 1 get each utility of v0
max
2
  re-
mind that µi c  ≤
n−1
n v0
max and µj c  ≤
n−1
n v0
max  for
any possible coalition structure c  it implies that agents i
and j cannot belong to a k-improvement blocking coalition
for c  for any k ≥ 2 1 − 1/n   the proof continues by in-
duction as follows  suppose that all the agents selected un-
til phase z  i e   agents belonging to n \ n z  cannot belong
to any k-improvement blocking coalition for c  for any k ≥
2 1 − 1/n   then agents iz 1 and jz 1 selected in the phase
z   1 of the algorithm cannot belong to any k-improvement
blocking coalition for c  for any k ≥ 2 1 − 1/n   as well 
in fact  suppose that such agents have a certain utility in the
coalition c  for the inductive hypothesis we have that they
can create a k-improvement blocking coalition for c  for any
k ≥ 2 1−1/n   only with agents belonging to n z  however 
since they have utility vz
max
2
and cannot get utility higher than
n−1
n vz
max  this is not possible  finally  it is easy to see that  if
there is an agent selected as the last one by the algorithm that
is alone in her coalition  she cannot form a blocking coalition 
and this finishes the proof 
finally  we provide the following theorem holding for the
special case of simple games  by combining theorem 2 with
theorem 4  it directly follows that a k-improvement core sta-
ble outcome can be computed in polynomial time for every
k ≥ 3/2 
theorem 7  every ss-fhg admits a k-improvement core
stable coalition structure that can be computed in polynomial
time  for every k ≥ 3/2 
4
efficiency
in this section we study the price of anarchy for the consid-
ered relaxed core stable outcomes  we start by showing that 
for every s-fhg and k ≥ 1  the social welfare of an optimal
outcome can be at most 2k times the social welfare of any
k-improvement core stable outcome 
theorem
8 
for
every
s-fhg
g
and
k
≥
1 
k-impr cpoa g  ≤ 2k 
proof  first of all  we need some additional notation and def-
initions  let δ>
c i  = �
j∈c j>i vi j  be the sum of valua-
tions of agent i for every agent j > i belonging to coalition
c  analogously  let µ>
i  c  = δ>
c  i 
|c|
be the part of utility of
agent i due to her valuations for every agent j > i belonging
to coalition c  it is worth noticing that  given the symmetry
of the valuations  for any coalition c  it holds that
sw c  = 2
�
i∈c
µ>
i  c  
 1 
let c∗ g  be an optimal coalition structure and c be any
k-improvement core stable coalition structure of game g  we
aim at showing that sw c∗ g  
sw c 
≤ 2k 
for any c∗ ∈ c∗ g   consider the following process com-
posed by |c∗| phases 
• phase 1  let c∗
1 = c∗  since c is k-improvement core
stable  coalition c∗
1 cannot be a k-improvement blocking
coalition for c  thus implying that there exists an agent  say
agent i1  such that µi1 c∗
1  ≤ kµi1 c  
• phase t  t = 2          |c∗|   let c∗
t = c∗
t−1 \  it−1   since
c is k-improvement core stable  coalition c∗
t cannot be a
k-improvement blocking coalition for c  thus implying that
there exists an agent  say agent it  such that µit c∗
t   ≤
kµit c  
assume  without loss of generality  that the agents are
numbered such that i1 < i2 <       < i|c∗|  notice that the
property of this assumption can be simultaneously obtained
for all coalitions of c∗  for instance assigning to all agents
in a same coalition consecutive numbers that respect the de-
sired ordering  by this assumption  for any t = 1          |c∗| 
it holds that
µit c∗
t   = δ>
c∗ it 
|c∗
t |
≥ δ>
c∗ it 
|c∗|
= µ>
it c∗  
 2 
by summing over all agents in coalition c∗  we obtain
sw c∗ 
=
2
�
i∈c∗
µ>
i  c∗  ≤ 2
|c∗|
�
t=1
µit c∗
t  
≤
2k
�
i∈c∗
µi c  
where the first equality holds by  1   the first inequality holds
by  2  and the last inequality holds because  for every t =
1          |c∗|  it is selected at phase t of the above described
process as an agent in c∗
t such that µit c∗
t   ≤ kµit c   by
applying the last inequality to every coalition in c∗ g   we
finally obtain
sw c∗ g   =
�
c∗∈c∗ g 
sw c∗  ≤ 2k
�
c∗∈c∗ g 
�
i∈c∗
µi c 
= 2k
�
i∈n
µi c  = 2k · sw c  
we now show that the analysis of theorem 8 is essentially
tight even for ss-fhgs 
theorem 9  there exists an infinite collection of ss-fhgs
such that  for every game g belonging to it  it holds that
1-impr cpoa g  ≥ 2 
moreover  for every k > 1 and
ϵ ∈  0  1/2   there exists an infinite collection of ss-fhgs
such that  for every game g belonging to it  it holds that
k-impr cpoa g  ≥ 2k 1 − ϵ  
sketch of proof  we first focus on the case k > 1  for every
triple  p  q  d  of positive integers  such that p > q and pq
is even  we construct an unweighted graph g representing a
game g as follows  the set of nodes of g is partitioned into
subset m =  1  2          m  of size m ≥ 2  and m subsets
l1  l2          lm  each of size d  with m = p d   1   we
proceedings of the thirtieth    ijcai-21 
186
 assume that �m
j=1 lj is an independent set in g  while the
subgraph induced by m is a t-regular graph  with t = q d  
1   notice that  by definition of t and m  this subgraph is well
defined  in fact  as it is well known  there always exists a t-
regular graph on m nodes when m ≥ t   1 and mt is even  
finally  each i ∈ m is connected to each node in li 
let us consider the coalition structure c made of coali-
tion m and md singleton coalitions  one for each node in
�m
j=1 lj  it can be proved that c is p/q-improvement core
stable  in order to evaluate the efficiency of c  we compare its
social welfare with the social welfare of the coalition struc-
ture ¯c  made of m coalitions  in which each agent i ∈ m
makes a coalition with the corresponding set li  the social
welfare of ¯c is m 2d
d 1 = 2pd  on the other hand  the so-
cial welfare of c is �
i∈m µi c  = t = q d   1   it fol-
lows that the p
q -improvement price of anarchy of g is at least
sw
� ¯c
�
/sw c  =
2pd
q d 1  = 2 p
q
�
1 −
1
d 1
�
  the claim
follows by observing that for every pair of rational numbers
k > 1 and ϵ ∈  0  1/2   there are infinite ways of choosing
the triple  p  q  d  such that k = p/q and ϵ =
1
d 1 
for the case k = 1  we can prove the claim by simplifying
the construction presented above  in particular by imposing
that the subgraph induced by m is a clique 
we now focus on the q-size core price of anarchy  for
q ∈  2  3   for s-fhgs  by theorem 1 we get that the social
welfare of the worst 2-size core stable outcome is at least the
social welfare of the worst 2-improvement core stable out-
come  analogously  for ss-fhgs  by theorem 2 we get that
the social welfare of the worst 3-size core stable outcome is at
least the social welfare of the worst 3
2-improvement core sta-
ble outcome  therefore  by theorem 8  the following upper
bounds can be directly obtained 
theorem
10 
for
any
s-fhg
g
it
holds
that
2-size cpoa g 
≤
4  moreover  for any ss-fhg g 
it holds that 3-size cpoa g  ≤ 3 
by exploiting the same ideas of the construction of theo-
rem 9  it is possible to show that  for any ϵ > 0 and any integer
q ≥ 2  there exists a game g such that q-size cpoa g  ≥
2
q
q−1 − ϵ  thus proving the tightness of the bounds provided
by the last theorem 
5
concluding remarks and open problems
in this paper we have investigated some relaxed variations
of core stability in the context of fractional hedonic games 
several worth investigating research directions arise from this
work  first of all  in a general context  we believe that the
investigated relaxed notions of core stability can be of inter-
est for other class of games and could be also investigated
in combination  i e   by considering blocking coalitions of
bounded cardinality in which every agent has to increase her
utility by a given factor  moreover  it would be interesting to
study other possible relaxations of stability notions  also with
respect to classical notions other than the core stability  that
can lead to model practical scenarios of multi-agent systems
in a more accurate way 
we now focus on the open problems for the considered
class of fractional hedonic games  it is worth noticing that 
in  aziz et al   2019   an instance admitting no core stable
outcome is provided  as a direct consequence  it follows that
there must exist ¯q and ¯k such that no q-size core stable out-
come exists for any q ≥ ¯q and no k-improvement core sta-
ble outcome exists for any k ≤ ¯k  in particular  it holds that
¯q = 11 and ¯k = 100/99   to this respect  an open problem
raised by our work is that of determining the maximum val-
ues of q and the minimum value of k for which q-size and k-
improvement core stable outcomes  respectively   i  are guar-
anteed to exist   ii  can be efficiently computed and  iii  are
guaranteed to be reached by any dynamics of the agents 
another interesting research direction is that of investigat-
ing the relations between q-size and k-improvement core sta-
ble outcomes  to this respect  some preliminary results are
provided by theorems 1 and 2  more generally  we con-
jecture that any q-size core stable coalition structure is
q
q−1-
improvement core stable 
with respect to the efficiency  it is worth studying the q-size
core price of anarchy of ss-fhgs and s-fhgs  in order to
provide suitable upper bounds for the cases q ≥ 4 and q ≥ 3 
respectively  to this respect  given the lower bound described
after theorem 10  we conjecture that the q-size core price of
anarchy of ss-fhgs and s-fhgs is
2q
q−1 for any integer q 
finally  we would like to focus on the q-size and k-
improvement core price of stability  that can be naturally de-
fined  similarly to the q-size and k-improvement core price
of anarchy  as the ratio between the social optimum and the
social welfare of the best stable outcome  roughly speaking 
a low core price of stability means that there exists a core sta-
ble solution that is close  in terms of efficiency  to the social
optimum  interestingly  to this respect  some preliminary re-
sults arise as a direct consequence of the theorems provided
in this paper  in particular  for s-fhgs  the k-improvement
core price of stability is 1 for k ≥ 2  because  by the proof of
theorem 5  the social welfare is in this case a potential func-
tion for the game  thus implying that the optimal solution is
k-improvement core stable  moreover  always for s-fhgs 
if k < 2 we know  by theorem 8  that the core price of stabil-
ity is at most 2k  because the core price of stability of a game
is always less then its core price of anarchy  for ss-fhgs 
by exploiting the fact that  by theorem 7  a 3
2-improvement
core stable solution  approximating  by theorem 8  the opti-
mal solution by a factor of 3  is guaranteed to exist and by
observing that a 3
2-improvement core stable solution is also
k-improvement core stable for any k > 3/2  we obtain an
improved upper bound equal to 3 for the k-improvement core
price of stability  with k ∈  3/2  2   a lower bound of 2 to
the core price of stability is provided in  carosi et al   2019 
theorem 5 1  when considering a notion of core stability in
which there is a structural property the blocking coalition has
to satisfy  thus implying that the  1-improvement  core price
of stability is at least 2  a matching lower bound for the case
k = 1  therefore  it would be very interesting to solve the
open problem of deriving tight bounds to the k-improvement
core price of stability for k ∈  1  2   besides the one of deter-
mining the q-size core price of stability 
proceedings of the thirtieth    ijcai-21 
187
 references
 aziz and savani  2016  haris aziz and rahul savani  he-
donic games 
in handbook of computational social
choice  pages 356–376  cambridge university press 
2016 
 aziz et al   2014  haris aziz  felix brandt  and paul har-
renstein  fractional hedonic games  in proceedings of the
13th international conference on autonomous agents and
multiagent systems  aamas  pages 5–12  2014 
 aziz et al   2015  haris aziz  serge gaspers  joachim gud-
mundsson  julián mestre  and hanjo täubig 
welfare
maximization in fractional hedonic games  in proceed-
ings of the twenty-fourth international joint conference
on artificial intelligence  ijcai  pages 461–467  2015 
 aziz et al   2019  haris aziz  florian brandl  felix brandt 
paul harrenstein  martin olsen  and dominik peters  frac-
tional hedonic games  acm trans  economics and com-
put   7 2  6 1–6 29  2019 
 banerjee et al   2001  suryapratim banerjee  hideo kon-
ishi  and tayfun sönmez  core in a simple coalition for-
mation game  social choice and welfare  18 1  135–153 
2001 
 bilò et al   2018  vittorio bilò  angelo fanelli  michele
flammini  gianpiero monaco  and luca moscardelli 
nash stable outcomes in fractional hedonic games  ex-
istence  efficiency and computation  journal of artificial
intelligence research  62 315–371  2018 
 bogomolnaia and jackson  2002  anna bogomolnaia and
matthew o  jackson  the stability of hedonic coalition
structures 
games and economic behavior  38 2  201–
230  2002 
 brandl et al   2015  florian brandl  felix brandt  and mar-
tin strobel 
fractional hedonic games  individual and
group stability  in proceedings of the 2015 international
conference on autonomous agents and multiagent sys-
tems  aamas  pages 1219–1227  2015 
 carosi et al   2019  raffaello carosi  gianpiero monaco 
and luca moscardelli  local core stability in simple sym-
metric fractional hedonic games  in proceedings of the
18th international conference on autonomous agents and
multiagent systems  aamas  pages 574–582  2019 
 cechlárová and romero-medina  2001  katarína
cech-
lárová and antonio romero-medina  stability in coalition
formation games 
int  j  game theory  29 4  487–494 
2001 
 drèze and greenberg  1980  jacques
drèze
and
joseph
greenberg  hedonic coalitions  optimality and stability 
econometrica  48 4  987–1003  1980 
 elkind et al   2020  edith elkind 
angelo fanelli 
and
michele flammini  price of pareto optimality in hedonic
games  artif  intell   288 103357  2020 
 flammini et al   2018  michele
flammini 
gianpiero
monaco  luca moscardelli  mordechai shalom  and
shmuel zaks 
online coalition structure generation in
graph games 
in proceedings of the 17th international
conference on autonomous agents and multiagent
systems  aamas  pages 1353–1361  2018 
 flammini et al   2021  michele flammini  bojana kodric 
gianpiero monaco  and qiang zhang 
strategyproof
mechanisms for additively separable and fractional hedo-
nic games 
journal of artificial intelligence research 
70 1253–1279  2021 
 kaklamanis et al   2020  christos kaklamanis  panagiotis
kanellopoulos  konstantinos papaioannou  and dimitris
patouchas  on the price of stability of some simple graph-
based hedonic games 
theoretical computer science 
2020 
 maschler et al   1969  michael maschler  bezalel peleg 
and lloyd stowell shapley  geometric properties of the
kernel  nucleolus  and related solution concepts  mathe-
matics of operations research  4 4  303–477  1969 
 monaco et al   2019  gianpiero monaco  luca moscardelli 
and yllka velaj  on the performance of stable outcomes in
modified fractional hedonic games with egalitarian social
welfare 
in proceedings of the 18th international con-
ference on autonomous agents and multiagent systems 
aamas  pages 873–881  2019 
 monaco et al   2020  gianpiero monaco  luca moscardelli 
and yllka velaj  stable outcomes in modified fractional
hedonic games  auton  agents multi agent syst   34 1  4 
2020 
 olsen  2012  martin olsen 
on defining and computing
communities  in proceedings of the 18th conference on
computing  the australasian theory symposium  cats 
pages 97–102  2012 
 shapley and shubik  1966  lloyd
stowell
shapley
and
martin shubik  quasi-cores in a monetary economy with
nonconvex preferences 
econometrica  34 4  805–827 
1966 
proceedings of the thirtieth    ijcai-21 
188
 "
None,2021,https-www-ijcai-org-proceedings-2021-0027-pdf,Reasoning over Argument-Incomplete AAFs in the Presence of Correlations,"Bettina Fazzinga, Sergio Flesca, Filippo Furfaro",None,https://www.ijcai.org/proceedings/2021/0027.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0027-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0027-pdf.pdf,"reasoning over argument-incomplete aafs in the presence of correlations
bettina fazzinga1∗   sergio flesca2   filippo furfaro2
1 icar-cnr  italy
2 dimes - universit a della calabria  italy
fazzinga@icar cnr it   flesca  furfaro @dimes unical it
abstract
we introduce argument-incomplete abstract argu-
mentation frameworks with dependencies  that ex-
tend the traditional abstract argumentation reason-
ing to the case where some arguments are uncertain
and correlated through logical dependencies  such
as mutual exclusion  implication  etc    we char-
acterize the complexities of the problems dsat of
deciding the satisfiability of the dependencies and
pdverσ s  of verifying extensions under the pos-
sible perspective  we show how they depend on the
forms of dependencies and  for pdverσ s   also
on the semantics of the extensions 
1
introduction
incomplete abstract argumentation frameworks  iaaf  are
an extension of dung s abstract argumentation frameworks
 aafs  enabling a  qualitative  representation of the uncer-
tainty involving arguments and attacks  basically  an iaaf
is an aaf where the set of arguments  resp   attacks  is
partitioned into the sets of certain and uncertain arguments
 resp   attacks   certain arguments/attacks are those whose
presence in the argumentation is sure  while uncertain ar-
guments/attacks may not occur in the argumentation 
as
observed in  baumeister et al   2018  coste-marquis et al  
2007  cayrol et al   2007   iaafs are well-suited for model-
ing a number of situations  for instance  when representing a
dispute that may be participated by several agents  it is natural
to model the arguments claimed by agents whose participa-
tion is not guaranteed as uncertain  analogously  arguments
encoding alternative interpretations of the same claim should
be considered as uncertain  when it is not known which of
them catches the intended meaning of the claim 
an iaaf compactly encodes the set of the alternative com-
binations of arguments and attacks that can actually occur in
the argumentation  each combination is called  completion 
and is an aaf containing all the certain arguments/attacks
of the iaaf plus a subset of its uncertain arguments/attacks 
in order to take into account the possibility of different sce-
narios for the argumentation  as represented by the comple-
tions   the traditional notion of extension for an aaf has
∗contact author
been re-formulated in terms of i∗-extension  fazzinga et al  
2020   a set of arguments s is a possible  resp   necessary 
i∗-extension of the iaaf if if  for some  resp   every  com-
pletion f of if  the set s is an extension of f 
example 1 consider the iaaf if over the arguments
a  b  c  d and the attacks  a  b    c  d    d  c  depicted in fig  1
 disregard the dotted edges for now   arguments a  b  c are
the only uncertain terms of the argumentation  so if has 8
completions  denoted as pairs ⟨ arguments  attacks ⟩  
f1 = ⟨ d   ∅⟩  f2 = ⟨ a  d   ∅⟩  f3 = ⟨ a  b  d     a  b  ⟩ 
f4 = ⟨ a  c  d     c  d    d  c  ⟩ 
f5 = ⟨ a  b  c  d     a  b    c  d    d  c  ⟩  f6 = ⟨ b  d   ∅⟩ 
f7 = ⟨ b  c  d     c  d    d  c  ⟩ 
f8 = ⟨ c  d     c  d    d  c  ⟩ 
the set  a  c  is a possible i∗-extension  under the admissi-
ble semantics   since it is an admissible extension in at least
one completion of if  such as f4 and f5   it is easy to see
that  among others  also  b  d  and  b  c  are possible admis-
sible i∗-extensions  under the necessary perspective  the only
admissible i∗-extensions are ∅ and  d  
a limit of the reasoning paradigm over iaafs is that it
does not take into account possible correlations between ar-
guments/attacks  in fact  there can be dependencies between
the arguments/attacks implying that some completions repre-
sent scenarios that cannot actually occur  and this may deeply
affect the reasoning process  as shown in example 2 
example 2 assume that the iaaf if of example 1 models
the arguments that can be introduced during a trial  and that
the uncertain arguments a  b  c are not independent  in par-
ticular  b and c are alternative interpretations of the same fact
given by the two experts xb and xc  and the defendant has to
choose who between xb and xc will testify  thus  exactly one
argument in  b  c  will occur in the argumentation  more-
over  the analyst knows that if b occurs in the argumentation 
also a will occur  since a is claimed by an expert xa that the
prosecutor always uses to disqualify what said by xb  the
analyst thinks that the prosecutor may put xa on the stand
even if xb is not called by the defendant  thus the implica-
tion between b and a in one way only  these dependencies
can be formally written as choice b  c  and b ⇒ a  and are
depicted in fig  1 as suitably labeled dotted edges 
it is easy to see that some of the completions enumerated
in example 1 encode scenarios that cannot occur  specifi-
proceedings of the thirtieth    ijcai-21 
189
 a
b
c
d
imply
xor
figure 1  grey nodes are uncertain arguments  imply- and choice-
labeled edges represent dependencies  the other edges are attacks
cally  f1  f5  f7 are not possible  since they violate the fact
that exactly one expert will be called by the defendant  i e 
choice b  c    and f6 is not possible as well  since it vio-
lates the constraint that if b occurs  also a occurs  i e  b ⇒ a  
hence  the only  valid  completions are f3  f4 and f8 
this entails that some of the conclusions drawn in ex-
ample 1 must be revised  when verifying if a set is an i∗-
extension  one should focus only on the valid completions 
hence  under the possible perspective   b  d  is not an admis-
sible i∗-extension  since in all the valid completions where b
and d occur together  the attack from a to b is not counterat-
tacked  analogously   b  c  is not an admissible i∗-extension 
since there is no valid completion containing b and c 
example 2 shows that disregarding the correlations be-
tween the terms of the argumentation can yield wrong assess-
ments  for instance  under the possible perspective  it may
happen that the completions witnessing that a set s is an i∗-
extension are not scenarios that can occur in practice  hence 
disregarding the correlations may lead the analyst to wrongly
consider s as a reasonably  robust  set of arguments  as hap-
pens in examples 1 and 2 for  b  d  and  b  c   
the main contribution of this paper is a study of funda-
mental problems supporting the reasoning over iaafs in the
presence of correlations  in particular  we focus on the case
of argument-incomplete aafs  aiaafs   baumeister et al  
2015   i e  iaafs where the uncertainty involves only the
arguments  as in examples 1  2  starting from them  we in-
troduce  aiaafs with dependencies   daiaafs   where the
analyst is allowed to specify correlations involving the uncer-
tain arguments  we consider a practical setting  where cor-
relations can be expressed in a user-friendly manner  the an-
alyst can specify a set of logical dependencies  where each
dependency is the application of one n-ary logical connective
 namely  or  choice  nand  or ⇒  over a set of arguments 
this way of specifying the correlations is prone to be imple-
mented in an intuitive visual interface  binary dependencies
 like the choice and ⇒ of example 2  can be naturally de-
picted as  possibly oriented  labeled edges between the in-
volved arguments  while more general n-ary correlations can
be depicted by circling the involved sets of arguments  see
fig  2  
given this  we characterize the complexity of two prob-
lems 
– dsat  is there a  valid  completion  i e  where no depen-
dency is violated  of a given daiaaf  this means deciding
if the specified correlations  make sense  
– pdverσ s   the verification problem for possible i∗-
extensions for a daiaaf under a semantics σ 
in particular  we study the sensitivity of the complexity of
the two problems to the form of dependency used to specify
the correlations  and  for the case of pdverσ s   also to the
semantics of extensions  we consider admissible  complete 
grounded  stable and preferred semantics   table 1 summa-
rizes our results  interestingly  after observing that dsat is
itself a source of complexity of pdverσ s   we show that
when dsat is trivial or polynomial-time solvable  the com-
plexity of pdverσ s  depends on the combination ⟨ depen-
dency  semantics ⟩  for some combinations  the complexity is
p  the same as the verification problem over iaafs in the ab-
sence of correlations  while for others the complexity moves
to np-complete 
2
preliminaries
an abstract argumentation framework  aaf  is a pair
⟨a  d⟩  where a is a finite set  whose elements are called ar-
guments  and d ⊆ a × a is a binary relation over a  whose
elements are called defeats or attacks  given a set of argu-
ments s and an argument a  we say that  s attacks a  if there
is an argument b in s such that b attacks a  and that  a attacks
s  if there is an argument b ∈ s such that a attacks b  more-
over  we say that a is acceptable w r t  s if every argument
attacking a is attacked by s  and say that s is conflict-free if
there is no attack between its arguments 
several semantics for aafs have been proposed to iden-
tify  reasonable  sets of arguments  called extensions  dung 
1995   a set s ⊆ a is  an admissible extension  ad  iff s
is conflict-free and all its arguments are acceptable w r t  s  a
stable extension  st  iff s is conflict-free and s attacks each
argument in a\s  a complete extension  co  iff s is admissi-
ble and s contains all the arguments that are acceptable w r t 
s  a grounded extension  gr  iff s is a minimal  w r t  ⊆ 
complete set of arguments  a preferred extension  pr  iff s is
a maximal  w r t  ⊆  complete set of arguments 
we recall the notion of argument-incomplete abstract ar-
gumentation framework  aiaaf   baumeister et al   2015  
definition 1  aiaaf  an argument-incomplete abstract ar-
gumentation framework is a tuple ⟨a  a   d⟩  where a and
a  are disjoint sets of arguments and d is a set of attacks be-
tween arguments in a ∪ a   the arguments in a  resp   a  
are said to be certain  resp   uncertain   i e  they are guaran-
teed  resp   not guaranteed  to occur in the argumentation 
an aiaaf compactly represents the alternative scenarios
for the argumentation  i e  all the possible combinations of
arguments and attacks that can occur according to what is
certain and uncertain  each scenario is called completion 
definition 2  completion  given
an
aiaaf
if
=
⟨a  a   d⟩  a completion for if is an aaf f = ⟨a′  d′⟩
where a ⊆ a′ ⊆  a ∪ a   and d′ = d ∩  a′ × a′  
in  fazzinga et al   2020   i∗-extensions were introduced to
adapt the notion of extension to the case of iaafs  and  con-
sequently  to aiaafs   specifically  since an iaaf encodes
several alternative scenarios  i∗-extensions were defined un-
der both the possible and the necessary perspective  where the
condition of being extension is required to be true in at least
one and every scenario  respectively  example 1 contains ex-
amples of possible and necessary i∗-extensions over aiaafs 
definition 3  i∗-extension  given an aiaaf if and a se-
mantics σ  a set s is a possible  resp   necessary  i∗-extension
proceedings of the thirtieth    ijcai-21 
190
 for if  under σ  if  for at least one  resp   for every  comple-
tion f of if  the set s is an extension of f under σ 
3
specifying correlations over aiaafs
the reasoning paradigm based on i∗-extensions considers the
uncertain arguments as  independent   the presence/absence
of an argument is not supposed to influence the presence of
other arguments  in fact  when addressing the verification
problem  every completion is a potential witness  resp  
counter-witness  of the fact that s is an i∗-extension under
the possible  resp   necessary  perspective 
however  the
independence assumption may not be reasonable  since some
correlation is known to exist between uncertain arguments 
and this has important consequences  as discussed below 
impact of the correlations on the reasoning 
as shown
in example 2  introducing dependencies may have the effect
of discarding some completions  as they turn out to describe
scenarios that cannot occur  this has a strong impact on the
reasoning  in fact  under the possible perspective  a set that
is an i∗-extension when dependencies are not considered
may be no longer an i∗-extension when dependencies are
taken into account  example 2 shows that this happens
with  b  c  and  b  d   since the completions witnessing
that they are extensions are impossible scenarios  according
to the choice- and imply- dependencies  
under the
necessary perspective  a set that  with no dependency  is
not an i∗-extension may become an i∗-extension when the
dependencies are considered 
for instance  consider an
aiaaf consisting in a conflict-free set s of certain arguments
and two uncertain arguments a and b attacking each other  if
no dependency is considered  s is not a necessary complete
i∗-extension  as there are two completions f1 and f2 where
s is not complete  i e  the completions where either b or
a is missing   consider now the two imply-dependencies
a ⇒ b and b ⇒ a  it is easy to see that  considering these
dependencies  f1 and f2 cannot be considered as possible
scenarios  and s becomes a necessary complete i∗-extension 
embedding correlations into aiaafs 
we now introduce
the forms of dependency that we allow to use for encoding the
known correlations  in order to make the task of specifying
them easy and intuitive  we consider dependencies expressed
by commonly used logical connectives 
definition 4  dependency  a dependency δ over an aiaaf
if = ⟨a  a   d⟩ is an expression x
⇒ y  imply∨-
dependency  or op x   op-dependency   where op ∈  or 
nand  choice  and x  y are non-empty subsets of a  
imposing dependencies allows the user to distinguish
 valid  completions from  invalid  completions  i e  scenar-
ios that can actually occur from impossible scenarios  
definition 5  valid completion  a
completion
f
=
⟨a′  d′⟩ is valid w r t a dependency δ  written f |= δ  iff
– δ is or x  and x ∩ a′ ̸= ∅ 
– δ is nand x  and x ∩ a′ ⊂ x 
– δ is choice x  and |x ∩ a′| = 1 
– δ is x ⇒ y and  if x ⊆ a′  then y ∩ a′ ̸= ∅ 
f is valid w r t  a set of dependencies ∆ if ∀δ ∈ ∆ f |= δ 
thus  an or-  resp   choice-  dependency imposes that at
least  resp   exactly  one of the specified arguments is in the
completion  a nand-dependency imposes that the specified
arguments cannot occur all together  imply∨ means that
if a completion contains all the arguments on the left-hand
side  then it must contain at least one of the arguments of
the right-hand side  we did not consider and and nor as
here they make no sense  an and-  resp   nor-  dependency
requires that each  resp   none  of the specified arguments
is in the completion  but this can be done by putting these
arguments in a  resp   removing these arguments from a   
definition 6  daiaaf  an
argument-incomplete
abstract
argumentation framework with dependencies  daiaaf  is a
pair dif = ⟨if  ∆⟩  where if is an aiaaf and ∆ a set of
dependencies over if 
the completions of a daiaaf dif = ⟨if  ∆⟩ are the com-
pletions of if  and the valid completions of dif are the
completions valid w r t  ∆  the notion of i∗-extension is nat-
urally adapted to daiaafs to take into account in the reason-
ing only the valid completions 
definition 7  i∗-extensions over daiaafs  given a daiaaf
dif and a semantics σ  a set of arguments s is a possible
 resp   necessary  i∗-extension for dif  under σ  if  for at
least one  resp   for every  valid completion f of dif  the
set s is an extension of f under σ 
motivation of the forms of the dependencies and their
expressiveness 
in the context of abstract argumentation 
since the structure of arguments is not modeled  it is reason-
able to model correlations as propositional formulae over sets
of variables representing the presence of arguments  now 
any propositional formula φ of this kind can be expressed as
a set of dependencies of our form  in fact  every clause c of a
cnf φ can be translated into a single dependency  reasoning
by cases on the form of c 
– c = x1 ∨ · · · ∨ xn  i e  c contains only positive literals  
c is equivalent to or x1  · · ·   xn  
– c = ¬x1 ∨ · · · ∨ ¬xn  i e  c contains only negative liter-
als   c is equivalent to nand x1          xn  
– c = ¬x1 ∨ · · · ∨ ¬xm ∨ xm 1 ∨ · · · ∨ xn  i e  c con-
tains both positive and negative literals   c is equivalent
to x1          xm ⇒ xm 1          xn
thus  a first motivation for considering these forms of depen-
dency is that they are  maximally  expressive  w r t  what is
reasonably supposed to be expressible  
observe that what said above means that
choice-
dependencies are not strictly necessary  as they could be
translated into sets of dependencies of the other forms  how-
ever  our choice to include choice as a form of dependency
is aligned with the rationale of expressing the correlations as
a set of dependencies rather than as a propositional formula
with ∧  ∨  ¬ and brackets  providing the analyst with a set
of  intuitive  primitives  whose name explicitly describes the
semantics of the correlations  furthermore  in practical cases 
encoding the correlations into the set ∆ gives the possibil-
ity to distinguish the various forms of correlations imposed
proceedings of the thirtieth    ijcai-21 
191
 by the analyst  which could be otherwise  hidden  if a gen-
eral propositional formula were used  this allows us to pro-
vide the contribution presented in the next section  a fine-
grained analysis of the impact of correlations on the compu-
tational complexity of the fundamental reasoning problems
over aiaafs  this contribution is still of interest if a propo-
sitional formula is used to encode correlations instead of the
set of dependencies  our study can be viewed as a sensitivity
analysis of the complexity of the reasoning tasks w rt  some
syntactic restrictions of practical interest 
4
reasoning over daiaafs
we first introduce two fundamental problems that support the
reasoning over daiaafs and that are the object of our study 
definition 8  dsat  dsat is the problem of verifying the
existence of a valid completion of a given daiaaf dif 
definition 9  pdverσ s   let dif be a daiaaf  s a set
of arguments  and σ a semantics  pdverσ s  is the problem
of verifying if s is a possible i∗-extension for dif under σ 
basically  dsat is the problem of deciding if the set of
dependencies specified in a daiaaf is not contradictory  and
is somehow preliminary to the reasoning task encoded by the
verification problem pdverσ s   as for the latter  observe
that we focus on the possible perspective  and defer the study
of the verification of necessary i∗-extensions to future work 
we thoroughly analyze the complexity of dsat and
pdverσ s   we investigate its sensitivity to the form of de-
pendencies appearing in the daiaaf and  for pdverσ s  
also to the semantics σ  in order to obtain fine-grained in-
sights on the sources of complexity  we include in our anal-
ysis two restrictions of the dependencies of definition 4 
namely choice2-dependency  i e  an choice over a pair of
arguments  and imply-dependency  i e  a ⇒ with a singleton
on the right-hand side  thus no disjunction in the head  
the results are summarized in table 1 
here  empty
means ∆ = ∅  and the corresponding row is a result from
 fazzinga et al   2020   where the verification problem over
iaafs  with no dependencies  was shown to be in p for
σ
∈
 ad  st  co  gr  and σp
2-complete for σ
=
pr 
any other stands for  any combination of 2  3  or more
forms of dependencies different from the combinations in the
other rows   the combinations summarized in any other
are those whose complexity is implied by the other rows  this
does not happen  for instance  for or nand  that is in a dis-
tinguished row  in this case  the np-completeness of dsat
and of pdverσ s  under σ ∈  ad  st  is not implied by the
polynomiality of these problems with only or or only nand 
the relevance of our sensitivity analysis is that  besides
giving an insight on the sources of complexity of dsat and
pdverσ s   it highlights the presence of restrictions  to the
set of logical connectives  that are of practical interest  as
they still allow the analyst to model several scenarios  and
that make reasoning over daiaafs an efficient task 
complexity of dsat 
the correctness of the results in ta-
ble 1 on dsat is stated in the following theorem  observe
that  in table 1   trivial  means that dsat is always true 
dsat
pdverσ s 
ad st
co
gr
pr
1 empty
trivial
p
p
p
σp
2
2 or
trivial
p
p
np
σp
2
3 nand
trivial
p
np
np
σp
2
4 imply∨
trivial
np
np
np
σp
2
5 imply
trivial
p
np
np
σp
2
6 choice
np
np
np
np
σp
2
7 choice2
p
p
np
np
σp
2
8 or nand
np
np
np
np
σp
2
9 or choice2
np
np
np
np
σp
2
10 nand choice2
np
np
np
np
σp
2
11 imply choice2
np
np
np
np
σp
2
12 imply∨ or
trivial
np
np
np
σp
2
13 imply or
trivial
np
np
np
σp
2
14 imply∨ nand
trivial
np
np
np
σp
2
15 imply nand
trivial
p
np
np
σp
2
16 any other
np
np
np
np
σp
2
table 1  complexity of dsat and pdverσ s   where np means
np-complete and σp
2 means σp
2-complete
this is obvious for the case where ∆ = ∅  and can be straight-
forwardly seen in the other cases  when at most imply∨
and or are allowed  the completion containing all the un-
certain arguments is always valid  when at most imply∨ and
nand are allowed  the completion where all the uncertain ar-
guments are discarded is valid 
theorem 1 the complexity of dsat  for the various restric-
tions on the set of allowed forms of dependencies  is that re-
ported on the second column of table 1 
complexity of pdverσ s  
we first introduce general
upper bounds for pdverσ s  that are independent from the
allowed forms of dependencies 
theorem 2 pdverσ s  is in np for σ ∈  ad  st  co  gr 
and in σp
2 for σ = pr 
the following two theorems distinguish two cases where
this upper bound is not strict  as pdverσ s  is in p 
theorem 3 pdverσ s  is in p if σ
∈  ad  st  and
only imply nand or only one among or  nand  imply 
choice2 is allowed 
theorem 4 pdverσ s  is in p when σ = co and only or
dependencies are allowed 
we now move to the cases not covered by theorems 3  4 
showing that the upper bounds of theorem 2 become strict 
for some rows of table 1  i e  6  8  9  10  11  16   this is
implied by the following proposition  entailing that if dsat
is np- hard  also pdverσ s  is np-hard 
proposition 1 for any σ ∈  ad  st  co  gr  pr   there is
a karp-reduction from dsat to pdverσ s   where the de-
pendencies allowed in pdverσ s  and dsat are the same 
proceedings of the thirtieth    ijcai-21 
192
 proof  given an instance isat of dsat consisting in the da-
iaaf ⟨if  ∆⟩  consider the instance iver of pdverσ s 
consisting in the pair
�
⟨if ′  ∆⟩  s
�
  where if ′ is if aug-
mented with a new argument x attacking all the arguments in
if  and s =  x   it is easy to see that the answer of isat
coincides with the answer of iver for any σ 
2
we now consider the cases where dsat is not np-hard 
thus the np lower bound for pdverσ s  must be proved 
theorem 5 if
only
or-dependencies
are
allowed 
pdverσ s  is np-hard under σ = gr 
proof  we show a reduction from sat  let φ be a 3cnf and
dif φ  =
�
⟨a  a   d⟩  ∆
�
be the daiaaf constructed as
follows  for each variable xi in φ  a contains the pair of
arguments i  i′ and a  the pair of arguments xi  ¬xi  while
d contains the four attacks  xi  i    i  ¬xi    ¬xi  i′    i′  xi  
and ∆ contains the dependency or xi  ¬xi   moreover  for
each clause cj = lj
1 ∨lj
2 ∨lj
3 in φ  where every lj
i is a literal  
∆ contains or lj
1  lj
2  lj
3   see the left-hand side of fig  2 for
an example of construction  we prove the equivalence   φ
is satisfiable  ⇔  s =  1  1′  2  2′          n  n′  is a possible
i∗-extension of dif φ  under σ = gr  
⇒  given a truth assignment ta making φ true  let f be the
completion of if φ  containing  for each i ∈  1  n   the ar-
gument xi if ta xi = true  and ¬xi otherwise  obviously  f
is a valid completion  moreover  s is the grounded extension
for f since  for each i ∈  1  n   one of the arguments i  i′ is
attacked by no argument  and defends the other one 
⇐  let f be a valid completion whose grounded extension is
s  since s contains  for each i ∈  1  n   both i and i′  at least
one of the arguments xi  ¬xi must not belong to f  com-
bining this with what imposed by dependency or xi  ¬xi  
we have that f contains exactly one of these arguments  for
each i ∈  1  n   hence  f encodes a truth assignment ta for
x1          xn  where ta xi  = true iff xi belongs to f  as f
is valid  the or-dependencies encoding the clauses of φ are
satisfied  thus ta is a truth assignment making φ satisfied  2
theorem 6 if
only
imply-dependencies
are
allowed 
pdverσ s  is np-hard under σ ∈  co  gr  
proof  we prove the case σ = co  the same reasoning works
x1
x1
1
1 
x2
x2
2
2 
x3
x3
3
3 
x4
x4
4
4 
or
or
or
or
or
or
x1
x1
na1
c1
imply
x2
x2
na2
imply
c2
x3
x3
imply
na3
imply
imply
2v1
2v2
2v3
figure 2  left  construction of theorem 5 for φ =  x1 ∨ ¬x2 ∨
x3  ∧  ¬x1 ∨ ¬x3 ∨ x4   right  construction of theorem 6 for
φ =  x1 ∨ x2 ∨ x3  ∧  ¬x1 ∨ ¬x2 ∨ ¬x3 
for σ = gr   we show a reduction from sat  let φ be
a 3cnf and dif φ  =
�
⟨a  a   d⟩  ∆
�
the daiaaf con-
structed as follows  for each variable xi  a  contains the two
arguments xi  ¬xi  and the argument 2vi  meaning that two
truth values have been assigned to xi   while a contains the
argument nai  meaning that xi has not been assigned a truth
value   in turn  d contains the attacks  xi  xi    ¬xi  ¬xi   as
well as  xi  nai  and  ¬xi  nai   moreover  for each clause
cj = lj
1 ∨ lj
2 ∨ lj
3  a  contains the argument ¬cj  and ∆ the
dependency lj
1  lj
2  lj
3 ⇒ ¬cj  where lj
k is the argument rep-
resenting the negation of lj
k  for each k ∈  1  3   finally  ∆
contains xi  ¬xi ⇒ 2vi  for each i ∈  1  n   see the right-
hand side of fig  2 for an example of construction  we prove
the equivalence   φ is satisfiable  ⇔  ∅ is a complete i∗-
extension for dif φ   
⇒  given a truth assignment ta for x1          xm making φ
true  let f be the completion of dif φ  containing  for each
i ∈  1  n   the argument xi if ta xi  = true  and ¬xi other-
wise  but no other argument from a   obviously  f is valid 
since  1  putting in f exactly one between xi and ¬xi does
not trigger any implication xi  ¬xi ⇒ 2vi  which would have
required the presence of 2vi in f   2  as ta makes φ true  no
implication lj
1  lj
2  lj
3 ⇒ ¬cj is triggered in f  moreover  f
admits no admissible extension other than ∅  an admissible
extension s can contain no argument of the form xi or ¬xi
 since they are self-attacking arguments   and no argument
nai  since these arguments cannot be defended from the at-
tacks from xi or ¬xi  
⇐  let f be a valid completion whose complete extension is
s = ∅  the validity of f and the fact that s = ∅ imply that 
for each i ∈  1  n   f contains at most one between xi and
¬xi  otherwise  the dependency xi  ¬xi ⇒ 2vi would have
implied the presence of 2vi in f  and since this argument is
not attacked  it should belong to s   moreover  since ∅ is
complete  there can be no unattacked nai  since the only at-
tacks towards nai in d are from xi and ¬xi  this means that
f  for each i ∈  1  n   contains exactly one between xi and
¬xi  hence  f encodes a truth assignment ta for x1          xn 
where ta xi  = true iff xi belongs to f  since ∅ is a com-
plete extension  it means that f contains no argument ¬cj  if
there were some ¬cj in f  it would be not attacked and thus
present in s   this means that  for every clause cj  no im-
ply-dependency with ¬cj on its right-hand side is triggered
in f  thus ta makes all the clauses true 
2
the remaining np-hard cases are stated in the theorem 7 
theorem 7 if only nand- or only choice2- dependen-
cies are allowed  pdverσ s  is np-hard under σ
∈
 co  gr  
if only imply∨- or only imply or- depen-
dencies are allowed  pdverσ s  is np-hard under σ ∈
 ad  st  co  gr  
finally  we consider the preferred semantics  here  the
lower bound is implied by the literature of aiaafs without
dependencies  baumeister et al   2018  
theorem 8 pdverσ s  is σp
2-hard under σ = pr 
proceedings of the thirtieth    ijcai-21 
193
 4 1
summary and discussion of the results
as for dsat  the satisfiability for some forms of dependen-
cies  see rows 1-5  12-15 of table 1  is always guaranteed  for
others  choice2  it can be checked in polynomial time  and
for all the other cases dsat is np-complete  observe that
the expressiveness of the  combined  forms of dependencies
for which dsat is np-complete is not necessarily the same 
for instance  it is easy to see that our choice-dependencies
 for which dsat is np-complete  are not sufficient to ex-
press some correlations encoded by a propositional formula 
as for pdverσ s   our analysis highlights three sources
of complexity  1  the forms of dependencies  2  the seman-
tics of extensions  and 3  the combination of 1  and 2   in
fact  when dsat is np-hard  also pdverσ s  is np-
hard 
however  even for the  combined  forms of depen-
dencies making dsat trivial or in p  pdverσ s  may
be hard 
specifically  whatever the form of dependency
is  pdverσ s  is σp
2-complete under σ = pr  and np-
complete under σ = gr  however  the σp
2-hardness under
σ = pr is independent from the presence of dependencies
 since it holds even over  traditional  aiaafs  where ∆ = ∅  
while under σ = gr pdverσ s  is in p if ∆ = ∅  the re-
maining combinations ⟨ form of dependency  semantics ⟩ are
more intricate  specifically  under σ = co  pdverσ s  is
in p only if we restrict ∆ to contain only or-dependencies 
under σ ∈  ad  st   pdverσ s  is in p only if we restrict
∆ to contain or-dependencies  or choice2-dependencies  or
combinations of imply- and nand- dependencies  allowing
combinations of dependencies behind these polynomial cases
makes the complexity explode 
5
related work
i∗-extensions have been introduced in  fazzinga et al   2020 
as a revision of the i-extensions defined in  baumeister et al  
2018   the difference between i∗- and i- extension is in the
set used to decide if s is an extension  in the latter  the pro-
jection of s over the completions is used  rather than s  this
projection can cause counter-intuitive side-effects  e g   even
a conflicting set can be an i-extension  in fact  the notion of
accepted arguments used in the literature of iaafs  baumeis-
ter et al   2021  corresponds to argument belonging to some
 or every  i∗-extension  and not i-extension   our sensitivity
analysis does not apply to i-extensions as pdverσ s  in that
case is already np-complete for σ = ad 
constraints in argumentation have been little investigated 
in  coste-marquis et al   2006   aafs are augmented with
a propositional formula with the aim of refining the set of
extensions  they do not consider uncertain terms  in the dy-
namic scenario   wallner  2020  considers constraints to limit
the admitted structural modifications when the sets of argu-
ments and attacks are updated on abstract dialectical frame-
works  adfs   brewka et al   2017  
in this regard  the
general relationship between argument-incomplete aafs and
adfs needs some further investigation as the latter may be
capable of encoding uncertain arguments and correlations 
beside the already mentioned  other works dealing with
uncertainty in aafs are the following  the partial argumen-
tation framework  paf   cayrol et al   2007  mainly differs
from iaafs since the semantics of extensions is not based on
completions  but on a revised notion of admissibility  where 
depending on the desired level of cautiousness  only certain
attacks or also uncertain attacks must be defended   reason-
ing over iaafs  extensions is also related to revising aafs to
enforce the existence of an extension  baumann and ulbricht 
2019   or to make a set an extension  coste-marquis et al  
2015   where  however  only minimal sets of changes are con-
sidered   and to the credulous/skeptical conclusion problems
in control argumentation frameworks  cafs   dimopoulos
et al   2018   in this regard  embedding correlations in cafs
is an interesting research direction 
several variants of aafs where the uncertainty is quan-
titatively specified have been proposed  some of them al-
low the specification of preferences and/or weights  bench-
capon  2003  amgoud and vesic  2011  modgil  2009 
dunne et al   2011  coste-marquis et al   2012  brewka et
al   2014   in other approaches  uncertainty is specified via
probabilities  according to the  epistemic   thimm  2012 
hunter and thimm  2014    or the  constellation  paradigm
 praafs   hunter  2014  dung and thang  2010  doder and
woltran  2014  dondio  2014  hunter  2012  li et al   2011 
fazzinga et al   2015   the last ones are the most related to
our framework  as praafs can be seen as iaafs where a
probability distribution  pdf  is defined over the completions 
typically  the correlations are hidden in the specified pdf  that
is defined by enumerating the completions and explicitly as-
signing a probability to each of them  up to our knowledge 
the only form of praaf allowing the explicit specification of
correlations is ind-d  fazzinga et al   2019   but only mutual
exclusion and co-existence can be expressed 
6
conclusions
an extension of argument-incomplete aafs has been inves-
tigated  where the analyst is allowed to specify correlations
among the uncertain arguments by imposing different forms
of dependencies  the impact of the presence of correlations
on the complexity of the satisfiability and the verification
problems  under the possible perspective and for dung s se-
mantics  has been thoroughly investigated  by studying the
sensitivity of the complexity to the form of dependencies used
to define the correlations  future directions of research stem-
ming from this work are extending our study to characterize
the complexity of the verification problem under the neces-
sary perspective  and the search for islands of tractability for
the np-hard cases related to syntactic restrictions of the log-
ical connectives that are still of practical interest 
references
 amgoud and vesic  2011  leila amgoud and srdjan vesic 
a new approach for preference-based argumentation
frameworks  ann  math  artif  int   63 2  149–183  2011 
 baumann and ulbricht  2019  ringo baumann and markus
ulbricht  if nothing is accepted - repairing argumentation
frameworks  j  artif  intell  res   66 1099–1145  2019 
 baumeister et al   2015  dorothea baumeister  j¨org rothe 
and hilmar schadrack 
verification in argument-
proceedings of the thirtieth    ijcai-21 
194
 incomplete argumentation frameworks 
in proc  of al-
gorithmic decision theory - 4th international conference
 adt   volume 9346  pages 359–376  2015 
 baumeister et al   2018  dorothea
baumeister 
daniel
neugebauer  j¨org rothe  and hilmar schadrack  verifi-
cation in incomplete argumentation frameworks 
artif 
intell   264 1–26  2018 
 baumeister et al   2021  dorothea
baumeister 
matti
j¨arvisalo  daniel neugebauer  andreas niskanen  and
j¨org rothe 
acceptance in incomplete argumentation
frameworks  artif  intell   295 103470  2021 
 bench-capon  2003  trevor j  m  bench-capon 
persua-
sion in practical argument using value-based argumenta-
tion frameworks  j  log  comput   13 3  429–448  2003 
 brewka et al   2014  gerhard brewka  sylwia polberg  and
stefan woltran  generalizations of dung frameworks and
their role in formal argumentation  ieee intelligent sys-
tems  29 1  30–38  2014 
 brewka et al   2017  gerhard brewka  stefan ellmauthaler 
hannes strass 
johannes peter wallner 
and stefan
woltran 
abstract dialectical frameworks  an overview 
flap  4 8   2017 
 cayrol et al   2007  claudette cayrol  caroline devred  and
marie-christine lagasquie-schiex 
handling ignorance
in argumentation 
semantics of partial argumentation
frameworks 
in proc  conf  symbolic and quantitative
approaches to reasoning with uncertainty  ecsqaru  
hammamet  tunisia  pages 259–270  2007 
 coste-marquis et al   2006  sylvie coste-marquis 
caro-
line devred  and pierre marquis  constrained argumen-
tation frameworks 
in proc  int  conf  on principles of
knowledge representation and reasoning  united king-
dom  2006  pages 112–122  2006 
 coste-marquis et al   2007  sylvie coste-marquis 
caro-
line
devred 
s ebastien
konieczny 
marie-christine
lagasquie-schiex  and pierre marquis  on the merging
of dung s argumentation systems  artif  intell   171 10-
15  730–753  2007 
 coste-marquis et al   2012  sylvie
coste-marquis 
s ebastien konieczny  pierre marquis  and mohand akli
ouali 
weighted attacks in argumentation frameworks 
in proc  principles of knowledge representation and
reasoning  kr   rome  italy  2012 
 coste-marquis et al   2015  sylvie
coste-marquis 
s ebastien
konieczny 
jean-guy
mailly 
and
pierre
marquis  extension enforcement in abstract argumenta-
tion as an optimization problem  in proc  int  conf  on
artificial intelligence  ijcai   pages 2876—-2882  2015 
 dimopoulos et al   2018  yannis
dimopoulos 
jean-guy
mailly  and pavlos moraitis 
control argumentation
frameworks 
in proc  conf  on artificial intelligence
 aaai   new orleans  usa  pages 4678–4685  2018 
 doder and woltran  2014  dragan
doder
and
stefan
woltran 
probabilistic argumentation frameworks - a
logical approach 
in proc  conf  scalable uncertainty
management  sum   oxford  uk  sept  15-17  pages
134–147  2014 
 dondio  2014  pierpaolo dondio  toward a computational
analysis of probabilistic argumentation frameworks  cy-
bernetics and systems  45 3  254–278  2014 
 dung and thang  2010  phan minh dung and phan minh
thang 
towards  probabilistic  argumentation for jury-
based dispute resolution  in proc  computational models
of argument  comma   italy  pages 171–182  2010 
 dung  1995  phan minh dung  on the acceptability of ar-
guments and its fundamental role in nonmonotonic reason-
ing  logic programming and n-person games  artif  intell  
77 2  321–358  1995 
 dunne et al   2011  paul e  dunne  anthony hunter  pe-
ter mcburney  simon parsons  and michael wooldridge 
weighted argument systems 
basic definitions  algo-
rithms  and complexity results  artif  intell   175 2  457–
486  2011 
 fazzinga et al   2015  bettina fazzinga  sergio flesca  and
francesco parisi  on the complexity of probabilistic ab-
stract argumentation frameworks  acm trans  comput 
log   16 3  22 1–22 39  2015 
 fazzinga et al   2019  bettina fazzinga  sergio flesca  and
filippo furfaro 
complexity of fundamental problems
in probabilistic abstract argumentation  beyond indepen-
dence  artif  intell   268 1–29  2019 
 fazzinga et al   2020  bettina fazzinga  sergio flesca  and
filippo furfaro  revisiting the notion of extension over
incomplete abstract argumentation frameworks  in proc 
joint conf  on artificial intelligence  ijcai   pages 1712–
1718  2020 
 hunter and thimm  2014  anthony hunter and matthias
thimm  probabilistic argumentation with incomplete in-
formation  in proc  eur  conf  on artificial intelligence
 ecai   prague  czech republic  pages 1033–1034  2014 
 hunter  2012  anthony hunter  some foundations for prob-
abilistic abstract argumentation  in proc  computational
models of argument  comma   vienna  austria  pages
117–128  2012 
 hunter  2014  anthony hunter  probabilistic qualification
of attack in abstract argumentation  int  j  approx  rea-
soning  55 2  607–638  2014 
 li et al   2011  hengfei li  nir oren  and timothy j  nor-
man  probabilistic argumentation frameworks  in proc 
int  workshop on theory and applications of formal ar-
gumentation  tafa   barcelona  spain  pages 1–16  2011 
 modgil  2009  sanjay modgil 
reasoning about prefer-
ences in argumentation frameworks  artif  intell   173 9-
10  901–934  2009 
 thimm  2012  matthias thimm  a probabilistic semantics
for abstract argumentation  in proc  eur  conf  on artificial
intelligence  ecai   france  pages 750–755  2012 
 wallner  2020  johannes peter wallner 
structural con-
straints for dynamic operators in abstract argumentation 
argument comput   11 1-2  151–190  2020 
proceedings of the thirtieth    ijcai-21 
195
 "
None,2021,https-www-ijcai-org-proceedings-2021-0028-pdf,Kemeny Consensus Complexity,"Zack Fitzsimmons, Edith Hemaspaandra",None,https://www.ijcai.org/proceedings/2021/0028.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0028-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0028-pdf.pdf,"kemeny consensus complexity
zack fitzsimmons1 and edith hemaspaandra2
1college of the holy cross
2rochester institute of technology
zfitzsim@holycross edu  eh@cs rit edu
abstract
the computational study of election problems gen-
erally focuses on questions related to the winner or
set of winners of an election  but social preference
functions such as kemeny rule output a full rank-
ing of the candidates  a consensus   we study the
complexity of consensus-related questions  with a
particular focus on kemeny and its qualitative ver-
sion slater  the simplest of these questions is the
problem of determining whether a ranking is a con-
sensus  and we show that this problem is conp-
complete  we also study the natural question of
the complexity of manipulative actions that have
a specific consensus as a goal  though determin-
ing whether a ranking is a kemeny consensus is
hard  the optimal action for manipulators is to sim-
ply vote their desired consensus  we provide evi-
dence that this simplicity is caused by the combi-
nation of election system  kemeny   manipulative
action  manipulation   and manipulative goal  con-
sensus   in the process we provide the first com-
pleteness results at the second level of the polyno-
mial hierarchy for electoral manipulation and for
optimal solution recognition 
1
introduction
elections are a widely used tool for aggregating the prefer-
ences of several agents into a collective decision  often the
goal is to determine a single winner or set of winners from
among a set of candidates  however  in other cases  such as
constructing a meta-search engine  dwork et al   2001  or ge-
netic maps  jackson et al   2008   the natural desired outcome
is a ranking 
one of the most compelling ways of aggregating prefer-
ences is the kemeny rule  it is known that computing a ke-
meny consensus  i e   a ranking closest to the electorate  is a
computationally difficult problem  we show that even simply
checking if a given ranking is a consensus is conp-complete 
this problem is naturally motivated by an agent wanting to
verify the claimed outcome of an election 
one of the most important lines of research in the com-
putational study of elections  see  e g   faliszewski and
rothe  2016   is the study of different manipulative actions
such as manipulation and control  bartholdi et al   1989a 
bartholdi et al   1992   where an agent  or agents  seek to
ensure their preferred outcome by either voting strategically
or modifying the structure of the election  in each of these
models  the goal is typically to ensure a preferred candidate
wins  for scenarios where the collective decision is a consen-
sus  it is natural to consider manipulative actions where the
goal of the agent s  is to reach a preferred consensus 
even though the problem of determining whether a rank-
ing is a kemeny consensus is hard  the optimal action for the
manipulators is to simply vote their desired consensus  we
provide evidence that this simplicity is caused by the combi-
nation of the manipulative action  manipulation   the manip-
ulative goal  consensus   and the election system  kemeny  
in particular 
• determining if a given ranking is a kemeny consensus
is conp-complete   section 3 
• control by deleting candidates for kemeny with the
goal of a particular consensus is σp
2-complete  and thus 
unlike manipulation  the optimal control action is not
polynomial-time computable    section 5 
• we provide evidence that manipulation  to winner  for
kemeny is also much harder than manipulation to con-
sensus  by showing that manipulation  to winner  for a
natural variant of slater  the qualitative version of ke-
meny  is σp
2-complete   section 6 
• the choice of system matters as well  for example the
optimal action for the manipulators to reach a consen-
sus is not polynomial-time computable for borda   sec-
tion 7 
2
preliminaries
an election consists of a set of candidates c and a collection
of voters v where each voter has a ranking  total order pref-
erence  over the set of candidates  for example  a > b > c 
where > denotes strict preference  is a vote over  a  b  c  
we consider voting rules that are social preference func-
tions  which map an election to a set of one or more rank-
ings  total orderings  of the candidates  one of the most-
important social preference functions is the kemeny rule  ke-
meny  1959  
a ranking > is a kemeny consensus if the sum of
the kendall tau distances to the voters is minimal  i e  
proceedings of the thirtieth    ijcai-21 
196
 �
a>b n b  a  is minimal  where for candidates a and b 
n b  a  denotes the number of voters that state b > a 
it is often useful to refer to the induced weighted major-
ity graph of the election when working with the kemeny
rule  the weighted majority graph of an election  c  v   has
a vertex for each candidate and for each pair of candidates
a  b ∈ c if n a  b  > n b  a  there is an arc  a  b  labeled
with n a  b  − n b  a  
example 1  consider an election with candidates  a  b  c  d 
and three voters with their votes  and the corresponding in-
duced weighted majority graph below 
• a > b > c > d
• c > a > d > b
• b > c > d > a
consensuses 
a > b > c > d 
b > c > a > d 
c > a > b > d  kendall tau distance  6 
we consider several different computational problems re-
lating to the kemeny rule  for readability  the formal defi-
nitions of these problems are deferred to where the results
appear 
we assume that the reader is familiar with the complexity
classes p  np  and conp  our complexity results also concern
the class σp
2= npnp  a class at the second level of the polyno-
mial hierarchy  which is the class of problems solvable by an
np-machine with access to an np oracle  meyer and stock-
meyer  1972  stockmeyer  1976  
3
consensus recognition
we now formally define the problem of determining whether
a ranking is a kemeny consensus 
name  kemeny consensus recognition
given  an election  c  v   and a total order x 
question  is x a kemeny consensus of the election 
hudry  2013  observes that the kemeny consensus recog-
nition problem  there called order recognition  is in conp 
and conjectures it is conp-complete 1 since it is easier to
think about np than about conp  we will often look at the
complement  i e   determining whether x is not a consensus 
as usual  the upper bound is easy to see  note that x is not
a kemeny consensus if and only if there exists a total order
whose distance to the election is less than that of x 
also note that the kemeny consensus recognition prob-
lem is not in np unless np = conp  since the kemeny score
of an election  kendall tau distance to a consensus  is greater
than k if and only if there exists a total order that is a ke-
meny consensus whose score is greater than k  so if ke-
meny consensus recognition is in np  then determining if
the kemeny score of an election is greater than k is in np 
this latter problem is conp-complete  since it is in essence
the complement of the problem kemeny score  which is np-
complete  bartholdi et al   1989b  
the above does not imply that kemeny consensus recog-
nition is conp-hard  it merely says that  assuming np ̸=
1hudry uses turing reductions  we look at the standard notion of
polynomial-time many-one reductions  which gives stronger results 
conp  the problem is in conp − np  under the assump-
tion that np ̸= conp  there are problems in conp − np
that are not conp-complete  ladner  1975   a natural can-
didate of such a problem is graph nonisomorphism problem 
note that this problem has some  easiness  properties that are
not shared by any natural conp-complete problem  such as a
zero-knowledge proof for the complement  goldreich et al  
1991  and a quasi-polynomial time algorithm  babai  2016  
we will now prove hudry s conjecture that kemeny con-
sensus recognition is conp-complete  as theorem 5  
optimal solution recognition problems induced by opti-
mization problems are very natural decision problems  but
there are only a couple of results in the literature  papadim-
itriou and steiglitz  1978  theorem 5  show that minimum
tsp tour recognition is conp-complete  armstrong and ja-
cobson  2003  study the global verification problem  which
is the complement of optimal solution recognition  related to
various np optimization problems and show that the optimal
solution recognition problems for vertex cover  max-sat 
and max-k-sat  k ≥ 2  are each conp-complete 
our proof of theorem 5 will use the conp-completeness
of minimum vertex cover recognition 
name  minimum vertex cover recognition
given  a graph g and a set of vertices x 
question  is x a minimum vertex cover of g 
theorem 2   armstrong and jacobson  2003    minimum
vertex cover recognition is conp-complete 
the kemeny score problem was shown hard by a reduction
from feedback arc set  fas   bartholdi et al   1989b   in
the full version  fitzsimmons and hemaspaandra  2021   we
show the following problem conp-complete 
name  minimum fas recognition
given  an irreflexive and antisymmetric directed graph g
and a set of arcs x 
question  is x a minimum fas of g  a minimum set of arcs
such that g − x is acyclic  
theorem 3  minimum fas recognition is conp-complete 
feedback arc sets and kemeny consensuses are very
closely related  bartholdi et al   1989b   we use the following
slightly unusual formulation of this relationship 
lemma 4  for g a directed graph  let e g  be the election
with candidates v  g  and for each arc  a  b  ∈ a g  one
voter voting a > b followed by all candidates in v  g  −
 a  b  in lexicographical order and one voter voting all can-
didates in v  g  −  a  b  in reverse lexicographical order
followed by a > b  this election is computable in polyno-
mial time  and has g with all arc weights 2 as its induced
weighted majority graph  mcgarvey  1953  
for x a minimal fas of g  i e   x is a fas of g and no
strict subset of x is a fas   and �
x a total order consistent
with g − x  i e   if  a  b  ∈ a g  − x  then a > b in �
x   it
holds that x is a minimum fas if and only if �
x is a kemeny
consensus of e g  
this gives us a reduction from minimum fas recognition
to kemeny consensus recognition  which gives us the fol-
lowing theorem 
proceedings of the thirtieth    ijcai-21 
197
 theorem 5  kemeny consensus recognition is conp-
complete 
proof 
given g and x  if x is not a minimal fas  which
can be determined in polynomial time   then output some-
thing that is not an instance of the problem  if x is a minimal
fas  then output e g   as defined in lemma 4  and a total or-
der consistent with g − x  which can be computed in poly-
nomial time  since g − x is acyclic  
k
from the above  one might think that conp-hardness for an
optimal solution recognition problem follows from a straight-
forward modification of the reduction for the related np-
complete decision problem  but this is only the case when the
witnesses of the two decision problems directly correspond to
each other  this is usually not the case  see for example the
proof of the analogous result for tournaments later in this pa-
per  theorem 15  
4
manipulative-actions-to-consensus
in the previous section we showed that kemeny consensus
recognition is conp-complete  given the hardness of this
problem  does it follow that manipulative actions with the
goal to reach a specific consensus are hard  this is true if we
look at decision problems such as  given an election and a to-
tal order x  can we perform a manipulative action such that
x is a consensus   such decision problems typically inherit
the conp-hardness  e g   by having no manipulators   it is still
interesting to look at these decision problems  since they may
be complete for classes above conp  which limits the tools we
have to solve these problems  standard approaches for solv-
ing problems in np or conp such as using sat solvers are not
appropriate for solving problems that are complete for higher
levels of the polynomial hierarchy such as σp
2 
we will also look at the problem of determining the ma-
nipulative action  it is possible that it is easy to determine the
best action  even though it is hard to determine whether such
an action leads to the desired outcome  in fact 
observation
6 
consider
kemeny-manipulation-to-
consensus  in which we are given an election  a collection of
manipulators  and a desired consensus x  and we ask if the
manipulators can vote so that x is a kemeny consensus of
the resulting election  it is easy to see that a total order x
can be made a consensus if and only if x is a consensus when
all manipulators vote x  for details see the full version  
and so the optimal action for the manipulators is straight-
forward  namely to vote x  and the complexity of the asso-
ciated decision problem kemeny-manipulation-to-consensus
is the same as for the recognition problem  namely  conp-
complete 
now we ask  what makes it easy to determine the manipu-
lative action  is it the election system  kemeny   is it the ma-
nipulative action  manipulation   is it the manipulative goal
 consensus  
note that the observation above has interesting repercus-
sions for other manipulative actions and for other manipula-
tive goals  for example  in bribery  we can assume that all
bribed voters vote the same x  where x is a consensus af-
ter bribery  and if the goal of the manipulators is to make a
preferred candidate p a winner  we can assume that all ma-
nipulators vote the same x  where x is a consensus after
manipulation   since if there is a manipulation such that p is
a winner  then there is a manipulation with a consensus x
that ranks p first  but then x is also a consensus when all
manipulators vote x  
despite this simplicity of all manipulators/bribed voters
voting the same  we will provide evidence in the next couple
of sections that determining the optimal manipulation to ob-
tain a kemeny consensus is easy because of the combination
of election system  kemeny   manipulative action  manipula-
tion   and manipulative goal  consensus  
5
control-to-consensus
electoral control models whether the structure of an election
can be modified to ensure a preferred outcome  bartholdi et
al   1992   control -to-winner  problems for kemeny tend to
be σp
2-complete  fitzsimmons et al   2019   note that win-
ner determination is already complete for parallel access to
np  hemaspaandra et al   2005    in this section we provide
evidence that this is also the case for control-to-consensus 
note that this implies that  unless np = conp  the opti-
mal control action to obtain a kemeny consensus is not
polynomial-time computable  in contrast to manipulation  
σp
2 lower bounds are often hard to prove  in part because
there are fewer known σp
2-complete problems  see schaefer
and umans  2002  for a list  and also because one needs
a closer correspondence between the two problems than for
np-hardness reductions 
we first show that optimal solution recognition for
the
σp
2-complete
problem
generalized
node
deletion
 gnd   rutenburg  1994  is πp
2-complete 
name  minimum gnd recognition
given  a graph g  integer ℓ  and set of vertices x 
question  is x a minimum set of vertices such that g − x
does not contain kℓ 1  a clique of size ℓ   1  
theorem 7  minimum gnd recognition is πp
2-complete 
this is the first completeness result at the second level of
the polynomial hierarchy for optimal solution recognition 
for details  see the full version 
the natural deletion analogues of minimum vertex cover
 resp  fas  recognition where we are additionally given a
delete limit k and ask if there exists a set of at most w vertices
such that x is a minimum vertex cover  minimum fas  respec-
tively  of g−w are also σp
2-complete  for details see the full
version   since there is a dearth of natural σp
2-complete prob-
lems  these results are interesting in their own right 
we will now look at control by deleting candidates  cdc  
we will show that the following problem is σp
2-complete 
name  kemeny-cdc-to-consensus
given  an election  c  v    delete limit k  and a total order
x over c 
question  does there exist a set d ⊆ c of at most k candi-
dates such that x restricted to c − d is a kemeny consensus
of  c − d  v   
though this problem is not the most natural  it does pro-
vide evidence that kemeny-control-to-consensus problems
are σp
2-complete 
proceedings of the thirtieth    ijcai-21 
198
 theorem 8  kemeny-cdc-to-consensus is σp
2-complete 
note that in the definition of kemeny-cdc-to-consensus 
it is important that x is a total order over c  if it were
over c − d  we would be able to see which candidates are
deleted from the problem instance  and the problem would
be equivalent to kemeny consensus recognition   however 
this makes the problem different from the σp
2-complete fas
problem  since total order x ranks all candidates  this means
that the straightforward σp
2 analogue of the reduction from
minimum fas recognition to kemeny consensus recog-
nition from the proof of theorem 5 does not work  in that
reduction  the order was a total order consistent with the di-
rected acyclic graph g − x  where x is a fas  however  be-
fore deletion  g − x is not necessarily acyclic  to prove σp
2-
completeness of kemeny-cdc-to-consensus  we need dif-
ferent  less natural σp
2-complete versions of vertex cover and
feedback arc set recognition that look more like kemeny-
cdc-to-consensus  in particular  we need to make sure that
the solutions for vertex cover and feedback arc set are  not
necessarily optimal  solutions for the whole graph  details
can be found in the full version 
there are other types of control  most notably control by
adding candidates and control by adding/deleting voters  as
problems  these are more compelling  for example  the def-
inition of control by deleting voters  cdv  to consensus is
straightforward and natural 
name  kemeny-cdv-to-consensus
given  an election  c  v    delete limit k  and a total order x 
question  does there exist a set w ⊆ v of at most k voters
such that x is a kemeny consensus of  c  v − w  
one might think that  in analogy to optimal action for ma-
nipulators being voting the consensus  the optimal action for
cdv would be to simply delete voters furthest from the de-
sired consensus  and for cav to simply add voters closest
to the desired consensus   however  the following example
shows that this is not the case 
example 9  consider an election with candidates  a  b  c  
five voters  three voting a > b > c  one voting a > c > b  and
one voting c > b > a  delete limit 1  and desired consensus
a > c > b 
note that a > c > b is not a consensus  if we delete the
voter furthest from the consensus  i e   the voter voting c >
b > a  then a > c > b is not a consensus  but if we delete one
of the a > b > c voters then a > c > b is a consensus 
this example with one of the a > b > c voters and the
c > b > a voter as the unregistered voters and an add limit of
1 shows the analogous counterexample for kemeny-cav-to-
consensus 
we conjecture that all these control-to-consensus problems
are σp
2-complete  however  we cannot modify the approach
above in a simple way  since one arc in a graph does not cor-
respond to one voter in the corresponding election  this is
also the reason that the complexity of  regular  kemeny voter
control -to-winner  is still open  fitzsimmons et al   2019  
6
manipulation -to-winner 
showing that manipulation is hard is hard  for example  it is
not too hard to show that control for borda is hard  russell 
2007   but the complexity of  coalitional  manipulation for
borda was open for a long time and np-completeness was
shown only after discovering an appropriate np-complete
problem in scheduling  davies et al   2014  betzler et al  
2011   and proving the np-completeness of manipulation for
copelandα for α ̸= 0 5 involved construction of elaborate
gadgets  faliszewski et al   2008  faliszewski et al   2010  
the reason that it is so hard to prove manipulation hard is
that the manipulators do not follow any structure other than
voting a total order  this means that basically all the structure
needs to come from the nonmanipulators 
for kemeny  we know from section 4 that we can assume
that all manipulators vote the same  so all we have to work
with is one total order  though we conjecture that kemeny-
manipulation is σp
2-complete  we have not succeeded in prov-
ing this  the closest we got is the following theorem  which
is explained in more detail after the theorem statement  we
note that this is the first σp
2-complete manipulation result 
theorem 10  slater-manipulation where candidates have
unary weights is σp
2-complete  even for one manipulator 
the slater rule  slater  1961  can be viewed as a qualita-
tive version of kemeny  it is defined as follows  a ranking >
is a slater consensus if the number of disagreements with the
majority graph induced by the voters is minimal  note that
for slater we look at the induced majority graph while for
kemeny we look at the induced weighted majority graph   in
our slater proofs  we will often look at the slater score of a
ranking  which is the number of agreements with the majority
graph  i e   ∥c∥ ∥c∥ − 1 /2 minus the number of disagree-
ments  so  the higher the score  the better the ranking 
candidates with weights for kemeny are a natural no-
tion  kumar and vassilvitskii  2010   for candidates with
weights  the contribution of each candidate to the score is
multiplied by its weight  for our result  we need only unary
weights  which is a step in the direction of not needing
weights 
the high-level reason that we obtain this result for slater
and not for kemeny is that in slater we can  freeze  certain
arcs in the majority graph  for example  if we have three non-
manipulators all voting a > b  and we have one manipulator 
then the manipulator cannot change the contribution to the
slater score of the pair  a  b   note that this is not the case
for kemeny 
candidates with weights also give more structure to the
manipulator  for example  if we have two candidates a and
b of weight 10  then the manipulator can rank a > b or b > a 
if we replace a by 10 little a s and 10 little b s  the manipula-
tor can rank those in any messy order it wants 
proof sketch of theorem 10  to show σp
2-hardness  we will
reduce from qsat2  stockmeyer  1976  wrathall  1976  
consider cnf formula φ = d1 ∧ · · · ∧ dm−1 over variables
x2          xn and let φ′ =  x1∨d1 ∧· · ·∧ x1∨dm−1 ∧¬x1 
 notice that φ′ has m clauses over variables x1          xn  
without loss of generality  assume that if φ is not satisfi-
able  then at most m − 3 clauses can be satisfied  this can
be accomplished by doubling each clause   we will in poly-
nomial time compute an election with one manipulator such
that ∃xn′ 1 · · · xn¬ ∃x2 · · · xn′φ x2          xn   if and only if
proceedings of the thirtieth    ijcai-21 
199
 the manipulator can vote such that the candidate  1 becomes
a winner 
first note that if ∃xn′ 1 · · · xn¬ ∃x2 · · · xn′φ x2          xn   
then ∃xn′ 1 · · · xn such that any assignment with x1 = true
satisfies m − 1 clauses of φ′ and any assignment with x1 =
false satisfies at most m − 2 clauses of φ′  if it is not the case
that ∃xn′ 1 · · · xn¬ ∃x2 · · · xn′φ x2          xn    then any
assignment with x1 = true satisfies m − 1 clauses of φ′ and
there is an assignment with x1 = false that satisfies m clauses
of φ′ 
now apply the reduction from max-sat to slater score
from conitzer  2006  to φ′  with the following change  we
replace each size m  super-candidate   a group of m can-
didates that  for the purposes of slater score  can be treated
as one single candidate of weight m  by one candidate of
weight m  this ensures that we only get slater consensuses
of a specific form and no  rogue  consensuses  this was not
a problem in conitzer  2006   since for the purposes of slater
scores it is enough that there exist a slater consensus of the
appropriate form  however  since we are interested in whether
a specific candidate can be a winner or not  we need to pre-
clude rogue consensuses with a rogue winner   this computes
a tournament2 in which each variable xi is represented by a
subtournament ti  which includes the vertices  i and −i 
and each clause by a candidate ck  the relevant properties of
the reduction are as follows 
• all slater consensuses rank t1 > · · · > tn 
• slater consensuses correspond to assignments satisfying
a maximum number of clauses of φ′ in the following
way  for ck a true clause  candidate ck is ranked  in
a specific way  among the candidates in a subtourna-
ment ti whose ranking encodes an assignment to xi that
makes ck true 
• if t1 s ranking encodes x1 = true  then candidate  1
is ranked first  if t1 s ranking encodes x1 = false  then
candidate −1 is ranked first 
•  1 is a slater winner or −1 is a slater winner 
• there is an assignment that satisfies ≥ k clauses of φ′ if
and only if the slater score is ≥ b   km  here  b  the
baseline score  and m are polynomial-time computable
constants that are small enough to be given in unary  
we want to keep as much of this construction as possible 
first we double every voter  so that the arc weights in the
induced tournament are all 2  we have one manipulator  note
that one manipulator cannot change an arc of weight 2  we
will now change the tournament a little  in such a way that the
manipulator can  set  the values of the existential variables
 xn′ 1          xn   but nothing else 
in the construction  we change how the existential
variables are represented  each such variable xi will
be represented by a graph consisting of four candi-
dates  i  −i  bi  di  each of weight m  recall that we al-
low unary weights for the candidates   these four can-
didates are connected by the following weight-2 arc 
2for every pair of vertices a  b  a → b or b → a  but not both 
the only  undeclared  arc is between  i and −i  this arc
will be determined by the vote of the manipulator   i > −i
will correspond to setting xi to true and −i >  i will corre-
spond to setting xi to false  let t ′
i be the subtournament after
the manipulator vote 
for clause candidate ck  we add the following arcs 
• if xi occurs positively in ck  add arcs
 i → ck  ck → −i  ck → bi  di → ck 
• if xi occurs negatively in ck  add arcs
−i → ck  ck →  i  ck → bi  di → ck 
• if xi does not occur in ck  add arcs
ck →  i  ck → −i  bi → ck  di → ck 
all other arcs are unchanged  in particular  all slater con-
sensuses rank t1 > · · · > tn′ > t ′
n′ 1 > · · · > t ′
n  note
that if we rank candidate ck before or after t ′
i  this contributes
a baseline score of 2m to the slater score  the only way a
clause candidate ck can gain points from t ′
i over the baseline
score of 2m is if ck is ranked among the candidates in t ′
i and
the value of xi encoded by the ranking of t ′
i makes ck true 
in that case  we gain m extra points 
example 11  for example  if xi is true and xi occurs posi-
tively in ck  we obtain the subtournament below and we can
order  i > ck > −i > bi > di so that ck gains 3m points
from t ′
i for the slater score 
from this  we get the following  for a specific fixed assign-
ment to xn′ 1          xn  and the manipulator voting accord-
ingly  
• slater consensuses correspond to assignments satisfying
a maximum number of clauses of φ′ in the following
way  for ck a true clause  candidate ck is ranked  in a
specific way  among the candidates in a subtournament
ti or t ′
i whose ranking encodes an assignment to xi that
makes ck true 
• if t1 s ranking encodes x1 = true  then  1 is ranked
first  if it encodes x1 = false  then −1 is ranked first 
•  1 is a slater winner or −1 is a slater winner 
• there is an assignment that satisfies ≥ k clauses of φ′ if
and only if the slater score is ≥ �b   km  here  �b is the
baseline score of the new construction  
if
∃xn′ 1 · · · xn¬ ∃x2 · · · xn′φ x2          xn   
then
∃xn′ 1 · · · xn such that any assignment with x1 = true satis-
fies m − 1 clauses of φ′ and any assignment with x1 = false
satisfies at most m−2 clauses of φ′  let the manipulator vote
proceedings of the thirtieth    ijcai-21 
200
 according to the assignment to xn′ 1 · · · xn  then the slater
score of a total order starting with −1 is < �b    m − 1 m
and the slater score of a total order starting with  1 is
≥ �b    m − 1 m  it follows that  1 is a slater winner 
for the converse  suppose the manipulator can vote such
that  1 is a winner  consider the assignment to xn′ 1 · · · xn
induced by the manipulator  if φ x2          xn′  were satisfi-
able  then any assignment with x1 = true satisfies m − 1
clauses of φ′ and there is an assignment with x1 = false
that satisfies m clauses of φ′  it follows that the slater score
≥ �b   mm and that the ranking of t1 in any slater consen-
sus encodes that x1 is false  this implies that −1 is always
ranked first  which contradicts the assumption that  1 is not
a winner 
k
slater
is
an
interesting
system
in
itself
 see 
e g   h¨ullermeier and f¨urnkranz  2004  for motivation
from the preference learning literature   but here we are
mostly interested in the closeness of slater to kemeny 
and view theorem 10 as supporting our conjecture that
kemeny-manipulation is σp
2-complete 
many lower bound proofs for kemeny transfer to slater
and vice versa by the following simple observation  this is
implicit in any source comparing kemeny and slater and ex-
plicitly stated for tournaments where every arc has weight 1
in bachmeier et al   2019   
observation 12  if all weights in the weighted majority
graph are the same  then the kemeny consensus and slater
consensuses coincide 
looking back at the proofs of the results from the previous
section  we immediately obtain the following corollaries 
corollary 13  slater consensus recognition is conp-
complete 
corollary 14  slater-cdc-to-consensus is σp
2-complete 
the definition of slater from this section allows an even
number of voters  not all slater definitions allow ties  i e  
slater is sometimes defined only for the case where the ma-
jority graph is a tournament  and also kemeny for tourna-
ments is an interesting problem  the proofs from the previ-
ous section construct elections with an even number of voters
and so do not give the analogous results about tournaments 
it is much more difficult to prove hardness for tournaments 
for example  feedback arc set is one of the original 21 np-
complete problems from karp  1972   but the complexity of
feedback arc set for tournaments was open for a long time 
alon  2006  showed np-completeness by derandomizing the
reduction from ailon et al   2008   conitzer  2006  gave a di-
rect proof of the result  we will modify the lovely reduction
from conitzer  2006  to prove the following  for slater this
answers an open question from hudry  2010   for details see
the full version 
theorem 15  slater and kemeny consensus recognition for
tournaments is conp-complete 
7
manipulation-to-consensus
recall from observation 6 that for kemeny-manipulation-to-
consensus the optimal action for the manipulators is to vote
their desired consensus  in contrast we show that for borda-
manipulation-to-consensus it is hard to compute the optimal
action for the manipulators  the borda election system  de
borda  1781  is an important rule that can be used to produce
a consensus by ranking each candidate by their borda score 
for an m-candidate election  each voter contributes m − i
points to the candidate ranked ith in their vote  note that in a
borda consensus candidates with the same score are tied 
we first show that for borda it is not always the case that a
manipulator should vote the desired consensus 
example 16  let there be the following five nonmanipulative
voters  two voters voting a > b > c > d  two voters voting
b > a > c > d  and one voter voting b > c > a > d 
let there be one manipulator with a preferred consensus of
a > b > c > d 
before manipulation  the candidates have the following
borda scores  score a  = 11  score b  = 13  score c  =
6  and score d  = 0  and so the consensus is b > a > c > d 
if the manipulator votes their preferred consensus the
resulting borda scores are  score a  = 14  score b  =
15  score c  = 7  and score d  = 0  with the borda con-
sensus of b > a > c > d 
however  manipulation is possible when the manipulator
instead votes a > c > d > b 
we now consider the complexity of borda-manipulation-
to-consensus  the proof from davies et al   2014   which
shows that coalitional manipulation for borda is np-complete
constructs an election such that manipulation is possible if
and only if after manipulation the candidates p  a1          aq 1
are all tied with the highest borda score and the remaining
candidate aq 2 has a strictly lower score  i e   the borda con-
sensus is  p  a1          aq 1  > aq 2  it follows that 
theorem 17 
borda-manipulation-to-consensus is np-
complete 
this immediately implies that the optimal action for
the manipulators is not polynomial-time computable  unless
p = np 
8
conclusion
we showed that even checking if a given ranking is a kemeny
consensus is conp-complete  we also showed that  though
determining whether a ranking is a kemeny consensus is
hard  the optimal action for the manipulators to reach a con-
sensus is easy  we provided evidence that this simplicity is
caused by the combination of election system  kemeny   ma-
nipulative action  manipulation   and manipulative goal  con-
sensus  
for future work  we are most interested in showing our
conjecture that kemeny-manipulation -to-winner  is σp
2-
complete  in addition  the study of elections where candidates
have weights is very natural and interesting 
acknowledgments
this work was supported in part by nsf-due-1819546  re-
search done in part while zack fitzsimmons was on research
leave at rensselaer polytechnic institute  we thank the re-
viewers for their helpful feedback and suggestions 
proceedings of the thirtieth    ijcai-21 
201
 references
 ailon et al   2008  n  ailon  m  charikar  and a  newman  aggre-
gating inconsistent information  ranking and clustering  jacm 
55 5  article 23  2008 
 alon  2006  n  alon 
ranking tournaments 
sidma  20 1–
2  137–142  2006 
 armstrong and jacobson  2003  d  armstrong and s  jacobson 
studying the complexity of global verification for np-hard dis-
crete optimization problems  j  glob  optim   27 83–96  2003 
 babai  2016  l  babai 
graph isomorphism in quasipolynomial
time  extended abstract   in proc  of stoc-16  pages 684–697 
june 2016 
 bachmeier et al   2019  g  bachmeier  f  brandt  c  geist  p  har-
renstein  k  kardel  d  peters  and h  seedig 
k-majority di-
graphs and the hardness of voting with a constant number of vot-
ers  jcss  105 130–157  2019 
 bartholdi et al   1989a  j  bartholdi  iii  c  tovey  and m  trick 
the computational difficulty of manipulating an election  scw 
6 3  227–241  1989 
 bartholdi et al   1989b  j  bartholdi  iii  c  tovey  and m  trick 
voting schemes for which it can be difficult to tell who won the
election  scw  6 2  157–165  1989 
 bartholdi et al   1992  j  bartholdi  iii  c  tovey  and m  trick 
how hard is it to control an election  math  comput  model 
16 8/9  27–40  1992 
 betzler et al   2011  n  betzler  r  niedermeier  and g  woegin-
ger  unweighted coalitional manipulation under the borda rule is
np-hard  in proc  of ijcai-11  pages 55–60  august 2011 
 conitzer  2006  v  conitzer  computing slater rankings using sim-
ilarities among candidates  in proc  of aaai-06  pages 613–619 
july 2006 
 davies et al   2014  j  davies  g  katsirelos  n  narodytska 
t  walsh  and l  xia  complexity of and algorithms for the ma-
nipulation of borda  nanson s and baldwin s voting rules  aij 
217 20–42  2014 
 de borda  1781  j -c  de borda 
m emoire sur les  elections au
scrutin  histoire de l acad emie royale des sciences  pages 657–
664  1781 
 dwork et al   2001  c  dwork  r  kumar  m  naor  and d  sivaku-
mar  rank aggregation methods for the web  in proc  of www-
01  pages 613–622  march 2001 
 faliszewski and rothe  2016  p  faliszewski and j  rothe  con-
trol and bribery in voting  in handbook of computational social
choice  pages 146–168  cambridge university press  2016 
 faliszewski et al   2008  p  faliszewski  e  hemaspaandra  and
h  schnoor  copeland voting  ties matter  in proc  of aamas-
08  pages 983–990  may 2008 
 faliszewski et al   2010  p  faliszewski  e  hemaspaandra  and
h  schnoor  manipulation of copeland elections  in proc  of
aamas-10  pages 367–374  may 2010 
 fitzsimmons and hemaspaandra  2021  z 
fitzsimmons
and
e  hemaspaandra  kemeny consensus complexity  tech  rep 
arxiv 2105 08540  cs gt   arxiv org  may 2021 
 fitzsimmons et al   2019  z 
fitzsimmons 
e 
hemaspaandra 
a  hoover  and d  narv aez  very hard electoral control prob-
lems  in proc  of aaai-19  pages 1933–1940  january/february
2019 
 goldreich et al   1991  o  goldreich  s  micali  and a  wigderson 
proofs that yield nothing but their validity for all languages in
np have zero-knowledge proof systems  jacm  38 3  691–729 
1991 
 hemaspaandra et al   2005  e  hemaspaandra  h  spakowski  and
j  vogel  the complexity of kemeny elections  tcs  349 3  382–
391  2005 
 hudry  2010  o  hudry  on the complexity of slater s problems 
ejor  203 1  216–221  2010 
 hudry  2013  o  hudry  complexity of computing median linear
orders and variants  endm  42 57–64  2013 
 h¨ullermeier and f¨urnkranz  2004  e 
h¨ullermeier
and
j  f¨urnkranz 
comparison of ranking procedures in pair-
wise preference learning  in proc  of ipmu-04  2004 
 jackson et al   2008  b  jackson  s  schnable  and s  aluru  con-
sensus genetic maps as media orders from inconsistent sources 
tcbb  5 2  161–171  2008 
 karp  1972  r  karp  reducibility among combinatorial problems 
in proc  of symposium on complexity of computer computa-
tions  pages 85–103  1972 
 kemeny  1959  j  kemeny 
mathematics without numbers 
daedalus  88 577–591  1959 
 kumar and vassilvitskii  2010  r  kumar and s  vassilvitskii 
generalized distances between rankings  in proc  of www-10 
pages 571–580  april 2010 
 ladner  1975  r  ladner  on the structure of polynomial time re-
ducibility  jacm  22 1  155–171  1975 
 mcgarvey  1953  d  mcgarvey  a theorem on the construction of
voting paradoxes  econometrica  21 4  608–610  1953 
 meyer and stockmeyer  1972  a  meyer and l  stockmeyer  the
equivalence problem for regular expressions with squaring re-
quires exponential space  in proc  of focs-72  pages 125–129 
october 1972 
 papadimitriou and steiglitz  1978  c  papadimitriou and k  stei-
glitz  some examples of difficult traveling salesman problems 
oper  res   26 3  434–443  1978 
 russell  2007  n  russell  complexity of control of borda count
elections 
master s thesis  rochester institute of technology 
2007 
 rutenburg  1994  v  rutenburg 
propositional truth mainte-
nance systems  classification and complexity analysis  amai 
10 3  207–231  1994 
 schaefer and umans  2002  m  schaefer and c  umans 
com-
pleteness in the polynomial-time hierarchy  part i  a com-
pendium  sigact news  33 3  32–49  2002 
 slater  1961  p  slater  inconsistencies in a schedule of paired com-
parisons  biometrika  48 3/4  303–312  1961 
 stockmeyer  1976  l  stockmeyer 
the polynomial-time hierar-
chy  tcs  3 1  1–22  1976 
 wrathall  1976  c  wrathall  complete sets and the polynomial-
time hierarchy  tcs  3 1  23–33  1976 
proceedings of the thirtieth    ijcai-21 
202
 "
None,2021,https-www-ijcai-org-proceedings-2021-0029-pdf,Two-Sided Matching Meets Fair Division,"Rupert Freeman, Evi Micha, Nisarg Shah",None,https://www.ijcai.org/proceedings/2021/0029.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0029-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0029-pdf.pdf,"two-sided matching meets fair division
rupert freeman1   evi micha2   nisarg shah2
1university of virginia
2university of toronto
freemanr@darden virginia edu   emicha nisarg @cs toronto edu
abstract
we introduce a new model for two-sided match-
ing which allows us to borrow popular fairness no-
tions from the fair division literature such as envy-
freeness up to one good and maximin share guar-
antee  in our model  each agent is matched to mul-
tiple agents on the other side over whom she has
additive preferences  we demand fairness for each
side separately  giving rise to notions such as dou-
ble envy-freeness up to one match  def1  and dou-
ble maximin share guarantee  dmms   we show
that  a slight strengthening of  def1 cannot always
be achieved  but in the special case where both
sides have identical preferences  the round-robin al-
gorithm with a carefully designed agent ordering
achieves it  in contrast  dmms cannot be achieved
even when both sides have identical preferences 
1
introduction
consider a group of agents seeking to divide some number
of indivisible goods amongst themselves  each agent has a
utility function describing the value that they have for every
possible bundle of goods  and each agent may have a differ-
ent utility function  this is a canonical resource allocation
problem that arises in estate division  partnership dissolution 
and charitable donations  to name just a few  a central goal
is to find an allocation of the goods that is fair 
one desirable notion of fairness is envy-freeness  foley 
1967   which requires that no agent prefer another agent s
allocation of goods to her own  this is a compelling defi-
nition but  due to the discrete nature of the problem  cannot
always be satisfied  instead  we must consider relaxed ver-
sions  with one popular relaxation being envy-freeness up to
one good  ef1   lipton et al   2004  budish  2011   which re-
quires that any pairwise envy can be eliminated by removing
a single good from the envied agent s allocation  an alloca-
tion satisfying ef1 always exists for a broad class of agent
utility functions  lipton et al   2004  
while quite general  the resource allocation model fails
to capture some allocation settings that we might be inter-
ested in  in particular  it does not allow for the possibility
of two-sided preferences  in which agents have preferences
over  goods   but also  goods  have preferences over agents 
for instance  when college courses are allocated to students 
it is reasonable to assume that students have preferences over
the courses they take  and that teachers in charge of courses
also have preferences over the students they accept  perhaps
measured by prerequisites or gpa  1 as another example 
consider the problem of matching social services to vulnera-
ble individuals2  where individuals have preferences over the
services they receive  and service providers have preferences
over the individuals they serve  perhaps based on demograph-
ics  location  or synergy with existing clients  
allowing for two-sided preferences is immediately remi-
niscent of the matching literature  in two sided matching 
it is generally assumed that each agent has ordinal prefer-
ences over the other side  and a matching is sought that is
in some sense stable to individual or group deviations  it is
well-known that stability is closely related to envy-freeness in
the sense that a one-to-one matching is stable if and only if it
eliminates justified envy  abdulkadiro˘glu and s¨onmez  2003  
a requirement specifying that any envy that i may feel for j s
match is  justified  by j s match preferring j to i  in many-to-
one settings  the notions remain tightly connected  with a sta-
ble matching being one that eliminates justified envy and has
no waste  justified envy-freeness has also been studied as in
its own right in the many-to-one setting  wu and roth  2018 
yokoi  2020  
justified envy  and therefore stability  fundamentally rely
on the idea that the less an agent is preferred by the other side 
the lower her own entitlement should be  however  in some
applications  it may be desirable to provide equal entitlements
or moral claims to agents regardless of how valued they are
by the agents on the other side  for example  instructors may
prefer students with high gpa over students with low gpa 
but it is not clear that universities should adopt such a pol-
icy in their course scheduling  and  in fact  usually do not  
therefore  while stability is a valuable notion in many set-
tings  in this work we consider two-sided preferences while
incorporating traditional notions from fair division 
our contributions 
we introduce and study a two-sided
resource allocation setting in which we have two groups of
1assigning students to courses has been studied before  budish 
2011  othman et al   2010  budish and cantillon  2012   but these
papers typically only consider the preferences of the students 
2http //csse utoronto ca/social-needs-marketplace
proceedings of the thirtieth    ijcai-21 
203
 agents  where each agent has preferences over agents on the
other side 
each agent must be  matched  to a subset of
agents on the other side  subject to a maximum degree con-
straint  our goal is to find a many-to-many matching that
provides fairness to both sets of agents simultaneously  the
standard resource allocation setting is a special case of our
model in which each good can be matched to at most one
agent  each agent can be matched to any number of goods 
and goods are indifferent to which agent they are assigned to 
as a natural tradeoff between expressiveness and succinct-
ness  we restrict our attention to additive preferences  in
which the utility for being matched to a group of agents is
equal to the sum of utilities for being matched to each agent
in the group individually  while conceptually simple  addi-
tive preferences have led to a rich body of work in fair divi-
sion  we focus primarily on the case in which all agents on
the same side have the same degree constraint  and the total
maximum degree on both sides is equal  in this case  it is
reasonable to seek a complete matching  which saturates the
degree constraints of all the agents on both sides 
we begin by considering double envy-freeness up to one
match  def1   requiring that ef1 hold for both sets of agents
simultaneously  we show that a complete matching satisfying
 a slight strengthening of  def1 does not always exists  but
in the special case where both sides have identical ordinal
preferences  it exists and can be computed efficiently using a
carefully designed round robin algorithm 
we also ask whether it is possible to find matchings that
satisfy double maximin share guarantee  dmms   a two-
sided version of the maximin share guarantee  even when
both sides have identical preferences  a complete dmms
matching may not exist  in contrast to the one-sided setting in
which an mms allocation is guaranteed to exist when agents
have identical preferences  in general  we show that approx-
imate dmms and approximate def1 are incompatible  al-
though in the special case where the degree constraint is equal
to two we can achieve exact versions of both simultaneously 
related work 
most related to our work is that of patro
et al   2020   who draw on the resource allocation literature
to guarantee fairness for both producers and consumers on a
two-sided platform  however  in their model  producers are
indifferent between the customers  thus  only one side has
interesting preferences  other work  s¨uhr et al   2019  has
focused on guaranteeing fairness in two-sided platforms over
time  rather than in a one-shot setting  of particular note is
the work of gollapudi et al   2020   who consider two-sided
ef1 in a dynamic setting  but obtain positive results primar-
ily for symmetric binary valuations  a much more restrictive
class of valuations than we consider  tadenuma  2011  stud-
ies envy minimization in two-sided matching subject to other
notions  including stability  but focuses on ordinal notions of
envy and restricts attention to one-to-one matchings 
the theories of matching and fair division each have a
rich history 
traditional work in matching theory has fo-
cused on one-to-one or many-to-one matchings  beginning
with the seminal work of gale and shapley  1962  and find-
ing applications in areas such as school choice  abdulka-
diro˘glu and s¨onmez  2003  abdulkadiro˘glu et al   2005 
hatfield et al   2011   kidney exchange  saidman et al  
2006   and the famous us resident-to-hospital match 3 we
note that ef1 as a condition becomes vacuous whenever
a set of agents has a maximum degree constraint of one 
so we focus instead on the more general case of many-to-
many matchings 
this case has also been well-explored
in the matching literature  roth  1984  sotomayor  1999 
roth and sotomayor  1992  echenique and oviedo  2006   al-
though that literature focuses on stability notions  which have
a very different flavor to our guarantees 
our work draws extensively on notions from the fair di-
vision literature  particularly envy-freeness and its relax-
ations  foley  1967  budish  2011  lipton et al   2004  and
the maximin share guarantee  budish  2011  
prior work
has studied the satisfiability of these properties in the re-
source allocation setting  caragiannis et al   2019  procac-
cia and wang  2014  kurokawa et al   2016   including the
house allocation setting in which each agent is  matched 
to a single item  aigner-horev and segal-halevi  2019 
beynier et al   2019  gan et al   2019   but  to our knowl-
edge  no work has considered satisfying them on both sides
of a market simultaneously 
2
preliminaries
for n ∈ n  define  n  =  0          n − 1   there are two dis-
joint groups of agents  denoted n ℓ   left   and n r   right   
of sizes nℓ and nr  respectively  for simplicity of notation 
we write n ℓ =  nℓ  and n r =  nr   when referring to an
agent by only its index  the group she belongs to will be clear
from context  we use indices i ∈  nℓ  and j ∈  nr  to refer to
agents on the left and right  respectively  we are given degree
constraints dℓ
i and dr
i such that each i ∈ n ℓ and each j ∈ n r
can be matched to at most dℓ
i and dr
j agents on the opposite
side  respectively  when dℓ
i = dℓ
i′ for any i  i′ ∈ n ℓ  resp 
dr
j = dr
j′ for any j  j′ ∈ n r   we denote by dℓ  resp  dr  the
common degree constraint of all agents in n ℓ  resp  n r  
a  many-to-many  matching m is represented as a binary
nℓ × nr matrix  where m i  j  = 1 if i ∈ n ℓ and j ∈ n r
are matched  and m i  j  = 0 otherwise  with slight abuse
of notation  we denote m ℓ
i =  j ∈ n r   m i  j  = 1  and
m r
j =
�
i ∈ n ℓ   m i  j  = 1
�
as the sets of agents on the
opposite side that agents i ∈ n ℓ and j ∈ n r are matched
to  respectively  we say that m is valid if it respects the
degree constraints  i e   if |m ℓ
i | ≤ dℓ
i for each i ∈ n l and
|m r
j | ≤ dr
j for each j ∈ n r 
hereinafter  we omit the
term valid  but will always refer to valid matchings 
we
say that m is complete if �
i∈n ℓ |m ℓ
i | = �
j∈n r |m r
j | =
min �
i∈n ℓ dℓ
i  �
j∈n r dr
j   that is  a complete matching is
one in which either every agent on the left has their degree
constraint met exactly  or every agent on the right does 
each agent i ∈ n ℓ has a valuation function uℓ
i   n r →
r≥0 and each agent j ∈ n r has a valuation function ur
j  
n ℓ → r≥0  when agents i ∈ n ℓ and j ∈ n r are matched 
they simultaneously receive utilities uℓ
i j  and ur
j i   respec-
tively 
we assume that utilities are additive 
thus  with
3https //www nrmp org/
proceedings of the thirtieth    ijcai-21 
204
 slight abuse of notation  the utilities to agents i ∈ n ℓ and
j ∈ n r under matching m are uℓ
i m ℓ
i   = �
j∈m ℓ
i uℓ
i j  and
ur
j m r
j   = �
i∈m r
j ur
j i   respectively 
our main constructive results take only the agents  prefer-
ence orders as input  for agent i ∈ n ℓ  resp  j ∈ n r   we
denote by σℓ
i  resp  σr
j  a linear order over n r  resp  n ℓ 
which is consistent with the valuation function uℓ
i  resp  ur
j  
i e   j ≻σℓ
i j′ whenever uℓ
i j  > uℓ
i j′   resp  i ≻σr
j i′ when-
ever ur
j i  > ur
j i′   4 with a slight abuse of notation  we
denote with σℓ
i p   resp  σr
j p   the position of alternative p
in σℓ
i  resp  σr
j  
inspired by envy-freeness up to one good  ef1  from clas-
sical fair division  budish  2011  lipton et al   2004   we de-
fine the following fairness guarantee in our setting 
definition 1  double envy-freeness up to c matches
 defc    we say that matching m is envy-free up to c
matches  efc  over n ℓ if for each pair of agents i  i′ ∈ n ℓ 
there exists sℓ ⊆ m ℓ
i′ with |sℓ| ≤ c such that uℓ
i m ℓ
i   ≥
uℓ
i m ℓ
i′ \ sℓ   similarly  we say that it is efc over n r if  for
each pair of agents j  j′ ∈ n r  there exists sr ⊆ m r
j′ with
|sr| ≤ c such that uℓ
j m r
j   ≥ uℓ
j m r
j′ \ sr   we say that m
is defc if it is efc over both n ℓ and n r 
when an algorithm takes as input only the preference rank-
ings  it must ensure that the matching it returns is defc
for all possible valuation functions which could have in-
duced the rankings  it is easy to observe that this is equiv-
alent to satisfying the following stronger guarantee which
uses the stochastic dominance  sd  relation this is akin to
the sd-ef1 strengthening of ef1  freeman et al   2020 
aziz  2020  
definition 2  sd double envy-freeness up to c matches
 sd-defc    we say that matching m is sd-envy-free up to
c matches  sd-efc  over n ℓ if  for every t ∈  nr  
�t
p=0 m i  σℓ
i p   ≥ �t
p=0 m i′  σℓ
i p   − c  ∀i  i′ ∈ n ℓ 
and is sd-efc over n r if  for every t ∈  nℓ  
�t
p=0 m σr
j p   j  ≥ �t
p=0 m σr
j p   j′  − c  ∀j  j′ ∈ n r 
m is called sd-defc if it is sd-efc over both n ℓ and n r 
finally  we extend a different fairness notion from classical
fair division called the maximin share guarantee  mms  
definition
3
 α-double
maximin
share
guarantee
 α-dmms    let m denote the set of valid matchings 
the maximin share value of agent i ∈ n ℓ is defined as
mmsℓ
i = maxm∈m mini′∈n ℓ uℓ
i m ℓ
i′  
and the maximin share value of agent j ∈ n r is defined as
mmsr
j = maxm∈m minj′∈n r ur
j m r
j′  
given α ∈  0  1   matching m is called α-maximin share fair
 α-mms  over n ℓ if uℓ
i m ℓ
i   ≥ α·mmsℓ
i for every i ∈ n ℓ 
and α-mms over n r if ur
j m r
j   ≥ α · mmsr
j for every
j ∈ n r  it is called α-dmms if it is α-mms for both n r
and n r  when α = 1  we write dmms instead of 1-dmms 
4ties among agents with equal utility are broken arbitrarily 
the notions of  sd- def1 and dmms are incompara-
ble to the traditional notions of stability and justified envy-
freeness  as the following example shows 
example 1  suppose n ℓ = n r =  0  1  2  3   the com-
mon degree requirement is 2  and each side has identical or-
dinal preference 0 ≻ 1 ≻ 2 ≻ 3 over the other side  the
only matching that is stable and eliminates justified envy is
the one that matches each i ∈  0  1  on the left with every
j ∈  0  1  on the right  and each i ∈  2  3  on the left with
every j ∈  2  3  on the right  indeed  if some i ∈  0  1 
on the left is not matched to some j ∈  0  1  on the right 
then j must be matched to some i′ ∈  2  3  on the left  which
would make  i  j  a blocking pair  and i would  justifiably 
envy i′ for her match with j  however  this matching vio-
lates def1 when  for example  agent 2 on the left has more
value for agent 1 on the right than for agents 2 and 3 on the
right combined  as this would leave her envious of agents 0
and 1 on the left  even after ignoring their match to agent 0
on the right   note that this matching also violates dmms 
since each agent on the left could partition those on the right
into bundles  0  3    0  3    1  2    1  2   guaranteeing them-
selves a better bundle than the  2  3  that agents 2 and 3 re-
ceive  on the other hand  any one-to-one matching satisfies
 sd- def1 and dmms  but many one-to-one matchings are
not stable or free of justified envy 
3
double envy-freeness up to one match
in this section  we focus on double envy-freeness up to one
match  more specifically  its strengthening sd-def1  we be-
gin in section 3 1 by presenting an impossibility result that
holds even under quite restrictive conditions  then  in sec-
tion 3 2  we present an algorithm that efficiently computes
an sd-def1 matching whenever both groups of agents have
identical ordinal preferences  in the full version of the pa-
per  we present an additional positive result for the case that
all agents have maximum degree constraint equal to two  and
one side has identical preferences 
3 1
sd-def1 matchings may not exist
our first main result says that a complete sd-def1 matching
may not exist  observe that without the completeness condi-
tion an empty matching is trivially sd-def1 
theorem 1  a complete sd-def1 matching is not guaran-
teed to exist 
the proof of theorem 1  along with all other omitted
proofs  can be found in the full version of the paper  it uses
a counterexample in which both sides have the same number
of agents  that is  n ℓ = n r = n   all agents have the same
degree constraint  dℓ = dr = d   and one group of agents
have identical preferences  uℓ
i = uℓ
i′ for all i  i′ ∈ n ℓ   thus 
theorem 1 holds even in this restricted case  and continues to
hold for more general settings 
a natural question  that we leave open  is whether the
impossibility continues to hold when we relax sd-def1 to
def1  we have found no counterexamples  even for sd-
def1  via simulation  the counterexample for sd-def1 is
carefully crafted but relies on the strength of sd-def1 
proceedings of the thirtieth    ijcai-21 
205
 3 2
identical ordinal preferences on both sides
theorem 1 says that a complete sd-def1 matching is not
guaranteed to exist even under quite restrictive conditions  it
is natural to ask whether there exist any settings in which a
complete sd-def1 matching can be guaranteed  in the full
version of the paper  we establish the existence of a complete
sd-def1 matching by restricting the degree bound  with still
only one side having identical preferences   in this section 
we consider a different restriction  when agents on both sides
have identical preferences  i e   σℓ
i = σℓ
i′ for all i  i′ ∈ n ℓ and
σr
j = σr
j′ for all j  j′ ∈ n r 
theorem 2  when nℓdℓ = nrdr and both groups of agents
have identical ordinal preferences  a complete sd-def1
matching always exists and can be computed efficiently 
the proof of theorem 2 follows from a series of lem-
mas  in the main text we focus on the simple case for which
n ℓ = n r = n and dℓ = dr = d  theorem 2 follows from
progressively reducing the general case to this simple case 
we denote by σℓ and σr the ordinal preferences of the
agents in n ℓ and n r  respectively  without loss of general-
ity  assume that σℓ = σr = 0 ≻       ≻ n−1  we want to find
an sd-def1 matching under which each agent is matched to
exactly d agents on the opposite side  a natural idea is to let
agents on one side pick agents on the other side in a round-
robin fashion  that is  we construct an ordering r over agents
on one side  and these agents take turns according to r in a
cyclic fashion with each agent  in her turn  making one match
to her most preferred agent  i e  lowest indexed agent  on the
opposite side who has less than d matches so far  a standard
argument from classical fair division shows that regardless of
the ordering r  the resulting matching will be sd-ef1 over
over the side that does the picking 5 however  as the example
below shows  not all orderings r lead to a matching that also
satisfies sd-ef1 over the other side 
example 2  consider the case where n = 5 and d = 2 
suppose the ordering r has agents on the left choose in the
order 0  1  2  3  4  then  agent 0 on the right will be matched
to agents 0 and 1 on the left  while agent 1 on the right will
be matched to agents 2 and 3 on the left  sd-ef1 is violated
as agent 1 significantly envies agent 0 on the right side 
we now show that when r is carefully designed  sd-ef1
can also be satisfied over the other side  resulting in sd-
def1  algorithm 1 takes as input parameters a ∈  n  and
x ∈  d  n − d   and for any choices of these parameters  con-
structs an ordering r over the agents on  say  the left side 
algorithm 2 then uses this ordering to run the round-robin
procedure while respecting the degree constraints  example 3
demonstrates these algorithms 
example 3  consider the same instance as example 2  with
n = 5 and d = 2  suppose we choose a = 3 and x = d = 2 
then the round robin ordering returned by algorithm 1 is
r 0  = 3   0 = 3  setting i = 0   r 1  = 3   3 = 1  i = 3  
r 2  = 3   1 = 4  i = 1   r 3  = 3   4 = 2  i = 4  
5as observed by biswas and barman  2018   the standard round
robin algorithm is not ef1 when agents have cardinality constraints 
but ef1 is retained provided that agents have identical preferences 
algorithm 1 round-robin-ordering n  a  x 
1  // x and n coprime  so x−1  mod n  exists
2  for i ∈  n  do
3 
r p  = a   px−1  mod n 
4  end for
5  return r
algorithm 2 restricted-round-robin-coprime n  d 
1  choose a ∈  0          n − 1  and x ∈  d  n − d 
2  r =round-robin-ordering n  a  x 
3  // round-robin with ordering r over agents on the left
4  m i  j  = 0  ∀i  j ∈  n 
5  for j ∈  n   t ∈  d  do
6 
m r j · d   t  mod n    j  = 1
7  end for
8  return m
and r 4  = 3   2 = 0  i = 2   with all addition performed
mod n  that is  agents on the left choose in order 3  1  4  2  0 
this results in the matching m ℓ
3 =  0  2   m ℓ
1 =  0  3  
m ℓ
4 =  1  3   m ℓ
2 =  1  4   and m ℓ
0 =  2  4   equivalent
to the formula provided directly in line 6 of algorithm 2  
the fact that this is sd-ef1 over n ℓ is easy to check  ex-
amining the matching  note that m r
0 =  1  3  = m ℓ
4  m r
1 =
 2  4  = m ℓ
0  m r
2 =  0  3  = m ℓ
4  m r
3 =  1  4  = m ℓ
2 
and m r
4 =  0  2  = m ℓ
3  that is  the matchings received by
agents on the right are the same as those received by agents
on the left  up to a cyclic shift  for this matching  sd-ef1
over n ℓ immediately implies sd-ef1 over n r 
the next result shows that for any choices of the param-
eters  the resulting matching is sd-def1  the idea of the
proof is to show that the structure in example 3 holds in gen-
eral  for any allowed choice of  a  x   the set of bundles re-
ceived by agents on the right is the same as the set of bundles
received by agents on the left  thus inheriting sd-ef1 from
the fact that the matching is constructed by agents on the left
choosing in round robin sequence 
lemma 1  when nℓ = nr = n and dℓ = dr = d are co-
prime and both groups of agents have identical ordinal pref-
erences  algorithm 2 efficiently computes a complete sd-
def1 matching 
proof  to avoid the
 mod n  notation in this proof  we
will treat integers as belonging to the ring z/nz of integers
modulo n 
thus  addition  multiplication  and multiplica-
tive inverses will be modulo n  note that x−1 exists because
x ∈  d  n − d  =  d  −d  is coprime with n 
we claim that the ordering r constructed in algorithm 1
is a valid ordering over the agents in n ℓ  notice that because
x ∈  d  −d  is coprime with n   p · x−1 i∈ n  =  n   thus 
each position in the ordering r is mapped to exactly one
agent  because agents on the left take d turns in a cyclic fash-
ion  it is convenient to think of an extended ordering r which
is the original r concatenated with itself d times  one can
check that this still obeys r p  = a   px−1 for all p ∈  nd  
next  we argue that the matching returned is a valid com-
plete matching  notice that during the round-robin  d agents
proceedings of the thirtieth    ijcai-21 
206
 on the left that are consecutive in the ordering pick a given
agent on the right before moving on to the next lowest in-
dexed agent on the right  further  each agent on the left gets
d turns  hence  it is easy to see that every agent is matched to
exactly d agents on the opposite side 
as mentioned earlier  the fact that the returned matching m
is sd-ef1 over n ℓ follows directly from the standard round-
robin argument in classical fair division  given any pair of
agents i  i′ ∈ n ℓ  if we ignored the first turn taken by i′  then
in each round agent i would get a turn before agent i′ does 
and hence  would not envy agent i′ in the sd sense  it remains
to show that m is also sd-ef1 over n r  we show that for
each agent j ∈ n r  there exists an agent i ∈ n ℓ such that
m r
j = m ℓ
i   sd-ef1 over n r will then follow from sd-ef1
over n ℓ given that σℓ = σr 
let us focus on agent j ∈ n r  because agents on the right
are picked from lowest-indexed to highest-indexed  agent j is
picked by the d agents from n ℓ who appear consecutively in
the  extended  ordering r at indices jd   t for t ∈  d   given
that r p  = a   px−1 for all p ∈  nd   we immediately have
m r
j =
�
a    jd   t x−1   t =  d 
�
 
next  let us focus on agent i ∈ n ℓ  if she is matched
to some agent j ∈ n r in a particular turn  then from the
observation above  it must be that i = a    jd   t x−1
for some t ∈  d  
solving this for j  we get that j =
  i − a x − t d−1  varying t ∈  d  in this equation gets
us the d agents on the right that agent i is matched to 
m ℓ
i =
�
  i − a x − t d−1   t =  d 
�
 
to show that for each j ∈ n r  there exists i ∈ n ℓ with
m ℓ
i = m r
j   we take two cases 
if x = n − d = −d  then x−1 =  −d −1 = −d−1  in
this case  it is easy to check that taking i = j suffices as
m r
j = m ℓ
j =
�
a − j − td−1   t =  d 
�
 
if x = d  then m r
j =
�
j   a   td−1   t =  d 
�
  while
m ℓ
i =
�
i − a − td−1   t =  d 
�
=
�
i − a −  d − 1 − t d−1   t =  d 
�
 
notice that m r
j coincides with m ℓ
j 2a−d−1 1 
algorithm 2 executes round-robin with the left side taking
turns  and allows freely choosing a ∈  n  and x ∈  d  n − d 
to decide their ordering 
note that if the right side takes
turns instead  the algorithm still produces a complete sd-
def1 matching  however  this extension does not find any
new matchings  when x = n − d  the matching produced
is symmetric  m ℓ
i = m r
i for all i ∈  n    and thus the same
regardless of which side takes turns  when x = d  the allo-
cations on one side are cyclic shift of the allocations on the
other side  hence  any matching produced by the right side
taking turns can also be produced by the left side taking turns
with appropriately chosen  a  x  
what about allowing choices of x other than just d and
n − d  at least for n = 7  d = 3  and a = 0  it is easy
to check by hand that no other choices of x produce an sd-
def1 matching  on the other hand  could it be that some of
the 2n choices of  a  x  are redundant and lead to the same
matching as other choices  the following result shows that
in every instance  all 2n choices lead to different matchings 
proposition 1  for any inputs n and d to algorithm 2  the 2n
possible choices of  a  x  result in distinct matchings 
given proposition 1  one may be tempted to conjecture that
these 2n choices generate all complete sd-def1 matchings 
however  in the full version of the paper  we show that this is
not the case  leaving open the question of characterizing the
set of all complete sd-def1 matchings 
the proof of theorem 2 continues by reducing the case
where n and d are not coprime to the coprime case  letting
g = gcd n  d   we divide both sides into g sub-groups of
n′ = n/g agents each  then  we run algorithm 2 a total
of g2 times to match agents from each sub-group on the left
to d′ = d/g agents from each sub-group on the right  this
matches each agent with exactly d agents from the opposite
side  note that we allow each of the g2 calls to algorithm 2 to
use arbitrary choices of a and x  nonetheless  we show that
the resulting complete matching must be sd-def1 
lemma 2  when nℓ = nr = n  dℓ = dr = d  and both
groups of agents have identical ordinal preferences  a com-
plete sd-def1 matching always exists and can be computed
efficiently 
finally  we turn our attention to the general case in which
we drop the constraints nℓ = nr and dℓ
i = dr
j = d  we do
however require that nℓ · dℓ = nr · dr  the proof of theo-
rem 2  which appears in the full version of the paper  uses a
trick of adding dummy agents to the side with fewer agents 
computing an sd-def1 matching as per lemma 2  and then
removing the dummy agents  the key is to show that the re-
moval of dummy agents reduces the degrees of the agents on
the opposite side exactly as intended and sd-def1 is pre-
served 
we note that it is possible to extend our constructive result
slightly beyond the case of nℓ · dℓ = nr · dr  without loss
of generality  assume that nℓ · dℓ < nr · dr  first  note that
in this case  no matching is complete  we can still make the
degree of each agent on the left equal to dℓ  but the best we
can hope for is that the degrees of agents on the right differ
by at most 1  i e   they are either
�
nℓ·dℓ/nr�
or
�
nℓ·dℓ/nr�
 6 in
this case  the trick outlined in theorem 2 only works when
the dummy agents are added to the left side  i e   if nℓ ≤ nr 
we conjecture that such an sd-def1 matching always exists
even when nℓ > nr  but leave it as an open question 
4
double maximin share guarantee
in this section  we focus first on the existence of dmms
matchings  and second on the existence of matchings that are
dmms and sd-def1 concurrently 
we begin by considering the case where agents on both
sides have identical preferences  i e   uℓ
i j  = uℓ
i′ j   for any
pair of agents i  i′ ∈ n ℓ  and any j ∈ n r  and similarly
ur
j i  = ur
j′ i   for any pair of agents j  j′ ∈ n r and any
i ∈ n ℓ  we show the following negative result  which stands
in contrast to the one-sided fair division setting in which an
mms allocation is guaranteed to exist when agents have iden-
tical preferences 
6in case that nℓ·dℓ/nr is an integer  we can set this to be dr and
achieve exactly equal degrees on the right side too 
proceedings of the thirtieth    ijcai-21 
207
 theorem 3  a 0 89-dmms matching may not exist  even
when agents on both sides have identical preferences 
proof  we denote by uℓ and ur the cardinal preferences of
the agents in n ℓ and n r respectively  as the utilities are
the same across the agents in the same group  we can define
mmsℓ = mmsℓ
i for all i ∈  nℓ   and mmsr = mmsr
j
for all j ∈  nr  
consider the instance with n = nℓ = nr = 7 and
d = dℓ = dr = 3  uℓ j  = n − j − 1 for all j ∈  n  
and ur i  = n − i − 1 for all i ∈  n   thus  for any complete
matching  �
i∈n ℓ uℓ m ℓ
i   = �
j∈n r ur m ℓ
j   = 63  this
means that mmsℓ = mmsr ≤ 9  because if all agents
receive equal utility then they each get utility 9  next  we
construct a matching m such that uℓ m ℓ
i   = 9 for all i ∈  n  
without loss of generality  assume that m ℓ
0  m ℓ
1  and m ℓ
2
all contain agent 0  then  we know that agents 1 and 2 cannot
be contained in these bundles  because then they would have
value larger than 9  implying that some other agent receives
utility less than 9  without loss of generality  we assume
that bundles m ℓ
3  m ℓ
4  and m ℓ
5 contain agent 1  now  we
observe that m ℓ
6 =  2  3  4   as there is no other way to have
uℓ m ℓ
6  = 9  as 0 and 2 can not belong to the same bundle
 such a bundle would be valued at least 10   we may assume
without loss of generality that agent 2 is contained in m ℓ
3  and
m ℓ
4  then  the constraint that uℓ m ℓ
3  = uℓ m ℓ
4  = 9 dic-
tates that m ℓ
3 = m ℓ
4 =  1  2  6   with these bundles fixed 
it is easy to check that the only m ℓ
5 that yields uℓ m ℓ
5  = 9
is m ℓ
5 =  1  3  5   lastly  without loss of generality  we may
assume that m ℓ
0 = m ℓ
1 =  0  4  5   and m ℓ
2 =  0  3  6  
hence  we conclude that the following matching is the only
one  subject to permutations of n ℓ  that satisfies mms for
agents on the left 
• m ℓ
0 = m ℓ
1 =  0  4  5 
• m ℓ
2 =  0  3  6 
• m ℓ
3 = m ℓ
4 =  1  2  6 
• m ℓ
5 =  1  3  5 
• m ℓ
6 =  2  3  4 
now  consider agents 0 ∈ n r and 4 ∈ n r  both are matched
to agents 0 ∈ n ℓ and 1 ∈ n ℓ  but agent 0 ∈ n r is matched
to agent 2 ∈ n ℓ while agent 4 ∈ n r is matched to agent
6 ∈ n ℓ  therefore  ur m r
0   ̸= ur m r
4    and this difference
persists regardless of permutations of n ℓ   it is therefore not
the case that every agent on the right receives utility 9  in
particular  one agent receives utility 8 or less  producing the
approximation ratio α = 8/9 < 0 89 
while a dmms matching may not exist  even when pref-
erences are identical  we can exploit the algorithms presented
in section 3 to obtain an approximation to dmms 
theorem 4  when nℓdℓ = nrdr and both groups of agents
have identical utilities  every complete sd-def1 matching
m is also 1
dℓ -mms over n ℓ  and
1
dr -mms over n r 
we next show an almost-matching upper bound that can
be achieved by any sd-def1 matching  to complement the-
orem 4  in fact  we show a more general result that trades
off the approximation to dmms with the approximation to
double envy-freeness 
theorem 5  there exists an instance with nℓ = nr = n and
dℓ = dr = d in which no matching is simultaneously c 2
d -
dmms and sd-defc for any c ∈  d  
finally  we show that a strong impossibility persists even if
we only require sd-ef1 on one side and mms on the other 
theorem 6  a matching that satisfies sd-ef1 over n ℓ and
mms over n r is not guaranteed to exist  even when agents
on both sides have identical preferences 
5
discussion
we have introduced a model that bridges two-sided match-
ing and fair division by requiring fairness on both sides of
a matching market 
we have shown that sd-ef1 can be
achieved for agents on both sides  when all agents on the left
side and all agents on the right share a common ordinal pref-
erence ranking over agents on the other side  when this con-
dition is not satisfied  there may exist no matching that satis-
fies sd-def1  we have also shown that there may not exist a
doubly mms matching even when agents have identical pref-
erences  while we do not rule out a good approximation to
dmms  we show that it is essentially impossible to obtain a
good approximation to dmms if one also requires sd-def1 
it is interesting to note that the proofs of theorems 4 and 5
do not rely on the constraints that an agent in n ℓ can have up
to d matches  and can be matched with an agent in n r at most
once  therefore  these theorems also hold in a one-sided fair
division problem where there are n agents and n/d items with
d copies each  and all the agents have identical preferences 
many interesting avenues for future research remain  for
example  one can hope to derive weaker positive results in
the case where one side has identical preferences  when the
side with identical preferences does the picking  algorithm 2
remains ef1 for that side  in the full version of the paper  we
conduct empirical simulations and observe that algorithm 2
remains ef1 for some of the agents on the other side as well
 and does better than the classical round-robin algorithm in
this aspect  
it would also be interesting to compare the
two-sided fair division setting with its one-sided counterpart
 where only one side has preferences and we seek fairness
only for this side   in our simulations  we observe that there
is a sharp contrast for envy-freeness  one-sided ef is almost
always achievable while two-sided def almost always isn t  
for the maximin share guarantee  however  there is no con-
trast  both one-sided mms and two-sided dmms are almost
always achievable  theoretically analyzing the probability
of satisfiability of these notions in random instances would
be an interesting direction for the future  one can also con-
sider two-sided versions of other fairness notions  including
those that remain interesting when the degree constraint is 1 
which could yield further interesting results in the one-to-one
or many-to-one settings  finally  it would also be interesting
to derive positive results when each agent can have a different
degree constraint 
proceedings of the thirtieth    ijcai-21 
208
 references
 abdulkadiro˘glu and s¨onmez  2003  a  abdulkadiro˘glu and
t  s¨onmez  school choice  a mechanism design approach 
american economic review  93 3  729–747  2003 
 abdulkadiro˘glu et al   2005  a 
abdulkadiro˘glu 
p a 
pathak  a e  roth  and t  s¨onmez 
the boston public
school match 
american economic review  95 2  368–
371  2005 
 aigner-horev and segal-halevi  2019  e 
aigner-horev
and e  segal-halevi 
envy-free matchings in bipartite
graphs and their applications to fair division 
arxiv
preprint arxiv 1901 09527  2019 
 aziz  2020  h  aziz  simultaneously achieving ex-ante and
ex-post fairness  in proc  of 16th wine  pages 341–355 
2020 
 beynier et al   2019  a 
beynier 
y 
chevaleyre 
l  gourv es  a  harutyunyan  j  lesca  n  maudet 
and a  wilczynski 
local envy-freeness in house allo-
cation problems 
autonomous agents and multi-agents
systems  33 5  591–627  2019 
 biswas and barman  2018  a  biswas and s  barman  fair
division under cardinality constraints  in proc  of 27th ij-
cai  pages 91–97  2018 
 budish and cantillon  2012  e  budish and e  cantillon 
the multi-unit assignment problem  theory and evidence
from course allocation at harvard 
american economic
review  102 5  2237–71  2012 
 budish  2011  e  budish 
the combinatorial assign-
ment problem 
approximate competitive equilibrium
from equal incomes 
journal of political economy 
119 6  1061–1103  2011 
 caragiannis et al   2019  i 
caragiannis 
d 
kurokawa 
h  moulin  a d  procaccia  n  shah  and j  wang  the
unreasonable fairness of maximum nash welfare  acm
transactions on economics and computation  teac  
7 3  1–32  2019 
 echenique and oviedo  2006  f  echenique and j  oviedo 
a theory of stability in many-to-many matching markets 
theoretical economics  1 2  233–273  2006 
 foley  1967  d  foley  resource allocation and the public
sector  yale economics essays  7 45–98  1967 
 freeman et al   2020  r  freeman  n  shah  and r  vaish 
best of both worlds  ex-ante and ex-post fairness in re-
source allocation  in proc  of 21st ec  pages 21–22  2020 
 gale and shapley  1962  d  gale and l s  shapley  college
admissions and the stability of marriage  americal math-
ematical monthly  69 1  9–15  1962 
 gan et al   2019  j 
gan 
w 
suksompong 
and
a a 
voudouris  envy-freeness in house allocation problems 
mathematical social sciences  101 104–106  2019 
 gollapudi et al   2020  s 
gollapudi 
k 
kollias 
and
b  plaut  almost envy-free repeated matching in two-sided
markets  in proc  of 16th wine  pages 3–16  2020 
 hatfield et al   2011  j w  hatfield  f  kojima  y  narita 
et al 
promoting school competition through school
choice  a market design approach 
stanford  stanford
university capital and economic opportunity working
group working paper  18 2011  2011 
 kurokawa et al   2016  d  kurokawa  a d  procaccia  and
j  wang  when can the maximin share guarantee be guar-
anteed  in proc  of 30th aaai  pages 523–529  2016 
 lipton et al   2004  r j  lipton  e  markakis  e  mossel 
and a  saberi  on approximately fair allocations of in-
divisible goods  in proc  of 6th ec  pages 125–131  2004 
 othman et al   2010  a  othman  t  sandholm  and e  bud-
ish  finding approximate competitive equilibria  efficient
and fair course allocation  in proc  of 9th aamas  pages
873–880  2010 
 patro et al   2020  g k  patro  a  biswas  n  ganguly  k p 
gummadi  and a  chakraborty  fairrec  two-sided fair-
ness for personalized recommendations in two-sided plat-
forms  in proc  of 29th www  pages 1194–1204  2020 
 procaccia and wang  2014  a d  procaccia and j  wang 
fair enough  guaranteeing approximate maximin shares 
in proc  of 14th ec  pages 675–692  2014 
 roth and sotomayor  1992  a e  roth and m  sotomayor 
two-sided matching  handbook of game theory with eco-
nomic applications  1 485–541  1992 
 roth  1984  a e  roth  stability and polarization of inter-
ests in job matching  econometrica  journal of the econo-
metric society  pages 47–57  1984 
 saidman et al   2006  s l  saidman  a e  roth  t  s¨onmez 
m u  ¨unver  and f l  delmonico  increasing the opportu-
nity of live kidney donation by matching for two and three
way exchanges  transplantation  81 773–782  2006 
 sotomayor  1999  m  sotomayor 
three remarks on the
many-to-many stable matching problem 
mathematical
social sciences  38 1  55–70  1999 
 s¨uhr et al   2019  t  s¨uhr  a j  biega  m  zehlike  k p 
gummadi  and a  chakraborty  two-sided fairness for re-
peated matchings in two-sided markets  a case study of a
ride-hailing platform  in proc  of the 25th sigkdd  pages
3082–3092  2019 
 tadenuma  2011  k  tadenuma  partnership  solidarity  and
minimal envy in matching problems  in social ethics and
normative economics  pages 155–167  springer  2011 
 wu and roth  2018  q  wu and a e  roth  the lattice of
envy-free matchings 
games and economic behavior 
109 201–211  2018 
 yokoi  2020  y  yokoi 
envy-free matchings with lower
quotas  algorithmica  82 2  188–211  2020 
proceedings of the thirtieth    ijcai-21 
209
 "
None,2021,https-www-ijcai-org-proceedings-2021-0030-pdf,Worst-case Bounds on Power vs. Proportion in Weighted Voting Games with Application to False-name Manipulation,"Yotam Gafni, Ron Lavi, Moshe Tennenholtz",None,https://www.ijcai.org/proceedings/2021/0030.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0030-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0030-pdf.pdf,"worst-case bounds on power vs  proportion in weighted voting games with an
application to false-name manipulation
yotam gafni1   ron lavi1 2   moshe tennenholtz1
1 technion - israel institute of technology
2 university of bath  uk
 yotam gafni@campus  ronlavi@ie  moshet@ie  technion ac il
abstract
weighted voting games are applicable to a wide
variety of multi-agent settings 
they enable the
formalization of power indices which quantify the
coalitional power of players  we take a novel ap-
proach to the study of the power of big vs  small
players in these games  we model small  big  play-
ers as having single  multiple  votes  the aggregate
relative power of big players is measured w r t  their
votes proportion  for this ratio  we show small con-
stant worst-case bounds for the shapley-shubik and
the deegan-packel indices  in sharp contrast  this
ratio is unbounded for the banzhaf index  as an ap-
plication  we define a false-name strategic normal
form game where each big player may split its votes
between false identities  and study its various prop-
erties  together our results provide foundations for
the implications of players  size  modeled as their
ability to split  on their relative power 
1
introduction
weighted voting games  wvgs  are a class of cooperative
games that naturally appear in diverse settings  such as par-
liaments  councils and firm shareholders  in recent years  they
were found to naturally appear in multi-agent systems such as
vcg auctions  bachrach et al   2011  and other online eco-
nomic systems  wvgs are defined by a set of players  their
weights  and a threshold t  a set of players forming a coali-
tion must have an aggregate weight of at least t  it is natural
to ask  what is a player s power to influence decisions  or  al-
ternatively  what is a player s share of the benefit of forming
a coalition  this power measure does not necessarily comply
with the player s proportional weight  for example  consider
a wvg with a large threshold t  a big player with weight
t − 1 and a small player with weight 1  despite the large
discrepancy in their weights  a consensus is required for any
motion to pass  suggesting they have equal power  this view
of power considers a player s pivotal role as  king-maker –
 to the victors go the spoils  
due to this reason  cooperative game theory studies power
indices to capture the true effective power of players in
wvgs  this literature views the power index of a player
as a numeric predictor of utility  the most prominent power
indices include the shapley-shubik index  shapley and shu-
bik  1954  which stems from the more general shapley value
 shapley  1952   and the banzhaf index  banzhaf iii  1964  
other power indices emphasize different aspects of the power
structure  such as the deegan-packel index  deegan and
packel  1978   which we also study  our work lies in the
intersection of three strands of wvg literature 
1 1
big vs  small players and group power
we lay out a wvg model with big vs  small players and
study the power of big players compared to their vote propor-
tion  assuming that all player weights are natural numbers and
consider all players with weight larger than 1 as  big  and all
players with weight 1  small   the inequality in voting –  big
vs  small  – is a main drive for the study of power indices  go-
ing back to the formation of the us electoral college  riker
 1986  points out that luther martin of maryland  a staunch
anti-federalist and one of the us founding fathers  analyzed
the then forming electoral college in a manner similar to the
banzhaf index  in the compilation by storing  2008   p  50 
martin claims 
the number of delegates ought not to be in exact
proportion to the number of inhabitants  because
the influence and power of those states whose del-
egates are numerous  will be greater  even relative
to their proportion  when compared to the influence
and power of the other states   
the contrast between big vs  small players exists not only in
traditional voting settings but also in modern contexts  for
example  we see multiple situations in which several small
websites  where here  small  is in terms of their number of
users  aggregate their market power by forming a unified ser-
vice platform to compete with a big incumbent website  sim-
ilarly we see aggregation of computational power  e g   min-
ing pools in bitcoin  consortia of cloud computing services  
the other direction of a big player splitting itself to multiple
small identities also exists  even when such a split is costly
in terms of advertising and maintaining the brand  e g   flight
search engines and web hosting services 
shapley and shubik  1954  demonstrate that in the settings
of one big player and many small players  the power of the
big player can be higher than its proportional weight  they
do not answer  nor ask  the question of how large this ratio
can be  they also do not analyze the opposite direction  of
proceedings of the thirtieth    ijcai-21 
210
 whether this ratio is bounded below by some constant  possi-
bly smaller than 1  as we explain below  our results general-
ize and answer these questions  beyond the case of one big
player and many small players  which we completely charac-
terize  our model and results extend in two aspects 
• arbitrary number of big  and small  players - we obtain
results regarding the power vs  proportion of any spe-
cific one big player and regarding the aggregate power
of big players  as the distinction to big and small im-
mediately suggests  the relative power of these groups
now becomes the focus  examples for such groups are
the top 1  wealthy people  the g7 countries  bitcoin s
large miners  these settings typically involve a few big
players and many small players  milnor and shapley
 1978  and neyman  1981  take this to an extreme by
considering so-called  oceanic games  where there are
a few significant large players and a continuum of small
players  in contrast  our results are not asymptotic and
hold for any arbitrary number of big and small players 
• the banzhaf and deegan-packel indices - since differ-
ent power indices structuring naturally encapsulates dif-
ferent aspects of strategic power  it is important to com-
pare the results of different indices given our model  and
more so as the banzhaf index gives qualitatively differ-
ent results than the other indices 
1 2
power vs  proportion
our main theoretical results  given in sections 3-5  character-
ize the ratio between the aggregate power of the big players
and their aggregate proportional weight for different power
indices 
most previous literature analyzes ways to adjust
voters  voting weights in order to equate voting power to
actual weight 
an early suggestion by  penrose  1946  is
that  in the un  states should be assigned seats proportional
to the square root of their population  in order to achieve
proportional representation for each citizen  worldwide  re-
gardless of her state   słomczy nski and zyczkowski  2006 
słomczy nski and ˙zyczkowski  2007  further suggest an im-
provement in the form of the double square root voting sys-
tem  where on top of assigning seats proportional to the
square root  the voting threshold  quota  of the representative
body itself is determined so to optimize proportionality 
more recently  attention was drawn to whether a good
choice of voting threshold  quota  can attain proportion-
ality  zick et al   2011  zick  2013  oren et al   2014 
bachrach et al   2016b  bachrach et al   2016a   theoreti-
cal guarantees  experimental results  and probabilistic mod-
els were suggested  for which this occurs  for example  these
works collectively establish that under some probabilistic as-
sumptions  setting the threshold t to be about 50  of the to-
tal sum of weights results in power being equal to proportion
with high probability  in contrast  our worst-case analysis of
this problem does not depend on probabilistic assumptions
that might not hold in reality  due to the independence as-
sumptions or specific properties of the distributions  we also
show examples where the threshold is very close to 50  and
the power is far from proportional  in addition  it may not be
possible to tune the threshold t because of exogenous dictates
 e g   important parliament votes  where a two-thirds major-
ity is required  or because the model aims to capture some
underlying reality  e g   over the internet  that constrains t 
a third approach focuses on probabilistic modelling of the
wvg weights  for example  jelnov and tauman  2014  show
that if player weights are sampled uniformly from the unit
simplex  the expected shapley-shubik power of a player rel-
ative to its proportion goes to 1 with rapid convergence in
the number of players  lindner and machover  2004  study a
different model where the ratio of the shapley-shubik index
to proportional weight in infinite chains of game instances
asymptotically approaches 1  chang et al   2006  follow up
with an experimental analysis of a similar model thus further
verifying the previous conceptual conclusions 
1 3
false-name manipulation in wvg
as an application of our main results for power vs  propor-
tion  we define in section 6 a false-name strategic normal-
form game where each big player may split its votes between
false identities  aziz et al   2011  are the first to study power
indices in the context of false-name manipulation  showing
upper and lower bounds on a player s gain  or loss  from
splitting its votes into two parts  for the shapley-shubik and
banzhaf indices  they also address a range of computational
issues  among them the decision problem of splitting into two
equal parts which is np-hard for both indices  faliszewski
and hemaspaandra  2009  show that the decision problem of
benefiting from splitting into two equal parts to be in pp  and
rey and rothe  2014  show it is pp-complete for the shapley-
shubik index  pp-complete for the banzhaf index with three
equal splits  and pp-hard for both indices with general splits 
our results contribute to the above literature on false-name
splits by unifying it with the two previously mentioned as-
pects   big vs  small  and  power vs  proportion   and by gen-
eralizing on two additional fronts 
• general splits - we consider splits into multiple identi-
ties  rather than splits into two or three identities  la-
sisi and allan  2017  initiated work on this more gen-
eral problem  where they show some upper and lower
bounds for the individual power gain from general splits
compared to the original power  these bounds assume
that only a single agent splits  where as the bounds we
provide hold under any combination of strategic manip-
ulations by the agents 
• global bounds on manipulation - by our results for the
power vs  proportion we extract useful global bounds on
manipulation  regularly power is compared before and
after splits  since previous work shows the most basic
questions in regard to successful power manipulation to
be computationally hard  developing global performance
bounds is important 
2
preliminaries
weighted voting games  wvgs   starting with weighted ma-
jority games  morgenstern and von neumann  1953  shapley 
1962   aim to capture a situation where several players need
to form a coalition  each player has a weight  and a subset
of players can form a coalition if their sum of weights passes
proceedings of the thirtieth    ijcai-21 
211
 a certain threshold  in this paper  we make a distinction be-
tween  big  versus  small  players  where small players have
a weight of one  formally 
definition 1   adapted from shapley  1962   a weighted vot-
ing game is a tuple  a  m  t  with
a =  a1       ar   m =
m
�
��
�
 1       1  
1 ≤ t ≤ m  
r
�
j=1
aj 
where a1       ar  m  t ∈ n  there are r  big players   m
 small players  of weight 1  and a coalition threshold t 1
we at times denote the small players as 11     1m  note that
a is a multiset  when we write a \  i   for some weight i  at
most one occurrence of i is removed from a 
a basic question in wvgs is how to split the gains from
forming a coalition among its members  one possible notion
of fairness is to split gains in a way that is approximately
proportional to the weights of the coalition members 
definition 2  the proportional value of a weighted voting
game is p a  m  t  =
r�
j=1
aj
m  
r�
j=1
aj
 
however reality tells us that many times the  power  of
players is different than their proportional weight  a well-
established literature on power indices formally studies this
by looking at our setting as a cooperative game  for the anal-
ysis we have the following value function v s  which de-
scribes whether a subset of players s ⊆ a ∪ m is able to
form a coalition 
v s  =
�1
�
s∈s
s ≥ t
0
otherwise 
we next compare the aggregate power of the big players  us-
ing several three well-known power indices  to their aggregate
proportional weight 
3
the shapley-shubik power index
define the ordered tuple a   m =  a1       ar  11       1m  
let sm r be the group of all permutations operating on m  
r objects  for some σ ∈ sm r  σ a   m  is the ordered
tuple which results by applying the permutation σ to a   m 
we usually omit the term a   m when it is clear from the
context  define σ|p  ¯σ|p as the set of all players  strictly  non-
strictly  preceding player p in permutation σ a   m   the
permutation pivotal player indicator function for a player p is
1p σ = v ¯σ|p  − v σ|p  
1there is some loss of generality by fixing the parameters ai  t
to be exact multiples of the weight of the small player  our model
can be slightly generalized as follows  let s be some minimal
weight corresponding to some operational or regulatory minimal
size of a venture  or to an electoral threshold for parliaments  any
player with an integer weight s ≤ w < 2s is termed  small  as
small players are the ones that cannot split  the model as presented
corresponds to the case s = 1 for tractability and readability but we
believe that our results hold for the more general model as well 
in words  the indicator 1p σ is equal to one if the players pre-
ceding p in the permutation σ a m  do not form a coalition
and adding p enables the coalition formation  in such a case 
we say that p is pivotal for σ  note that 1p σ ∈  0  1  and
that each permutation has exactly one pivotal player 
definition 3   adapted from  winter  2002   the shapley-
shubik power index of a weighted voting game  a m t  is
φp a  m  t  = eσ∼uni sm r  1p σ  
for a player p  whether a big player ai or a small player 1i  
where uni is the uniform distribution over a discrete set 
this definition is a special case of the shapley value applied
to wvgs  three well-known properties of this power index
are symmetry  efficiency  and non-negativity  which we utili-
tize in our proofs 
definition 4  the shapley-proportional ratios are the global
supremum  infiumum  over all weighted voting games
¯rφ = sup
a m t
r�
j=1
φaj a  m  t 
p a  m  t 
  rφ = inf
a m t
r�
j=1
φaj a  m  t 
p a  m  t 
 
note that rφ ≥ 0 because of non-negativity 
example 1   ¯rφ is at least 2   for some k ≥ 2  consider
a =  k   m = k − 1  t = k  then φa1 a  m  t  = 1  while
p a  m  t  = 1
2  
1
4k−2 
in fact  this asymptotic lower bound is tight 
theorem 1  ¯rφ = 2 
to prove theorem 1  we first show in lemma 1 a recursive
relation for the shapley-shubik index  we are then able to
give an inductive proof of theorem 1  to appear in the full
version of this paper 
lemma 1  the following recursion holds for φ1
φ1 a  m  t  =
�
�
�
�
�
�
�
�
�
�
�
�
�
�
�
�
�
�
�
1
m   r
t = 1
1
m   r
� �
1≤i≤r
ai<t
φ1 a\ ai   m  t − ai  
 m−1 φ1 a  m−1  t − 1 
�
t > 1
the following example shows that rφ = 0 
example 2  for any k ≥ 2  choose a =  k   m = k  t =
2k  then φa1 a  m  t  =
1
k 1 while p a  m  t  = 1
2 
in example 2  a big player has less power in terms of the
shapley-shubik index than its proportional weight  in the
next example the opposite holds 
example 3  for a single player  it may hold that its individual
power to proportional weight ratio is unbounded  consider
a =  2  k   m = 1  t = k   3  then φa1 a  m  t  = 1
3
while
a1
m 
r
�
j=1
aj
=
2
k 3 
nevertheless  there does exist an upper bound on the
shapley-shubik index of any individual big player 
theorem 2  φai a  m  t  ≤
ai
m   r 
proceedings of the thirtieth    ijcai-21 
212
 4
the banzhaf index
we show a contrary result for the banzhaf index  banzhaf iii 
1964   where an asymptotic example has an unbounded ratio
of aggregate big players  power over their proportion 
definition 5   see  dubey and shapley  1979   let p s  be
the power set of s  and uni be the uniform distribution over
a discrete set  the absolute banzhaf index of a wvg is 
β′
ai a  m  t  = es∼uni p  a\ ai ∪m   v s ∪  ai   − v s  
β′
1 a  m  t  = es∼uni p  a∪m\ 1    v s ∪  1   − v s    
the normalized banzhaf index is 
βai =
β′
ai a  m  t 
r
�
j=1
β′
aj   mβ′
1 a  m  t 
 
while the shapley-shubik index gives equal probabilities
to all permutations over players  the banzhaf index gives
equal probabilities to all subsets of players  the normaliza-
tion is needed to achieve the efficiency property  where sum-
mation over the indices of all players sums up to exactly one 
the absolute banzhaf indices may sum to less or more than
1  for an individual absolute banzhaf index  by definition
β′
ai a  m  t  ≤ 1
 1 
definition 6  the banzhaf-proportional ratios are the global
supremum over all wvgs
¯rβ′ = sup
a m t
r
�
i=1
β′
ai a  m  t 
p a  m  t 
 
a similar definition holds for ¯rβ 
while the power of the big players cannot be much larger
than their proportional weight according to the shapley-
shubik index  the bhanzaf index gives a different result 
theorem 3  ¯rβ′  ¯rβ are unbounded 
the proof of theorem 3  given in the full version of the
paper  shows that the ratio in the following example goes to
infinity with k 
example 4  consider a =  2k   m = k1 5  t = 2k k1 5
2
 
then for k = 1600  we have
p a  m  t =
3200
3200 16001 5 = 1
21  β′
a1 a  m  t ≈0 999999 
the intuition for the calculation is as follows  since there
is only one big player  and all other players have a weight
of one  only the size of the subset of other players matters
for the index  choosing a subset s of small identical players
with uniform probability is like letting each small player par-
ticipate in the chosen subset with probability 1
2  a bernoulli
trial   so  the size of the subset is sampled from the binomial
distribution with parameters b m  1
2   measure concentra-
tion properties of the symmetric binomial distribution around
its mean imply that with high probability the size of the sam-
pled set is close enough to m
2 so that the big player in the
example is pivotal  details of this calculation can be directly
extracted from the argument in the proof of theorem 3  the
normalized banzhaf index is for these parameters is 
βa1 a  m  t ≈
0 999999
0 999999 16001 5 · 3 52795 ∗ 10−33 ≈1 
this yields 21 for both the ratio of absolute banzhaf to
proportion and normalized banzhaf to proportion 
example 4 is in the spirit of section b of  penrose  1946 
and the asymptotic results analysed in section 7 of  dubey
and shapley  1979   as far as we know  the exact bound that
we derive along with its the formal analysis are new 
theorem 7 of  aziz et al   2011  states that if a single
player splits her votes between exactly two identities  its
power as measured by the banzhaf index cannot increase by
a factor larger than 2  in contrast  theorem 3 above shows
that  with general splits  a player might end up decreasing its
power by an unbounded factor  this paints an overall non-
favorable picture for false-name manipulations as measured
by the banzhaf index 
5
the deegan-packel index
definition 7  an all-pivotal set in a wvg is a set s such that
for any player s ∈ s  v s  − v s \ s  = 1  let the set of
all-pivotal subsets be ap  the deegan-packel index is 
ρai a  m  t  = es∼uni ap  
�1ai∈s
|s|
�
 
where uni is the uniform disribution over a discrete set 
thus  the deegan-packel index is similar to the banzhaf
index but takes into account only the all-pivotal subsets that
are  in a sense  the minimal coalitions  it also considers the
size of the coalition  so a participation in a large coalition
results in less  power  than being a part of a small coalition 
one can verify that this index is efficient  i e   the sum of
indices of all players is always exactly one 
definition 8  the deegan-packel-proportional ratio is the
global supremum over all wvgs
¯rρ = sup
a m t
r�
i=1
ρai a  m  t 
p a  m  t 
 
example 5  ¯rρ ≥ 2  let a =  k   m = k −1  t = k  then
ρa1 a  m  t  = 1  while p a  m  t  =
k
2k−1 
theorem 4  ¯rρ ≤ 3 
the theorem follows from lemmas given in appendices e f 
it exploits properties of the all-pivotal coalition in two thresh-
old regimes  if the threshold is large  we show that enough
small players must participate in an all-pivotal coalition  mak-
ing the relative power of the big players in such a coalition
small  if the threshold is small  we are able to use algebraic
manipulations over binomials to derive the bound 
proceedings of the thirtieth    ijcai-21 
213
 6
a power index false-name game
in this section  we consider a framework general to all power
indices under the possibility of votes split by big players in
the voting game 
our discussion focuses on the shapley-
shubik power index  where we give a conjecture with em-
pirical results  we begin with a notation  given a natural
number a  define the integer partitions of a as
partitions a  =
a�
i=1
�
�
� b1       bi 
����
i
�
j=1
bj = a  ∀i
j=1bj ∈ n
�
�
�
in words  the partitions of a are all the different sets of natu-
ral numbers such that their sum is a  note that we allow sev-
eral big players to split into multiple identities each  which
is stronger than many other incentive analyses of false-name
attack where only one strategic player is considered 
definition 9  the false-name weighted voting game for a
power index α ∈  φ  β  ρ    let  a  m  t  be a wvg 
we define a non-cooperative game with |a| strategic play-
ers  which are the big players in the wvg   the strategy
space of each strategic player is partitions ai  
given
strategies si =  b1
i        bci
i   for 1 ≤ i ≤ r  let b =
 b1
1       bc1
1        b1
r       bcr
r    the payoff for player i is
uα
i  s1       sr  =
ci
�
j=1
αbj
i  b  m  t  
let c =
r�
i=1
ci stand for the total number of elements in b 
we wish to understand how the option to split  submit
false-name bids  changes the power of the strategic players 
the previous section sheds light on this question 
theorem 5  when α = φ  the shapley-shubik index   then
for any tuple of strategies s1       sr 
r
�
i=1
uφ
i  s1       sr  ≤ 2p a  m  t  
in particular  this happens in any mixed or pure nash or cor-
related equilibrium of the game 
a similar result holds for the deegan-packel power index 
proof  by theorem 1  considering b as determined by the set
of strategies s1       sr as the set of big players in the theorem
 and where the number of big players is c   we have
r
�
i=1
ci
�
j=1
φbj
i  b  m  t  ≤ 2
r�
i=1
ci
�
j=1
bj
i
m  
r�
i=1
ci
�
j=1
bj
i
= 2
r�
j=1
aj
m  
r�
j=1
aj
 
thus  strategically splitting vote weights using false-name
manipulations cannot increase the overall power of the big
players to be more than double their proportional weight  on
the other hand  we conjecture that such strategic manipula-
tions cannot harm their overall shapley-shubik power 
conjecture 1  for the shapley-shubik index φ with any
weighted voting game  a  m  t  and a choice of strate-
gies resulting in a corresponding weighted voting game
 b  m  t   it holds that
r
�
i=1
φai a  m  t  ≤ 2
r
�
i=1
ci
�
j=1
φbj
i  b  m  t  
remark 1 
• section 6 2 supports the conjecture with empirical re-
sults obtained by an exhaustive search over small wvgs 
• theorem 1 is a special case of the conjecture  where
each player i s strategy choice is
ai
�
��
�
 1       1  
• theorem 6 of  aziz et al   2011  states that a single
player that splits her votes to exactly two identities can-
not decrease its shapley-shubik index by more than a
factor of n 1
2   our conjecture gives a much stronger
bound for the aggregate power of big players  the worst
decrease of aggregate power  caused by any combina-
tion of splits  is by a constant factor of 2 
combining theorem 5 and conjecture 1 yields 
corollary 1  for all strategies s1       sr in the shapley false-
name wvg  a  m  t   if conjecture 1 holds 
1
2
r
�
i=1
φai a  m  t  ≤
r
�
i=1
uφ
i  s1       sr  ≤ 2p a  m  t  
to conclude  false-name attacks can unboundedly increase
the aggregate shapley-shubik power index of the big play-
ers  e g   by splitting to singletons  example 2   however 
no attack can increase the power to more than twice the
power resulting from the simple attack of splitting to single-
tons  theorem 5   false-name attacks can also decrease the
shapley-shubik index  example 1   however  we believe  as
expressed in conjecture 1  that no false-name attack can de-
crease the aggregate shapley-shubik power to be less than
one-half of the original power 
6 1
the worst-case effects of false-name
manipulation for a single player
while the total utility of the big players is conjectured to not
lose much by splits  a single player may multiplicatively lose
arbitrarily much in b compared to a  this is evident by ex-
ample 3  but we give two additional examples that do not re-
quire all players to fully split  in the first example  the player
that chooses not to split loses by this choice  in the second
example  the player that chooses to split loses by this choice 
example
6 
consider
a
=
 k  k  k   b
=
 k 
k
� �� �
1       1 
k
� �� �
1       1   m = k  t = 4k  then
φa1 a  m  t  =
1
k   3
φb1
1 b  m  t  =
1
3k   1 
thus  with k ≥ 6  the ratio is higher than 2  the exam-
ple can be generalized to exceed any bound r  with a =
r 1
�
��
�
 k       k   b = k 
r
�
��
�
k
� �� �
1       1      
k
� �� �
1       1   m=k  t = r   2 k 
proceedings of the thirtieth    ijcai-21 
214
 example 7  consider a =  k  k   b =  
k
� �� �
1       1  k   m =
0  t =k 1  then
φa1 a  m  t  = 1
2 
a1
�
j=1
φbj
1 b  m  t  =
1
k   1 
the basic upper bound on the power of a single big player
that theorem 2 yields continues to hold under the possibility
of splits  and it decreases as the number of splits increase 
corollary 2  for a player i  and any strategy choice s1       sr
of the players  it holds that 
uφ
i  s1       sr  =
ci
�
j=1
φbj
i  b  m  t 
t hm 2
≤
ci
�
j=1
bj
i
m  
r�
k=1
ck
≤
ci
�
j=1
bj
i
m   r    ci − 1  =
ai
m   r    ci − 1  
this further yields another result 
corollary 3  for the settings where there is a single big
player a1 and m small players  and any threshold t  the big
player has a strategy that guarantees at least 1
2 the power of
its best possible strategy 
proof  we
start
by
showing
that
p a  m  t 
≥
1
2 sups1 uφ
1 s1   and then give a strategy s1 that attains
uφ
1 s1  = p a  m  t  
if a1 > m  p a  m  t  >
1
2 ≥
1
2 sups1 uφ
1 s1   by the
efficiency property of the shapley-shubik index 
assume a1 ≤ m  the big player is the only strategic player
in the game  by corollary 2  for any strategy s1 
uφ
1 s1  ≤
a1
m   1 ≤
2a1
m   a1
= 2p a  m  t  
thus  the proportional value for the big player is at least
half as good as the best possible strategy  by the symmetry
property of the shapley-shubik index  s1 =
a1
�
��
�
 1       1    full
split   guarantees the proportional value 
6 2
experimental results
to support conjecture 1  we ran an exhaustive validation over
all wvgs with m < 25 
r�
j=1
aj < 25  a total of 5  833  920
wvgs were checked against all valid sub-partitions of them 
resulting in a total of 1  246  727  916 valid pairs being com-
pared  the maximal ratio attained was 1 958333′  the mini-
mal ratio attained was 0 08  the exhaustive search consists of
two parts  first  using dynamic programming over a dual re-
cursion to that of lemma 1  see appendix i in the full version
of the paper   we built a full recursion table of all shapley-
shubik indices for the wvgs in the range  then  for each
wvg we considered all valid partition strategy sets b 
while the maximal ratio over all instances of the experi-
mental analysis was close to 2  in most instances the ratio was
0
0 5
1
1 5
2
0
0 2
0 4
ratio
instance percent - exhaustive search
figure 1  ratio of big players  power before and after splits
much closer to 1  figure 1 shows a histogram of the number
of cases  on the y-axis  for different possible ratios between
0 and 2  on the x-axis   as can be seen from the figure  the
ratio is concentrated around 1 
7
discussion and future directions
many questions remain open  we find conjecture 1 hard to
prove even in limited settings 
for example  consider the
wvg  b  m  t  where m < t < �|b|
i=1 bi  i e   the overall
weights of the small players are less than the threshold  which
itself is less than the overall weights of the big players  in this
case it is possible to show that if we take a =  �|b|
i=1 bi   i e  
a single big player  then that player has a shapley-shubik in-
dex of 1 in the wvg  a  m  t   the conjecture s inequality
in that case then states that the sum of shapley-shubik indices
of the big players in b is larger or equal to 1
2  this reads as
a very clean combinatorial problem  if we draw a permu-
tation at random over a multiset of integers m ×  1  ∪ b 
with m < t < �|b|
i=1 bi  then the probability that the piv-
otal player  crossing the threshold t  is  big  is higher than
the probability that it is  small   this can be even simplified
further if we assume all big players are of identical size k 
section 6 is developed in regards to the shapley-shubik
index  the negative nature of the results in section 4 make
a similar treatment of the banzhaf index superfluous  but the
deegan-packel index might induce a similar conjecture and
experimental results  the model itself could be generalized
so that the threshold value t and big players  values a are not
a multiple of the small players value  or into some other idea
of looser distinctions between big and small players  tight
bounds can be derived for the deegan-packel index  and sim-
ilar results explored for other power indices in common use 
such as these by johnston  1978   holler and packel  1983 
and coleman  1971   generalizing our results to a larger class
of cooperative games is also interesting 
acknowledgments
yotam gafni and moshe tennenholtz were supported by
the european research council  erc  under the european
union s horizon 2020 research and innovation programme
 grant no  740435  
ron lavi was partially supported by the isf-nsfc joint
research program  grant no  2560/17  
proceedings of the thirtieth    ijcai-21 
215
 references
 aziz et al   2011  haris aziz  yoram bachrach  edith elkind  and
mike paterson 
false-name manipulations in weighted voting
games 
journal of artificial intelligence research  40 57–93 
2011 
 bachrach et al   2011  yoram bachrach  morteza zadimoghad-
dam  and peter key  a cooperative approach to collusion in auc-
tions  sigecom exch   10 1  17–22  march 2011 
 bachrach et al   2016a  yoram bachrach  yuval filmus  joel oren 
and yair zick  analyzing power in weighted voting games with
super-increasing weights  in martin gairing and rahul savani 
editors  algorithmic game theory  pages 169–181  berlin  hei-
delberg  2016  springer berlin heidelberg 
 bachrach et al   2016b  yoram bachrach 
yuval filmus 
joel
oren  and yair zick 
a characterization of voting power for
discrete weight distributions  in proceedings of the 25th inter-
national joint conference on artificial intelligence  page 74–80 
aaai press  2016 
 banzhaf iii  1964  john f banzhaf iii  weighted voting doesn t
work  a mathematical analysis  rutgers l  rev   19 317  1964 
 chang et al   2006  pao-li chang  vincent chua  and mosh e ma-
chover  l s  penrose s limit theorem  tests by simulation  math-
ematical social sciences  51 90–106  01 2006 
 coleman  1971  james s coleman  control of collectivities and
the power of a collectivity to act  social choice  pages 269–300 
1971 
 deegan and packel  1978  j  deegan and edward packel  a new
index of power for simple n-person games  international journal
of game theory  7 113–123  01 1978 
 dubey and shapley  1979  pradeep dubey and lloyd s shapley 
mathematical properties of the banzhaf power index  mathemat-
ics of operations research  4 2  99–131  1979 
 faliszewski and hemaspaandra  2009  piotr faliszewski and lane
hemaspaandra 
the complexity of power-index comparison 
theoretical computer science  410 1  101 – 107  2009 
 holler and packel  1983  manfred j  holler and edward w 
packel 
power  luck and the right index 
zeitschrift f¨ur na-
tional¨okonomie / journal of economics  43 1  21–29  1983 
 jelnov and tauman  2014  artyom jelnov and yair tauman  vot-
ing power and proportional representation of voters 
interna-
tional journal of game theory  43 4  747–766  2014 
 johnston  1978  ronald john johnston  on the measurement of
power  some reactions to laver  environment and planning a 
10 8  907–914  1978 
 lasisi and allan  2017  ramoni o lasisi and vicki h allan 
false-name manipulation in weighted voting games  empirical
and theoretical analysis  computational intelligence  33 3  478–
506  2017 
 lindner and machover  2004  ines lindner and mosh e machover 
l s  penrose s limit theorem  proof of some special cases  math-
ematical social sciences  47 37–49  01 2004 
 milnor and shapley  1978  j  w  milnor and l  s  shapley  values
of large games ii  oceanic games  mathematics of operations
research  3 4  290–307  1978 
 morgenstern and von neumann  1953  oskar
morgenstern
and
john von neumann  theory of games and economic behavior 
princeton university press  1953 
 neyman  1981  abraham neyman  singular games have asymp-
totic values  mathematics of operations research  6 2  205–212 
1981 
 oren et al   2014  joel oren  yuval filmus  yair zick  and yoram
bachrach  power distribution in randomized weighted voting  the
effects of the quota  https //arxiv org/abs/1408 0442  2014 
 penrose  1946  lionel s penrose  the elementary statistics of ma-
jority voting  journal of the royal statistical society  109 1  53–
57  1946 
 rey and rothe  2014  anja rey and j¨org rothe  false-name ma-
nipulation in weighted voting games is hard for probabilistic
polynomial time  the journal of artificial intelligence research 
50 1  573–601  may 2014 
 riker  1986  william h riker 
the first power index 
social
choice and welfare  pages 293–295  1986 
 shapley and shubik  1954  lloyd s shapley and martin shubik  a
method for evaluating the distribution of power in a committee
system  american political science review  48 3  787–792  1954 
 shapley  1952  lloyd s shapley 
a value for n-person games 
technical report  rand corp santa monica ca  1952 
 shapley  1962  lloyd s shapley  simple games  an outline of the
descriptive theory  behavioral science  7 1  59–66  1962 
 storing  2008  herbert j storing  the complete anti-federalist  vol-
ume 2  university of chicago press  2008 
 słomczy nski and zyczkowski  2006  wojciech słomczy nski and
k  zyczkowski  penrose voting system and optimal quota  acta
physica polonica b  37 3133–3143  2006 
 słomczy nski and ˙zyczkowski  2007  wojciech słomczy nski and
karol ˙zyczkowski  from a toy model to the double square root
voting system  homo oeconomicus  24 3-4  381–399  2007 
 winter  2002  eyal winter  chapter 53 the shapley value  volume 3
of handbook of game theory with economic applications  pages
2025 – 2054  elsevier  2002 
 zick et al   2011  yair zick 
alexander skopalik 
and edith
elkind  the shapley value as a function of the quota in weighted
voting games  in proceedings of the 22nd international joint
conference on artificial intelligence  pages 490–496  2011 
 zick  2013  yair zick  on random quotas and proportional repre-
sentation in weighted voting games  in proceedings of the 23rd
   pages
432–439  2013 
proceedings of the thirtieth    ijcai-21 
216
 "
None,2021,https-www-ijcai-org-proceedings-2021-0031-pdf,Even More Effort Towards Improved Bounds and Fixed-Parameter Tractability for Multiwinner Rules,"Sushmita Gupta, Pallavi Jain, Saket Saurabh, Nimrod Talmon",None,https://www.ijcai.org/proceedings/2021/0031.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0031-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0031-pdf.pdf,"even more effort towards improved bounds and fixed-parameter tractability
for multiwinner rules
sushmita gupta1   pallavi jain2   saket saurabh1 3 and nimrod talmon4
1the institute of mathematical sciences  hbni  india 
2indian institute of technology jodhpur  india 
3university of bergen  norway 
4ben-gurion university of the negev  israel 
sushmitagupta@imsc res in  pallavi@iitj ac in  saket@imsc res in  and talmonn@bgu ac il
abstract
multiwinner elections have proven to be a fruitful
research topic with many real-world applications 
we contribute to this line of research by improv-
ing the state of the art regarding the computational
complexity of computing good committees  more
formally  given a set of candidates c  a set of voters
v  each ranking the candidates according to their
preferences  and an integer k  a multiwinner vot-
ing rule identifies a k-sized committee  based on
these given voter preferences  in this paper we con-
sider several utilitarian and egailitarian owa  or-
dered weighted average  scoring rules  which are an
extensively-researched family of rules  and a sub-
family of the family of committee scoring rules  
first  we improve the result of betzler et al   jair 
2013   which gave a o nn  algorithm for com-
puting winner under the chamberlin courant rule
 cc   where n is the number of voters  to a running
time of o 2n   which is optimal 
furthermore 
we study the parameterized complexity of the pes-
simist voting rule and describe a few tractable and
intractable cases  apart from such utilitarian voting
rules  we extend our study and consider egalitarian
median and egalitarian mean  both committee scor-
ing rules   showing some tractable and intractable
results  based on nontrivial structural observations 
1
introduction
given the numerous applications of multiwinner voting  the
research on multiwinner elections is quite dense by now  fal-
iszewski et al   2017b   in such elections there is a set of m
candidates  a set of n voters  and an integer k  and the task
of a multiwinner voting rule is to aggregate the preferences
of the voters and identify a committee  namely a set of k can-
didates  in particular  much research has been done on de-
signing multiwinner voting rules  including offering various
general classes of such rules 
one particularly popular class of multiwinner voting rules
is the class of committee scoring rules  csrs   elkind et al  
2017  faliszewski et al   2018  faliszewski et al   2019   this
class of multiwinner voting rules is very rich and contains a
variety of voting rules  see  e g    faliszewski et al   2017a  
much of the research is concentrated on the computational
complexity of computing winners under various multiwin-
ner voting rules  including under various csrs   because for
many applications it is crucial to be able to efficiently com-
pute exact winners  as might be expected  computing win-
ners under some csrs can be done in polynomial-time  e g  
k-borda  faliszewski et al   2017b    while for others the cor-
responding decision problem is np-hard 
as with other np-hard problems  it is natural to aim at
circumventing the computational intractability of those csrs
for which winner determination is np-hard  such endeavors
have led to applying the framework of parameterized com-
plexity by identifying parameters that allow for exact algo-
rithms that are efficient whenever those parameters are small 
some of the commonly studied parameters are the commit-
tee size k and the number of voters  n  indeed  this line of
research has proven to be rather successful  see  e g    bred-
ereck et al   2017  bredereck et al   2020  faliszewski et al  
2017a  faliszewski et al   2019  faliszewski et al   2018 
aziz et al   2018  betzler et al   2013  betzler et al   2012 
faliszewski et al   2017c  yang and wang  2018  zhou et
al   2019  liu and guo  2016  aziz et al   2014  misra et
al   2015    in this article  we further advance this line of
research 
before we describe our specific contributions  we first
provide some preliminaries regarding multiwinner elections 
concentrating on csrs  owa rules  and the specific rules we
consider in this paper  and parameterized complexity 
1 1
multiwinner elections
an ordinal multiwinner election consists of a set of m can-
didates  a set of n voters  each providing a linear order over
the candidates  and an integer k  the goal of a multiwinner
voting rule is  given a multiwnner election  to output a set of
k candidates  referred to as a winning committee 1
an important class of multiwinner voting rules is the class
of committee scoring rules  csrs   these rules operate by
defining the satisfaction of a voter from a committee as a
function that considers only the positions of the committee
in the ranking  or preference list  of the voter  in particular 
1indeed  there might be several co-winning committees  we ig-
nore such issues of tie-breaking here as they only clutter the techni-
cal presentation 
proceedings of the thirtieth    ijcai-21 
217
 for a voter v  let posv c  denote the position of candidate c in
the ranking of v  e g   if v  a ≻ b ≻ c ≻ d then posv b  = 2 
as b is ranked second by v  then  given a voter v and a com-
mittee s  it implies a position vector  denoted by posv s  
which is a sorted vector of the positions of the candidates in
the committee  in the ranking of v  e g   if v  a ≻ b ≻ c ≻ d 
then the position vector of the committee  c  b  is  2  3   as
b is ranked second by v and c is ranked third  now  a com-
mittee scoring function  f  is a function that takes a position
vector and outputs a score  equivalently  a satisfaction value  
formally  f    0          m − 1 k → z≥0 
some scoring functions that we will use throughout the pa-
per are described next 
• median scoring function 
given a value of λ
≤
k 
the median scoring function is defined to be
f p1          pk  = m − pλ  that is  it is the borda score
of the committee member ranked λ by the correspond-
ing voter  e g   for λ = 1  the satisfaction of a voter
v  a ≻ b ≻ c ≻ d from a committee  b  c   by the me-
dian scoring function  would be 2  as b is the committee
member ranked the highest by v among all committee
members  and it is ranked second by v  similarly  for
λ = 2  the satisfaction of v would be 1  as c is the sec-
ond highest committee member of v 
• best scoring function  given a value of λ ≤ k  the
best scoring function is defined to be f p1          pk  =
�
i∈ λ  m−pi   that is  it is the sum of the borda scores
of the committee member ranked in first λ positions by
the corresponding voter  e g   for λ = 2  the satisfaction
of a voter v  a ≻ b ≻ c ≻ d from a committee  b  c  d  
by the best scoring function  would be 3 
we wish to mention here that these scoring functions are
referred as λ-median and λ-mean in the literature  skowron
et al   2016   note that such terminology fixes the value of
λ  however we allow λ to be even function of k  e g   when
λ = k  k-mean is same as k-borda and k-median is same as
pessimist  so to avoid such inconsistencies we consider λ as
a part of the input 
given some specific committee scoring function f  one can
define various voting rules  two natural possibilities are to
consider the voting rule that aims at finding a committee that
maximizes the sum  over the voters  of the satisfaction from
the committee  skowron et al   2016   and the voting rule that
aims at finding a committee that maximizes the min  over the
voters  of the satisfaction from the committee  aziz et al  
2018   formally  we have the following 
• given a committee scoring function f  by utilf we re-
fer to the voting rule that selects the committee that max-
imizes the sum of voter satisfaction  i e   utilf selects
arg maxs
�
v∈v f posv s   
• given a committee scoring function f  by egalf we re-
fer to the voting rule that selects the committee that maxi-
mizes the satisfaction of the least satisfied voter  i e   egalf
selects arg maxs minv∈v f posv s    the study of egalitar-
ian committee scoring rules was initiated by aziz et al   2018 
and remained unstudied for various scoring functions so far 
when f is a median scoring function and λ = 1  the vot-
ing rule utilf is the prominent multiwinner voting rule
chamberlin courant  cc   which was proposed by cham-
berlin and courant  1983   for λ = k under the same scoring
function  the voting rule utilf is known as pessimist  for
median scoring function f  we call the voting rule egalf
as egalitarian-median  and for the best scoring function  we
call it as egalitarian-best 
throughout the paper  we use βv c  to denote the borda
score of the candidate c from the voter v  and borda x  c 
to denote �
v∈x βv c   the sum of the borda scores of the
candidate c from the voters in x  for a set x  we use ⟨x⟩ to
denote an arbitrary ordering of x 
1 2
parameterized complexity
a central notion in parameterized complexity is fixed-
parameter tractability  fpt   which means  for a given in-
stance  x  k   decidability in time f k ·poly |x|   where f · 
is an arbitrary computable function and poly ·  is a polyno-
mial function  however  all problems are not fpt  con-
trastingly  w 1  or w 2 -hardness captures the intractabil-
ity in parameterized complexity 
we refer the reader to
books  downey and fellows  2013  cygan et al   2015 
niedermeier  2006  
1 3
our contributions
here  we list our contributions  table 1 summarizes our re-
sults  the notation o⋆ f k   suppresses poly n  m  factors 
• for the voting rule cc  we give an algorithm that runs in
o⋆ 2n  time  and this exponential dependence on n is opti-
mal  assuming set cover conjecture   this is an improve-
ment over known o⋆ nn -time algorithm proposed by bet-
zler et al   betzler et al   2013  
• for the voting rule pessimist  we show that it is w 1 -hard
wrt  k and xp wrt  n  i e   polynomial time solvable for con-
stant number of voters   the np-hardness of pessimist was
established in  skowron et al   2016   however the same re-
duction does not give w-hardness 
• for the voting rule egalitarian-median  we have following 
– we first show that it is np-hard for all the values of
λ < k  note that for λ = 1  the problem is known
as egalitarian-cc  aziz et al   2018  and also referred
as minimax cc  betzler et al   2013   for which np-
hardness  w 2 -hardness wrt  k  and an o⋆ nn -time
algorithm was established by betzler et al   betzler et
al   2013   for λ = k  the problem is known as egali-
tarian pessimist which is known to be polynomial time
solvable  aziz et al   2018  
– next  we study the parameterized complexity wrt  the
parameter k  we show that the problem is w-hard wrt 
k when either λ or k − λ is a constant or λ = ϵk  where
0 < ϵ < 1  despite of these intractable results  we have
an fpt wrt  k when the required satisfaction is at most
m − g k   where g is some computable function 
– next  we give an algorithm that runs in o⋆ 2n log λ 1  
time  note that this algorithm gives o⋆ 2n -time al-
gorithm for egalitarian-cc  and this exponential depen-
dence on n is optimal  assuming set cover conjecture  
proceedings of the thirtieth    ijcai-21 
218
 problem
results
conditions
reference
cc
o⋆ 2n  algorithm
thm  1
ω 2n  lower bound
 betzler et al   2013 
pessimistic
w 1 -hard wrt  k
n arbitrary
thm  2
poly-time solvable
n constant
thm  3
egalitarian-median
np-hard
for all λ ∈  k − 1 
thm  4
w 2 -hard wrt  k
λ constant
thm  5
w 2 -hard wrt  k
λ = ϵk  0 < ϵ < 1
thm  2
w 1 -hard wrt  k
k − λ  η ̸= 0 constants
thm  6
poly-time solvable
λ = k
 aziz et al   2018 
fpt wrt k
η = m − g k 
thm  7
o⋆ 2n log λ 1   algorithm
thm  8
ω 2n  lower bound
λ = 1
 betzler et al   2013 
o⋆ 2n2  algorithm
cor  3
o⋆ 2n log k−λ 1   algorithm
thm  9
egalitarian-best
np-hard and w 2 -hard wrt  k
for every constant λ
thm  10
np-hard and w 2 -hard wrt  k
λ = ϵk  0 < ϵ < 1
thm  11
np-hard and w 1 -hard wrt  k
λ = k
 aziz et al   2018 
poly-time solvable
n and λ constants
thm  12
table 1  summary of our results  here  k denotes the size of the committee  n denote the number of voters  and η denotes the committee
score  the lower bound results are due to the reduction from the hitting set problem assuming set cover conjecture  a blue cell means
the result holds for an arbitrary instance 
note that this is an improvement over known o⋆ nn -
time algorithm proposed by betzler et al   betzler et al  
2013   the same algorithm gives an fpt algorithms
wrt  n that runs in o⋆ 2n2  time for all the value of λ 
– next 
we
give
an
algorithm
that
runs
in
o⋆ 2n log k−λ 1   time 
note that for λ = k − 1 
this gives an o⋆ 2n -time algorithm 
• for the voting rule egalitarian-best  we show that it is np-
hard and w-hard wrt  k when either λ or k − λ is a constant
or λ = ϵk  where 0 < ϵ < 1  note that for λ = k  it is
known as egalitarian-k-borda which is known to be np-hard
and w-hard wrt  k  aziz et al   2018   moreover  it can be
solved in polynomial time when n and λ are constants 
all the missing and formal proofs will be presented in the
journal version 
2
chamberlin-courant  cc 
we give an optimal algorithm for cc that runs in o⋆ 2n 
time  which is an improvement over the known o⋆ nn -time
algorithm proposed in  betzler et al   2013   furthermore 
the exponential dependence on n is optimal  assuming the set
cover conjecture  scc   that says that we cannot have an al-
gorithm that runs in o⋆  2 − ϵ n  time  where 0 < ϵ ≤ 1
and n is the size of the universe  we can infer the same about
cc  this follows due to the reduction from hitting set to
cc by betzler et al   where the universe and the family of
sets is mapped to the candidates and the voters  resp  the
lower bound for hitting set follows from its linear size re-
ducibility from set cover for which we have the set cover
conjecture  in that canonical reduction  the universe in the
instance of set cover corresponds to the set family in the
instance of hitting set  so unless the scc fails  hitting
set cannot have an algorithm that runs in time o⋆  2−ϵ m  
where m is the family size  the lower bound for cc holds
due to its reduction from hitting set 
theorem 1  cc is solvable in o⋆ 2n  time 
we begin our discussion with an observation about cc 
any committee of size k  denoted by s  yields a k-partition
of the voter set  denoted by v1          vk  i e pairwise disjoint
sets that cover v
= ∪i∈ k vi  such that for each i ∈  k 
voters in district vi are represented by a unique candidate in
s  the one they rank above all others in s  we say that this
partition is induced by s  thus  in order to find the optimal
cc committee it is enough to find a k-partition of the voters
that yields the maximum cc score for the given instance 
in this exposition we have an instance i =  v   c   k  η  
the goal is to decide if there exists a k-sized committee s ⊆c
such that if  vi   i ∈  k   is the partition induced by s  then
η ≥ �
i∈ k  borda vi  ci   a trivial k-partition algorithm for
a voter set of size n requires o kn  time  but by reducing our
problem to polynomial multiplication involving polynomial-
many multiplicands  representing pairwise disjoint subsets of
v   each with degree at most o 2n  we can find the desired
partition in time 2nmo 1   the trick is that while multiplying 
the degree allows us to keep track of the combined score if
the multiplicands constitute different districts of a partition 
before we dive into the details  we will discuss the main idea
and some terminologies used in the algorithm 
big picture 
any subset x ⊆ v can be viewed as a sub-
set of  n   let χ x  denote the characteristic vector of x 
defined as an n-length vector whose ith bit is 1 iff i ∈ x 
we view χ x  as an n-digit binary number  a crucial ob-
servation guiding our algorithm is that two sets x1 and x2
proceedings of the thirtieth    ijcai-21 
219
 are disjoint iff the number of 1s in χ x1    χ x2   binary
sum/modulo 2  is equal to |x1|   |x2|  so  for each subset
x ⊆ v of size t for which there exists a candidate c ∈ c
such that α = borda x  c  we make a polynomial p 1
t α x 
that contains the monomial xχ x   this type of representa-
tion allows us to succinctly capture the property of disjoint-
ness between the subsets of v   as well as allowing us to test at
the end if all the k disjoint subsets taken together also  cover 
v   to see this let us consider disjoint subsets x1  x2 ⊆ v  
then  the polynomial xχ x1  × xχ x2  = xχ x1  χ x2  fol-
lows from normal polynomial multiplication  due to the dis-
jointness of the sets  their characteristic vectors are as well 
i e   none of the n positions have 1 in both χ x1  and χ x2  
consequently  χ x1    χ x2  is also an n-length binary
string that contains exactly |x1|   |x2| many 1s  we only
construct polynomials that result from multiplying at most k
monomials representing subsets of v   moreover  when mul-
tiplying monomials we keep track of each one s contribution
to the score of a potential committee for which the set corre-
sponding to the monomial will form a district  for this pur-
pose  we create a family of polynomials representing the var-
ious scores that such a district may contribute based on which
candidate is representing it 
in the final step  we look for a polynomial that contains a
monomial whose degree is  1 n  the string of n ones  this
is because this monomial was generated by multiplying k
monomials that constitute a k-partition of v   the fact that
we never go beyond an n-length string as the degree ensures
that the actual degree of the monomial in terms of decimal is
at most 2n  this allows us to use the o d log d  algorithm to
multiply two polynomials of degree d  in decimal  in no more
that o⋆ 2n  time   moenck  1976   thus  in this manner we
can obtain an algorithm that runs in time o⋆ 2n  
before we discuss our algorithm  we have to introduce
some notations and terminologies  let v be a set of size n 
two binary strings of length n are said to be disjoint if for
each i ∈  n   the ith bits in the two strings are different  the
hamming weight of a binary string s  denoted by h s   is
defined to be the number of 1s in the string s  a monomial
xi is said to have hamming weight h  if the binary represen-
tation of i has hamming weight h  the following result is
used crucially in our algorithm 
corollary 1  subsets x1  x2 ⊆ v are disjoint if and only if
hamming weight of the string χ x1  χ x2  is |x1| |x2| 
the hamming projection of a polynomial p x  to h  de-
noted by hh p x    is the sum of all the monomials of p x 
which have hamming weight h  we define the representa-
tive polynomial of p x   denoted by r p x    as the sum of
all the monomials that have non-zero coefficient in p x  but
have coefficient 1 in r p x    i e  it ignores the actual coeffi-
cients and only remembers whether the coefficient of is non-
zero  we say that a polynomial p x  contains a monomial
xi if the coefficient of xi is non-zero  the zero polynomial is
one in which the coefficient of each monomial is 0 
proof  now we are ready to present the algorithm 
algorithm 
for the instance i =  c   v   k  η   we will de-
fine k types of polynomials iteratively  we start with type 1 
for any s ∈  n  and α ∈   m − 1 n   we define
p 1
s α x  =
�
y ⊆v   |y |=s 
∃c∈c   borda y c =α
xχ y  
thus  a polynomial of type 1 contains information about
all subsets of v of a fixed size and for whom there exists
a candidate whose borda score from that subset is a fixed
value  all the polynomials of type 1 taken together contain
information about all possible subsets of v  
for any s ∈  n  and α ∈   m − 1 n   we define the poly-
nomials of type j ∈  k  \ 1  as follows
p j
s α x  =
�
s1 s2∈ n   s1 s2=s 
α1 α2∈ mn   α1 α2=α
r
�
hs
�
p 1
s1 α1 × p j−1
s2 α2
��
a j-type polynomial is defined by multiplying polynomi-
als of type j − 1 and 1  the use of the h ·  operator en-
sures that the only monomials that survive are those that are
formed by multiplying monomials with degrees that repre-
sent disjoint characteristic vectors  see corollary 1   thus 
a j-type polynomial contains information about all sets that
are formed by the disjoint union of j pairwise disjoint sets
that yield a certain score  each polynomial represents a set
of voters of specific size who give a specific borda score to a
j-sized committee  the r ·  operator keeps coefficients to at
most 1 
after defining these polynomials  the algorithm checks
among the polynomials of type k  if for some α ≥ η  the
polynomial p k
n α x  is non-zero  if so  then it returns  yes  
else it returns  no  
3
pessimist
we resolve the complexity of pessimist  find a committee
under pessimist rule  
theorem 2  pessimist is w 1 -hard wrt  k 
the proof is via a parameterized reduction from the in-
dependent set problem on regular graphs  we begin by
discussing the main idea behind our reduction
proof sketch  in our reduction  we associate the vertex set of
the ∆-regular graph g =  v  e  of the instance of inde-
pendent set with both the set of voters and the set of can-
didates of the instance of pessimist  additionally  we have
a large set of dummy candidates  whose role and number is
strategically chosen to identify  no -instances  for each voter
v ∈ v   we create a large separation between the set of candi-
dates that represent his neighbors in g  n v   and those that
are not his neighbors  n v   this is done by placing a block
of dummy candidates in between these two sets in that voter s
preference list  the preference list of voter v is
cv ≻ ⟨n v ⟩ ≻ ⟨dv⟩ ≻ ⟨n v ⟩ ≻       other dummies      
where cv denotes the  clone  of v  the candidate correspond-
ing to the vertex v  dv denotes the set of dummies corre-
sponding to voter v  and the suffix denoted by       contains
the sets of dummies corresponding to other voters 
proceedings of the thirtieth    ijcai-21 
220
 the affect of this arrangement is that an independent set of
size k  say s  when viewed as a k-sized committee of can-
didates  call it ˆs  induces a partition of the voter set  voters
whose clone is in the committee  those whose one neighbor
is in the committee  and those whose neighbors are not in
the committee  since the committee defines an independent
set in g  we know that if vertex v ∈ s  then its neighbors
cannot be in ˆs  thus voter v s score for ˆs is due to a can-
didate in n v   if v /∈ s  then its neighbor s  may or may
not be in s  all those vertices whose neighbors are not in
s contribute a similarly high score towards ˆs  those whose
neighbor belongs to s contribute a lower score towards ˆs 
these precise contributions lead us to set the target score to
be η =  2n3   ∆ n −  2n2   ∆  · min n − k  k∆   where
the term min n − k  k∆  comes into play because that is the
upper bound on the number of neighbors a k-sized subset of
vertices can have outside the set  specifically  it upper bounds
|n s |  additionally  we remark that |dv| = 2n2  and so the
total number of dummies is exactly 2n3  the choice of these
numbers is driven by our calculation in the reverse direction 
in the reverse direction  suppose that we have a k-sized
committee  call it ˆs  whose score is at least η  first  we note
that ˆs does not contain any dummy candidate  because it ap-
pears in the suffix of n − 1 voters and thus the contribution
from them will be so low that ˆs cannot achieve η  next we
argue that if there is even a pair of candidates in ˆs that share
an edge in g  then the score of ˆs is strictly less than η  this
calculation dictates the size of dv  described above 
next  we show that the problem can be solved in polyno-
mial time when the number of voters is a constant  the idea
is that for each voter  we can guess the last candidate  rep-
resentative  who is in the committee  then  we know that
any candidate who is ranked lower than the representative is
not part of the committee  and so delete all those candidates 
next  we choose any k-sized set of candidates from the re-
maining set to obtain the desired committee 
theorem 3  pessimist is solvable in polynomial time  when
n is constant 
4
egalitarian-median
in this section  we study the computational and parameter-
ized complexity of egal-med  finding a winning commit-
tee under the egalitarian-median rule   we first define some
terminologies that will be used throughout the section  let
 c   v   λ  k  η  be an instance of egal-med  for a voter
v and integer ℓ  prefixv ℓ  denote the set of top ℓ candi-
dates in the preference list of v  i e   prefixv ℓ  =  c ∈
c   βv c  ≥ m − ℓ   similarly  suffixv ℓ  denote the set of
last ℓ candidates or the set of candidates whose borda score
is less than ℓ in the preference list of v  i e   suffixv ℓ  =
 c ∈ c   βv c  < ℓ  
we begin with the intractability results 
to prove np-
hardness  we give a polynomial-time reduction from e-
hitting set  in which given a universe u  integers s  ˜k  and
a family  f  of subsets of u such that the size of every set in
f is s  we shall find a ˜k-sized set s ⊆ u such that for any
set f ∈ f  f ∩ s ̸= ∅  this is a variant of the well-known
hitting set problem  where the size of every set in the fam-
ily is same  e-hitting set is known to be np-hard for all
s ≥ 2  garey and johnson  1979   towards giving reduction 
we first note that in a winning committee  for every voter  we
can have at most k − λ candidates whose score is less than
the required score  so  we create a voter corresponding to
every set in the family f and a candidate corresponding to
elements of the universe u  then  we encode that the win-
ning committee has the candidates corresponding to elements
that are not in the hitting set  so  a voter vf corresponding to
the set f ranks all the candidates corresponding to elements
in f at the end  clearly  we do not want all these candidates
in the committee  otherwise we will not get a hitting set  so 
we set the required satisfaction as s and λ as k −  s − 1  
so that s candidates from the suffixv s  cannot be in the
winning committee  below  we prove it formally 
theorem 4  egal-med is np-hard for all λ ∈  k − 1  
proof sketch  let  u  f  s  ˜k  be an instance of e-hitting
set  let |u| = ˜n and |f| = ˜m  without loss of gener-
ality  we assume that ˜n ≥ ˜k   s  we construct an instance
 c   v   λ  k  η  of egal-med as follows  for every element
u ∈ u  we add a candidate cu in c   for every f ∈ f  we
add a voter vf in f  for a subset x ⊆ u  let cx denote
the set of all the candidates corresponding to the elements in
the set x  next  we define the preference list of every voter 
vf   as follows  vf   ⟨c \ cf ⟩ ≻ ⟨cf ⟩  let k = ˜n − ˜k 
λ = k −  s − 1   and η = s  this completes the construction 
intuitively  we capture that if s is a solution to  u  f  s  ˜k  
then the set of candidates corresponding to the elements in
u \s form a desired committee  and vice-versa  since η = s
and λ = k −  s − 1   we ensure that for every voter vf at
most k − λ =s − 1 candidates from suffixvf  s  are in the
committee  thus  we ensure that for any voter vf   cf is not
a subset of the committee as |cf | = s  hence  if s has score
η  then the subset of elements of u whose corresponding can-
didates are not in the committee is a hitting set 
next  we prove that egal-med is w 2 -hard wrt  k  when
either λ is a constant or λ = ϵk  where 0 < ϵ < 1  to-
wards that we again give a polynomial-time reduction from
e-hitting set  which is known to be w 2 -hard wrt  solu-
tion size  downey and fellows  1995   note that the above
reduction  theorem 4  is not parameter preserving  to prove
the following theorem  in the reduction  we capture that for
every voter  we shall choose at least λ candidates from top
m − η candidates  in the winning committee  note that in
the above reduction  we captured the opposite of this  i e   the
winning committee can have at most k − λ candidates from
the last η candidates in the preference list of a voter 
theorem 5  egal-med is w 2 -hard wrt  k for constant λ 
next  we show that the problem is even hard when λ = ϵk 
where 0 < ϵ < 1 
corollary 2  egal-med is w 2 -hard wrt  k  when λ = ϵk 
where 0 < ϵ < 1 
proceedings of the thirtieth    ijcai-21 
221
 next  we prove that egal-med is w 1 -hard wrt  k when
k − λ is a non-zero constant  towards that we give a poly-
nomial time reduction from the s-red/blue nonblocker
problem  in which given a graph g =  v  e   where v is par-
titioned into two color classes vred and vblue and every vertex
in vblue has s neighbors in vred  and an integer k  we have to
decide the existence of a k-sized set s ⊆ vred such that every
vertex in vblue has at least one neighbor that is not in s  this
problem is known to be w 1 -hard wrt  k for s ≥ 2  downey
and fellows  2013   we view this problem as hitting neigh-
borhood of every vertex of vblue in the set vred at most s − 1
times  so  for every vertex in vred  we create a candidate 
and for every vertex in vblue  we create a voter  now  for
every voter vx  where x is a vertex in vblue  the candidates
corresponding to the neighbors of x in vred are lowest ranked
candidates  we set λ and η so that any winning committee
takes at most s − 1 of these lower ranked candidates 
theorem 6  egal-med is w 1 -hard wrt  k  even when k−
λ and η are non-zero constants 
next  we identify a tractable case wrt  the parameter k  the
idea of the following algorithm is also based on the fact that
for every voter  we shall choose at least λ candidates from
the top m − η candidates  which we view as hitting the sets
prefixv m − η  for every voter v at least λ times  thus  if
prefixv m − η  = g k   then we can use known algorithm
in  mellor et al   2010  for this variant of the hitting set
problem to obtain an algorithm for our problem  there the
algorithm is for d-sized sets  but it gives us fpt wrt  k as in
our case the size of these sets is g k  
theorem 7  egal-med is fpt wrt  k when η = m − g k  
where g k  is any computable function of k 
next  we show that the problem is tractable wrt  n  the
number of voters  towards that we first give an algorithm
that runs in o⋆ 2n log λ 1   time  note that this algorithm
gives an o⋆ 2n -time algorithm for egalitarian cc  λ =
1 in egal-med   which is an improvement over known
o⋆ 2n log n  algorithm in  betzler et al   2013   furthermore 
this running time is tight under set cover conjecture due to
the reduction from the hitting set problem in  betzler et
al   2013  
so far  we view the problem as hitting the prefix of a voter
λ times  next  we visualise this problem as covering a voter
λ times using the candidates in the prefix  using this idea 
we reduce the problem to set multicover  where given a
universe u  a family of subsets  f  of u  and integers k  ℓ 
we shall decide the existence of a subset f′ ⊆ f  where
|f′| ≤ k  such that for every element u ∈ u  there are at
least ℓ sets in f′ that contains u  and then use the known
exact algorithm in  hua et al   2010  for set multicover
to obtain the desired result 
theorem 8  egal-med is solvable in o⋆ 2n log λ 1   time 
proof sketch  given an instance  c   v   λ  k  η  of egal-
med  we create an instance  u  f  ℓ  k′  of the set mul-
ticover problem as follows  for every voter v ∈ v   we add
an element ev in u  let c ′ ⊆ c be a subset of candidates that
belongs to top |c | − η candidates for any voter v ∈ v   that
is c ′ = ∪v∈v prefixv |c | − η   for every c ∈ c ′  we add
a set fc =  ev ∈ u   βv c  ≥ η  to the set f  we set ℓ = λ
and k′ = k  next  we use the exact algorithm for set mul-
ticover in  hua et al   2010  that runs in o⋆ 2|u| log ℓ 1  
time  note that λ = ℓ and |u| = |v |  thus  we obtain an
algorithm for egal-med that runs in o 2n log λ 1   
note that in the instance  u  f  ℓ  k′  of set multi-
cover  ℓ ≤ 2|u|  thus  we have the following result 
corollary 3  egal-med is solvable in o⋆ 2n2  time 
next  we give an algorithm for egal-med that runs in
o 2n log k−λ 1   time  note that if k − λ is constant  we
have an algorithm with running time 2o n   here  we again
use the idea that from the suffix part of every voter  we shall
pick at most k − λ candidates in the winning committee 
and devise a dynamic programming algorithm 
the intu-
itive idea is as follows  given an instance  c   v   λ  k  η 
of egal-med  we partition c into two parts c1 and c2
such that c1 = ∪v∈v suffixv η  and c2 = c \ c1  we
guess the number of candidates  say k1 ≤ k  in the winning
committee from the set c1  i e   for a winning committee s 
|s ∩ c1| = k1  next  using dp  we find a k1-sized committee
which is a subset of c that has the following property  for ev-
ery voter v  the committee contains at most k − λ candidates
from suffixv η   then  we add any k − k1 candidates from
the candidate set c2 to obtain a winning committee 
theorem 9  egal-med is solvable in o⋆ 2n log k−λ 1   
5
egalitarian-best
here  we study the computational and parameterized com-
plexities of egal-best  finding a winning committee un-
der the egalitarian-best rule   the idea behind the follow-
ing reduction is same as in theorem 5 
by setting η =
˜n   λ˜n   sλ    λ−1  λ−2 
2
in the proof of theorem 5  we
obtain the following 
theorem 10  egal-best is np-hard and w 2 -hard wrt 
k  when λ is a constant 
as argued for corollary 2  we have the following 
theorem 11  egal-best is np-hard and w 2 -hard wrt  k
even when λ = ϵk  where 0 < ϵ < 1 
fortunately  we have the following tractable case  the idea
is that for every voter we can guess the set of λ candidates
whose borda score will be counted in the score 
theorem 12  egal-best can be solved in polynomial time
for constant n and λ 
acknowledgments
the authors were supported by the following grants  s  gupta
by serb-starting research grant  srg/2019/001870   s 
saurabh by european research council  erc  under the eu-
ropean union s horizon 2020 research and innovation pro-
gramme  grant no  819416   and swarnajayanti fellowship
grant  dst/sjf/msa- 01/2017-18   n  talmon by the israel
science foundation  isf  grantno 630/19 
proceedings of the thirtieth    ijcai-21 
222
 references
 aziz et al   2014  haris aziz  serge gaspers  joachim gud-
mundsson  simon mackenzie  nicholas mattei  and toby
walsh  computational aspects of multi-winner approval
voting  in mpref aaai workshops  2014 
 aziz et al   2018  haris aziz  piotr faliszewski  bernard
grofman  arkadii slinko  and nimrod talmon  egalitarian
committee scoring rules  in proceedings of ijcai  pages
56–62  2018 
 betzler et al   2012  nadja
betzler 
robert
bredereck 
jiehua chen  and rolf niedermeier  studies in computa-
tional aspects of voting  in the multivariate algorithmic
revolution and beyond  pages 318–363  springer  2012 
 betzler et al   2013  nadja betzler  arkadii slinko  and jo-
hannes uhlmann 
on the computation of fully propor-
tional representation 
j  artif  intell  res   47 475–519 
2013 
 bredereck et al   2017  robert
bredereck 
piotr
fal-
iszewski 
andrzej
kaczmarczyk 
rolf
niedermeier 
piotr skowron  and nimrod talmon  robustness among
multiwinner voting rules  in proceedings of sagt  pages
80–92  2017 
 bredereck et al   2020  robert
bredereck 
piotr
fal-
iszewski  andrzej kaczmarczyk  dušan knop  and rolf
niedermeier 
parameterized algorithms for finding a
collective set of items  in proceedings of aaai  20  pages
1838–1845  2020 
 chamberlin and courant  1983  john r  chamberlin and
paul n  courant 
representative deliberations and rep-
resentative decisions  proportional representation and the
borda rule  am  political sci  rev   pages 718–733  1983 
 cygan et al   2015  marek cygan  fedor v  fomin  łukas
kowalik 
daniel lokshtanov 
dániel marx 
marcin
pilipczuk  michal pilipczuk  and saket saurabh  parame-
terized algorithms  springer  2015 
 downey and fellows  1995  robert
g 
downey
and
michael r  fellows 
fixed-parameter tractability and
completeness i 
basic results 
siam j  comput  
24 4  873–921  1995 
 downey and fellows  2013  robert
g 
downey
and
michael r  fellows 
fundamentals of parameterized
complexity  volume 4  springer  2013 
 elkind et al   2017  edith elkind  piotr faliszewski  piotr
skowron  and arkadii slinko  properties of multiwinner
voting rules  soc  choice welf   48 3  599–632  2017 
 faliszewski et al   2017a  piotr faliszewski  piotr skowron 
arkadii slinko  and nimrod talmon  multiwinner rules on
paths from k-borda to chamberlin-courant  in proceedings
of ijcai  pages 192–198  2017 
 faliszewski et al   2017b  piotr faliszewski  piotr skowron 
arkadii slinko  and nimrod talmon  multiwinner voting 
a new challenge for social choice theory  in u  endriss 
editor  trends in computational social choice  ai access
foundation  2017 
 faliszewski et al   2017c  piotr faliszewski  piotr skowron 
and nimrod talmon  bribery as a measure of candidate
success  complexity results for approval-based multiwin-
ner rules 
in proceedings of aamas  17  pages 6–14 
2017 
 faliszewski et al   2018  piotr faliszewski  piotr skowron 
arkadii slinko  and nimrod talmon  multiwinner ana-
logues of the plurality rule  axiomatic and algorithmic per-
spectives  soc  choice welf   51 3  513–550  2018 
 faliszewski et al   2019  piotr faliszewski  piotr skowron 
arkadii slinko  and nimrod talmon 
committee scor-
ing rules  axiomatic characterization and hierarchy  acm
trans  on economics and computation  7 1  3  2019 
 garey and johnson  1979  michael r garey and david s
johnson  computers and intractability  a guide to the
theory of np-completeness  w  h  freeman  1979 
 hua et al   2010  qiang-sheng
hua 
yuexuan
wang 
dongxiao yu  and francis cm lau 
dynamic pro-
gramming based algorithms for set multicover and
multiset multicover problems 
theor  comput  sci  
411 26-28  2467–2474  2010 
 liu and guo  2016  hong liu and jiong guo  parameter-
ized complexity of winner determination in minimax com-
mittee elections 
in proceedings of aamas  16  pages
341–349  2016 
 mellor et al   2010  drew mellor  elena prieto  luke math-
ieson  and pablo moscato  a kernelisation approach for
multiple d-hitting set and its application in optimal multi-
drug therapeutic combinations  plos one  5 10  e13055 
2010 
 misra et al   2015  neeldhara misra  arshed nabeel  and
harman singh  on the parameterized complexity of mini-
max approval voting  in proceedings of aamas  15  pages
97–105  2015 
 moenck  1976  robert t moenck  practical fast polynomial
multiplication  in proceedings of symsac  pages 136–
148  1976 
 niedermeier  2006  rolf niedermeier  invitation to fixed-
parameter algorithms  oxford university press  2006 
 skowron et al   2016  piotr skowron  piotr faliszewski  and
jérôme lang  finding a collective set of items  from pro-
portional multirepresentation to group recommendation 
artif  intell   241 191–216  2016 
 yang and wang  2018  yongjie yang and jianxin wang  pa-
rameterized complexity of multi-winner determination 
more effort towards fixed-parameter tractability  in pro-
ceedings of aamas  pages 2142–2144  2018 
 zhou et al   2019  aizhong zhou  yongjie yang  and jiong
guo 
parameterized complexity of committee elections
with dichotomous and trichotomous votes  in proceedings
of aamas  pages 503–510  2019 
proceedings of the thirtieth    ijcai-21 
223
 "
None,2021,https-www-ijcai-org-proceedings-2021-0032-pdf,Fair and Efficient Resource Allocation with Partial Information,"Daniel Halpern, Nisarg Shah",None,https://www.ijcai.org/proceedings/2021/0032.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0032-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0032-pdf.pdf,"fair and efficient resource allocation with partial information
daniel halpern1   nisarg shah2
1harvard university
2university of toronto
dhalpern@g harvard edu  nisarg@cs toronto edu
abstract
we study the fundamental problem of allocating in-
divisible goods to agents with additive preferences 
we consider eliciting from each agent only a rank-
ing of her k most preferred goods instead of her full
cardinal valuations  we characterize the value of k
needed to achieve envy-freeness up to one good and
approximate maximin share guarantee  two widely
studied fairness notions  we also analyze the mul-
tiplicative loss in social welfare incurred due to the
lack of full information with and without the fair-
ness requirements 
1
introduction
the theory of fair division studies how goods  or bads  should
be fairly divided between individuals  a k a  agents  with dif-
ferent preferences over them  while the pioneering fair divi-
sion research in economics  starting with the work of stein-
haus  1948   focused on divisible goods which can be split
between the agents  a significant body of recent research
within computer science has focused on allocation of indi-
visible goods  bouveret et al   2016  
suppose we wish to partition a set of indivisible goods m
among a set of agents n  in doing so  we would like to take
the agents  preferences into account  thus  the first step is to
decide how to represent these subjective opinions over the
possible bundle of goods the agent could receive  some of
the early work on fair division uses complete ordinal rank-
ings  agents can have a nearly-arbitrary ordering over all 2|m|
subsets of the goods  although of theoretical interest  as the
number of goods grows  this domain quickly becomes too
expressive and often leads to methods that are computation-
ally infeasible  see  e g   herreiner and puppe  2002    on
the other end  another common approach is to allow agents
to express ordinal preferences over the |m| singleton subsets
and extend these to ordinal preferences over all possible bun-
dles  see  e g    brams and king  2005  brams et al   2003 
aziz et al   2015    however  this suffers from the opposite
problem and can often be too restrictive 
recent work has thus focused on a different option  addi-
tive cardinal preferences  this preference domain is popu-
lar as it offers a sweet spot between simplicity and expres-
siveness 
here  each agent i places a non-negative value
vi g  on each good g and her value for a bundle of goods
s ⊆ m is assumed to be the sum of her values for the indi-
vidual goods in s  i e   �
g∈s vi g   theoretically  this valu-
ation class gives way to algorithms achieving strong fairness
guarantees  amanatidis et al   2016  caragiannis et al   2019 
chaudhury et al   2020  ghodsi et al   2018  garg and taki 
2020   practically  additive valuations are much simpler to
elicit than fully combinatorial valuations  which has led to
their adoption by popular fair division tools such as spliddit
and adjusted winner 1
however  expressing additive valuations still requires plac-
ing an exact numerical value on each good  which can some-
times be difficult or infeasible  an interesting tradeoff can
be achieved by eliciting ordinal preferences from the agents 
but viewing them as partial information regarding underly-
ing cardinal preferences  this idea originates from the re-
lated field of voting theory  where a growing body of work on
the distortion framework uses ordinal preferences of voters
over candidates as means to pick a candidate approximately
maximizing social welfare according to the underlying cardi-
nal preferences  procaccia and rosenschein  2006  boutilier
et al   2015  caragiannis et al   2017  mandal et al   2019 
mandal et al   2020  kempe  2020  amanatidis et al   2020  
in this paper  we focus on eliciting from each agent a rank-
ing of her k most preferred goods  i e   a prefix of her pref-
erence ranking over the goods   a system designer deliber-
ating on whether to use such partial information over tradi-
tional cardinal valuations may immediately be interested in
the price of the missing information  in line with the afore-
mentioned work  we analyze distortion in the context of fair
division  i e   the worst-case  multiplicative  loss in social
welfare — the sum of the values that agents place on their
own bundles — incurred due to the missing information 
in addition  we are also interested in achieving qualita-
tive fairness guarantees  it is  after all  fair division  two
popular guarantees for allocation of indivisible goods are
envy-freeness up to one good  ef1   lipton et al   2004 
budish  2011  and approximate maximin share guarantee
 mms   kurokawa et al   2018   which we define in sec-
tion 2  with access to agents  full preference rankings over
the goods  it is known that ef1 can be achieved via the round
robin algorithm  lipton et al   2004  caragiannis et al   2019  
1www spliddit org  www nyu edu/projects/adjustedwinner/
proceedings of the thirtieth    ijcai-21 
224
 under which agents take turns picking goods in a cyclic fash-
ion  for mms  amanatidis et al   2016  show that  using
just ordinal preferences over the goods  it is impossible to
guarantee better than a 1/hn approximation of mms  where
hn = θ log n  is the nth harmonic number and n is the
number of agents  in contrast  given additive cardinal pref-
erences  even 3/4-mms can be achieved  ghodsi et al   2018 
garg and taki  2020   what is the best mms approximation
that can be achieved given agents  preference rankings over
all the goods  more generally  if we are only given agents 
preference rankings over their k most preferred goods  for
what values of k can we achieve ef1 and approximate mms 
what distortion do we incur if  in addition to the missing
cardinal information  we also impose these fairness require-
ments  we answer these questions in our work 
1 1
our contribution
a bit more formally  a deterministic  resp  randomized  ordi-
nal allocation rule takes as input the partial preference rank-
ings and returns an allocation  resp  a distribution over allo-
cations  of the goods to the agents  the distortion of the rule
is the ratio of the maximum social welfare of any allocation
to the  expected  social welfare of the allocation returned  in
the worst case over all problem instances in a family  as is
common in the literature on distortion  we assume normal-
ized valuations  the total value each agent places on all goods
is normalized to 1  we are interested in two questions  first 
how much information is needed to achieve certain fairness
guarantees  second  what is the best distortion of any deter-
ministic or randomized ordinal allocation rule with or without
a fairness constraint 2
our results answer these questions for all values of k  but
for simplicity  we summarize the results for when complete
rankings are given  k = m  in figure 1  without any fairness
constraint  the simple deterministic rule that simply allocates
all the goods to a single agent achieves distortion n  we show
that not even a randomized rule with access to complete rank-
ings can achieve distortion better than n 
next  we consider two fairness requirements 
envy-
freeness up to one good  ef1  and approximate maximin
share  mms   ef1 is known to be achievable given com-
plete rankings  k = m   we characterize the exact value of
k needed to achieve ef1  for mms  we derive almost tight
bounds the best possible approximation as a function of k 
for the case of complete rankings  k = m   our results show
that 1/ 2hn -mms is achievable  almost matching the asymp-
totic upper bound of 1/hn due to amanatidis et al   2016  
thus  we establish  for the first time  that the best approxi-
mation to mms given ordinal preference information scales
logarithmically in the number of agents 
we also show that when ordinal allocation rules are re-
quired to guarantee ef1 or α-mms for α > 0  determinis-
tic rules face ω n2  distortion while randomized rules face
ω n  distortion  and matching upper bounds can be derived
 in case of mms  along with best-known α-mms approxima-
tion   our distortion upper bounds are achieved through effi-
2for a randomized rule  we require that the fairness constraint be
met by all allocations in the support of the distribution returned 
fairness
det
rand
none
n
n
ef1
θ n2 
θ n 
α-mms
θ n2 
θ n 
cardinal
cardinal
  p
ordinal
  p
θ √n 
θ n2 
θ n2 
figure 1  the table on the left summarizes the optimal distortion
for deterministic and randomized rules with access to the complete
rankings  k = m   note that α-mms is achievable for α = 1/2hn 
but not for α > 1/hn  however  the distortion lower bounds hold
for any α > 0  the diagram on the right shows the worst-case ratio
of social welfare between pairs of settings from the following three 
cardinal valuations given  cardinal valuations given but property p
required  ordinal preferences given but property p required  the
diagram holds for both p ∈  ef1  α-mms  and the top-right arrow 
the price of fairness p  is due to barman et al   2020  
cient algorithms  in the full version 3 we also show that var-
ious other fairness guarantees studied in the literature cannot
be achieved given just ordinal preference information  even
with complete rankings 
1 2
related work
there has been a substantial amount of work on using ordinal
preferences in fair allocation of indivisible goods  for exam-
ple  aziz et al   2015  consider the question of checking the
existence of allocations that possibly or necessarily satisfy
certain fairness guarantees such as envy-freeness given only
ordinal preferences of the agents over the goods  bouveret
et al   2010  study similar questions  but given partial ordinal
preferences of the agents over bundles of goods 
some of the work does not assume any underlying cardi-
nal preferences  instead  it aims to obtain guarantees defined
directly in terms of the ordinal preferences  for example 
baumeister et al   2017  and nguyen et al   2017  use the so-
called scoring vectors to convert agents  ordinal preferences
into numerical proxies for their utility and then consider max-
imizing various notions of social welfare or guaranteeing var-
ious fairness properties in terms of such utilities 
another related line of work uses ordinal allocation rules
 such as picking sequence rules  in settings with cardinal val-
uations  for example  aziz et al   2016  focus on the com-
plexity of checking what social welfare such rules can pos-
sibly or necessarily achieve  amanatidis et al   2016  seek
to use picking sequence rules to obtain approximation of
the maximin fair share guarantee  indeed  as mentioned ear-
lier  we settle a question left open in their work  however 
their main focus is on ensuring truthfulness  i e   preventing
agents from manipulating their preferences  manipulations
under picking sequence rules have received significant atten-
tion  aziz et al   2017b  aziz et al   2017a  
2
model
for j ∈ n  let  j  =  1          j   let n =  n  be a set of
agents and m =  m  be a set of goods  each agent i is en-
3www cs toronto edu/ nisarg/papers/distortion-fair-division pdf
proceedings of the thirtieth    ijcai-21 
225
 dowed with a valuation function vi   2m → r⩾0  which is
additive  vi s  = �
g∈s vi  g   for all i ∈ n  s ⊆ m  and
unit-sum  vi m  = 1 for all i ∈ n  to simplify notation  we
write vi g  instead of vi  g   for a good g ∈ m  we refer to
v =  v1          vn  as the valuation profile 
for k ∈  m   a top-k ranking σi of agent i is a rank-
ing of agent i s k most valuable goods  ties broken arbitrar-
ily   we say that a good is ranked by an agent if it appears
in their top-k ranking and unranked otherwise  we refer to
σ =  σ1          σn  as the top-k preference profile  or  simply 
preference profile   note that the value of k is the same for
all agents  when k = m  we refer to these as complete rank-
ings  we say that vi is consistent with σi  denoted vi ▷ σi  if
vi g  ⩾ vi g′  for all g  g′ ∈ m such that either g ≻σi g′
if both g and g′ are ranked or g is ranked and g′ is unranked 
we say that v is consistent with σ  denoted v ▷ σ  if vi ▷ σi for
each i ∈ n 
we are interested in taking as input  n  m  k  σ   which
we refer to as an instance  and finding an allocation of the
goods to the agents  for a set of goods s ⊆ m and ℓ ∈ n  let
πℓ s  denote the set of ordered partitions of s into ℓ bundles 
an allocation a =  a1          an  ∈ πn m  is a partition of
the goods into n bundles  where ai is the bundle allocated to
agent i  under this allocation  the utility to agent i is vi ai  
given a valuation profile v  the social welfare of an allocation
a is sw a  v  = �
i∈n vi ai   we simply write sw a  when
the valuation profile v is clear from the context 
we will use i to denote a family of instances  we will use
ir to denote the family of instances in which relation r over
k  n  and m is satisfied  for example  ik=m is the family of
instances with complete rankings and ik⩾n−1 is the family
of instances with rankings of at least n − 1 goods 
a  randomized  ordinal allocation rule  hereinafter  sim-
ply a rule  f for a family of instances i takes an instance
 n  m  k  σ  from i — for simplicity  we refer to σ as the
sole input to f— and returns a distribution over the set of al-
locations πn m   we say that f is deterministic if it always
returns a distribution with singleton support  we will some-
times refer to a distribution over allocations as a randomized
allocation  the distortion of an ordinal allocation rule f with
respect to a family of instances i  denoted disti f   is the
worst-case approximation ratio it provides to the social wel-
fare over all instances of i 
disti f  =
sup
 n m k σ ∈i
sup
v v▷σ
maxa∈πn m  sw a  v 
e sw f σ   v  
 
where the expectation is over possible randomization in f 
when i is clear from the context  we may drop it from the
notation  note that if i1 ⊆ i2  then disti1 f  ⩽ disti2 f  
following prior work and to help compare our distortion
bounds to the known price of fairness bounds  see figure 1  
we provide distortion bounds parametrized by the number of
agents n  we are interested in the lowest distortion that deter-
ministic and randomized ordinal allocation rules can achieve 
a fairness property p
maps every instance i
=
 n  m  k  σ  to a  possibly empty  set of allocations p i  
every allocation in p i  is said to satisfy p in instance i 
often  fairness properties are defined in terms of agent valu-
ations rather than rankings  in this case  an allocation is said
to satisfy p in instance i only if it is satisfied by p for all
valuations consistent with σ  we say that a rule f satisfies
property p if for all σ  every allocation in the support of f σ 
satisfies p  we are also interested in determining whether
ordinal allocation rules can satisfy prominent fairness prop-
erties  and when they can  determining the lowest possible
distortion they can achieve subject to such properties 
given an instance i =  n  m  k  σ  with valuations v  we
are interested in the following fairness properties 
definition 1  ef1   an allocation a is called envy-free up to
one good  ef1  if for every pair of agents i  j  either vi ai  ⩾
vi aj  or there exists a good g ∈ aj such that vi ai  ⩾
vi aj \  g   
definition 2  balancedness   an allocation a is called bal-
anced if |ai|−|aj|⩽ 1 for all i  j ∈ n  i e   if the agents
receive approximately an equal number of goods 
definition 3  mms   the maximin share of agent i is
mmsi =
max
a∈πn m  min
aj∈a vi aj  
given α ∈  0  1   an allocation a is called α-maximin share
fair  α-mms  if vi ai  ⩾ α · mmsi for all agents i ∈ n 
when α = 1  we simply say that a is an mms allocation 
3
distortion of ordinal allocation rules
we begin by analyzing the lowest distortion that deterministic
and randomized ordinal allocation rules can achieve in the
absence of any fairness requirement  this precisely captures
value of cardinal preference information  or the loss incurred
in social welfare due to having only ordinal preferences 
even without any preference information  k = 0   a triv-
ial deterministic rule that allocates all the goods to an arbi-
trary single agent achieves distortion n  indeed  the social
welfare of such an allocation is 1  while the maximum social
welfare cannot be larger than n since valuations are unit-sum
 vi m  = 1 for all i ∈ m   we show that not even random-
ized ordinal allocation rules with access to complete rankings
 k = m  can achieve lower distortion  the proof can be found
in the full version 
theorem 1  there exists a deterministic ordinal allocation
rule with distortion n for the family ik⩾0 
on the other
hand  no randomized ordinal allocation rule achieves distor-
tion lower than n even for the restricted family of ik=m 
3 1
fairness lower bounds
in this section  we analyze the lowest distortion that ordinal
allocation rules can achieve when they are required to satisfy
some fairness constraints  this captures the combined price
of the lack of cardinal preference information and the impo-
sition of fairness constraints  figure 1 contrasts this with the
sole price of the former analyzed in section 3 and the sole
price of the latter from known results in the literature  per-
haps not surprisingly  it turns out that the two together lead to
a much greater loss in social welfare than each individually 
another consequence of our results is that while random-
ized ordinal rules are no more powerful than deterministic
ones in the absence of any fairness requirements  theorem 1  
imposing fairness requirements makes their powers diverge 
proceedings of the thirtieth    ijcai-21 
226
 keeping aside the question of distortion  we are also inter-
ested in determining which fairness properties ordinal alloca-
tion rules can satisfy  a negative answer can be interpreted as
a qualitative price of the lack of cardinal preferences 
we begin by establishing a lower bound on the distortion
of deterministic ordinal allocation rules that holds when any
fairness property from a broad class is imposed  even with
access to complete rankings  later  we argue that the fairness
properties of our interest belong to this class  recall that we
require the allocation returned by the rule to satisfy the fair-
ness property  regardless of the unobserved cardinal valua-
tions  consistent with the observed ordinal preferences  
theorem 2  let p be a fairness property such that when the
number of goods equals the number of agents  for every pref-
erence profile σ  an allocation satisfies p for all valuations
consistent with σ if and only if each agent receives a single
good  then  the distortion of every deterministic ordinal al-
location rule satisfying p is ω n2  for the family ik=m 
proof  fix such a fairness property p  a number of agents
n  and a deterministic ordinal allocation rule f on ik=m  i e  
only taking complete rankings  satisfying p  first  let us sup-
pose that n is even  we construct an instance with n goods 
that is  with m = n  we split the goods into three differ-
ent categories and construct a preference profile σ as follows 
the first category consists of a single good g∗ that is ranked
highest by all agents  the next category consists of n/2 goods
labeled g 1 2   g 3 4           g n−1 n   for each ℓ ∈  n/2   good
g 2ℓ−1 2ℓ  is ranked second by both agents 2ℓ−1 and 2ℓ  the
final category consists of the remaining n/2 − 1 goods  the
construction above identifies the two most preferred goods
for all agents  their preference rankings from the third rank
onward can be arbitrary 
let a be the allocation returned by f given σ  by the
assumption of the theorem statement  each agent must re-
ceive exactly one good in a  without loss of generality  let
us assume that agent 1 receives g∗ 
in addition  for each
ℓ ∈  2          n/2   at least one of agents 2ℓ − 1 and 2ℓ does
not receive good g 2ℓ−1 2ℓ   without loss of generality  as-
sume that agent 2ℓ − 1 does not receive it  let us construct a
consistent valuation profile as follows 
• agent 1 has value 1/n for each good 
• agent 2 has value 1 for g∗ and 0 for all other goods 
• for ℓ ∈  2          n/2   agent 2ℓ − 1 has value 1/2 for g∗ 
1/2 for g 2ℓ−1 2ℓ   and 0 for all other goods  and agent
2ℓ has value 1 for g∗ and 0 for all other goods 
under a  the only agent receiving positive utility is agent 1 
who receives utility 1/n  therefore  the social welfare is 1/n 
in contrast  consider the allocation that gives g∗ to agent 2 
g 2ℓ−1 2ℓ  to agent 2ℓ − 1 for each ℓ ∈  2          n/2   and the
remaining goods arbitrarily such that each agent receives a
single good  it is easy to check that its social welfare is at
least 1    n/2 − 1  · 1/2 = n/4   1/2  therefore  the distortion
of f is at least  n/4   1/2 / 1/n  ∈ ω n2  
if n is odd  we can construct the described instance with
n − 1 agents and n − 1 goods  add a good ranked last by all
agents  and add an agent whose preference ranking matches
that of one of the other agents  using similar arguments as
above  regardless of the allocation a chosen by f  we can
construct a consistent valuation profile in which the social
welfare of a is 1/n  while the optimal social welfare is at least
 n−1 /4   1/2  resulting in ω n2  distortion 
notice that in the proof of theorem 2  we contrast the so-
cial welfare achieved by the rule satisfying p against that of
an allocation that assigns each agent a single good  thus also
satisfying p  that is  the ω n2  lower bound continues to
hold even when comparing to the optimal social welfare sub-
ject to p  on the other hand  our matching upper bounds pre-
sented later hold even when comparing to the optimal social
welfare without any fairness constraints 
4
ef1
we now turn our attention to ef1  we begin by fully charac-
terizing the values of k  in relation to n and m  for which we
can achieve ef1  the rules we construct are based on pick-
ing sequence rules  a picking sequence is simply a sequence
of agents p1          pℓ  where ℓ ⩽ m  it is a deterministic rule
that works as follows  it first gives agent p1 their favorite
good  then gives agent p2 their favorite good among the ones
remaining  and so on  for ℓ steps  if ℓ < m  we design a
way — different for each case — for allocating the remaining
goods  a well-known picking sequence rule is round robin 
which has the cyclic picking sequence 1          n  1          n       
repeated for a total of m steps 
theorem 3  with n agents and m goods  it is possible to
guarantee ef1 using top-k rankings if and only if
k ⩾
�
�
�
m − n 
if m mod n = 0 
m − 2 
if m mod n = 1 
m −  m mod n  
if m mod n > 1 
proof  fix arbitrary n  m  and k  we begin with the lower
bounds  showing that ef1 can only be achieved if k is suffi-
ciently large  all of our constructions have the same prefer-
ence profile  all agents agree on which goods are in the top
k  that is  they rank goods g1          gk in some order and do
not rank the remaining m − k goods  for a given allocation
a  let si = |ai ∩  g1          gk  | be the number of the top-k
goods received by agent i  note that k ⩾ �
i∈n si  we use
the following lemma 
lemma 1  if agents agree on which goods are in the top k
and an allocation a is ef1 for all consistent valuations  then
si ⩾ |aj|−1 for all distinct agents i  j ∈ n 
proof  consider a consistent valuation profile in which agent
i has zero value for the goods ai \  g1          gk  but equal
value for all other goods  including all of the ones in aj   if
si < |aj|−1  ef1 would be violated for agent i 
suppose there exists an allocation a guaranteed to be ef1 
we show that this implies k is sufficiently large as per the
theorem statement  let q ∈ n and r ∈  n − 1  be such that
m = qn   r  since a is guaranteed to be ef1 given ordinal
preferences  it must be balanced  that is  |aj|−|ai|⩽ 1 for all
agents i and j  using lemma 1  we can see that |ai|⩾ si ⩾
proceedings of the thirtieth    ijcai-21 
227
 |aj|−1  in our case  this means that r agents have bundles
with size q   1 and the remaining n − r have bundles with
size q  in the following  we use k ⩾ �
i∈n si 
• suppose r = 0  so |ai|= q for all agents i  by lemma 1 
si ⩾ q − 1 all agents i  so k ⩾  q − 1 n = m − n 
• suppose r = 1  therefore  one bundle  without loss of
generality a1  has size q  1  and all the others have size
q  we have that s1 ⩾ q − 1 and si ⩾ q for all i ̸= 1 by
lemma 1  this implies k ⩾ qn − 1 = m − 2 
• suppose r > 1  as at least two agents have bundles of
size q   1  by lemma 1  si ⩾ q for all agents i  this
implies k ⩾ qn 
next  we prove the upper bounds  showing that if k is
sufficiently large  ef1 can be guaranteed  to do this  we
make modifications to the aforementioned round robin rule 
which  with a picking sequence of length m  is known to
guarantee ef1 
note that to run this rule  only ordinal
information is needed but complete rankings  or at least
k ⩾ m − 1  are needed  to work with round robin  we
label the goods in the order they are chosen as follows
g1 1  g2 1          gn 1  g1 2          gℓ t  where good gi j is the jth
good picked by agent i  we refer to t  the largest number
of goods picked by any agent  as the number of  rounds 
and goods gi t for i ∈ n as goods picked in the last round 
note that not all agents will necessarily pick a good in the last
round  we make use of the following lemma  the proof can
be found in the full version 
lemma 2  suppose we run round robin to m steps with ac-
cess to complete rankings but reassign the goods received by
agents in the last round such that no agent receives more than
one good  then the resulting allocation remains ef1 
all the rules we design will run round robin to at most
k steps and then assign the remaining goods in a way that
can be accomplished without access to the remaining ordi-
nal preferences  we will then argue that the remaining goods
were assigned in a way such that they only permuted the last
round of goods in a hypothetical allocation given by running
round robin to m steps with access to complete rankings  by
lemma 2  this implies ef1 
first  suppose m mod n = 0 and k ⩾ m − n  the rule
works as follows  it runs round robin for m − n steps and
assigns the remaining n goods so that each agent receives ex-
actly one  this is ef1 by lemma 2 as the resulting allocation
could also have been computed by running round robin using
complete rankings and reassigning the goods from the last
round in the way that was arbitrarily chosen 
next  suppose m mod n = 1 and k ⩾ m − 2  the rule
works in a very similar way  it runs round robin for m − 2
steps and assigns the remaining two goods to the last agent in
the order  or if m = 1  just assigns the good to an arbitrary
agent   this is ef1 by lemma 2 as the resulting allocation
could have been computed by running round robin and giving
the singular good of the final round to the nth agent in the
order 
finally  suppose m mod n > 2 and k ⩾ m −  m mod n  
as before  we run round robin for m −  m mod n  steps and
assign the remaining m mod n goods such that each agent
receives at most one  this is again ef1 by lemma 2 
let ief 1 be the family of instances with k  n  and m val-
ues satisfying the relation specified in theorem 3  i e  for
which it is possible to achieve ef1   then  the best possible
distortion subject to the requirement of achieving ef1 is as
follows  the proof can be found in the full version 
theorem 4  among deterministic ordinal rules  all ef1 rules
have unbounded distortion on ief 1 ∩ ik=0 and the lowest
possible distortion of an ef1 rule with respect to ief 1 ∩
ik⩾1 is θ n2   among randomized ordinal rules  the lowest
possible distortion of an ef1 rule on ief 1 is θ n  
5
mms
we now turn to our most technical results  which are regard-
ing approximate maximin share  mms  guarantee  before
we consider distortion subject to approximate mms  we need
to know what approximation to mms is possible to achieve 
given full cardinal information  it is known that exact mms
cannot be achieved  kurokawa et al   2018   but 3/4-mms
can  ghodsi et al   2018  garg and taki  2020  
given complete preference rankings  k = m   amanatidis
et al   2016  show that it is not possible to achieve α-mms
for α > 1/hn  where hn = θ log n  is the nth harmonic
number  on the opposite end  they only establish a weaker
ω 1/√n  lower bound  leaving open the question of what the
best possible mms approximation is given complete prefer-
ence rankings  we settle this question by showing that the
best possible mms approximation for k = m is θ 1/hn 
 specifically  we derive a lower bound of 1/2hn   we also ex-
tend the lower and upper bounds to the case of k < m 
our algorithm is similar to the one provided by amanatidis
et al   2016  to achieve ω 1/√n   but our improvement cru-
cially relies on lemma 3  which requires an intricate proof
 given in     to achieve the desired bounds  note that for
m ⩽ n  mms can trivially be satisfied by giving each agent
at most one good  thus  we focus on m > n 
theorem 5  when m > n  the following hold 
• if k < n − 1  we cannot achieve α-mms for any α > 0 
• if k = n − 1  we can achieve
1
⌊ m−n 2
2
⌋-mms  but no
higher 
• if k ⩾ n  we can achieve α-mms for α = k−n 1
m−n 1 ·
1
2hn  
but not for α >
k
hn m−n − m−k  
proof  most of the proof is located in     here  we show
the most interesting case  the lower bound for k ⩾ n  we
borrow and build upon ideas from the proof of the ω 1/√n 
lower bound due to amanatidis et al   2016  
we construct a picking sequence rule achieving the desired
mms approximation  fix an agent  for now  suppose we
are working with complete rankings  with k = m  suppose
the first time this agent appears in the picking sequence is at
the ℓth position  we call this the agent s 0th appearance  for
some ℓ ⩽ n  and then  the agent s jth appearance occurs at
or before position  ℓ   ⌊j · 2hn n − ℓ   1 ⌋  in the picking
proceedings of the thirtieth    ijcai-21 
228
 sequence for every j  as long as this quantity does not exceed
m   then  we claim that the agent must be guaranteed at least
1/ 2hn  fraction of her mms value  to see this  note that the
agent picks a good at least as valuable as her ℓth most favorite
good in her 0th appearance  and then an additional good at
least as valuable as her  ℓ   ⌊j · 2hn n − ℓ   1 ⌋ th favorite
good in her jth appearance for each j  let s denote the to-
tal value the agent places on her ℓ − 1 most valuable goods 
then  this picking sequence guarantees the agent utility at
least
1−s
2hn n−ℓ 1   on the other hand  note that the mms
value of the agent is at most
1−s
n−ℓ 1  this is because regardless
of how the agent partitions the goods into n bundles  ignoring
the  at most  ℓ−1 bundles containing her ℓ−1 most valuable
goods  even the average value across the remaining  at least
n − ℓ   1  bundles is at most
1−s
n−ℓ 1  hence  it follows that
the agent is guaranteed at least a 1/2hn fraction of her mms 
now  instead of assuming we have complete rankings  sup-
pose we just have top-k for some k ⩾ n  in this case  sup-
pose we run the above picking sequence for just k steps 
then  rather than being guaranteed
1−s
2hn n−ℓ 1   the agent
is only guaranteed
k−ℓ 1
m−ℓ 1 ·
1−s
2hn n−ℓ 1  
as their mms
value remains the same and ℓ ⩽ n  this agent is guaranteed
k−n 1
m−n 1 ·
1
2hn -mms as needed  the remaining m − k goods
can be allocated arbitrarily 
our picking sequence gives a guarantee of this style to each
agent  albeit for different values of ℓ  in particular  for each
agent i ∈  n   the picking sequence provides this guarantee
with ℓ = i  the construction is very simple 
1  for 1 ⩽ i ⩽ n and 0 ⩽ j ⩽
�
m−i
2hn n−i 1 
�
  we cre-
ate the pair  i  i ⌊j · 2hn n − i   1 ⌋   indicating that
agent i s jth appearance must occur at or before the po-
sition indicated in the second component — we refer to
this as the deadline 
2  we sort the pairs with respect to their second coordinate 
3  the first coordinates with respect to the above sorting
are a prefix of the picking sequence 
4  if the length of the above sequence is m  we are done 
otherwise we arbitrarily assign the remaining picks 
5  if k < m  we truncate the sequence to length k 
the idea of steps 2–4 is to produce a picking sequence
that meets all the deadlines by using earliest-deadline-first
scheduling  it is known that if all the deadlines can be met 
then this greedy scheduling procedure is guaranteed to return
a sequence meeting them  to show that all deadlines are met 
we want to show that there are at most d pairs introduced in
step 1 with the second coordinate  deadline  at most d  for all
d ⩽ m  note that in particular  this implies that there are at
most m pairs in total  so step 3 would not produce a sequence
of length more than m 
to prove this  let us first consider d ⩽ n  observe that the
1st appearance deadline of any agent is at or after position n 
1  this is because i ⌊2hn n − i   1 ⌋ ⩾ 1 ⌊n − i   1⌋ =
n   1 for all i ∈  n   this implies that the only pairs with
deadline at most n are the n pairs of the form  i  i  for i ∈  n 
corresponding to the 0th appearances of all the agents  which
immediately implies the desired goal holds for all d ⩽ n 
next  consider d
⩾
n   1 the number of pairs for
agent i with the second coordinate at most d is at most
1  
�
d−i
2hn n−i 1 
�
 
therefore  the number of total pairs
with second coordinate at most d is at most �n
i=1 1  
�
d−i
2hn n−i 1 
�
= n   �n
i=1
�
d−i
2hn n−i 1 
�
  our goal is to
show that this value is at most d  which is equivalent to the
following lemma  the proof is deferred to    
lemma 3  for all n
∈
n and for all d
⩾
n   1 
�n
i=1
�
d−i
2hn n−i 1 
�
⩽ d − n 
this completes the proof of the theorem 
strikingly  while ω n2  distortion is unbeatable subject to
α-mms for any α > 0  for k ⩾ n  we can achieve a match-
ing o n2  distortion even while simultaneously achieving
the best-known mms approximations for all k  introduced
in theorem 5  the proof is deferred to    
theorem 6  the best possible distortion is as follows 
• on ik=n−1  any deterministic ordinal rule satisfying α-
mms for α > 0 must have unbounded distortion  how-
ever  there is a randomized ordinal rule achieving the
best-possible 1/
� m−n 2
2
�
-mms and distortion n 
• on ik⩾n  any deterministic ordinal rule satisfying α-
mms for α > 0 must have distortion ω n2   and there is
a deterministic ordinal rule achieving o n2  distortion
with α-mms for the best-known α =
k−n 1
m−n 1 ·
1
2hn  
further  there is a randomized ordinal rule that achieves
α-mms for α = k−n 1
m−n 1 ·
1
2hn with distortion n 
6
discussion
in this paper  we analyze which fairness properties can be
achieved and what loss in social welfare must be incurred
 distortion  when only ordinal preference information is pro-
vided in the form of top-k rankings 
this is inspired by a growing literature on distortion in
voting  procaccia and rosenschein  2006   a recent line of
work has focused on imposing additional structure on the
underlying cardinal preferences  anshelevich et al   2018 
gkatzelis et al   2020   in fair division  one can also study
natural restrictions on the underlying cardinal preferences
such as a limit on the number of goods an agent can derive
positive utility from or on the maximum difference between
the values two agents can derive from the same good 
another thread of research on distortion in voting has fo-
cused on the tradeoff between distortion and the amount of
preference information elicited  mandal et al   2019  mandal
et al   2020  kempe  2020  amanatidis et al   2020   our re-
sults already offer one such tradeoff by allowing the designer
to pick the value of k  an interesting direction for the future
would be to study such a tradeoff while allowing arbitrary —
not necessarily ordinal — elicitation and measuring the num-
ber of bits of information elicited 
proceedings of the thirtieth    ijcai-21 
229
 references
 amanatidis et al   2016  g 
amanatidis 
g 
birmpas 
and
e  markakis  on truthful mechanisms for maximin share alloca-
tions  in proceedings of the 25th international joint conference
on artificial intelligence  ijcai   pages 31–37  2016 
 amanatidis et al   2020  g  amanatidis  g  birmpas  a  filos-
ratsikas  and a  a  voudouris  peeking behind the ordinal cur-
tain  improving distortion via cardinal queries  in proceedings
of the 34th aaai conference on artificial intelligence  aaai  
pages 1782–1789  2020 
 anshelevich et al   2018  e  anshelevich  o  bhardwaj  e  elkind 
j  postl  and p  skowron  approximating optimal social choice
under metric preferences 
artificial intelligence  264 27–51 
2018 
 aziz et al   2015  h  aziz 
s  gaspers 
s  mackenzie 
and
t  walsh  fair assignment of indivisible objects under ordinal
preferences  artificial intelligence  227 71–92  2015 
 aziz et al   2016  h  aziz  t  kalinowski  t  walsh  and l  xia 
welfare of sequential allocation mechanisms for indivisible
goods  in proceedings of the 22nd european conference on ar-
tificial intelligence  ecai   pages 787–794  2016 
 aziz et al   2017a  h  aziz  s  bouveret  j  lang  and s  macken-
zie  complexity of manipulating sequential allocation  in pro-
ceedings of the 31st aaai conference on artificial intelligence
 aaai   pages 328–334  2017 
 aziz et al   2017b  h  aziz  p  goldberg  and t  walsh  equilibria
in sequential allocation  in proceedings of the 5th international
conference on algorithmic decision theory  adt   pages 270–
283  2017 
 barman et al   2020  s  barman  u  bhaskar  and n  shah  opti-
mal bounds on the price of fairness for indivisible goods  in pro-
ceedings of the 16th conference on web and internet economics
 wine   pages 356–369  2020 
 baumeister et al   2017  d  baumeister  s  bouveret  j  lang  n  t 
nguyen  t  t  nguyen  j  rothe  and a  saffidine 
posi-
tional scoring-based allocation of indivisible goods  autonomous
agents and multi-agent systems  31 3  628–655  2017 
 boutilier et al   2015  c  boutilier  i  caragiannis  s  haber  t  lu 
a  d  procaccia  and o  sheffet  optimal social choice functions 
a utilitarian view  artificial intelligence  227 190–213  2015 
 bouveret et al   2010  s  bouveret  u  endriss  and j  lang  fair
division under ordinal preferences  computing envy-free allo-
cations of indivisible goods  in proceedings of the 19th euro-
pean conference on artificial intelligence  ecai   pages 387–
392  2010 
 bouveret et al   2016  s  bouveret  y  chevaleyre  and n  maudet 
fair allocation of indivisible goods  in f  brandt  v  conitzer 
u  endriss  j  lang  and a  d  procaccia  editors  handbook of
computational social choice  pages 284–310  cambridge uni-
versity press  2016 
 brams and king  2005  s  j  brams and d  l  king  efficient fair
division  help the worst off or avoid envy 
rationality and
society  17 4  387–421  2005 
 brams et al   2003  s  j  brams  p  h  edelman  and p  c  fish-
burn  fair division of indivisible items  theory and decision 
55 2  147––180  2003 
 budish  2011  e  budish  the combinatorial assignment problem 
approximate competitive equilibrium from equal incomes  jour-
nal of political economy  119 6  1061–1103  2011 
 caragiannis et al   2017  i  caragiannis  s  nath  a  d  procaccia 
and n  shah  subset selection via implicit utilitarian voting  jour-
nal of artificial intelligence research  58 123–152  2017 
 caragiannis et al   2019  i  caragiannis  d  kurokawa  h  moulin 
a  d  procaccia  n  shah  and j  wang  the unreasonable fairness
of maximum nash welfare  acm transactions on economics and
computation  teac   7 3  1–32  2019 
 chaudhury et al   2020  b 
r 
chaudhury 
j 
garg 
and
k  mehlhorn 
efx exists for three agents 
in proceedings
of the 21st acm conference on economics and computation
 ec   pages 1–19  2020 
 garg and taki  2020  j  garg and s  taki  an improved approxi-
mation algorithm for maximin shares  in proceedings of the 21st
acm conference on economics and computation  ec   pages
379–380  2020 
 ghodsi et al   2018  m  ghodsi  m  hajiaghayi  m  seddighin 
s  seddighin  and h  yami  fair allocation of indivisible goods 
improvements and generalizations  in proceedings of the 19th
acm conference on economics and computation  ec   pages
539–556  2018 
 gkatzelis et al   2020  v  gkatzelis  d  halpern  and n  shah  re-
solving the optimal metric distortion conjecture 
in proceed-
ings of the 61st symposium on foundations of computer science
 focs   pages 1427–1438  2020 
 herreiner and puppe  2002  d  herreiner and c  puppe  a simple
procedure for finding equitable allocations of indivisible goods 
social choice and welfare  19 2  415–430  2002 
 kempe  2020  d  kempe 
communication  distortion  and ran-
domness in metric voting  in proceedings of the 34th aaai con-
ference on artificial intelligence  aaai   pages 2087–2094  2020 
 kurokawa et al   2018  d  kurokawa 
a  d  procaccia 
and
j  wang 
fair enough  guaranteeing approximate maximin
shares  journal of the acm  65 2  1–27  2018 
 lipton et al   2004  r  j  lipton  e  markakis  e  mossel  and
a  saberi  on approximately fair allocations of indivisible goods 
in proceedings of the 6th acm conference on economics and
computation  ec   pages 125–131  2004 
 mandal et al   2019  d  mandal  a  d  procaccia  n  shah  and
d  p  woodruff  efficient and thrifty voting by any means neces-
sary  in proceedings of the 33rd annual conference on neural
information processing systems  neurips   pages 7180–7191 
2019 
 mandal et al   2020  d  mandal  n  shah  and d  p  woodruff  op-
timal communication-distortion tradeoff in voting  in proceed-
ings of the 21st acm conference on economics and computation
 ec   pages 795–813  2020 
 nguyen et al   2017  n  t  nguyen  t  t  nguyen  and j  rothe 
approximate solutions to max-min fair and proportionally fair
allocations of indivisible goods  in proceedings of the 16th in-
ternational conference on autonomous agents and multi-agent
systems  aamas   pages 262–271  2017 
 procaccia and rosenschein  2006  a  d  procaccia and j  s 
rosenschein  the distortion of cardinal preferences in voting  in
proceedings of the 10th international workshop on cooperative
information agents  cia   pages 317–331  2006 
 steinhaus  1948  h  steinhaus 
the problem of fair division 
econometrica  16 101–104  1948 
proceedings of the thirtieth    ijcai-21 
230
 "
None,2021,https-www-ijcai-org-proceedings-2021-0033-pdf,Accomplice Manipulation of the Deferred Acceptance Algorithm,"Hadi Hosseini, Fatima Umar, Rohit Vaish",None,https://www.ijcai.org/proceedings/2021/0033.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0033-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0033-pdf.pdf,"accomplice manipulation of the deferred acceptance algorithm
hadi hosseini1   fatima umar2 and rohit vaish3
1pennsylvania state university
2rochester institute of technology
3tata institute of fundamental research
hadi@psu edu  fu1476@rit edu  rohit vaish@tifr res in
abstract
the deferred acceptance algorithm is an elegant so-
lution to the stable matching problem that guar-
antees optimality and truthfulness for one side of
the market  despite these desirable guarantees  it
is susceptible to strategic misreporting of prefer-
ences by the agents on the other side  we study
a novel model of strategic behavior under the de-
ferred acceptance algorithm  manipulation through
an accomplice  here  an agent on the proposed-
to side  say  a woman  partners with an agent on
the proposing side—an accomplice—to manipulate
on her behalf  possibly at the expense of wors-
ening his match   we show that the optimal ma-
nipulation strategy for an accomplice comprises of
promoting exactly one woman in his true list  i e  
an inconspicuous manipulation  
this structural
result immediately gives a polynomial-time algo-
rithm for computing an optimal accomplice manip-
ulation  we also study the conditions under which
the manipulated matching is stable with respect to
the true preferences  our experimental results show
that accomplice manipulation outperforms self ma-
nipulation both in terms of the frequency of occur-
rence as well as the quality of matched partners 
1
introduction
the deferred acceptance  da  algorithm  gale and shap-
ley  1962  is a crowning achievement of the theory of two-
sided matching  manlove  2013   and forms the backbone
of a wide array of real-world matching markets such as
entry-level labor markets  roth  1984  roth and peranson 
1999  and school choice  abdulkadiro˘glu et al   2005b 
abdulkadiro˘glu et al   2005a  
under this algorithm  one
side of the market  colloquially  the men  makes proposals
to the other side  the women  subject to either immediate re-
jection or tentative acceptance  a key property of the da
algorithm is stability which says that no pair of unmatched
agents should prefer each other over their assigned partners 
this property has played a significant role in the long-term
success of several real-world matching markets  roth  1991 
roth  2002  
the attractive stability guarantee of the da algorithm  how-
ever  comes at the cost of incentives  as any stable matching
procedure is known to be vulnerable to strategic misreporting
of preferences  roth  1982   the special proposal-rejection
structure of the da algorithm makes truth-telling a dominant
strategy for the proposing side  i e   the men  dubins and
freedman  1981  roth  1982   implying that any strategic be-
havior must occur on the proposed-to side  i e   the women 
this model of strategic behavior by a woman—which we call
self manipulation—has been the subject of extensive study
in economics and computer science  dubins and freedman 
1981  gale and sotomayor  1985b  demange et al   1987 
teo et al   2001  kobayashi and matsui  2009  kobayashi and
matsui  2010  vaish and garg  2017  deng et al   2018  
our interest in this work is in studying a different model
of strategic behavior under the da algorithm called manipu-
lation through an accomplice  bendlin and hosseini  2019  
under this model  a woman reports her preferences truthfully 
but asks an agent on the proposing side  a k a  an accomplice 
to manipulate the outcome on her behalf  possibly worsening
his match in the process 
such a strategic alliance can naturally arise in the assign-
ment of students to schools under a school-proposing setup 
where a  well-connected  student could have a school ad-
ministrator manipulate on his/her behalf  possibly at a small
loss to the school  similarly  in a student-proposing setting 
schools can strategize by making themselves appear less at-
tractive to students from low-income backgrounds  thus forc-
ing a change in the students  preferences  hatfield et al  
2016   accomplice manipulation can also be seen as a con-
trol problem  wherein a woman can bribe a man to lie on
her behalf  bribery has been extensively studied in compu-
tational social choice in the context of voting  and our work
can be seen as investigating this phenomenon in the two-sided
matching framework 
at first glance  manipulation through an accomplice might
not seem any more powerful than self manipulation  as the
latter provides direct control over the preferences of the ma-
nipulator  interestingly  there exist instances where this intu-
ition turns out to be wrong 
example 1  accomplice vs  self   consider the following
preference profile where the da outcome is underlined  the
notation  m1   w3 w2 w1 w4  denotes that for man m1  the
first choice woman is w3  the second choice is w2  and so on 
proceedings of the thirtieth    ijcai-21 
231
 m1  w∗
3
w2
w1
w4
w1  m4
m∗
3
m1
m2
m2  w1
w∗
4
w2
w3
w2 
m∗
4
m3
m2
m1
m3  w2
w4
w∗
1
w3
w3 
m3
m∗
1
m2
m4
m4  w∗
2
w1
w3
w4
w4 
m∗
2
m1
m3
m4
figure 1  comparing no-regret accomplice and self manipulation
against truthful reporting  left  and against each other  right  
suppose w1 seeks to improve her match via manipulation 
the optimal self manipulation strategy for w1 is truth-telling 
as m2 is the only man who proposes to her under the da al-
gorithm  on the other hand  w1 can improve her outcome
by asking m1 to misreport on her behalf  indeed  if m1 mis-
reports by declaring ≻′
m1 = w1 ≻ w3 ≻ w2 ≻ w4  then
w1 s match improves from m2 to m3  the new da matching
is marked by ∗   notice that the accomplice m1 preserves his
initial match  meaning he does not incur any  regret  
the above example highlights that accomplice manipula-
tion could  in principle  have an advantage over self manipu-
lation  however  it is not apriori clear how frequent such an
advantage might be in a typical matching scenario  to inves-
tigate the latter question  we take a quick experimental detour 
accomplice manipulation is a viable strategic behavior 
we simulate a two-sided matching scenario for an increas-
ingly larger set of agents  specifically  n ∈  3          40  
where n is the number of men/women  and for each setting 
generate 1000 preference profiles uniformly at random  for
each profile  we compute the optimal self manipulation under
the da algorithm for a fixed woman  teo et al   2001   and
the optimal accomplice manipulation by any man  we allow
any man to be chosen as an accomplice as long as he is not
worse off  i e   a no-regret accomplice manipulation   fig-
ure 1 illustrates the fraction of instances where accomplice
and self manipulation are strictly more beneficial than truth-
ful reporting  and how they compare against each other  ex-
ample 1 and figure 1 suggest that the incentive for manipu-
lation through an accomplice is not only present but actually
more prevalent than self manipulation  additionally  as we
discuss later in our experimental results  women are expected
to receive better matches when manipulating through an ac-
complice  figure 2   these promising observations call for a
systematic study of the structural and computational aspects
of the accomplice manipulation problem  which is the focus
of our work 
our contributions 
we consider two models of strategic
behavior— no-regret manipulation  wherein the accomplice s
own match doesn t worsen upon misreporting  and with-
regret manipulation  where the accomplice could get a worse
match —and make the following contributions 
• no-regret manipulation 
our main theoretical result
 theorem 2  is that any optimal no-regret accomplice ma-
nipulation can be simulated by promoting exactly one
woman in the true preference list of the accomplice  in
other words  the manipulation is inconspicuous  vaish and
garg  2017   this structural finding immediately gives a
polynomial-time algorithm for computing an optimal ma-
nipulation  corollary 2   we also show that the inconspic-
uous no-regret strategy results in a matching that is stable
with respect to the true preferences  corollary 3  
• with-regret manipulation 
for the more permissible
strategy space that allows the accomplice to incur regret 
the optimal manipulation strategy once again turns out be
inconspicuous  theorem 3   however  in contrast to the
no-regret case  the inconspicuous with-regret strategy is no
longer guaranteed to be stability-preserving  example 3  
nevertheless  any blocking pair can be shown to necessar-
ily involve the accomplice  proposition 2   this property
justifies the use of an accomplice who can be encouraged
to tolerate some regret to benefit a woman 
• experiments  on the experimental front  we work with
preferences generated uniformly at random  and find that
accomplice manipulation outperforms self manipulation
with respect to the frequency of occurrence  the quality of
matched partners  and the fraction of women who can im-
prove their matches  section 6  
2
related work
much of the early work on strategic aspects of stable
matchings focused on truncation manipulation  gale and
sotomayor  1985a  roth and rothblum  1999  coles and
shorrer  2014  jaramillo et al   2014   where the misreported
preference list is required to be a prefix of the true list 
the literature on self manipulation via permutation is more
recent and has focused on computational aspects 
teo et
al   2001  provided a polynomial-time algorithm for comput-
ing the optimal permutation manipulation by a woman under
the men-proposing da algorithm  deng et al   2018  studied
stability-preserving permutation manipulation by a coalition
of women and showed that such manipulations are inconspic-
uous  vaish and garg  2017  showed that an optimal permu-
tation manipulation by a single agent is inconspicuous even
without the stability-preserving requirement  they also stud-
ied conditions under which the manipulated outcome is stable
with respect to the true preferences 
huang  2006  studied  weakly  pareto improving permuta-
tion manipulation by a coalition of men  revisiting the result
of dubins and freedman  1981  on the impossibility of ma-
nipulations that are strictly improving for every member of
the coalition 
the accomplice manipulation model was proposed by
bendlin and hosseini  2019   who noted that manipulation
through an accomplice can be strictly more preferable for the
woman than optimal self manipulation  however  they left
the structural and computational questions open 
balinski and s¨onmez  1999  studied a closely related prob-
lem in school choice wherein the students have an incen-
tive to make themselves appear less preferable to colleges
 by performing badly on tests  under the college-optimal al-
gorithm  hatfield et al   2016  similarly showed that in a
proceedings of the thirtieth    ijcai-21 
232
 student-optimal mechanism  schools have the incentive to de-
liberately make themselves look less attractive to  undesir-
able  students  for example  a private school that is legally
required to cap its tuition fee for low-income students could
make itself less attractive by increasing the rent in dormitories
or requiring the students to purchase expensive uniforms 
3
preliminaries
3 1
stable matching problem
problem setup 
an instance of the stable marriage prob-
lem  gale and shapley  1962  is specified by the tuple
⟨m  w  ≻⟩  where m is a set of n men  w is a set of n
women  and ≻ is a preference profile which consists of the
preference lists of all agents  the preference list of any man
m ∈ m  denoted by ≻m  is a strict total order over all
women in w  for any w ∈ w  the list ≻w is defined anal-
ogously   we use w1 ⪰m w2 to denote  either w1 ≻m w2
or w1 =m w2   the latter denotes that man m is indif-
ferent between w1 and w2   and write ≻−m to denote the
preference lists of all men and women except man m  thus 
≻=  ≻−m  ≻m  
stable matchings 
a matching is a function µ   m ∪w →
m ∪ w such that µ m  ∈ w for all m ∈ m  µ w  ∈ m
for all w ∈ w  and µ m  = w if and only if µ w  = m  a
matching µ admits a blocking pair with respect to the pref-
erence profile ≻ if there is a man-woman pair  m  w  who
prefer each other over their assigned partners under µ  i e  
w ≻m µ m  and m ≻w µ w   a stable matching is one
that does not admit any blocking pair  we will write s≻ to
denote the set of all matchings that are stable with respect to
≻  in addition  for any pair of matchings µ  µ′  we will write
µ ⪰m µ′ to denote µ m  ⪰m µ′ m  for all m ∈ m  and
µ ⪰w µ′ for the women  
deferred acceptance algorithm 
given a preference pro-
file ≻  the deferred acceptance  da  algorithm of gale and
shapley  1962  proceeds in rounds  in each round  it consists
of a proposal phase  where each man who is currently un-
matched proposes to his favorite woman from among those
who have not rejected him yet  followed by a rejection phase
where each woman tentatively accepts her favorite proposal
and rejects the rest  the algorithm terminates when no fur-
ther proposals can be made  gale and shapley  1962  showed
that given any profile ≻ as input  the da algorithm always re-
turns a stable matching as output  we denote this matching
by da ≻   they observed that this matching is men-optimal 
i e   it assigns each man his favorite stable partner among all
stable matchings in s≻  mcvitie and wilson  1971  subse-
quently showed that this matching is also women-pessimal 
proposition 1   gale and shapley  1962  mcvitie and
wilson  1971    let ≻ be a preference profile and let
µ  = da ≻   then  µ ∈ s≻  furthermore  for any µ′ ∈ s≻ 
µ ⪰m µ′ and µ′ ⪰w µ 
accomplice manipulation 
under this model of strategic
behavior  a woman w  instead of misreporting herself  has
a man m provide a manipulated preference list  say ≻′
m 
in order to improve her match  given a preference profile
≻  we say that w can manipulate through accomplice m if
µ′ w  ≻w µ w   where µ  = da ≻   ≻′ =  ≻−m  ≻′
m  
and µ′  = da ≻′  
we will often refer to  m  w  as the
manipulating pair  not to be confused with a blocking pair  
throughout this paper  any manipulation will be assumed to
be optimal unless stated otherwise  that is  there exists no
other list ≻′′
m for the accomplice m such that µ′′ w  ≻w
µ′ w   where ≻′′ =  ≻−m  ≻′′
m   and µ′′  = da ≻′′   note
that we assume that the manipulator has full information
about the preferences of other agents  extending our results
to incomplete or uncertain information settings is an interest-
ing direction for future research 
no-regret and with-regret manipulation 
we say that the
accomplice m incurs regret if his match worsens upon mis-
reporting  i e   µ m  ≻m µ′ m   it is known that the da
algorithm is strategyproof for the proposing side  dubins and
freedman  1981   which means that no man can improve his
match by unilaterally misreporting his preferences  there-
fore  for any man m ∈ m and for any misreport ≻′
m  we
have that µ m  ⪰m µ′ m   thus  equivalently  we say that
man m incurs regret if µ m  ̸= µ′ m   we will consider two
models of accomplice manipulation in this paper  no-regret
manipulation wherein only those misreports ≻′
m are allowed
under which µ m  = µ′ m   and with-regret manipulation 
where the accomplice is allowed  but not required  to incur
regret  thus  any no-regret strategy is also a with-regret strat-
egy  recall that the misreport in example 1 was a no-regret
manipulation 
stability relaxations 
for any preference profile ≻ and
a fixed man m ∈ m  we say that a matching µ is m-
stable  bendlin and hosseini  2019  with respect to ≻ if any
blocking pair  if one exists  in µ involves the man m  that is 
for any pair  m′  w′  that blocks µ under ≻  we have m′ = m 
clearly  a stable matching is also m-stable  under accom-
plice manipulation  it can be shown that any matching µ′ that
is stable with respect to the manipulated profile  in particular 
when µ′ = da ≻′   is m-stable with respect to the true pro-
file ≻  proposition 2   we note that proposition 2 strengthens
a result of bendlin and hosseini  2019  who proved a similar
statement only for a da matching  the proof of this result 
along with all other omitted proofs  can be found in the full
version of the paper  hosseini et al   2020  
proposition 2  let ≻ denote the true preference profile  for
any man m  let ≻′ =  ≻−m  ≻′
m   and let µ′ ∈ s≻′ be any
matching that is stable with respect to ≻′  then  µ′ is m-
stable with respect to ≻ 
3 2
structural observations
push up/push down operations 
note that given a pro-
file ≻  the preference list of any man m can be written as
≻m=  ≻l
m  µ m   ≻r
m   where µ = da ≻  and ≻l
m  respec-
tively  ≻r
m  is the set of women that m prefers to  respec-
tively  finds less preferable than  µ m   interestingly  the da
outcome does not change even if each man m arbitrarily per-
mutes the parts of his list above and below his da-partner
µ m   this result  due to huang  2006   is recalled below 
proposition 3   huang  2006    let ≻ be a preference pro-
file and let µ  = da ≻  
for any man m ∈ m  let
proceedings of the thirtieth    ijcai-21 
233
 ≻′
m =  πl ≻l
m   µ m   πr ≻r
m    where πl and πr are ar-
bitrary permutations of ≻l
m and ≻r
m  respectively  let ≻′ =
 ≻−m  ≻′
m   and let µ′  = da ≻′   then  µ′ = µ 
proposition 3 considerably simplifies the structure of ac-
complice manipulations that we need to consider  indeed  we
can assume that any manipulated list ≻′
m is such that the rel-
ative ordering of agents in the parts above and below µ′ m 
is the same as under the true list ≻m  where µ′  = da ≻′ 
and ≻′ =  ≻−m  ≻′
m  are the post-manipulation da out-
come and preference profile  respectively 
this observation implies that  without loss of general-
ity  any manipulated list ≻′
m can be obtained from the
true list ≻m by only push up and push down opera-
tions  wherein a set of women is pushed up above the
true match µ m   and another disjoint set is pushed below
µ m  
importantly  no permutation or shuffling operation
is required as part of the manipulation 
formally  start-
ing with the true list ≻m=  ≻l
m  µ m   ≻r
m   we say that
man m performs a push up operation for a set x ⊆ w
if the new list is ≻x↑
m  =  ≻l
m ∪x  µ m   ≻r
m \x  
like-
wise  a push down operation of a set y
⊆ w results in
≻y ↓
m  =  ≻l
m \y  µ m   ≻r
m ∪y   
for
manipulation
via
push
down
operations
only 
huang  2006  has shown that the resulting matching is
weakly improving for all men  together  with the fact that
the da algorithm is strategyproof for the proposing side  in
our case the men   dubins and freedman  1981   we get that
the da partner of the accomplice remains unchanged after a
push down operation 
proposition 4   dubins and freedman  1981  huang  2006   
let ≻ be the true preference profile and let µ  = da ≻  
for any subset of women x ⊆ w and any fixed accomplice
m ∈ m  let ≻′ =  ≻−m  ≻x↓
m   and µ′  = da ≻′   then 
µ′ ⪰m µ and µ′ m  = µ m  
the effect of push down operations for the proposed-to
side is the exact opposite  as the resulting matching makes
all women weakly worse off 
lemma 1  let ≻ be the true preference profile and let
µ  = da ≻  
for any subset of women x ⊆ w  let
≻′ =  ≻−m  ≻x↓
m   and µ′  = da ≻′   then  µ ⪰w µ′ 
lemma 1 shows that in order to improve the partner of
the woman w  the use of push up operations  by the ac-
complice  is necessary  however  it is not obvious upfront
whether push up alone suffices  indeed  it is possible that the
optimal strategy involves some combination of push up and
push down operations  to this end  our theoretical results
will show that  somewhat surprisingly  pushing up at most
one woman achieves the desired optimal manipulation  the-
orems 2 and 3   this strategy is known in the literature as
inconspicuous manipulation  which we define next 
inconspicuous manipulation 
given a profile ≻ of true
preferences and any fixed accomplice m  the manipulated list
≻′
m is said to be an inconspicuous manipulation if the list ≻′
m
can be derived from the true preference list ≻m by promoting
exactly one woman and making no other changes  the notion
of inconspicuous manipulation has been previously studied in
the context of self manipulation  where w misreports herself  
where it was shown that an optimal self manipulation is  with-
out loss of generality  inconspicuous  vaish and garg  2017 
deng et al   2018  
4
no-regret accomplice manipulation
let us start by observing that the da matching after an ar-
bitrary  i e   not necessarily push up  no-regret accomplice
manipulation may not be stable with respect to the true pref-
erences 
example 2  consider the following preference profile where
the da outcome is underlined 
m1   w∗
2
w†
1
w3
w4
w5
w1   m†
1 m3 m∗
2 m4 m5
m2   w∗
1
w†
2
w3
w4
w5
w2   m†
2 m∗
1 m3 m4 m5
m3  w1
w∗ †
3
w4
w2
w5
w3   m∗ †
3 m1 m2 m4 m5
m4   w4
w∗ †
5
w1
w2
w3
w4   m∗ †
5 m3 m1 m2 m4
m5   w5
w∗ †
4
w1
w2
w3
w5   m∗ †
4 m1 m2 m3 m5
suppose the manipulating pair is  m3  w4  
the da
matches after the accomplice m3 submits the manipulated list
≻′
m3 = w4 ≻ w3 ≻ w1 ≻ w2 ≻ w5 are marked by ∗  the
manipulation results in w4 being matched with her top choice
m5  i e   ≻′
m3 is an optimal manipulation   an improvement
over her true match m4  although m3 does not incur regret 
the manipulated matching admits a blocking pair  m3  w1 
with respect to the true preferences 
notice that if instead m3 were to submit ≻′′
m3 = w4 ≻
w1 ≻ w3 ≻ w2 ≻ w5 as his preference list in example 2 
then the resulting da matching  indicated by †  would be sta-
ble with respect to the true preferences while still allowing
w4 to match with m5  i e   ≻′′
m3 is also optimal   the ma-
nipulated list ≻′′
m3 is derived from the true list ≻m3 through
a no-regret push up operation  our first main result of this
section  theorem 1  shows that this is not a coincidence  the
set of all stable matchings with respect to a profile after a no-
regret push up operation is always contained within the stable
set of the true preference profile 
theorem 1  no-regret push up is stability preserving   let ≻
be a preference profile  and let µ  = da ≻   for any subset of
women x ⊆ w and any man m  let ≻′ =  ≻−m  ≻x↑
m    and
µ′  = da ≻′   if m does not incur regret  then s≻′ ⊆ s≻ 
a primary consequence of theorem 1 is that the da match-
ing after a no-regret accomplice manipulation is weakly pre-
ferred over the true da outcome by all women  while the op-
posite is true for the men 
corollary 1 
let ≻ be a preference profile and let
µ  = da ≻   for any man m  let ≻′ =  ≻−m  ≻x↑
m   and
µ′  = da ≻′   if m does not incur regret  then µ′ ⪰w µ and
µ ⪰m µ′ 
as observed in section 3 2  any manipulation by the ac-
complice can be  without loss of generality  assumed to com-
prise only of push up and push down operations  we will now
show that combining these operations is not necessary  that
is  any manipulation that is achieved by a combination of push
up and push down operations can be weakly improved by a
push up operation alone  lemma 2   we note that this result
does not require the no-regret assumption  and applies to the
with-regret setting as well 
proceedings of the thirtieth    ijcai-21 
234
 lemma 2  let  m  w  be a manipulating pair and let ≻ be
a preference profile  for any subsets of women x ⊆ w and
y ⊆ w  let ≻′ =  ≻−m  ≻x↑
m   denote the preference pro-
file after pushing up the set x  and ≻′′ =  ≻−m  ≻x↑ y ↓
m
 
denote the profile after pushing up x and pushing down y
in the true preference list ≻m of man m  let µ  = da ≻  
µ′  = da ≻′   and µ′′  = da ≻′′   then  µ′ w  ⪰w µ′′ w  
having narrowed down the strategy space to push up op-
erations alone  we will now turn our attention to inconspic-
uous manipulations  recall that such a manipulation involves
promoting exactly one woman in the accomplice s true pref-
erence list to a higher position   we will show that any match
for the manipulating woman w that can be obtained by push-
ing up a set of women can also be achieved by promoting
exactly one woman in that set  lemma 3   in other words 
any no-regret push up operation is  without loss of general-
ity  inconspicuous  we note that although lemma 3 assumes
no regret for the accomplice  the corresponding implication
actually holds even in the with-regret setting  see lemma 4  
lemma 3  let  m  w  be a manipulating pair  and let
x ⊆ w be an arbitrary set of women that m can push up
without incurring regret  then  the match for w that is ob-
tained by pushing up all women in x can also be obtained by
pushing up exactly one woman in x 
we will now use the foregoing observations to prove our
main result  theorem 2  
theorem 2  if there is an optimal no-regret accomplice ma-
nipulation  then there is an optimal inconspicuous no-regret
accomplice manipulation 
proof  from proposition 3  and subsequent remarks   we
know that any accomplice manipulation can be simulated via
push up and push down operations  lemma 2 shows that
any beneficial manipulation that is achieved by some com-
bination of pushing up a set x ⊆ w and pushing down
y ⊆ w can be weakly improved by only pushing up x 
finally  from lemma 3  we know that any match for the ma-
nipulating woman w that is achieved by pushing up x ⊆ w
is also achieved by pushing up exactly one woman in x  thus
establishing the desired inconspicuousness property 
theorem 2 has some interesting computational and struc-
tural implications  first  the inconspicuousness property im-
plies a straightforward polynomial-time algorithm for com-
puting an optimal no-regret accomplice manipulation  corol-
lary 2   second  the da matching resulting from an incon-
spicuous no-regret manipulation is stable with respect to the
true preferences  corollary 3   together  these results rec-
oncile the seemingly conflicting interests of the manipulator
 who wants to compute optimal manipulation efficiently  and
the central planner  who wants the resulting matching to be
stable with respect to the true preferences  
corollary 2  an optimal no-regret accomplice manipulation
strategy can be computed in o n3  time 
corollary 3  the da outcome from an inconspicuous no-
regret accomplice manipulation is stable with respect to the
true preferences 
in summary  recall from example 2 that an arbitrary opti-
mal no-regret strategy may not be stability-preserving  nev-
ertheless  any optimal no-regret strategy admits an equivalent
inconspicuous strategy  theorem 2  which indeed preserves
stability  corollary 3  
5
with-regret accomplice manipulation
no-regret manipulations come at no cost for the accomplice
and thus are a viable strategic behavior  as shown in figure 1  
yet  a more permissive strategy space may allow for the ac-
complice to incur some regret  such with-regret manipula-
tions may be justifiable in practice  an accomplice s idiosyn-
cratic preference may be tolerant to a small loss in exchange
of gain for the partnering woman  or a woman may persuade
a man to withstand some regret by providing side-payments 
we will start by illustrating that a with-regret accomplice
manipulation can be strictly more beneficial compared to its
no-regret and self manipulation counterparts 
example 3  with-regret vs  no-regret   consider the follow-
ing preference profile where the da outcome is underlined 
m1  w∗
4
w†
1
w2
w5
w3
w1   m†
1 m∗
2 m3 m4 m5
m2   w2
w4
w∗
1
w†
5
w3
w2   m∗ †
3 m5 m1 m2 m4
m3   w1
w∗ †
2
w4
w3
w5
w3   m2 m∗
5 m1 m†
4 m3
m4   w1
w†
3
w∗
5
w2
w4
w4   m4 m3 m∗
1 m†
5 m2
m5   w1
w†
4
w∗
3
w5
w2
w5   m∗
4 m†
2 m5 m1 m3
suppose the manipulating pair is  m1  w1   the da match-
ing after m1 submits the optimal no-regret1 manipulated list
≻′
m1 = w2 ≻ w4 ≻ w1 ≻ w5 ≻ w3 and the optimal with-
regret manipulated list ≻′′
m1 = w1 ≻ w4 ≻ w2 ≻ w5 ≻ w3
are marked by ∗ and †  respectively 
both manipulation
strategies improve w1 s matching compared to truthful re-
porting  but w1 strictly prefers the with-regret outcome 
example 3 highlights two key differences between optimal
no-regret and with-regret manipulations  first  the matching
after the inconspicuous with-regret manipulation  marked by
†  admits a blocking pair  m1  w4  with respect to the true
profile ≻  this is in contrast to the no-regret case which is sta-
bility preserving  theorem 1   second  in contrast to corol-
lary 1  an optimal with-regret manipulation is not guaranteed
to weakly improve or worsen the matching for all agents on
one side  indeed the women w3 and w5 are strictly worse off
while w1 is strictly better off  similarly  the man m1 is strictly
worse off while m4 and m5 strictly improve 
the primary distinction between no-regret and with-regret
manipulation lies in the push up operations  if pushing up a
set of women does not cause regret for the accomplice  then
pushing up any subset thereof does not either  by contrast  if
by pushing up a set of women the accomplice incurs regret 
then there exists exactly one woman in that set who causes
the same level of regret when pushed up individually  as
previously mentioned  with-regret push up operations do not
1to see why ≻′
m1 is an optimal no-regret manipulation  note that
the woman-optimal stable matching  with respect to ≻  matches w1
with m2  from theorem 2 and corollary 3  an optimal no-regret
manipulation is  without loss of generality  stability preserving  and
from proposition 1  m2 is the best stable partner for w2 
proceedings of the thirtieth    ijcai-21 
235
 uniformly affect all men and all women  in contrast to corol-
lary 1   moreover  the set of attained matchings after a with-
regret manipulation are no longer stable with respect to true
preferences  in contrast to theorem 1   which makes the anal-
ysis challenging 
despite these structural differences  we are able to prove
an analogue of lemma 3 for with-regret push up operations
 lemma 4   our proof of this result relies on the fact that all
proposals that occur when the accomplice pushes up a set of
women are contained in the union of sets of proposals that
occur when pushing up individual women in that set  this is
relatively easy to prove for the no-regret case  since the da
matchings after these push up operations are all stable with
respect to true preferences  theorem 1   although we cannot
rely on the same stability result for the with-regret case  we
circumvent the issue by reasoning about the sets of proposals
in greater detail 
lemma 4  let  m  w  be a manipulating pair  and let
x ⊆ w be an arbitrary set of women that m can push up
 while incurring regret   then  the match for w that is ob-
tained by pushing up all women in x can also be obtained by
pushing up exactly one woman in x 
subsequently  an optimal with-regret manipulation is 
without loss of generality  inconspicuous  the proof is sim-
ilar to that of the no-regret case  theorem 2  with the only
difference being the use of lemma 4 in place of lemma 3 
theorem 3  if there is an optimal with-regret accomplice ma-
nipulation  then there is an optimal inconspicuous with-regret
accomplice manipulation 
theorem 3 immediately implies a polynomial-time algo-
rithm for computing an optimal with-regret accomplice ma-
nipulation  moreover  the da outcome from any inconspic-
uous with-regret accomplice manipulation is m-stable with
respect to the true preferences  proposition 2  
corollary 4  an optimal with-regret accomplice manipula-
tion strategy can be computed in o n3  time 
6
experimental results
in addition to the experiments described in section 1  we per-
formed a series of simulations to analyze the performance of
accomplice manipulation  as for the previous experimental
setup  we generated 1000 profiles uniformly at random for
each value of n ∈  3          40   where n is the number of
men/women  and allowed any man to be chosen as an ac-
complice for each experiment unless stated otherwise 
comparing the quality of partners 
we first compare the
quality of partners that a fixed strategic woman w is matched
with through no-regret accomplice and self manipulation 
figure 2 illustrates the distributions of improvement  in terms
of rank difference  out of only those instances where w is
strictly better off through the two strategies individually  in
other words  the self  respectively  accomplice  manipulation
boxplots only reflect the data for when self  respectively  ac-
complice  manipulation is successful  it is evident that  in ex-
pectation  w is matched with better partners through no-regret
accomplice manipulation 
figure 2  comparing no-regret accomplice and self manipulation
in terms of the improvement in the rank of the matched partner of
w  the solid bars  whiskers  and dots denote the interquartile range 
range excluding outliers  and outliers  respectively 
figure 3  comparing no-regret accomplice and self manipulation in
terms of the fraction of women who benefit 
the fraction of women who improve 
we additionally
compare the fraction of women who are able to improve
through no-regret accomplice and self manipulation individ-
ually  teo et al   2001  reported that 5 06  of women were
able to improve using self manipulation when n = 8  in our
experiment  this value is similarly 4 18   however  9 99  of
women are able to improve through no-regret accomplice ma-
nipulation  as illustrated in figure 3  the fraction of women
who benefit from no-regret accomplice manipulation is con-
sistently more than double that of self manipulation 
7
concluding remarks
we showed that accomplice manipulation is a viable strate-
gic behavior that only requires inconspicuous misreporting of
preferences and is frequently more beneficial than the classi-
cal self-manipulation strategy  a natural avenue for future
research is to investigate a setting with multiple accomplices
working together to manipulate the outcome for the strate-
gic woman  or one where the accomplice and the manipu-
lating woman can misreport their preference lists simultane-
ously  analyzing the benefits of such coalitional manipula-
tion strategies—with or without regret—on one or both sides 
and studying their structural and algorithmic properties are
intriguing directions for future work 
acknowledgements
hh acknowledges support from nsf grant #1850076  rv
acknowledges support from onr#n00014-171-2621  project
no  rti4001 of the department of atomic energy  govern-
ment of india  and prof  r narasimhan postdoctoral award 
proceedings of the thirtieth    ijcai-21 
236
 references
 abdulkadiro˘glu et al   2005a  atila
abdulkadiro˘glu 
parag a pathak  and alvin e roth 
the new york
city high school match 
american economic review 
95 2  364–367  2005 
 abdulkadiro˘glu et al   2005b  atila
abdulkadiro˘glu 
parag a pathak  alvin e roth  and tayfun s¨onmez 
the boston public school match 
american economic
review  95 2  368–371  2005 
 balinski and s¨onmez  1999  michel balinski and tayfun
s¨onmez  a tale of two mechanisms  student placement 
journal of economic theory  84 1  73–94  1999 
 bendlin and hosseini  2019  theodora bendlin and hadi
hosseini  partners in crime  manipulating the deferred
acceptance algorithm through an accomplice  in pro-
ceedings of the aaai conference on artificial intelligence 
volume 33  pages 9917–9918  2019 
 coles and shorrer  2014  peter coles and ran shorrer  op-
timal truncation in matching markets  games and eco-
nomic behavior  87 591–615  2014 
 demange et al   1987  gabrielle demange  david gale  and
marilda sotomayor  a further note on the stable match-
ing problem  discrete applied mathematics  16 3  217–
222  1987 
 deng et al   2018  yuan deng  weiran shen  and pingzhong
tang  coalitional permutation manipulations in the gale-
shapley algorithm  in proceedings of the 17th interna-
tional conference on autonomous agents and multiagent
systems  pages 928–936  2018 
 dubins and freedman  1981  lester e dubins and david a
freedman 
machiavelli and the gale-shapley algo-
rithm  the american mathematical monthly  88 7  485–
494  1981 
 gale and shapley  1962  david gale and lloyd s shapley 
college admissions and the stability of marriage  the
american mathematical monthly  69 1  9–15  1962 
 gale and sotomayor  1985a  david gale and marilda so-
tomayor  ms  machiavelli and the stable matching prob-
lem 
the american mathematical monthly  92 4  261–
268  1985 
 gale and sotomayor  1985b  david gale and marilda so-
tomayor  some remarks on the stable matching problem 
discrete applied mathematics  11 3  223–232  1985 
 hatfield et al   2016  john william hatfield  fuhito kojima 
and yusuke narita 
improving schools through school
choice  a market design approach  journal of economic
theory  166 186–211  2016 
 hosseini et al   2020  hadi hosseini  fatima umar  and ro-
hit vaish  accomplice manipulation of the deferred ac-
ceptance algorithm 
arxiv preprint arxiv 2012 04518 
2020 
 huang  2006  chien-chung huang 
cheating by men in
the gale-shapley stable matching algorithm  in euro-
pean symposium on algorithms  pages 418–431  springer 
2006 
 jaramillo et al   2014  paula jaramillo  c¸ aˇgatay kayı  and
flip klijn  on the exhaustiveness of truncation and drop-
ping strategies in many-to-many matching markets  so-
cial choice and welfare  42 4  793–811  2014 
 kobayashi and matsui  2009  hirotatsu kobayashi and to-
momi matsui  successful manipulation in stable marriage
model with complete preference lists  ieice transac-
tions on information and systems  92 2  116–119  2009 
 kobayashi and matsui  2010  hirotatsu kobayashi and to-
momi matsui  cheating strategies for the gale-shapley
algorithm with complete preference lists  algorithmica 
58 1  151–169  2010 
 manlove  2013  david manlove  algorithmics of matching
under preferences  volume 2  world scientific  2013 
 mcvitie and wilson  1971  david g mcvitie and leslie b
wilson  the stable marriage problem  communications
of the acm  14 7  486–490  1971 
 roth and peranson  1999  alvin e roth and elliott peran-
son  the redesign of the matching market for american
physicians  some engineering aspects of economic de-
sign  american economic review  89 4  748–780  1999 
 roth and rothblum  1999  alvin e roth and uriel g roth-
blum 
truncation strategies in matching markets—
in search of advice for participants 
econometrica 
67 1  21–43  1999 
 roth  1982  alvin e roth 
the economics of matching 
stability and incentives  mathematics of operations re-
search  7 4  617–628  1982 
 roth  1984  alvin e roth  the evolution of the labor mar-
ket for medical interns and residents  a case study in
game theory  journal of political economy  92 6  991–
1016  1984 
 roth  1991  alvin e roth  a natural experiment in the or-
ganization of entry-level labor markets  regional mar-
kets for new physicians and surgeons in the united king-
dom 
the american economic review  pages 415–440 
1991 
 roth  2002  alvin e roth 
the economist as engineer 
game theory  experimentation  and computation as
tools for design economics  econometrica  70 4  1341–
1378  2002 
 teo et al   2001  chung-piaw teo  jay sethuraman  and
wee-peng tan 
gale-shapley stable marriage problem
revisited  strategic issues and applications  management
science  47 9  1252–1267  2001 
 vaish and garg  2017  rohit vaish and dinesh garg  ma-
nipulating gale-shapley algorithm  preserving stability
and remaining inconspicuous  in proceedings of the 26th
  
pages 437–443  2017 
proceedings of the thirtieth    ijcai-21 
237
 "
None,2021,https-www-ijcai-org-proceedings-2021-0034-pdf,Guaranteeing Maximin Shares: Some Agents Left Behind,"Hadi Hosseini, Andrew Searns",None,https://www.ijcai.org/proceedings/2021/0034.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0034-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0034-pdf.pdf,"guaranteeing maximin shares  some agents left behind
hadi hosseini1 and andrew searns2
1pennsylvania state university
2rochester institute of technology
hadi@psu edu  abs2157@rit edu
abstract
the maximin share  mms  guarantee is a desirable
fairness notion for allocating indivisible goods 
while mms allocations do not always exist  sev-
eral approximation techniques have been devel-
oped to ensure that all agents receive a fraction of
their maximin share  we focus on an alternative
approximation notion  based on the population of
agents  that seeks to guarantee mms for a fraction
of agents  we show that no optimal approximation
algorithm can satisfy more than a constant number
of agents  and discuss the existence and computa-
tion of mms for all but one agent and its relation to
approximate mms guarantees  we then prove the
existence of allocations that guarantee mms for 2
3
of agents  and devise a polynomial time algorithm
that achieves this bound for up to nine agents  a
key implication of our result is the existence of al-
locations that guarantee mms⌈3n/2⌉  i e   the value
that agents receive by partitioning the goods into
⌈ 3
2n⌉ bundles  improving the best known guarantee
of mms2n−2  finally  we provide empirical exper-
iments using synthetic data 
1
introduction
fair division deals with the allocation of a set of resources
to a set of agents in a fair manner  brams and taylor  1996 
foley  1967  hosseini et al   2020   one of its most notable
application domains deals with the allocation of indivisible
 and non-shareable  goods  these applications arise  for ex-
ample  in dividing inheritance and dispute resolution  brams
and taylor  1996   task assignment or course allocation  bud-
ish  2011   and have been popularized in recent years due to
publicly accessible platforms such as spliddit 
the most desirable fairness notion  envy-freeness  requires
that each agent weakly prefers his own allocation to that of
all other agents  a weaker notion  called proportionality  re-
quires that each agent receives 1
n of her valuation of all goods 
where n is the total number of agents  unfortunately  in the
indivisible domain neither of these notions are guaranteed to
exist  consider a single good and two interested agents  nei-
ther envy-freeness nor proportionality can be satisfied as one
agent is destined to remain empty handed 
a third fairness notion  proposed by budish  2011   is the
maximin share  mms  guarantee  which can be seen as a gen-
eralization of the cut-and-choose protocol  brams and taylor 
1996   in a nutshell  the maximin share is the value that an
agent can guarantee by dividing the goods into n bundles  as-
suming that all other agents choose a bundle before she does 
there is no reason to believe that such a bound can always
be satisfied for all agents  it turns out that an mms allocation
does not always exist  kurokawa et al   2018   and even when
it exists  computing an mms partition is intractable  bou-
veret and lemaˆıtre  2016   thus  several approximation tech-
niques were developed to guarantee that each agent receives a
fraction of her mms  while these techniques are compelling 
they may leave a large fraction of agents without their mms
guarantee 
we propose to circumvent this obstacle by taking an or-
thogonal direction based on the degree of fairness in the soci-
ety of agents  our goal is to find allocations that give a large
fraction of agents their maximin share guarantee  possibly
leaving a small fraction of agents behind  since mms alloca-
tions do not always exist   this approach is related to ordinal
approximations of mms and is of interest in several appli-
cation domains  resources in a hospital must be distributed
among tasks/procedures in a manner that a subset of critical
tasks can be fully accomplished  senior college students  as a
fraction of all students  must be guaranteed seats in courses
to avoid graduation delays 
unfortunately  envy-freeness and proportionality cannot be
approximated in this dimension  for instance  one may be in-
terested in minimizing the fraction of envious agents  envy-
freeness  similarly proportionality  may leave almost all but
one agent unsatisfied  consider n goods and n agents with
identical valuations  having 1 −  n − 1 ϵ value for one good
and ϵ for the rest  any distribution of goods will leave n − 1
agents envious  therefore  focusing on the maximin share
guarantee we ask the following questions 
what fraction of agents can be guaranteed their
mms value  and can we compute allocations that
guarantee mms for the majority of the agents 
1 1
our contributions
we propose a novel fairness framework  called  α  β -mms 
wherein α fraction of agents receive β approximations of
their mms value and investigate the interplay between the
proceedings of the thirtieth    ijcai-21 
238
 two approximation parameters  we establish the connection
between  α  β -mms and ordinal approximations of mms
 proposition 1   and investigate the computational boundaries
of α and β as follows 
• optimal mms  we prove the existence of a family of in-
stances where almost all agents do not receive their mms
by any optimal-mms allocation that aims to maximize β for
all agents  our counterexample uses a quadratic number of
goods  where n − 3 agents  n − 4 if n is odd  do not receive
their mms in any optimal-mms allocation  theorem 1  
• computing   n−1
n   β -mms  we devise a polynomial-time
algorithm achieving  α  β -mms when α =
n−1
n
 theo-
rem 2   a consequence of this result is a tight approximation
for n ≤ 4 that immediately implies an algorithm for comput-
ing mmsn 1 for n < 4  corollary 1  
• existence of   2
3  1 -mms  we prove the existence of
  2
3  1 -mms  theorem 3   and provide an algorithm that
achieves this bound in polynomial time for n < 9  theo-
rem 4   a key implication of our result is the existence of al-
locations that guarantee mms⌈3n/2⌉  i e   the value an agent
receives by partitioning the goods into ⌈ 3
2n⌉ bundles  corol-
lary 2   our result significantly improves the best known guar-
antee of mms2n−2  aigner-horev and segal-halevi  2019  
on the experimental front  we show that a simplified 
polynomial-time variant of our algorithm satisfies a large
fraction of agents on the most  difficult  instances and this
fraction grows as the ratio of goods to agents increases 
1 2
related work
on a high level  our approach is related to notions defined
to measure the degree of fairness in a society of agents
whether it pertains to minimizing the maximum or sum
of envy  chevaleyre et al   2007  chen and shah  2018 
nguyen and rothe  2014   minimizing envy ratio  lipton et
al   2004   balancing the amount of envy experienced in a
society  or promoting fairness through equitable allocations
where agents receive the same level of utility  schnecken-
burger et al   2017  freeman et al   2019   another closely
related line of work suggests the notion of counting instances
of envious pairs—among several other plausible measures—
as opposed to measuring the intensity of envy  feldman and
kirman  1974  
on a technical level  the non-existence of mms alloca-
tions  procaccia and wang  2014  and its intractability  bou-
veret and lemaˆıtre  2016  woeginger  1997  has given rise
to a number of approximation techniques  these algorithms
guarantee that each agent receives an approximation of their
maximin share  recently  nguyen et al   2017  gave a poly-
nomial time approximation scheme  ptas  for a notion de-
fined as optimal-mms  that is  the largest value  β  for which
each agent i receives the value of βmmsi  since the number
of possible partitions is finite  an optimal-mms allocation al-
ways exists  and it is an mms allocation if β ≥ 1  the cur-
rent best results guarantee β ≥ 2/3  kurokawa et al   2018 
garg et al   2018  and β ≥ 3/4  garg and taki  2020 
ghodsi et al   2018  in general  and β ≥ 7/8  amanatidis
et al   2017  and β ≥ 8/9  gourv es and monnot  2019  in the
case of three agents 
2
preliminaries
let n =  1          n  be a set of agents and m denote a set of
m indivisible goods  where m > n  we denote the value of
agent i ∈ n for good g ∈ m by vi g  ≥ 0  we assume that
the valuation functions are additive  that is  for each subset
g ⊆ m  vi g  = �
g∈g vi g   an instance of the problem
is i = ⟨n  m  v ⟩ where v is the valuation profile of agents 
an allocation a =  a1          an  is an n-partition of m that
allocates the bundle of goods in ai to each agent i ∈ n 
definition 1  envy-freeness   an allocation a is envy-free
 ef  if for every pair of agents i  j ∈ n  vi ai  ≥ vi aj   an
allocation a is envy-free up to one good  ef1  if for every pair
of agents i  j ∈ n such that aj ̸= ∅  there exists some good
g ∈ aj such that vi ai  ≥ vi aj \  g    an allocation a is
envy-free up to any good  efx  if for every pair i  j ∈ n such
that aj ̸= ∅  for any good ∀g ∈ aj  vi ai  ≥ vi aj \  g   
these definitions are due to foley  1967   budish  2011   and
caragiannis et al   2016  respectively 
definition 2  maximin share guarantee   let πk m  de-
note the set of k-partitions of m  the k-maximin share
guarantee of agent i ∈ n on πk m  is
mmsk
i  m  =
max
 a1 a2    ak ∈πk m  min
j∈ k  vi aj  
where  k  =  1          k   intuitively  this is the minimum
value that can be guaranteed if agent i partitions the goods
into k bundles and chooses the least valued bundle 
an allocation a =  a1          ak  ∈ πk m  is an mmsk
allocation if and only if ∀i ∈ n  vi ai  ≥ mmsk
i   note that
mmsn
i  m  ≤
vi m 
n
since proportionality implies mms 
when it is clear from the context  we write mmsi instead
of mmsn
i  m  and simply refer to it as agent i s mms value 
definition 3  optimal-mms   while an mms alloca-
tion does not always exist  an optimal relaxation of mms
guarantees that agents receive a fraction of their mms
value  nguyen et al   2017   given an instance i
=
⟨n  m  v ⟩  the optimal-mms value is defined by
λ∗ i  =
max
 a1     an ∈πn m  min
i
vi ai 
mmsn
i
 
by definition  an allocation that gives each agent a λ∗ i  frac-
tion of its mmsn
i  m  value is guaranteed to exist 
ordered instance 
an instance is ordered when all agents
agree on the linear ordering of the goods  irrespective of their
valuations  formally  i is an ordered instance if there ex-
ists an ordering of goods   g1  g2          gm  such that for all
agents i ∈ n we have vi g1  ≥ vi g2  ≥       ≥ vi gm  
bouveret and lemaˆıtre  2016  showed that ordered instances
are the  hardest  for achieving mms  in fact  these instances
are the only known structures for which mms does not ex-
ist  kurokawa et al   2018   the next lemma states that given
an unordered instance  it is always possible to generate a
corresponding ordered instance in polynomial time  further-
more  if the ordered instance admits an mms allocation  the
original instance also admits an mms allocation which can
be computed in polynomial-time 
proceedings of the thirtieth    ijcai-21 
239
 lemma 1   barman and krishna murthy  2017    let i′ =
⟨n  m  v ′⟩ be an ordered instance constructed from the orig-
inal instance i = ⟨n  m  v ⟩  given allocation a′ on i′  a
corresponding allocation a on i can be computed in polyno-
mial time such that for all i ∈ n  vi ai  ≥ v′
i a′
i  
scale invariance 
the scale invariance property of mms
states that if an agent s valuations are scaled by a factor  then
its mms value scales by the same factor 
lemma 2   ghodsi et al   2018    let i = ⟨n  m  v ⟩ be an
instance and c > 0 be a real scalar  let i′ = ⟨n  m  v ′⟩
be constructed so that v′
i g  = cvi g  for all g ∈ m  then
mms
′k
i  m  = cmmsk
i  m  
thus  an instance i = ⟨n  m  v ⟩ and a real value k can be
scaled to form a new instance i′ = ⟨n  m  v ′⟩  such that for
each agent i ∈ n  v′
i g  =
k
vi m vi g   and v′
i m  = k 
valid reduction 
we call the act of removing a set ai ⊆ m
of goods and an agent i a valid reduction if the following
two conditions hold  i  vi ai  ≥ mmsn
i  m  and ii  ∀j ∈
n \  i   mmsn−1
j
 m \ ai  ≥ mmsn
j  m  
lemma 3   garg et al   2018    given an ordered instance
i = ⟨n  m  v ⟩ with |n| = n such that mmsn
i
≤ 1  if
vi  gn  gn 1   ≥ 1  then removing ai =  gn  gn 1  and
agent i forms a valid reduction  similarly  the removal of  g1 
and agent i forms a valid reduction if vi  g1   ≥ 1 
normalized instance 
an instance is normalized if all of
the following properties hold  i  the instance is ordered  ii 
it is scaled so that vi m  = n  and iii  it is reduced so that
vi g1  < 1 and vi  gn  gn 1   < 1  by combining lemma 1 
2  and 3  we may assume that instances are normalized  we
prove this claim in lemma 4 
3
approximating maximin share
we introduce a fairness concept that allows for interpolation
between two dimensions in approximating mms pertaining
to the fraction of agents α that receive a β approximation of
their maximin share 
definition 4   α  β -mms   an allocation a guarantees
 α  β -mms if α ∈  0  1  fraction of agents receive at least
their β ∈  0  1  approximation of their mmsn
i   formally 
given an instance i = ⟨n  m  v ⟩  an allocation a guar-
antees  α  β -mms if there exists a subset n ′ ⊆ n with
|n ′| ≥ ⌊α|n|⌋ such that for all i ∈ n ′  vi ai  ≥ βmmsn
i  
we say that  α  β -mms exists if for any instance i =
⟨n  m  v ⟩  for every subset n ′ ⊆ n of agents such that
|n ′| = ⌊α|n|⌋  there exists an allocation a such that for
all i ∈ n ′  vi ai  ≥ βmmsn
i  
previous mms approximation results can be seen in this
context as efforts to tighten the approximation bound for all
agents  α = 1   notably  greedy algorithms exist to compute
 1  2
3 -mms  barman and krishna murthy  2017  garg et al  
2018  and  1  3
4 -mms  ghodsi et al   2018  allocations 
remark 1  it is crucial to highlight two key distinctions 
first  in contrast to previous works  ortega  2018  nyman et
al   2020   the definition of  α  β -mms existence does not
only hold for a fixed subset of agents  rather  it is a stronger
concept that holds for every subset of ⌊αn⌋ agents  sec-
ond   α  β -mms enables a social planner to pre-select the
n ′ ⊂ n of ⌊αn⌋ agents–independent of their preferences–
according to some priority ordering over the agents or by se-
lecting the agents uniformly at random  for instance  a higher
priority may be given to senior college students  a practice
that is already common in most course allocation procedures 
3 1
 α  1 -mms implies mmsk for k ≥ ⌈ n
α⌉
budish  2011  showed that approximating the competi-
tive equilibrium from equal incomes  a-ceei  guarantees
mmsn 1 m   i e  adding a dummy agent and asking all
agents to partition the goods into n   1 bundles  however 
this result does not imply the existence of mmsn 1 in allo-
cating indivisible goods because allocations achieved by a-
ceei may have excess supply or excess demands  this ap-
proach can result in infeasible allocations in fair division set-
tings that do not allow the addition of excess goods  there-
fore  the existence of mmsk for n 1 ≤ k ≤ 2n−2 remains
an open problem  in proposition 1 we show the relation be-
tween mmsk with  α  β -mms 
proposition 1  the existence of  α  1 -mms implies the ex-
istence of mmsk for k ≥ ⌈ n
α⌉ 
proof  suppose that  α  1 -mms exists  given an instance
i = ⟨n  m  v ⟩ with n agents  we construct an instance
i′ from i by adding ⌈ n
α⌉ − n dummy agents  therefore 
|n ′| = ⌈ n
α⌉  since  α  1 -mms exists  for every subset
n ′′ ⊆ n ′ of size ⌊α|n ′|⌋  there exists an allocation which
satisfies  α  1 -mms on that set of agents  thus  we may
choose the ⌊α|n ′|⌋ agents to contain exactly the well-defined
original set of agents in n  that is  n ′′  = n  hence  each
agent i ∈ n receives at least vi ai  ≥ mms|n ′|  which im-
plies mms⌈ n
α ⌉ for agents in n 
3 2
failure of optimal mms algorithms
there are two primary motivations behind the approxima-
tion parameter α  the fraction of agents   first  proposition 1
states that fixing β = 1 immediately implies an ordinal ap-
proximation of mms by partitioning goods into k > n bun-
dles  second  our next theorem shows that maximizing the
value of β for all agents may result in only a small fraction of
agents  α  receiving their mms value  theorem 1 shows that
there exists a family of instances where any optimal-mms
allocation only gives a small constant number of agents their
mms value  thus  an optimal-mms algorithm  e g   nguyen
et al   2017   will result in an  α  λ∗ -mms allocation such
that α goes to zero as the number of agents  n  increases 
theorem 1  for every n ≥ 4  there exists an instance with
o n2  goods where every optimal-mms allocation guaran-
tees at most 3  4 if n is odd  agents their mms value 
the proof is inspired by constructions proposed by
kurokawa et al   2016  2018   but it includes a few intricate
modifications by separating agents into ⌈ n
2 ⌉ groups and set-
ting up valuations such that only one group can receive its
proceedings of the thirtieth    ijcai-21 
240
 mms value  the details and the necessary proofs are pro-
vided in the full version  hosseini and searns  2021  
theorem 1 illustrates that if the goal is to reach an optimal-
mms threshold  the fraction of agents  α  who receive their
mms guarantee  β = 1  goes to zero as the number of agents
increases  thus  we ask for what values of α   α  1 -mms is
guaranteed to exist 
4
computing  α  β -mms for n − 1 agents
4 1
a   2
3  1 -mms algorithm for three agents
it is worth noting that although mms always exists for n = 2
and can be achieved through the cut-and-choose protocol
 bouveret and lemaˆıtre  2016   computing such an alloca-
tion remains hard  amanatidis et al   2017   nonetheless  for
two agents an allocation that guarantees mms3 to each agent
can be computed in polynomial time through an ef1 allo-
cation  aigner-horev and segal-halevi  2019   we use this
result to obtain the following result 
proposition 2  for three agents    2
3  1 -mms always exists
and can be computed in polynomial time 
proof  by the definition of  α  β -mms  we can select any
arbitrary subset of agents n ′ ⊂ n such that |n ′| = 2  then 
run an ef1 algorithm on n ′  which outputs an allocation a 
both agents in n ′ are guaranteed to receive their mms3  i e  
for each i ∈ n ′ we have vi ai  ≥ mms3
i   implying that 2
3 of
agents receive their mms  by the construction proposed by
kurokawa et al   2018   an mms allocation does not always
exist for three agents  thus    2
3  1 -mms is a tight bound 
4 2
a general algorithm for n ≥ 4
to extend the analysis of approximate mms for n−1 agents 
we first provide an important lemma that enables us to focus
on normalized instances in the remainder of this paper  this
lemma states that we can employ valid reductions repeatedly
 see section 2  for computing  α  β -mms allocations 
lemma 4  given an instance i = ⟨n  m  v ⟩  we can com-
pute a normalized instance i′ = ⟨n ′  m ′  v ′⟩ in polyno-
mial time such that any  α  β -mms allocation on i′ implies
 α  β -mms on i 
we now focus attention on designing a polynomial-time
algorithm that guarantees β mms for n−1 agents  the algo-
rithm relies on removing an arbitrary agent and computing an
efx allocation for the remaining n − 1 agents  by lemma 1
an ordered instance can be generated  and easily converted
back  from an unordered instance  a simple variant to the
envy-graph algorithm satisfies efx on ordered instances
 barman and krishna murthy  2017   we show that apply-
ing this procedure to normalized  and thus ordered  instances
satisfies   n−1
n   1
2  n 2
n−1  -mms  since β depends on n  we
cannot trivially extend this result to any  not normalized  in-
stances  nonetheless  we prove that together with lemma 4
and lemma 1 we can compute   n−1
n   1
2  n 2
n−1  -mms for any
instance in polynomial-time  the full proof of the theorem 
along with necessary discussions  can be found in the full ver-
sion of the paper  hosseini and searns  2021  
n
 α  β -mms
4
 3/4  1 -mms
5
 4/5  7/8 -mms
6
 5/6  4/5 -mms
7
 6/7  3/4 -mms
table 1  approximation bounds of  α  β  for various n < 8 
theorem
2 
given
any
instance
of
n
agents 
  n−1
n   1
2  n 2
n−1  -mms
can
be
computed
in
polynomial
time 
by proposition 1  we can add a dummy agent when n = 3
and select the original set of agents to obtain the following 
corollary 1  for n = 3 agents  computing an allocation
satisfying mms4
i   ∀i ∈ n can be done in polynomial time 1
remark 2  theorem 2 immediately illustrates an intriguing
interpolation between the approximation ratios of α and β 
for n < 7  a better approximation of mms values  β  can
be achieved in polynomial time by sacrificing only one agent 
recall that the best approximation algorithms to date guar-
antee only  1  3
4 -mms  ghodsi et al   2018  for general ad-
ditive valuations  table 1 shows the interpolation between α
and β for n = 4 to n = 7 
5
the existence of   2
3  1 -mms allocations
theorem 2 optimizes the fraction of agents  α  and provides
an efficient approach in achieving approximate mms for
n−1 agents  another plausible  and often practical  approach
aims at maximizing the fraction of agents α who receive their
mms guarantee  β = 1  
it turns out that simple modifications to existing approxi-
mation algorithms can guarantee   1
2  1 -mms allocations  a
key question is whether we can improve this bound for α be-
yond 1
2 and show the existence of such allocations  in what
follows  we show that   2
3  1 -mms exists and discuss an algo-
rithm achieving this bound in polynomial-time when n < 9 
our existence proof of   2
3  1 -mms relies on combining
techniques of bag-filling  strong normalization  and a variant
of the lone divider procedure  before discussing our main re-
sult  we briefly describe these techniques 
bag-filling 
given a normalized instance  a good is high-
value for agent i if vi g  ≥ 1
2  otherwise it is low-value  the
bag-filling algorithm is a greedy approach for forming bun-
dles in a normalized instance  an agent initializes a bag with a
high-value good  and then adds low-value goods until the bag
is worth at least 1  she then picks another high-value good
and repeats this process 2 for each bag  the total value never
exceeds 1   1
2 = 3
2 since the last added good is low-value 
remark 3  bag-filling alone cannot guarantee   2
3  1 -mms
as it may  run out  of low-value goods before filling ⌊ 2n
3 ⌋
1independently  aigner-horev and segal-halevi  2019  utilized
envy-free matchings to compute mmsn 1 for 3 agents 
2similar approaches have been used by garg et al   2018   garg
and taki  2020   ghodsi et al   2018  to compute  1  2
3 -mms and
 1  3
4 -mms allocations  in their algorithms  the bag is filled until
any agent values it at least 1 
proceedings of the thirtieth    ijcai-21 
241
 ⌊ 2n
3 ⌋
a1
a2
a3
a4
a5
a6
a7
a8
a9
s
a10 a11 a12
figure 1  a sample mms partition for the divider  the tiny shapes  triangle  circles  squares  and diamonds  represent high-value goods and
are ordered from g1 to g10  note that each bundle contains no more than one high-value good  all pieces indicated in red  including the red
diamonds  indicate the goods that were allocated in previous iterations  there are two such high-value goods  so n′ = ⌊ 2n
3 ⌋ − 2 = 6  the
first step is pairing the lowest 2s remaining high-value goods into s bundles   g6  g10  and  g8  g9   the second phase is restricted bag-filling
that only uses low-value goods from the the remainder sets corresponding to already allocated high-value goods  within teal boxes   the solid
borders show all remainder sets  next  the remaining goods  shown in purple are used for simple bag-filling to fill the remaining 2 bundles 
bundles if the remaining value consists entirely of high-value
goods  consider n = 9 agents with identical valuations as
follows  5 goods of value 0 99  5 goods of value 0 01  1 good
of value 0 95  1 good of value 0 05  3 goods of value 0 55 
and 3 goods of value 0 45  here  mmsn
i = 1 for all agents 
the high-value goods are valued more than 0 5  during bag-
filling  there will be three bundles of  0 99  0 45   one bun-
dle of  0 99  0 05   and one bundle of  0 99  0 01   since
only 5 bundles were filled and ⌊ 2n
3 ⌋ = 6  we need to fill one
more bundle  adding all remaining low-value goods to the
next high-value good 0 95 yields a total value 0 99  the re-
maining value is tied up with the high-value goods  0 55  
strong normalization 
we say an instance is strongly nor-
malized if it is ordered  vi m  = n  and mmsn
i = 1  ob-
serve that the definition of strong normalization implies that
each bundle of an mms partition is valued exactly 1  further-
more  this implies that vi g1  ≤ 1 and that vi gn 1  ≤ 1
2 
lemma 5  for any additive instance i = ⟨n  m  v ⟩  there
exists another strongly normalized instance i′ = ⟨n  m  v ′⟩
such that i′ is ordered and for all i ∈ n  mmsn
i = 1 and
vi m  = n  furthermore  an  α  β -mms allocation on i′ is
also an  α  β -mms allocation on i 
lemma 5 shows that any instance i can be modified via
a non-polynomial-time transformation into a new instance i′
that is strongly normalized such that an  α  β -mms alloca-
tion on i′ implies an  α  β -mms allocation on i  hence  we
can focus only on strongly normalized instances 
algorithm description 
at its core  our algorithm imple-
ments the lone divider procedure for indivisible goods on
n′ = ⌊ 2n
3 ⌋ of the agents  the lone divider procedure is an
extension of the proportional cake-cutting algorithm  robert-
son and webb  1998  that leverages non-empty envy-free
matchings in a bipartite graph  it proceeds as follows  given
n′ agents in n ′  first  an arbitrary agent divides the goods
into n′ acceptable bundles  a1          an′   second  we con-
struct a bipartite graph between agents in n ′ and the bundles
 a1          an′  wherein each edge connects an agent i ∈ n ′ to
a bundle ak such that vi ak  ≥ 1  notice that the divider will
be adjacent to all bundles  next  we compute a non-empty
envy-free matching  where no unmatched agent is adjacent to
a bundle that was assigned to some other agent  a non-empty
envy-free matching always exists if |n n ′ | ≥ |n ′|  where
n n ′  denotes the set of bundles adjacent to n ′  aigner-
horev and segal-halevi  2019   all matched agents receive
their bundles and leave  after the removal of matched agents
and goods  we repeat the same procedure over the remaining
goods and agents until there are no remaining agents 3
the primary challenge in proving   2
3  1 -mms existence
lies in showing that in each iteration  given n′ remaining
agents  the divider agent can form n′ bundles valued at least
1  we show that under the strong normalization assumption 
the divider is always able to form n′ bundles either by pairing
high-value goods or through restricted bag-filling 
theorem 3  a   2
3  1 -mms allocation is guaranteed to exist
for any subset of ⌊ 2n
3 ⌋ agents 
our proof relies on two technical cases based on the num-
ber of high-value goods  h   if h ≤ ⌊ 2n
3 ⌋  there are not many
high-value goods  and thus  the simple bag-filling guarantees
our desired result  the most challenging cases arise when
h > ⌊ 2n
3 ⌋  that is  when there are too many high-value goods 
let s = h − ⌊ 2n
3 ⌋ be the number of excess high-value goods
as shown in figure 1  here  we show that the divider agent is
able to form the necessary bundles  i e  the number of remain-
ing agents  by adopting the following strategies  if n′ ≤ s  we
can simply pair the remaining high-value goods since there
are at least 2n′ high-value goods available  which implies n′
bundles are valued more than 1  on the other hand  if n′ > s 
we are able to form s bundles by pairing the remaining high-
value goods  this means that we still need an additional n′−s
bundles  the key to handling this step relies on the restricted
bag-filling procedure with exactly one high-value good per
bundle but we restrict which low-value goods are used to fill
bundles  in restricted bag-filling  we only use the low-value
goods from bundles of the divider s mmsn partition whose
high-value goods are no longer available  since those goods
have been allocated in some previous round or assigned dur-
ing pairing   as highlighted in figure 1 by teal boxes 
the main reason behind this restriction is to ensure that not
too much value is  wasted  during bag-filling  as discussed in
3see  hosseini and searns  2021  for the technical details 
proceedings of the thirtieth    ijcai-21 
242
 remark 3   the restricted bag-filling relies on the strong nor-
malization assumption - this way we can guarantee that the
low-value goods used in restricted bag-filling have sufficient
value when bundled with at most one high-value good 
our proof follows by showing that if n′ ≥ 2s  it is possible
to form n′ − s bundles through restricted bag-filling  oth-
erwise if n′ < 2s  using restricted bag-filling we can form
s bundles  in this case  we still need to form an additional
n′ − 2s bundles  which is possible through simple bag filling
by targeting for each bundle to have at most 3
2 value 
remark 4  the strong normalization assumption in the proof
of theorem 3 requires modifying the values of some goods
depending on an mms partition for agent i  furthermore 
the restricted bag-filling phase of theorem 3 selects available
low-value goods from specific bundles of an mms partition
for agent i  because of these dependencies on finding mms
partitions  theorem 3 does not imply a polynomial time algo-
rithm for   2
3  1 -mms 
we show that by relaxing the strong normalization assump-
tion to the weaker normalization of lemma 4  we can devise a
polynomial time algorithm for   2
3  1 -mms when n < 9  es-
sentially  this algorithm is a simplified variant of our previous
procedure that only includes simple bag-filling and pairing to
form the required bundles in the lone divider procedure  intu-
itively  since the total value of low-value goods is guaranteed
to be at least 1 − vi g1   at least one bundle can be allocated
during bag-filling  when n < 9  adding the pairing phase
forms ⌊ n
2 ⌋   1 > ⌊ 2n
3 ⌋ bundles 
theorem 4  for n < 9    2
3  1 -mms can be computed in
polynomial time 
theorem 4 only guarantees a   2
3  1 -mms allocation when
n < 9  we show by construction that this is tight  see  hos-
seini and searns  2021  for details   we construct a family
of instances with n ≥ 9 in which a small error in comput-
ing the mms bound causes bag-filling to stop before ⌊ 2n
3 ⌋
bundles have been allocated  the challenge presented here
is not unique to our algorithm  any algorithm that satisfies
  2
3  1 -mms must be able to detect that mmsn
i < 1 for all
agents  however  this task is intractable even when agents
have identical valuations  bouveret and lemaˆıtre  2016  
combining this construction with theorem 4 implies that
no smaller counter-example exists  we note that despite this
bound  the algorithm is still practical as there is no bound
on the number of goods  for example  more than 99  of in-
stances in the spliddit dataset deal with less than 9 agents 
the analysis in theorem 3 and theorem 4 are indifferent
to the set of agents n ′  consequently  we may select any sub-
set of ⌊ 2n
3 ⌋ agents to be given their full mms  an immediate
consequence of this result  together with proposition 1  is that
there always exists an allocation of goods such that each agent
receives at least the value of mms⌈ 3n
2 ⌉  moreover  this allo-
cation can be computed in polynomial time when ⌈ 3n
2 ⌉ < 9 
corollary 2  an allocation satisfying mms⌈ 3n
2 ⌉ always ex-
ists  moreover  such allocations can be computed in polyno-
mial time when n < 6 
figure 2  fraction of agents  α  receiving their maximin share  i e  
 α  1 -mms 
6
empirical evaluations
the
polynomial
algorithm
of
theorem
4
guarantees
  2
3  1 -mms only for n < 9  we evaluate a variant of this
algorithm that does not rely on the strong normalization as-
sumption  details relegated to the full version   it is similar
to the algorithm of theorem 4 until either no more bundles
can be allocated during the lone divider procedure or all ⌊ 2n
3 ⌋
agents that were initially selected have received a bundle val-
ued at least 1  in the latter case  any remaining goods are dis-
tributed among the unselected n − ⌊ 2n
3 ⌋ agents using bag-
filling with priority given to agents who accept the smallest
bundles  notice that this algorithm does not guarantee that all
initially selected agents receive their mms 
we focus on ordered instances—as the most difficult in-
stances in achieving mms  bouveret and lemaˆıtre  2016 —
and generate 1 000 instances for each combination of n and
m  instances are sampled uniformly at random  ordered  and
scaled such that vi m  = n for all agents i ∈ n  figure 2
illustrates the fraction of agents who receive their mms for
n = 3 to 50 agents and m = 3 to 200 goods  in almost all in-
stances  the algorithm goes beyond the 2
3 bound  on average
across all instances  more than 90  of agents receive their
mms  moreover  the fraction of agents receiving their mms
improves as either n or m increases  we also observe linear
bands where a lower fraction of agents are satisfied due to the
ratio of goods to agents  in addition  when m < 2n a large
fraction of the agents receive their mms and are removed
during the reduction phase of normalization 
7
discussion
theorem 3 proves the existence of   2
3  1 -mms for any n 
which implies the existence of mms⌈ 3n
2 ⌉  therefore  improv-
ing the bound on  α  1 -mms for α > 2
3 and closing the gap
between mms⌈ 3n
2 ⌉ and mmsn 1 is an intriguing future di-
rection  theorem 4 provides a tractable approach for comput-
ing   2
3  1 -mms for n < 9  yet  computing such allocations
for any n  if possible  will require further techniques to cir-
cumvent computing exact mms bounds  another interesting
avenue for future research is exploring ptas algorithms that
guarantee optimal-mms  heinen et al   2018  for a fraction
of agents to achieve  α  1 -mms for α ∈   2
3  n−1
n   
acknowledgements
hh acknowledges the support from nsf grant #1850076  we
are grateful to erel segal-halevi for his valuable input that
improved the proof of theorem 3 
proceedings of the thirtieth    ijcai-21 
243
 references
 aigner-horev and segal-halevi  2019  elad
aigner-horev
and erel segal-halevi 
envy-free matchings in bipartite
graphs and their applications to fair division 
arxiv preprint
arxiv 1901 09527  2019 
 amanatidis et al   2017  georgios
amanatidis 
evangelos
markakis  afshin nikzad  and amin saberi 
approxima-
tion algorithms for computing maximin share allocations  acm
transactions on algorithms  talg   13 4  52  2017 
 barman and krishna murthy  2017  siddharth
barman
and
sanath kumar krishna murthy 
approximation algorithms
for maximin fair division 
in proceedings of the 2017 acm
conference on economics and computation  pages 647–664 
acm  2017 
 bouveret and lemaˆıtre  2016  sylvain
bouveret
and
michel
lemaˆıtre 
characterizing conflicts in fair division of indivis-
ible goods using a scale of criteria 
autonomous agents and
multi-agent systems  30 2  259–290  mar 2016 
 brams and taylor  1996  steven j brams and alan d taylor  fair
division  from cake-cutting to dispute resolution  cambridge
university press  1996 
 budish  2011  eric budish  the combinatorial assignment prob-
lem  approximate competitive equilibrium from equal incomes 
journal of political economy  119 6  1061–1103  2011 
 caragiannis et al   2016  ioannis caragiannis  david kurokawa 
herv e moulin  ariel d procaccia  nisarg shah  and junxing
wang 
the unreasonable fairness of maximum nash welfare 
in proceedings of the 2016 acm conference on economics and
computation  pages 305–322  acm  2016 
 chen and shah  2018  yiling chen and nisarg shah  ignorance is
often bliss  envy with incomplete information  technical report 
2018 
 chevaleyre et al   2007  yann chevaleyre  ulle endriss  sylvia es-
tivie  and nicolas maudet 
reaching envy-free states in dis-
tributed negotiation settings  in proceedings of the 20th inter-
national joint conference on artificial intelligence  pages 1239–
1244  morgan kaufmann publishers inc   2007 
 feldman and kirman  1974  allan feldman and alan kirman 
fairness and envy  the american economic review  64 6  995–
1005  1974 
 foley  1967  duncan k  foley  resource allocation and the public
sector  yale economic essays  7 45–98  1967 
 freeman et al   2019  rupert freeman  sujoy sikdar  rohit vaish 
and lirong xia  equitable allocations of indivisible goods  in
proceedings of the twenty-eighth international joint conference
on artificial intelligence  ijcai-19  pages 280–286  7 2019 
 garg and taki  2020  jugal garg and setareh taki  an improved
approximation algorithm for maximin shares  in proceedings of
the 21st acm conference on economics and computation  ec
 20  page 379–380  new york  ny  usa  2020  association for
computing machinery 
 garg et al   2018  jugal garg  peter mcglaughlin  and setareh
taki 
approximating maximin share allocations 
in 2nd
symposium on simplicity in algorithms  sosa 2019   schloss
dagstuhl-leibniz-zentrum fuer informatik  2018 
 ghodsi et al   2018  mohammad ghodsi  mohammadtaghi haji-
aghayi  masoud seddighin  saeed seddighin  and hadi yami 
fair allocation of indivisible goods  improvements and general-
izations  in proceedings of the 2018 acm conference on eco-
nomics and computation  pages 539–556  acm  2018 
 gourv es and monnot  2019  laurent gourv es and j erˆome mon-
not  on maximin share allocations in matroids  theoretical com-
puter science  754 50–64  2019 
 heinen et al   2018  tobias
heinen 
nhan-tam
nguyen 
trung thanh nguyen  and j¨org rothe 
approximation and
complexity of the optimization and existence problems for
maximin share  proportional share  and minimax share allocation
of indivisible goods 
autonomous agents and multi-agent
systems  32 6  741–778  2018 
 hosseini and searns  2021  hadi hosseini and andrew searns 
guaranteeing maximin shares  some agents left behind  arxiv
preprint arxiv 2105 09383  2021 
 hosseini et al   2020  hadi hosseini  sujoy sikdar  rohit vaish 
jun wang  and lirong xia  fair division through information
withholding 
in proceedings of the thirty-fourth aaai con-
ference on artificial intelligence  aaai-20   pages 2014–2021 
2020 
 kurokawa et al   2016  david kurokawa  ariel d procaccia  and
junxing wang  when can the maximin share guarantee be guar-
anteed  in proceedings of the thirtieth aaai conference on ar-
tificial intelligence  pages 523–529  aaai press  2016 
 kurokawa et al   2018  david kurokawa  ariel d procaccia  and
junxing wang  fair enough  guaranteeing approximate maximin
shares  journal of the acm  jacm   65 2  8  2018 
 lipton et al   2004  richard
j
lipton 
evangelos
markakis 
elchanan mossel  and amin saberi 
on approximately fair
allocations of indivisible goods  in proceedings of the 5th acm
conference on electronic commerce  pages 125–131  acm 
2004 
 nguyen and rothe  2014  trung thanh nguyen and j¨org rothe 
minimizing envy and maximizing average nash social welfare in
the allocation of indivisible goods  discrete applied mathemat-
ics  179 54–68  2014 
 nguyen et al   2017  nhan-tam nguyen  trung thanh nguyen 
and j¨org rothe  approximate solutions to max-min fair and pro-
portionally fair allocations of indivisible goods  in proceedings
of the 16th conference on autonomous agents and multiagent
systems  pages 262–271  2017 
 nyman et al   2020  kathryn nyman  francis edward su  and
shira zerbib  fair division with multiple pieces  discrete ap-
plied mathematics  283 115 – 122  2020 
 ortega  2018  josu e ortega  social integration in two-sided match-
ing markets  journal of mathematical economics  78 119–126 
2018 
 procaccia and wang  2014  ariel d procaccia and junxing wang 
fair enough  guaranteeing approximate maximin shares  in pro-
ceedings of the fifteenth acm conference on economics and com-
putation  pages 675–692  acm  2014 
 robertson and webb  1998  jack robertson and william webb 
cake-cutting algorithms  be fair if you can  ak peters/crc
press  1998 
 schneckenburger et al   2017  sebastian schneckenburger  britta
dorn  and ulle endriss  the atkinson inequality index in multia-
gent resource allocation  in proceedings of the 16th conference
on autonomous agents and multiagent systems  pages 272–280 
2017 
 woeginger  1997  gerhard j woeginger  a polynomial-time ap-
proximation scheme for maximizing the minimum machine com-
pletion time  operations research letters  20 4  149–154  1997 
proceedings of the thirtieth    ijcai-21 
244
 "
None,2021,https-www-ijcai-org-proceedings-2021-0035-pdf,"Surprisingly Popular Voting Recovers Rankings, Surprisingly!","Hadi Hosseini, Debmalya Mandal, Nisarg Shah, Kevin Shi",None,https://www.ijcai.org/proceedings/2021/0035.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0035-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0035-pdf.pdf,"surprisingly popular voting recovers rankings  surprisingly 
hadi hosseini1   debmalya mandal2   nisarg shah3 and kevin shi3
1pennsylvania state university
2columbia university
3university of toronto
hadi@psu edu  dm3557@columbia edu  nisarg@cs toronto edu  kevins shi@mail utoronto ca
abstract
the wisdom of the crowd has long become the de
facto approach for eliciting information from indi-
viduals or experts in order to predict the ground
truth 
however  classical democratic approaches
for aggregating individual votes only work when
the opinion of the majority of the crowd is relatively
accurate  a clever recent approach  surprisingly
popular voting  elicits additional information from
the individuals  namely their prediction of other in-
dividuals  votes  and provably recovers the ground
truth even when experts are in minority  this ap-
proach works well when the goal is to pick the cor-
rect option from a small list  but when the goal is
to recover a true ranking of the alternatives  a di-
rect application of the approach requires eliciting
too much information  we explore practical tech-
niques for extending the surprisingly popular algo-
rithm to ranked voting by partial votes and predic-
tions and designing robust aggregation rules  we
experimentally demonstrate that even a little pre-
diction information helps surprisingly popular vot-
ing outperform classical approaches 
1
introduction
the wisdom of the crowd has been the default choice for un-
covering the ground truth  suppose we wish to determine the
true answer to the question   is philadelphia the capital of
pennsylvania   condorcet s jury theorem suggests that if
we elicit votes from a large crowd  the majority answer will
be correct with high probability even if  on average  the crowd
is only slightly more accurate than a random selection  how-
ever  in some domains the crowd can be highly inaccurate and
experts may be in minority  for example  when the very ques-
tion listed above is posed to real crowds  the majority answer
is often  the incorrect   yes   de boer and bernstein  2017  
to circumvent this difficulty and uncover the ground truth
even when the majority is wrong  prelec et al   2017  intro-
duce the surprisingly popular  sp  algorithm  this algorithm
asks each individual not only what she thinks the answer is
 the vote   but also what fraction of the other participants she
thinks will say yes/no  the prediction   then  instead of sim-
ply selecting the majority  i e  popular  answer  the algorithm
selects the answer that is surprisingly popular  i e   whose
actual frequency in the votes is greater than its average pre-
dicted frequency  they show that as the crowd gets larger
in the limit  this approach will provably recover the correct
answer with probability 1  even if the crowd is less accurate
than a random selection on average 
the intuition behind their algorithm  borrowed from their
work  is as follows 
suppose there are two hypothetical
worlds  one where philadelphia is the capital and one where
it is not  in the former world  a greater fraction  say 90  
would say  yes  than the fraction  say 60   that would say
 yes  in the latter  however  the 60  of the people who be-
lieve the correct world is the former would predict the fre-
quency of  yes  to be 90   whereas the remaining 40  would
predict it to be 60   this would make the average predicted
frequency of  yes  to be somewhere between 60  and 90  
higher than its actual frequency of 60   in other words  the
majority but incorrect answer  yes  would be surprisingly un-
popular while  no  would be surprisingly popular and correct 
several works have demonstrated the effectiveness of this
approach in a wide range of domains  prelec et al   2017 
lee et al   2018  wang et al   2019  palley and soll  2019 
rutchick et al   2020  mandal et al   2020a   prediction ques-
tions have also been used to boost the accuracy of surveys on
social networks  galesic et al   2018   prelec et al   2017 
show how to apply their approach to questions with non-
binary votes and non-binary ground truth 
when the true
answer lurks among r options  their approach requires each
individual to predict the exact frequency of each of r op-
tions among other individuals  votes  we are interested in
ranked voting  i e   when the ground truth is a ranking of m
alternatives  note that in this case  the approach of prelec
et al   2017   which we refer to as surprisingly popular  sp 
voting  would require eliciting predictions in the form of a
distribution over r = m  options  which is clearly infeasi-
ble for even moderate values of m  thus  the main research
questions we address are 
how do we extend surprisingly popular voting to
effectively recover a ground truth ranking of alter-
natives  if we elicit partial vote and prediction 
how do we aggregate them and what information-
accuracy tradeoff does this offer 
proceedings of the thirtieth    ijcai-21 
245
 1 1
our contributions
we focus on eliciting only ordinal vote and prediction infor-
mation  for the vote  we ask individuals to provide their opin-
ion of either just the top alternative of the ground truth rank-
ing  top  or the full ground truth ranking  rank   for the pre-
diction  informally  we ask individuals to predict either just
a single alternative  top  or a ranking of alternatives  rank 
based on the other individuals  votes  the exact prediction
elicited under various conditions is described in section 3  in
addition to these four elicitation formats  we use as bench-
mark two classical elicitation formats in which top and rank
votes are elicited but no prediction is elicited  because the
sp algorithm of prelec et al   2017  does not work on par-
tial votes and predictions  we first design a novel aggregation
method for such partial information 
next  we conduct an empirical study with 720 partici-
pants from amazon s mechanical turk platform 
we ask
the participants questions on geography  movies  and artwork
which admit a ground truth ranking of four alternatives and
elicit their responses in the aforementioned six elicitation for-
mats  we compare the different elicitation formats using four
metrics  difficulty  measured through response time as well
as perceived difficulty   expressiveness  error in recovering
the ground truth top alternative  and error in recovering the
ground truth ranking 
our results show that even when the vote and prediction in-
formation are individually no better than random guesses  by
combining the two pieces of information sp voting performs
significantly better  further  it outperforms a whole slew of
conventional voting rules which ignore prediction informa-
tion and only aggregate the votes  we also observe that when
it is necessary to choose between eliciting more complex vote
information and eliciting more complex prediction informa-
tion  the latter may be the right choice 
1 2
related work
our work builds on the sp voting approach of prelec et
al   2017  
this approach in turn builds on its precursor 
the bayesian truth serum  bts   prelec  2004   which also
uses participants  predictions  but for a different objective  to
decide payoffs to the participants which incentivize them to
honestly report their votes and predictions 
prediction markets  arrow et al   2008  chen and pen-
nock  2010   quadratic voting  lalley and weyl  2018   and
peer prediction  miller et al   2005  are alternative approaches
to recovering the ground truth  which  like sp voting  al-
low a minority of experts to override the majority opinion 
instead of eliciting participants  predictions of other partici-
pants  votes  prediction markets and quadratic voting ask par-
ticipants to place a bet on their vote while peer prediction
methods require them to participate in multiple tasks 
these recent approaches stand in contrast to a large body
of work on epistemic social choice  pivato  2019  and noisy
voting  caragiannis et al   2016   which build on the sem-
inal work of de condorcet  1785   galton  1907   and
young  1988   some of this literature focuses on statistical
models of errors in participants  votes such as the mallows
model  the bradley-terry model  the thurstone-mosteller
model  and the plackett-luce model  however  all these mod-
els assume that a participant is ever-so-slightly more likely to
report the correct option than an incorrect option  hence  ap-
proaches based on these models can fail to recover the ground
truth when the majority of the crowd is misinformed 
finally  our work is reminiscent of a recent flurry of work
on the elicitation-distortion tradeoff in computational so-
cial choice  mandal et al   2019  abramowitz et al   2019 
mandal et al   2020b  kempe  2020  amanatidis et al   2020  
in this line of work  there is no ground truth  instead  partic-
ipants have subjective preferences and the goal is to identify
the decision that maximizes the social welfare  rather than
directly eliciting participants  utility functions  various elici-
tation formats are used to elicit partial preferences to analyze
the tradeoff between the amount of information elicited and
the approximation to social welfare  called distortion   our
work replaces the distortion with its counterpart  that is  the
accuracy of recovering an underlying ground truth 
2
model
let a be a set of m alternatives and l a  be the set of rank-
ings over a  for a ranking σ ∈ l a  and x ∈  1          m  
let σ x  be the alternative in the xth highest position in σ 
sp voting uses a bayesian model  in the following  we
present a special case of the model for ranked voting  there
exists a ground truth ranking π∗ ∈ l a  drawn from a prior
p  there are n voters  each voter i observes a noisy rank-
ing σi ∈ l a  drawn from a signal distribution prs ·|π∗  
the voters know both the prior p and the signal distribution
prs ·|π∗   however  the principal is unaware of both  follow-
ing prelec et al   2017   we assume that p π   prs σ|π  > 0
for all rankings σ  π ∈ l a  to avoid degeneracy 
conventional voting would ask each voter i to simply re-
port her observed noisy ranking σi and use a voting rule such
as the kemeny rule or borda count to aggregate the reported
rankings  sp voting additionally asks each voter i to make
inferences about the reports of other voters  given her ob-
served noisy ranking σi and the prior p  voter i can compute
a posterior distribution over the ground truth  given by
prg π∗|σi  =
prs σi|π∗  · p π∗ 
�
π′∈l a  prs σi|π′  · p π′  
in turn  the voter can also infer a distribution over the noisy
ranking σj observed by another voter j 
pro σj|σi  = �
π∗∈l a  prs σj|π∗  · prg π∗|σi  
sp voting asks each voter i to report not only her observed
noisy ranking σi  the vote   but also her inferred distribution
pro ·|σi  over other voters  noisy rankings  the prediction  
given these reports  for a ranking π ∈ l a   let f π  =
�n
i=1 1 σi = π  denote the number of voters who vote π and
g ·|π  denote the average of reported predictions pro ·|σi 
across all voters i with σi = π  then  the sp algorithm of
prelec et al   2017  computes the prediction-normalized vote
count for each possible ground truth π as
v  π  = f π  · �
π′∈l a 
g π′|π 
g π|π′  
 1 
proceedings of the thirtieth    ijcai-21 
246
 the following result due to prelec et al   2017   rephrased
in our context  guarantees that the ground truth ranking will
have the highest prediction-normalized vote count under the
assumption that the highest posterior probability for ground
truth ranking π will be assigned by a voter who observes
noisy ranking π 
theorem 1   prelec et al   2017    suppose the prior p
and the signal distribution prs are such that prg π|π  >
prg π|π′  for all distinct rankings π  π′ ∈ l a   then  we
have that pr π∗ ∈ argmaxπ∈l a v  π   → 1 as n → ∞ 
3
elicitation formats   aggregation rules
note that the prediction requested from voter i  pro ·|σi   is a
distribution over m  rankings  eliciting this would undoubt-
edly place significant cognitive burden on the voter  thus  our
goal is to elicit partial vote and prediction information from
the voters  since eliciting numerical information is known
to be difficult  camerer  2011   we focus on eliciting ordi-
nal information for prediction  we develop aggregation rules
for recovering the ground truth from ordinal information and
empirically evaluate the effectiveness of sp voting 
3 1
elicitation formats
we focus on two types of vote reports  and for each of them 
two types of prediction reports  below we provide formal
explanations of these formats in the context of our model 
in the next section  we provide example phrasings that were
used to pose the various questions to the participants in our
empirical study  let ri and qi respectively denote the vote
and prediction reports submitted by voter i 
• top vote  voter i reports the top alternative in her ob-
served noisy ranking  i e   ri = σi 1  
– top prediction  voter i estimates the most fre-
quent alternative among the other votes  i e  qi =
argmaxa∈a
�
σ∈l a  σ 1 =a pro σ|σi  
– rank prediction 
voter i estimates the rank-
ing
of
the
alternatives
by
their
frequency
among
the
other
votes 
i e  
qi
∈
l a 
such
that
�
σ∈l a  σ 1 =qi x  pro σ|σi 
≥
�
σ∈l a  σ 1 =qi y  pro σ|σi  for all x > y 
• rank vote  voter i reports her entire observed noisy
ranking  i e   ri = σi 
– top prediction  voter i estimates the alternative
that appears most frequently in the top position
of the other votes 
formally  this is equivalent
to the top prediction in case of a top vote  qi =
argmaxa∈a
�
σ∈l a  σ 1 =a pro σ|σi  
– rank prediction  voter i estimates the most fre-
quent ranking among the other votes  i e   qi ∈
argmaxσ∈l a  pro σ|σi   note that this is differ-
ent from the rank prediction in case of a top vote 
this gives rise to four elicitation formats  which we refer
to as top-top  top-rank  rank-top  and rank-rank with
the first component denoting the vote format and the second
denoting the prediction format  as a benchmark  we use top-
none and rank-none  where top and rank votes are elicited 
respectively  but no prediction information is elicited 
3 2
aggregation rules
there are two difficulties in applying the sp algorithm of pr-
elec et al   2017  — maximizing v  π  given in equation  1 
— in our setting 
first  the effectiveness of the approach depends on how ac-
curately functions f and g from equation  1  match their ex-
pected values  which in turn depends on how large the number
of voters is compared to the number of options among which
the ground truth lurks  in our case  since the ground truth is
one of m  rankings  the approach would be ineffective unless
each question is answered by a number of voters much larger
than m   instead  we determine the ground truth comparison
of each of
�m
2
�
pairs of alternatives independently by apply-
ing the algorithm from equation  1  on the relevant pairwise
comparison data extracted from the reports of the voters 
second  even for comparing a pair of alternatives  equa-
tion  1  requires cardinal prediction information whereas our
input is ordinal  we propose a simple parametric model in
which  for each elicitation format  we use two parameters 
α ∈  0 5  1  and β ∈  0  0 5   to convert ordinal pairwise
predictions into cardinal pairwise predictions to be utilized
by the sp algorithm  in section 4  we describe how we train
these parameter values  the formal algorithm and its detailed
description are provided in the full version 1
note that applying our algorithm for comparing each pair
of alternatives independently results in a tournament  which
we use for two prediction tasks  predicting the top alternative
in the ground truth ranking and predicting the entire ground
truth ranking  for the former task  we select the alternative
that defeats the maximum number of other alternatives in the
resulting tournament  breaking ties uniformly at random  and
consider the frequency of predicting the correct top alterna-
tive  for the latter task  we compute the kendall tau distance
of the tournament from the ground truth ranking 
finally  note that there are no prediction reports for top-
none and rank-none and we consider a natural extension of
sp voting  in particular  for top-none  sp voting returns an
acyclic tournament comparing alternatives by their plurality
scores  and for rank-none  it returns the  potentially cyclic 
majority preference tournament  we then select an alterna-
tive/ranking as described earlier 
4
experiment design
to test the effectiveness of sp voting for recovering ranked
ground truth with only ordinal elicitation  we conducted an
empirical study by recruiting 720 participants  turkers  from
amazon mechanical turk  mturk   a popular crowdsourcing
marketplace  an average turker spent about 15 minutes to
complete the survey  the survey was designed as follows 
datasets 
to generate questions with an underlying ground
truth comparison of alternatives  we used three datasets from
three distinct domains 
1https //arxiv org/abs/2105 09386
proceedings of the thirtieth    ijcai-21 
247
 1  the geography dataset2 contains 230 countries with
their 2019 population estimates according to the united
nations 
2  the movies dataset3 contains 15 743 movies with their
lifetime box-office gross earnings 
3  the paintings dataset4 contains 80 paintings with their
latest auction prices 
questions 
in each domain  the numerical values associ-
ated with the alternatives allow a ground truth comparison
among the alternatives  for each domain  we considered the
top 50 alternatives with the highest values  from these  we
generated 20 questions  each comparing four alternatives se-
lected such that two consecutive alternatives in the ground
truth ranking were exactly 6 ranks apart in the global rank-
ing of all 50 alternatives  collectively  we had 60 questions
across all three domains  for each of the 60 questions and
each of the 6 elicitation formats described in section 3  we
elicited 20 responses  generating a total of 7  200 responses 
turker assignment 
figure 1 shows the workflow faced
by a turker  each of the 720 turkers responded to 10 ques-
tions split evenly among two randomly assigned elicitation
formats    the turkers were divided roughly equally between
the 30 ordered pairs of elicitation formats called treatments 
further  as mentioned above  each question under each elici-
tation format was assigned to the same number of turkers 
preview  
consent
tutorial
 elicitation
format 1 
5 questions
 elicitation
format 1 
review
 elicitation
format 1 
tutorial
 elicitation
format 2 
5 questions
 elicitation
format 2 
review
 elicitation
format 2 
quiz
submit
figure 1  the workflow of a turker 
tutorials 
as shown in figure 1  each set of five ques-
tions in a fixed elicitation format was preceded by a tutorial 
the tutorial was designed specifically for the elicitation for-
mat and tested turkers  understanding of the vote and pre-
diction formats  it contained a sample question along with
pre-specified beliefs over the correct answer as well as over
the other responses  turkers had to successfully pass the tu-
torial by converting the given beliefs into the requested vote
and prediction format in order to proceed to the questions 
reviews 
each set of five questions was also succeeded by
a review  which asked the turkers to rate the difficulty  from
very easy to very difficult  and expressiveness  very little
to very significant  of the elicitation format of the preceding
questions  while we controlled the difficulty level of vari-
ous questions from a given domain  as we show in section 5
the three domains themselves differed significantly in their
difficulty  in anticipation of this and to ensure that the turk-
ers  implicit comparison between their two assigned elicita-
tion formats is not influenced by the domains  the study was
2retrieved from worldpopulationreview com
3retrived from boxofficemojo com/chart/top lifetime gross
4generously provided by the authors of prelec et al   2017  
designed such that the sequence of domains encountered by
a turker in the first five questions precisely matched that in
the next five questions  see the full version for details such
as the consent form  the tutorial for each domain  the review 
and other details 
response
qualifications 
to
ensure
high-quality
re-
sponses  in addition to providing training in the form of tu-
torials  we restricted participation in our study to turkers who
had  a  at least 90  approval rate on previous tasks   b  at
least 100 completed tasks  and  c  the region set to us east
 us-east-1  on mturk  additionally  at the end of the survey 
the turkers were required to answer a quiz  which repeated
the four alternatives from the last question they answered and
asked them to identify the alternative they chose or ranked
first in their vote  the turkers were incentivized to answer the
quiz correctly  see below   in our case  over 82  of turkers
passed the quiz 
payments 
the payment was divided into two parts  a base
payment of 50¢ was provided conditioned on completing the
entire survey including all tutorials  questions  and reviews  a
bonus payment of 50¢ was provided conditioned on correctly
answering the quiz question 
elicitation formats 
in section 3  we discussed six elicita-
tion formats and described what vote and prediction a given
voter i should submit as a function of her observed noisy
ranking σi  the prior p  and the signal distribution prs  in
our empirical study  we design natural and intuitive phrasing
to elicit the corresponding responses from the turkers  the
full version of the paper contains sample phrasings for all six
elicitation formats and screenshots from our user interface 
here we give one example for the top-rank elicitation for-
mat  consider a question which asks to compare four coun-
tries  united kingdom  vietnam  russia  and kenya  by their
population  under the top-rank elicitation format  the vote
and prediction questions would be as follows 
• part a  vote   which country do you think is the most
populated among the following 
• part b  prediction   imagine that other participants
will also answer part a  how do you think the follow-
ing countries will be ordered from the most common re-
sponse  top  to the least common  bottom  
training 
recall that in our aggregation method  for each
elicitation format  we use two parameters  α ∈  0 5  1  and
β ∈  0  0 5   to convert ordinal predictions into cardinal pre-
dictions that can be then used in the sp algorithm  to learn
effective values of these parameters  we split the dataset into
a training and a test set  for each elicitation format  we se-
lected 5 questions from each of three domains  reserving the
remaining 15 questions from each domain for the test set  us-
ing these 15 questions  we performed a grid search over α
ranging from 0 55 to 0 95 in increments of 0 025 and β rang-
ing from 0 05 to 0 45 in increments of 0 025 and selected the
values with the lowest mean squared error 
5
results
in this section  we present our results averaged across all three
domains  in the full version  we present more detailed results
proceedings of the thirtieth    ijcai-21 
248
 figure 2  average time spent 
figure 3  perceived difficulty 
figure 4  perceived expressiveness 
averaged across each domain separately  all confidence in-
tervals shown are 95  intervals  we compare the elicitation
formats using four key metrics  difficulty  i e  cognitive bur-
den   expressiveness  error in predicting the ground truth top
alternative  and error in predicting the ground truth ranking 
5 1
difficulty   expressiveness
we measure the following three metrics 
• response time  response time is known to be a good
objective proxy for the cognitive load associated with a
task  rauterberg  1992   we measure the amount of time
spent by the turkers on the tutorials and questions of the
elicitation format 
• perceived difficulty  as a subjective indicator of diffi-
culty  we consider the perceived difficulty reported by
the turkers  from very easy to very difficult  during the
review stage of the elicitation format 
• perceived expressiveness  expressiveness indicates the
amount of information that the turkers felt they were
able to convey through the elicitation format  from very
significant to very little  
figure 2 shows the average time spent by the workers on
the tutorial and on an average question under the six elicita-
tion formats along with 95  confidence intervals  lower is
better   we observe a statistically significant trend  when we
fix a vote format  say top or rank   the average time spent
increases for both tutorials and questions as we make the pre-
diction format more complex  none → top → rank   in the
full version  we show the average time spent for each domain
and observe that the choice of the domain does not signifi-
cantly affect it regardless of the elicitation format 
figure 3 and figure 4 respectively show the reported distri-
butions of perceived difficulty  easier is better  and perceived
expressiveness  higher is better   interestingly  the turkers
found the six elicitation formats to be of very similar diffi-
culty and similar expressiveness 
5 2
predicting the ground truth top alternative
we now turn to analyzing how effectively the different elic-
itation formats help us predict the ground truth  in addition
to measuring the error of the ground truth estimate returned
by our algorithm  we also measure the error in the input votes
and predictions themselves  note that every vote and predic-
tion is an estimate of some truth  either the ground truth or
a summary statistic of the other votes   thus  its error can be
measured with respect to the truth it is attempting to uncover 
first  we consider predicting simply the top alternative in
the ground truth ranking  for our algorithm as well as for
the input votes and predictions  we use  as error measure  the
frequency of incorrectly guessing the top alternative of the
truth they attempt to estimate  figure 5 shows the average
prediction errors for various elicitation formats  lower is bet-
ter  5 we remind the reader that the effectiveness of sp voting
should be judged based only on elicitation formats which in-
clude some prediction information 
given four alternatives  selecting an alternative uniformly
at random would result in a prediction error of 0 75 
in-
terestingly  both the vote and prediction reports individually
have average error around this benchmark  yet  by combin-
ing these two pieces of individually erroneous information 
sp voting is able to achieve significantly lower error  this is
not surprising because sp voting approach is design precisely
to pick out the minority of experts lurking among a majority
of non-experts by combining vote and prediction information 
moreover  for a fixed type of vote  either top or rank   as the
prediction formats become more complex  none → top →
rank   the performance of sp voting improves 
figure 6 compares sp voting to several standard vot-
ing rules including plurality  plurality with runoff  borda 
copeland  instant runoff voting  irv   and maximin rule 
which ignore the prediction information and simply aggre-
gate the vote information in a democratic manner 6 the con-
ventional voting rules run on elections containing votes from
three elicitation formats  rank-none  rank-top  and rank-
rank  whereas sp voting runs on each elicitation format in-
dividually  we can see that for rank-rank  sp voting  right-
most orange bar  outperforms all conventional voting rules 
despite having access to just a third of the samples  this in-
dicates that the prediction information helps significantly 
these observations hold even when we consider each do-
main separately  these results are provided in the full version 
5 3
predicting the ground truth ranking
we now consider predicting the full ground truth ranking  for
sp voting result as well as the individual votes and predic-
tions  we use the kendall-tau  kt  distance to measure the
error of the sp voting result  votes  and predictions compared
to the true ranking they aim to estimate  figure 7 shows the
average kt distance for different elicitation formats  lower
5sp voting errors are obtained by averaging over 60 elections
associated with 60 questions  vote/prediction errors are averaged
over 1200 responses and have narrower confidence intervals 
6see  brandt et al   2016  for definitions of these rules 
proceedings of the thirtieth    ijcai-21 
249
 figure 5  average error in predicting the top alternative in the
ground truth  by combining both the vote and predictions  sp voting
achieves a much lower error than in either piece of information 
figure 6  comparing sp voting with conventional voting for pre-
dicting the top alternative  incorporating the prediction reports helps
sp voting significantly outperform conventional voting 
figure 7  average error in predicting the ground truth ranking 
by combining both the vote and prediction information  sp voting
achieves a much lower error than in either piece of information 
figure 8  comparing sp voting with conventional voting for pre-
dicting the ground truth ranking  incorporating the prediction re-
ports helps sp voting significantly outperform conventional voting 
is better   given four alternatives  selecting a uniformly ran-
dom ranking will have an average kt distance of 3  both the
votes and prediction reports have average error around this
benchmark  similar to predicting the top alternative  sp vot-
ing produces significantly lower average error by combining
these two noisy pieces of information  moreover  for each
vote format  either top or rank   as the prediction report be-
comes more expressive  none → top → rank  the average
error of sp voting decreases 
finally  we compare sp voting with standard voting rules
 figure 8  in terms of the average kt distance and find that
sp voting again outperforms all voting rules for rank-rank 
5 4
prediction vs  vote
our results illustrate the importance of prediction in recover-
ing the ground truth  while eliciting ranked votes and pre-
dictions  rank-rank  achieves the lowest error  an intriguing
question arises when we seek to choose an elicitation format
that provides a reasonable tradeoff between accuracy and dif-
ficulty/expressiveness  figures 5 and 7 show that top-rank
significantly outperforms rank-top while both formats are
comparable in terms of response time  perceived difficulty 
and perceived expressiveness  thus  if we wish to choose an
elicitation format slightly more complex than top-top  mak-
ing the prediction more expressive is more promising than
that of the vote  the same observation holds when comparing
top-top versus rank-none  this shows that when a tradeoff
between more complex vote and more complex prediction is
necessary  eliciting more complex prediction may be better 
6
discussion
we extended surprisingly popular voting to recover a ground
truth ranking of alternatives and  through a crowdsourcing
study across different domains  showed that it outperforms
conventional voting approaches without significantly increas-
ing elicitation  in our study  the ground truth is a ranking over
four alternatives  and a challenging future direction is to ex-
tend this approach to rankings with more than four alterna-
tives  for a large number of alternatives  any practical elicita-
tion scheme would ask the voters to report a partial rank over
the alternatives  which will make it challenging to design ag-
gregation rules for such partial ranks 
another interesting direction would be to derive theoret-
ical performance guarantees for surprisingly popular voting
when the number of participants is finite  the results of pr-
elec et al   2017  hold only in the limit  and when only partial
votes and predictions are elicited  this may require assuming
a parametric signal distribution such as the mallows model  
acknowledgements
the authors were partly supported by nsf grant #1850076
 hosseini   a postdoctoral fellowship from columbia dsi
 mandal   and an nserc discovery grant  shah  
proceedings of the thirtieth    ijcai-21 
250
 references
 abramowitz et al   2019  ben abramowitz  elliot anshele-
vich  and wennan zhu  awareness of voter passion greatly
improves the distortion of metric social choice  in pro-
ceedings of the 15th international conference on web and
internet economics  wine   pages 3–16  2019 
 amanatidis et al   2020  georgios
amanatidis 
geor-
gios birmpas  aris filos-ratsikas  and alexandros a 
voudouris  peeking behind the ordinal curtain  improving
distortion via cardinal queries  in proceedings of the 34th
aaai conference on artificial intelligence  aaai   pages
1782–1789  2020 
 arrow et al   2008  kenneth j  arrow  robert forsythe 
michael gorham  robert hahn  robin hanson  john o 
ledyard  saul levmore  robert litan  paul milgrom 
forrest d  nelson  george r  neumann  marco otta-
viani  thomas c  schelling  robert j  shiller  vernon l 
smith  erik snowberg  cass r  sunstein  paul c  tetlock 
philip e  tetlock  hal r  varian  justin wolfers  and eric
zitzewitz  the promise of prediction markets  science 
320 5878  877–878  2008 
 brandt et al   2016  felix brandt  vincent conitzer  ulle
endriss  j erˆome lang  and ariel d procaccia  handbook
of computational social choice 
cambridge university
press  2016 
 camerer  2011  colin f camerer  behavioral game theory 
experiments in strategic interaction  princeton university
press  2011 
 caragiannis et al   2016  ioannis caragiannis  ariel d pro-
caccia  and nisarg shah  when do noisy votes reveal the
truth  acm transactions on economics and computation
 teac   4 3  1–30  2016 
 chen and pennock  2010  yiling chen and david m pen-
nock 
designing markets for prediction 
ai magazine 
31 4  42–52  2010 
 de boer and bernstein  2017  patrick m de boer and abra-
ham bernstein  efficiently identifying a well-performing
crowd process for a given problem  in proceedings of the
2017 acm conference on computer supported coopera-
tive work and social computing  pages 1688–1699  2017 
 de condorcet  1785  marquis de condorcet 
essai sur
l application de l analyse  a la probabilit e de d ecisions ren-
dues  a la pluralit e de voix  imprimerie royal  1785  fac-
simile published in 1972 by chelsea publishing company 
new york 
 galesic et al   2018  mirta galesic  w bruine de bruin 
marion dumas  a kapteyn  je darling  and e meijer 
asking about social circles improves election predictions 
nature human behaviour  2 3  187–193  2018 
 galton  1907  francis galton  vox populi  nature  75 450–
451  1907 
 kempe  2020  david kempe  communication  distortion 
and randomness in metric voting  in proceedings of the
34th aaai conference on artificial intelligence  aaai  
pages 2087–2094  2020 
 lalley and weyl  2018  steven p lalley and e glen weyl 
quadratic voting  how mechanism design can radicalize
democracy  in aea papers and proceedings  volume 108 
pages 33–37  2018 
 lee et al   2018  michael d lee  irina danileiko  and julie
vi  testing the ability of the surprisingly popular method
to predict nfl games 
judgment and decision making 
13 4  322  2018 
 mandal et al   2019  debmalya mandal  ariel d procaccia 
nisarg shah  and david woodruff  efficient and thrifty
voting by any means necessary  in advances in neural
information processing systems  pages 7180–7191  2019 
 mandal et al   2020a  debmalya
mandal 
goran
radanovi c  and david parkes 
the effectiveness of
peer prediction in long-term forecasting 
in proceed-
ings of the aaai conference on artificial intelligence 
volume 34  pages 2160–2167  2020 
 mandal et al   2020b  debmalya mandal  nisarg shah  and
david p woodruff 
optimal communication-distortion
tradeoff in voting  in proceedings of the 21st acm con-
ference on economics and computation  pages 795–813 
2020 
 miller et al   2005  nolan miller  paul resnick  and richard
zeckhauser 
eliciting informative feedback  the peer-
prediction method 
management science  51 9  1359–
1373  2005 
 palley and soll  2019  asa b palley and jack b soll  ex-
tracting the wisdom of crowds when information is shared 
management science  65 5  2291–2309  2019 
 pivato  2019  marcus pivato  realizing epistemic democ-
racy  in the future of economic design  pages 103–112 
2019 
 prelec et al   2017  draˇzen prelec  h sebastian seung  and
john mccoy  a solution to the single-question crowd wis-
dom problem  nature  541 7638  532  2017 
 prelec  2004  draˇzen prelec 
a bayesian truth serum for
subjective data  science  306 5695  462–466  2004 
 rauterberg  1992  matthias rauterberg 
a method of
a quantitative measurement of cognitive complexity 
human-computer interaction 
tasks and organisation 
pages 295–307  1992 
 rutchick et al   2020  abraham m rutchick  bryan j ross 
dustin p calvillo  and catherine c mesick  does the  sur-
prisingly popular  method yield accurate crowdsourced
predictions 
cognitive research  principles and impli-
cations  5 1  1–10  2020 
 wang et al   2019  juntao
wang 
yang
liu 
and
yil-
ing chen 
forecast aggregation via peer prediction 
arxiv 1910 03779  2019 
 young  1988  h  p  young  condorcet s theory of voting 
the american political science review  82 4  1231–1244 
1988 
proceedings of the thirtieth    ijcai-21 
251
 "
None,2021,https-www-ijcai-org-proceedings-2021-0036-pdf,SURPRISE! and When to Schedule It.,"Zhihuan Huang, Shengwei Xu, You Shan, Yuxuan Lu, Yuqing Kong, Tracy Xiao Liu, Grant Schoenebeck",None,https://www.ijcai.org/proceedings/2021/0036.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0036-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0036-pdf.pdf,"surprise  and when to schedule it 
zhihuan huang1 2 ∗   shengwei xu1 2 4 ∗   you shan3   yuxuan lu1 2  
yuqing kong1 2 † ‡   tracy xiao liu3 §   grant schoenebeck4 ¶
1department of computer science  peking university
2center on frontiers of computing studies  peking university
3school of economics and management  tsinghua university
4school of information  university of michigan
 zhihuan huang  shengwei xu  yx lu  yuqing kong @pku edu cn  shany19@mails tsinghua edu cn 
liuxiao@sem tsinghua edu cn  schoeneb@umich edu
abstract
information flow measures  over the duration of
a game  the audience s belief of who will win 
and thus can reflect the amount of surprise in a
game  to quantify the relationship between infor-
mation flow and audiences  perceived quality  we
conduct a case study where subjects watch one of
the world s biggest esports events  lol s10  in
addition to eliciting information flow  we also ask
subjects to report their rating for each game  we
find that the amount of surprise in the end of the
game plays a dominant role in predicting the rat-
ing  this suggests the importance of incorporating
when the surprise occurs  in addition to the amount
of surprise  in perceived quality models  for con-
tent providers  it implies that everything else being
equal  it is better for twists to be more likely to hap-
pen toward the end of a show rather than uniformly
throughout 
1
introduction
the live streaming industry has been burgeoning around the
world in recent years  this includes live streaming games
which  in turn  encompasses content like esports  e g   league
of legends  dota2  cs go  apex legends   sports games
 e g   football  tennis   and other games like chess  poker  and
virtual casinos  esports and its related brands occupy 24 2 
of the hours watched on twitch tv 1 about 609 million peo-
ple spent over 5 billion hours watching video game streams
∗equal contribution
†corresponding author
‡supported by national natural science foundation of china
award number 62002001
§supported by the national key research and development pro-
gram of china award number 2018yfb1004503
¶supported by  united states  national science foundation
award number 2007256
1https //www pwc de/en/technology-media-and-
telecommunication/digital-trend-outlook-esport-2020/media-
broadcasts html
in 2016 2
despite the popularity of these live shows  their quality
varies significantly  we hypothesize an audience s perceived
quality for such live streamed content is  in part  derived from
the surprise in the content  one way to capture the effect of
surprise is to solicit information flow delivered from the show 
before the game commences  the audience might have an im-
perfect idea of who will win  as the live game unfolds  the
audience learns better about who the winner is likely to be 
in particular  the winner is clear by the time the game ends 
information flow measures  over the duration of a game the
audience s belief of who will win  intuitively  the surprise 
measures how much information flow fluctuates over time 
a key challenge is to quantify the relationship between the
audiences  information flow and audiences  perceived qual-
ity  prior studies either assume such relationship theoretically
 ely et al   2015  or use a statistical model to generate the
theoretic information flow and indirectly measure audiences 
perceived quality  e g   by audience size   bizzozero et al  
2016  scarf et al   2019  buraimo et al   2020   we instead
elicit data directly from the audience to quantify the relation-
ship and provide new insights for the development of such
perceived quality models  specifically  we elicit audiences 
real-time beliefs to compute the amount of surprise in a game 
we then study the relationship both between the amount of
surprise and perceived quality and also the relationship be-
tween when the surprise occurs and perceived quality 
we design the information flow elicitation platform to
collect the audiences  continuous beliefs and afterward rat-
ings  specifically  subjects watch live streaming games and
update their beliefs for the games  outcomes as many times
as they want  the platform monetarily rewards agents for
their information flow reports in such a way that more accu-
rate reports lead to higher payments  subjects also rate the
game quality afterwards 
we use our platform to conduct a study targeting lol
s10 3
2based on nate nead s report https //investmentbank com/
esports-gaming-video-content/
3the 2020 league of legends world championship is the tenth
world championship for league of legends  an esports tournament
for the video game developed by riot games  it was held from 25
proceedings of the thirtieth    ijcai-21 
252
 summary of our results 
we find that the second half of
the game has a larger amount of surprise compared to the first
half and the amount of surprise at the end of the game has
the strongest impact on the subjects  average ratings  more-
over  subjects  average ratings are significantly positively cor-
related with the games  surprise amount  interestingly  the
surprise amount in the first half of the game is negatively
correlated with the average ratings  while this correlation in
the second half is positive  one conjecture is that subjects
overweight their watching experience in later time periods 
which is not captured in prior studies  in other words  our re-
sults suggest that the perceived quality model should consider
the time factor and the designers can use a better information
revelation strategy such that the game is more likely to have
a twist near the end  additionally  we conduct robustness
checks by considering alternative causes of perceived qual-
ity fluctuations  e g   the favorite  home  team wins  and the
results are consistent 
2
belief curves  median curves  and surprise
in this section  we formally define the belief curve for each
agent  and the aggregation of agent s beliefs into the informa-
tion flow and median curve to compute the amount of surprise
in a game 
we focus on the two-team competition setting 
belief curves and information flow 
in game g  subject s
has a sequence of belief updates  the blue dots in figure 2 
chronologically   t0  p0    t1  p1         tn  pn    where n is
the number of times that subject s updates her belief in game
g  furthermore  t0 = startg shows that she reports her prior
belief p0 at the start of the game  then she updates her belief
from p0 to p1 at time t1 and keeps updating her belief to the
end  for convenience  let tn 1 = endg  for all 0 ≤ i ≤ n 
during period  ti  ti 1   subject s s belief remains to be pi 
a subject s s belief curve ps
g    startg  endg  �→  0  1 
for a game g represents her continuous belief throughout the
game  where ps
g t  is her belief for the winning probability of
the blue team at time t  figure 2   the belief curve can be
generated from her belief updates  formally 
definition 1  belief curve   subject s s belief curve is ps
g  
 startg  endg  �→  0  1  where
ps
g t   = pi
if t ∈  ti  ti 1  for all 0 ≤ i ≤ n
the information flow is the collection of all the belief
curves 
median curve 
to reduce the bias caused by irrational
agents who always report extreme beliefs  e g   0   or 100   
we use the median curve to compute the surprise amount  see
figure 1 for illustration of median curve and surprise amount 
definition 2  median curve   for a game g which is watched
by a set s of subjects  we define median curve as
g
 
 startg  endg  �→  0  1  as the median of the belief curve of
all subjects in s for game g  namely
∀t ∈  startg  endg   as
g  t  = median  ps
g t |s ∈ s  
september to 31 october in shanghai  china  there were 74 rounds
of games in total and each game lasts for 30 to 40 minutes 
figure 4 shows the median curves of three different games
from our data set 
surprise 
intuitively 
if
the
median
curve
fluctuates
severely  it suggests that this game has a high degree of sur-
prise  following ely et al   2015   we define the amount of
surprise as the sum of the change in the median curve 4 for-
mally 
definition 3  surprise amount   given a curve which is a step
function in  x0  xm 1 
f t  = αi
if t ∈  xi  xi 1  for all 0 ≤ i ≤ m
we define the surprise amount of this curve as
surp f   =
m
�
i=0
|αi 1 − αi|
surps
g  = surp as
g   is the amount of surprise in game g 
which is the sum of absolute value of changes of the median
curve as
g  5 we define as
g1 as as
g restricted to  startg  midg 
and as
g2 as as
g restricted to  midg  endg  where midg =
startg endg
2
  surps
g1  = surp
�
as
g1
�
is the amount of sur-
prise in the first half of game g and surps
g2  = surp
�
as
g2
�
is
the amount of surprise in the second half of game g 
figure 1  surprise amount  we have three subjects s1  s2  s3 whose
belief curves are green  yellow and blue respectively  we aggregate
their curves to a median curve which is the median of subjects  belief
point wisely  the surprise amount is defined as the sum of changes 
which is |∆1|   |∆2| 
perceived quality vs  surprise 
we estimate g s perceived
quality by its average rating rs
g over all subjects s who watch
game g  to quantify the relationship both between the amount
of surprise and perceived quality and also study the relation-
ship between when the surprise occurs and perceived quality 
we test the relationship between 1  game g s surprise amount
surps
g and its average rating rs
g   2  game g s surprise amount
in the first half surps
g1 and rs
g   3  game g s surprise amount
in the second half surps
g2 and rs
g  
4this is seeming unrelated to the  surprisal score  sometimes
used in machine learning 
5since for all s ∈ s  ps
g t  is a step function in  startg  endg 
of finite intervals  as
g  t  is also a step function in  startg  endg  of
finite intervals 
proceedings of the thirtieth    ijcai-21 
253
 3
data collection methods
we first describe our information flow elicitation platform
which was used to collect that data  second  we describe the
data we collected 
3 1
information flow elicitation platform
a game is a competition between two teams  e g   the red
team vs  the blue team  for each game  the study aims to col-
lect three types of information from each subject  their team
preference  their real-time belief of the blue team s winning
probability  and their quality rating for the game  specifi-
cally  there are three stages for each game  before  during 
and after  before the game  subjects report their preferences
for the team  they also report their prior belief for the blue
team s winning probability  during the game  subjects up-
date their real-time belief of the winning probability when-
ever they want  after the game  they report their ratings for
the game on a likert scale  i e   from 1 to 9  how much did
you like the game 
figure 2  workflow overview  we use a game in lol s10 to il-
lustrate the workflow  the game is between two teams  blue and
red  we ask subjects their team preference before the game  sub-
jects view the game live and update their belief according to the
game 6after the game  subjects rate the game 
incentives 
for each game  subjects receive a monetary re-
ward which depends on their overall prediction accuracy  to
measure the overall prediction accuracy  we use the quadratic
scoring rule  brier  1950  gneiting and raftery  2007  to
measure the prediction accuracy at every t and integrate the
quadratic score over  startg  endg  
formally  each subject receives a score which depends on
her belief curve  when the game ends  the outcome og for the
blue team is either 0 or 1  subject s s quadratic score at time
6the screenshots of the game is from lol s10 s live streaming
platform  https //www bilibili com/
t is 1 −  ps
g t  − og 2  the overall quadratic score of subject
s is 
score ps
g  =
1
endg − startg
� endg
startg
 1 −  ps
g t  − og 2 dt
for example  we consider a game where the starting time
is 00 00  the ending time is 00 50  and the red team wins in
the end  a subject reports her prior belief 40  for the win-
ning probability of the blue team at the beginning  then she
updates her belief to 80  at 00 25  50  at 00 30  and 0  at
00 40  her score will be   1−0 42 × 25−0 − 1−0 82 ×
 30−25 − 1−0 52 × 40−30 − 1−02 × 50−40  ×
 1/50  = 0 86 
for subject s  at every time t  the expected quadratic score
is maximized when ps
g t  is her true belief at time t  the
expected score is maximized when ∀ t  ps
g t  is her true be-
lief at time t  thus  our score is incentive-compatible  how-
ever  this leads to non-fixed cost  to fix the budget  following
lambert et al   2015   we calculate the average score over all
subjects in game g  scoreg  subject s s reward is then
 1   score ps
g  − scoreg  b
mg
where mg denotes the number of subjects in game g  with
the aforementioned reward  the total reward for the game is
fixed to b  moreover  the reward is always non-negative and
has the same incentive properties as the original score 
3 2
datasets
league of legends 
league of legends is a free 5v5 online
moba  multiplayer online battle arena  game created and
published by riot games  the goal of the teams is to destroy
the enemy team s base  the match ends immediately after
one teams  base is destroyed 
data properties 
we use our platform to conduct a study
for lol s10 which consisted of 76 individual games  we
recruited 107 subjects from top chinese universities  for each
game  a link to participate was sent out to all the participants 
subjects could participate in as many or as few games as they
like  additionally  we did not restrict the number of agents
that signed up for each game 
we obtained 4 566 observations in total  where an obser-
vation consisted of one particular subject participating in one
particular game  5 subjects participated in all 76 games  3
subjects of them only participate once  the average number
of games that a subject participated in was 42 67 
exploratory data analysis 
the average score for our
subjects in each game was 0 817 
the average payment
for our subjects in each game was 10 26 cny  about $1 58
usd   yielding a total payment of 46 850 cny  about $7 230
usd  
moreover  the median frequency for belief updating is 5
and the average is 5 87  68  subjects are majoring in stem 
all subjects report that they have experience watching lol
live 
for each game  we can measure the number of subjects 
the average rating  the duration  the peak time  the surprise in
proceedings of the thirtieth    ijcai-21 
254
  a  before
 b  during
 c  after
figure 3  screenshots of our platform  the above figures are subjects  interface of our platform 
proceedings of the thirtieth    ijcai-21 
255
 0 0
0 2
0 4
0 6
0 8
1 0
time
0
20
40
60
80
100
belief   
rating  7 065 rank  12/76
 a  likelihood that g2 beats sn
0 0
0 2
0 4
0 6
0 8
1 0
time
0
20
40
60
80
100
belief   
rating  4 564 rank  61/76
 b  likelihood that dwg beats psg
0 0
0 2
0 4
0 6
0 8
1 0
time
0
20
40
60
80
100
belief   
rating  4 432 rank  64/76
 c  likelihood that uol beats drx
figure 4  median curves of three games in lol s10  the figures above shows the median curves of three games with different ratings  the
game in  a  has a very high rating  rank 12 among all 76 games  this game is between two well matched teams  there are several reversals
in the game  the game in  b  has a low rating  rank 61/76   dwg is the champion team  and psg is a weak team  the subjects are confident
that dwg will win in the beginning  and the outcome fulfills their expectation  the game in  c  also has a low rating  rank 64/76   uol is
slightly weaker than drx  by the middle of the game  drx has taken control and the second half has no big surprises 
the first half and the second half  the peak surprise  the end
surprise and the overall surprise  the peak time measures the
most surprising time in the game which we define as the mid-
dle of the time interval of 2 5 minutes that has the maximum
amount of surprise  the peak surprise is defined as the sur-
prise amount generated in the peak time  the end surprise is
defined as the surprise amount generated in the last 2 5 min-
utes 
average
min
max
number of subjects
59 974
28
83
average rating
5 709
3 600
8 235
duration  min 
32 039
18 817
45 317
peak time  min 
23 950
2 600
44 042
1st half surprise
0 262
0 040
0 675
2nd half surprise
0 531
0 010
1 445
peak surprise
0 278
0 090
0 790
end surprise
0 162
0
0 725
overall surprise
0 793
0 150
1 750
table 1  summary statistics of our data
table 1 displays the average  minimum  and maximum of
each of these quantities  note that on average  the surprise in
the second half is twice the surprise in the first half 
figure 5 shows a histogram of the first four of these quan-
tities 
observe that the most frequent peak times are be-
tween 20 to 30 minutes  this corresponds to a key part of
the matches  killing the first dragon  baron nashor   which
appears exactly at the 20th minute of the match  and is typ-
ically killed between the 20 and 30 minute mark and grants
the successful team a lasting advantage 
figure 6 a  shows a scatter plot of the surprise in the first
half and second half of each match  the points are colored by
how exciting the match was  measured by the match s average
rating  we can see that these values are negatively correlated 
20
30
40
50
60
70
number
0
5
10
15
20
25
30
count
 a  the number of subjects in
games
1
3
5
7
9
average rating
0
5
10
15
20
25
30
count
 b  average game rating
0
10
20
30
40
50
time min 
0
5
10
15
20
25
30
count
 c  length of the game
0
10
20
30
40
50
time min 
0
5
10
15
20
25
30
count
 d  time that peak occurs
figure 5  histogram of multiple statistics over all games  a  number
of participating subjects  b  the average ratings  c  duration d  the
peak times  when surprise is the highest   we also draw the kernel
density estimation curve of these histograms 
figure 6 b  is a scatter plot of the surprise in the peak time
and end time of each match  these values are positively cor-
related  we also find that peak is end for 19 7  games 
figure 7 displays the amount of surprise over time  short
proceedings of the thirtieth    ijcai-21 
256
 0 2
0 4
0 6
1st half surprise
0 0
0 5
1 0
1 5
2nd half surprise
4
5
6
7
8
rating
 a  first half vs  second half
0 2
0 4
0 6
peak surprise
0 0
0 2
0 4
0 6
0 8
end surprise
4
5
6
7
8
rating
 b  peak vs  end
figure 6  relationship between surprise in different time  each
point represents a game and is colored by the game s average rat-
ing  the figures also show the linear regression lines 
games  tend not to have too much surprise  perhaps  because
the teams are unevenly matched  long games tend to start off
with less surprise  likely as the teams remain evenly matched 
but have a substantial amount of surprise toward the end 
5
10
15
20
25
30
35
40
45
time min 
0 0
0 1
0 2
0 3
0 4
0 5
0 6
0 7
0 8
surprise
duration < 25 min
duration in 25 to 35 min
duration > 35 min
figure 7  amount of surprise over time  we discretize time and  at
each time  calculate the surprise amount in the time interval of 2 5
minutes centered at that time  each dot in the figure represents the
surprise amount in a certain game and a certain time interval  the
color of a dot shows the duration of the corresponding game  there
are three colors in total  red means the corresponding game lasts
less than 25 minutes  green means it lasts 25 to 35 minutes  and blue
means it lasts more than 35 minutes  the colored lines represent the
average surprise amount in games with the same color at a certain
time 
4
results
first  we analyze the relationship between the subjects  rat-
ings and the amount of surprise in the game  we find that the
average rating is significantly positively correlated with the
amount of surprise  figure 8 a   table 2  column  1    we
further divide the game into two halves and observe opposite
effects between the two time windows  there is a signifi-
cantly positive correlation between the ratings and the sur-
prise amount in the second half  figure 8 c   table 2  col-
umn  3    while this correlation is negative in the first half
 figure 8 b   table 2  column  2    this result remains when
we regress on both the first half surprise and the second half
surprise together  figure 8 b   table 2  column  4   
 1 
 2 
 3 
 4 
surprise
1 214∗∗∗
 0 399 
1st half
-2 921∗∗∗
-2 100∗∗
surprise
 0 911 
 0 846 
2nd half
1 743∗∗∗
1 533∗∗∗
surprise
 0 368 
 0 366 
constant 4 746∗∗∗
6 473∗∗∗
4 783∗∗∗
5 444∗∗∗
 0 340 
 0 269 
 0 227 
 0 345 
n
76
76
76
76
adj  r2
0 099
0 110
0 222
0 273
table 2  ols regression of surprise and rating in different time pe-
riods  the dependent variable is rating score  the independent vari-
able in columns  1    2    3  is surprise  1st half surprise  2nd half
surprise respectively  and the independent variable in columns  4 
are the 1st half surprise and 2nd half surprise  together  the 1st and
2nd half surprise indicates that the amount of surprise of the 1st and
2nd half of the game  the surprise represents overall amount of
surprise in the whole game  standard errors are reported in paren-
theses           and   indicate statistical significance at the 1   5  
and 10  levels  respectively 
importantly  the second half surprise better predicts the av-
erage rating than the overall surprise  the coefficient value is
1 743 for second half surprise while it is 1 214 for the over-
all surprise  moreover  the adjusted r2 value is also greater
when using second half surprise than when using the overall
surprise  one possibility is that subjects may overweight their
watching experiences in the second half of the game  our re-
sult suggests that to optimize the information revelation strat-
egy  the optimization goal should consider time factors and
emphasize the later surprise more 
a possible explanation for this result is the peak-end-effect
 kahneman et al   1993  baddeley and hitch  1993   that
is  people judge an experience mostly based on how they felt
at its peak  the most intense point  and at its end  rather than
based on the sum of their feeling at all moments of the experi-
ence  thus  we further analyze the effect of the peak surprise
and the end surprise in our data  see definition in section 3 2  
our results show that both of them are highly correlated with
the average rating  while the end surprise has the highest cor-
relation  see table 3   note that the end surprise explains
even more than the second half surprise  the end surprise s
adjusted r2 value is 0 232 which is greater than the second
half surprise s adjusted r2 value 0 222  
second  we observe a salient increase  decrease  in ratings
for subjects whose preferred team wins  loses   in a game
with audiences whose preferences are homogeneous  e g   a
popular team vs  an unpopular team  such individual rating
biases lead to an unfairly high  low  average rating for a game
depending on the outcome of the game  therefore  we sepa-
rate games into three categories  win  lose and neutral  the
win  lose  category includes games where the winning  los-
ing  team was preferred by a majority of subjects  the neutral
category consists of games where neither team was preferred
by the majority  recall that subjects can also be neutral in their
proceedings of the thirtieth    ijcai-21 
257
 uncategorized
0 0
0 5
1 0
1 5
surprise
4
5
6
7
8
rating
 a  whole game
0 0
0 5
1 0
1 5
1st half surprise
4
5
6
7
8
rating
 b  1st half
0 0
0 5
1 0
1 5
2nd half surprise
4
5
6
7
8
rating
 c  2nd half
0 0
0 5
1 0
1 5
peak surprise
4
5
6
7
8
rating
 d  peak time
0 0
0 5
1 0
1 5
end surprise
4
5
6
7
8
rating
 e  end time
categorized
0 0
0 5
1 0
1 5
surprise
4
5
6
7
8
rating
neutral
lose
win
 f  whole game
0 0
0 5
1 0
1 5
1st half surprise
4
5
6
7
8
rating
neutral
lose
win
 g  1st half
0 0
0 5
1 0
1 5
2nd half surprise
4
5
6
7
8
rating
neutral
lose
win
 h  2nd half
0 0
0 5
1 0
1 5
peak surprise
4
5
6
7
8
rating
neutral
lose
win
 i  peak time
0 0
0 5
1 0
1 5
end surprise
4
5
6
7
8
rating
neutral
lose
win
 j  end time
figure 8  relationship between surprise amount and rating  in the figures above  each point represents a game and the y-axis is the average
rating of the subjects  the x-axis is the surprise amount of the whole game  a f   the first half  b g   the second half  c h   the peak time  d i  
and the end time  e j  correspondingly  in the second row  the games are classified into three categories  the red points represent the game
won by the majority preferred team  the blue dots is the game where the majority preferred team failed  and the gray dots represent the game
where no team is preferred by the majority  most of them are neutral    the second row analyses the relationship between surprise amount
and rating using data of only one category  the results are similar to the above row which suggests the robustness of the conclusion 
 1 
 2 
 3 
peak surprise 3 459∗∗∗
-0 582
 0 947 
 1 637 
end surprise
3 146∗∗∗
3 497∗∗∗
 0 647 
 1 183 
constant
4 746∗∗∗
5 200∗∗∗
5 304∗∗∗
 0 290 
 0 156 
 0 335 
n
76
76
76
adj  r2
0 141
0 232
0 223
table 3  ols regression of peak-end surprise and rating  the depen-
dent variable is rating score  the independent variable in columns
 1    2  is peak surprise  end surprise  respectively  the independent
variables in column  3  are peak surprise  end surprise  together 
the peak surprise indicates the amount of surprise in peak time 
the end surprise indicates the amount of surprise generated in the
last 2 5 minutes  standard errors are reported in parentheses      
    and   indicate statistical significance at the 1   5   and 10 
levels  respectively 
team preference   the results are in figure 8 f  to 8 j  and
table 4  again  we observe similar results across all three
categories of games 
in addition to the amount of surprise  we also explore other
factors that may affect the audience s average rating 
comeback size  it is defined as one minus the minimum
winning probability of the winner during the game  this
feature characterizes how big the surprise of the outcome
is  the coefficient value is 1 737 and the adjusted r2
value is 0 029 
number of leader changes  it is defined as the number of
times when the team with more than 50  winning prob-
ability changes  this feature characterizes the team with
advantage changes  the coefficient value is −0 677 and
the adjusted r2 value is 0 017 
rubbish time  given a threshold p  the rubbish time is de-
fined as the proportion of time period between the last
time that the winner s winning probability ≥ p and the
end of the match  p is a parameter from 0 5 to 1  this
feature characterizes the unsurprising time before the
end  intuitively  rubbish time is correlated with the end
surprise and negatively correlated with the rating  our
results show that p = 0 7 has the best performance
which has the coefficient value as −1 524 and the ad-
justed r2 value as 0 175 
among the above three factors  the rubbish time is the most
relevant factor but is still less effective than the end surprise 
proceedings of the thirtieth    ijcai-21 
258
  1 
 2 
 3 
 4 
all
win game
lose game
neutral
game
surprise
1 692∗∗∗
1 211∗∗∗
2 088∗∗∗
1 760∗∗∗
 0 293 
 0 489 
 0 557 
 0 507 
win
1 498∗∗∗
 0 198 
lose
-0 376
 0 232 
constant 3 928∗∗∗
5 783∗∗∗
3 162∗∗∗
3 879∗∗∗
 0 251 
 0 389 
 0 585 
 0 385 
n
76
27
19
30
adj  r2
0 575
0 165
0 420
0 276
table 4  ols regression of surprise and rating in different games 
column  1  is the pooling result  column  2  refers to games where
the majority preferred team wins  column  3  refers to games where
the majority preferred team loses  and column  4  is for games
where no team is preferred by the majority  the dependent vari-
able is the rating score  the independent variable in column  1  is
the amount of surprise  a dummy for winning  losing   i e   whether
the game is won  lost  by the majority preferred team  the inde-
pendent variable in columns  2    3    4  is the amount of surprise 
respectively  standard errors are reported in parentheses          
and   indicate statistical significance at the 1   5   and 10  levels 
respectively 
5
related work
surprise vs 
perceived quality 
starting from ely et
al   2015   a growing literature examines the relationship
between the surprise and the perceived quality in different
games  such as tennis games  bizzozero et al   2016   soccer
games  buraimo et al   2020  and rugby games  scarf et al  
2019  
however  instead of eliciting belief curves  this literature
typically constructs them from existing data  for example 
bizzozero et al   2016  model the probability of a certain side
winning by explicitly using tennis s scoring systems  simi-
larly  buraimo et al   2020  use an in-play model which ad-
ditionally exploits the information on team strength which is
embedded in the pre-match odds  buraimo et al   2020  and
scarf et al   2019  both use the poisson model to estimate the
number of goals scored by the participating teams in order to
calculate the probability of the final outcome of the game  lu-
cas et al   2017  analyze the tweets during the world cup and
use the emotional changes to measure the surprise  in con-
trast to these studies which estimate surprise using statistical
models  our study measures the perceived surprise amount by
dynamically eliciting subjects  beliefs 
these works also use different proxies for perceived qual-
ity  buraimo et al   2020  analyze the relationship between
surprise and the real-time audience size for both halves of
soccer games  instead  we focus on the relationship between
surprise and the overall rating  thus  prior studies do not
observe how the timing effects of surprise affect perceived
quality 
in addition to surprise  massive literature also studies sus-
pense  which is defined as how much the belief curve is ex-
pected to move in the very near future  since measuring sus-
pense requires the ability to predict what might happen in the
near future  the analysis for suspense is beyond the scope of
the paper  in the future  it might be possible to learn a model
from the data which enables the analysis of suspense 
prediction markets and polls 
prediction markets are de-
signed to elicit continuously updated forecasts about uncer-
tain events  prior studies have proved that prediction mar-
ket can outperform internal sales projections  plott and chen 
2002   journalists  forecasts of oscar winners  pennock et
al   2001   and expert economic forecasters  gurkaynak and
wolfers  2006  
in prediction polls  forecasters express their beliefs by an-
swering questions like  how likely is this event    in both
prediction markets and polls  forecasters can update their pre-
dictions whenever they wish  in contrast to prediction mar-
kets  in prediction polls  forecasters update their predictions
individually  rothschild and wolfers  2011  s work shows
that using prediction polls in elections can achieve better ac-
curacy than opinion polls 
a few studies have compared the performance of predic-
tion markets and polls  though there is no conclusive answer
 goel et al   2010  rieg and schoder  2010  atanasov et al  
2017   both goel et al   2010  and rieg and schoder  2010 
find no significant differences between these two methods 
atanasov et al   2017  find that the aggregation rules in pre-
diction polls affect its accuracy level  for example  simply
averaging all polls performs worse than a prediction market 
while weighting the polls properly leads to a better perfor-
mance than a prediction market  our elicitation method is
more similar to prediction polls 
6
conclusion
we study the relationship between a game s surprise amount
and its perceived quality  we develop a platform that collects
audiences  real-time beliefs and ratings of the lol s10  our
empirical analysis suggests that the level of surprise in the
later time of a game has a stronger impact on subjects  rat-
ings  this indicates that the audience would prefer surprise
to occur in the end of a game  a future direction is to define a
new perceived quality model that considers time factors and
theoretically analyze the optimal way to reveal information
over time in this model  future work could similarly opti-
mize suspense 
moreover  we expect that belief polls could be embedded
in live streaming games as an entertainment feature  last but
not least  we can collect other information such as the text in
bullet comments to better construct the information flow 
acknowledgments
we would like to thank our anonymous reviewers for their in-
sightful suggestions which substantially improved the paper 
we also thank kening ren  jialun yang  xinlun zhang  fan
yan and zheng zhong for their help and useful discussions 
finally  we thank our participants in our lol s10 study for
their time  attention and effort  some of the figures are gen-
erated with python matplotlib  hunter  2007  
proceedings of the thirtieth    ijcai-21 
259
 references
 atanasov et al   2017  pavel atanasov  phillip rescober 
eric stone  samuel a swift  emile servan-schreiber 
philip tetlock  lyle ungar  and barbara mellers  distilling
the wisdom of crowds  prediction markets vs  prediction
polls  management science  63 3  691–706  2017 
 baddeley and hitch  1993  alan d baddeley and graham
hitch  the recency effect  implicit learning with explicit
retrieval  memory   cognition  21 2  146–155  1993 
 bizzozero et al   2016  paolo bizzozero  raphael flepp 
and egon franck  the importance of suspense and sur-
prise in entertainment demand  evidence from wimble-
don 
journal of economic behavior   organization 
130 47–63  2016 
 brier  1950  g  w  brier  verification of forecasts expressed
in terms of probability  monthly weather review  78 1–3 
1950 
 buraimo et al   2020  babatunde buraimo  david forrest 
ian g mchale  and jd tena  unscripted drama  soccer
audience response to suspense  surprise  and shock  eco-
nomic inquiry  58 2  881–896  2020 
 ely et al   2015  jeffrey ely  alexander frankel  and emir
kamenica  suspense and surprise  journal of political
economy  123 1  215–260  2015 
 gneiting and raftery  2007  tilmann gneiting and adrian
raftery  strictly proper scoring rules  prediction  and es-
timation  journal of the american statistical association 
102 359–378  03 2007 
 goel et al   2010  sharad goel  daniel m reeves  duncan j
watts  and david m pennock  prediction without markets 
in proceedings of the 11th acm conference on electronic
commerce  pages 357–366  2010 
 gurkaynak and wolfers  2006  refet gurkaynak and justin
wolfers 
macroeconomic derivatives  an initial analy-
sis of market-based macro forecasts  uncertainty  and risk 
technical report  national bureau of economic research 
2006 
 hunter  2007  j  d  hunter  matplotlib  a 2d graphics envi-
ronment  computing in science   engineering  9 3  90–
95  2007 
 kahneman et al   1993  daniel
kahneman 
barbara
l
fredrickson  charles a schreiber  and donald a re-
delmeier  when more pain is preferred to less  adding a
better end  psychological science  4 6  401–405  1993 
 lambert et al   2015  nicolas s  lambert  john langford 
jennifer wortman vaughan  yiling chen  daniel m 
reeves  yoav shoham  and david m  pennock  an ax-
iomatic characterization of wagering mechanisms  jour-
nal of economic theory  156 389 – 416  2015  computer
science and economic theory 
 lucas et al   2017  gale m  lucas  jonathan gratch  niko-
laos malandrakis  evan szablowski  eli fessler  and jef-
frey nichols  goaalll   using sentiment in the world cup
to explore theories of emotion  image and vision comput-
ing  65 58–65  2017  multimodal sentiment analysis and
mining in the wild image and vision computing 
 pennock et al   2001  david m pennock  steve lawrence 
finn ˚arup nielsen  and c lee giles  extracting collective
probabilistic forecasts from web games  in proceedings
of the seventh acm sigkdd international conference on
knowledge discovery and data mining  pages 174–183 
2001 
 plott and chen  2002  charles r plott and kay-yut chen 
information aggregation mechanisms  concept  design
and implementation for a sales forecasting problem  work-
ing paper no  1131  california institute of technology  di-
vision of the humanities and social sciences  2002 
 rieg and schoder  2010  robert rieg and ramona schoder 
forecasting accuracy  comparing prediction markets and
surveys-an experimental study  journal of prediction mar-
kets  4 3   2010 
 rothschild and wolfers  2011  david rothschild and justin
wolfers  forecasting elections  voter intentions versus ex-
pectations  available at ssrn 1884644  2011 
 scarf et al   2019  phil scarf  rishikesh parma  and ian
mchale 
on outcome uncertainty and scoring rates in
sport  the case of international rugby union  european
journal of operational research  273 2  721–730  2019 
proceedings of the thirtieth    ijcai-21 
260
 "
None,2021,https-www-ijcai-org-proceedings-2021-0037-pdf,Dynamic Proportional Rankings,"Jonas Israel, Markus Brill",None,https://www.ijcai.org/proceedings/2021/0037.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0037-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0037-pdf.pdf,"dynamic proportional rankings
jonas israel and markus brill
research group efficient algorithms
technische universit¨at berlin
10587 berlin  germany
 j israel  brill @tu-berlin de
abstract
proportional ranking rules aggregate approval-style
preferences of agents into a collective ranking such
that groups of agents with similar preferences are
adequately represented  motivated by the applica-
tion of live q a platforms  where submitted ques-
tions need to be ranked based on the interests of the
audience  we study a dynamic extension of the pro-
portional rankings setting  in our setting  the goal
is to maintain the proportionality of a ranking when
alternatives  i e   questions —not necessarily from
the top of the ranking—get selected sequentially 
we propose generalizations of well-known aggre-
gation rules to this setting and study their mono-
tonicity and proportionality properties 
we also
evaluate the performance of these rules experimen-
tally  using realistic probabilistic assumptions on
the selection procedure 
1
introduction
from  ask-me-anything  sessions to panel discussions and
town hall meetings  an increasing number of both virtual and
in-person discussion formats are enhanced by digital tools
that aim to make the event more interactive and responsive
to the audience  using live q a platforms such as slido
 www sli do   mentimeter  www mentimeter com  or pigeon-
hole live  www pigeonholelive com   participants in the au-
dience can submit questions and upvote questions submitted
by others  a moderator then selects the most popular ques-
tions for the discussion  by reducing barriers to participation
 e g   by allowing anonymous submissions   these tools aim
to better represent the diversity in the audience 
the moderator of the discussion is presented with an aggre-
gated list  in which audience questions are ranked by popular-
ity  i e   number of upvotes   based on this ranking  the mod-
erator then picks the next question  when selecting a ques-
tion  it is usually not required to follow the ranking strictly 
rather  the choice is at the moderator s discretion  allowing
him or her to take into account other factors such as discus-
sion flow  etc  that being said  it is generally expected that
questions at the top of the ranking are more likely to be se-
lected than questions further down in the list  after a question
has been selected  it is removed from the ranking 
ranking questions solely by popularity  though intuitively
appealing  has a major downside  minority opinions might
go completely unrepresented  even when the minority makes
up a substantial proportion of the audience  to illustrate this
phenomenon  which is often referred to as  tyranny of the
majority   consider a situation in which the audience is com-
posed of two groups  one group makes up 60  of the entire
audience and is only interested in questions related to topic a 
the remaining 40  of participants are only interested in ques-
tions on a different topic b  now  assuming that sufficiently
many questions on topic a have been submitted  and that par-
ticipants only upvote questions related to their own interest 
questions on topic b are unlikely to appear anywhere near the
top of the ranking  which is populated exclusively by ques-
tions on topic a  as a consequence  questions on topic b are
very unlikely to be selected  despite the fact that these ques-
tions are supported by 40  of the audience 
in this paper  we propose an approach to avoid the prob-
lem of underrepresenting minority opinions  specifically  we
model the scenario described above as a proportional repre-
sentation problem and employ ranking algorithms based on
 approval-based  proportional voting rules  aziz et al   2017 
brill et al   2017   the algorithms we consider aggregate the
upvotes of the participants into a proportional ranking over
questions  such that each minority  i e   group of participants
with similar preferences  is represented in the ranking to an
extent that is proportional to the group s size  whenever a
question is selected by the moderator  our methods dynami-
cally recompute the ranking  pushing questions supported by
underrepresented groups closer to the top 
at a technical level  our point of departure is the theory of
proportional rankings  skowron et al   2017   which studies
how a collective ranking over a set of alternatives can be con-
structed in such a way that majority and minority opinions
are represented adequately  the question we are interested in
is how proportional ranking algorithms can be adapted to the
dynamic setting  more specifically  we ask 
how can the proportional representativeness of a
collective ranking be maintained in a dynamic set-
ting  where alternatives get selected sequentially 
to answer this question  we consider two well-known aggre-
gation rules dating back to the late 19th century  sequen-
tial phragm en  phragm en  1894  and sequential pav  thiele 
1895   these two rules  together with a few variants of the
proceedings of the thirtieth    ijcai-21 
261
 latter  performed best in the analysis conducted by skowron
et al   2017   for both rules  we propose two distinct general-
izations to the sequential selection setting  a dynamic variant
and a myopic variant  see section 3 for details   as a bench-
mark  we also consider the rule that simply orders questions
by the number of received upvotes 
our contribution 
in this paper   i  we formalize the set-
ting of dynamic ranking rules and generalize the rules of
phragm en and thiele to this setting  section 3    ii  we de-
fine a notion of satisfaction monotonicity and analyze to what
extent the considered rules satisfy it  section 4    iii  we pro-
vide theoretical bounds regarding two different proportional-
ity notions  section 5   and  iv  we experimentally evaluate
our dynamic ranking rules  section 6   omitted proofs and
further details can be found in the full version of this paper
 israel and brill  2021  
related work 
proportional representation is a fundamen-
tal desideratum in multiwinner elections  monroe  1995 
faliszewski et al   2017  lackner and skowron  2020   for
approval preferences in particular  a wide variety of pro-
portionality axioms have been studied  aziz et al   2017 
s anchez-fern andez et al   2017  janson  2018  peters and
skowron  2020   proportionality in the context of rankings
has been considered in the aforementioned paper by skowron
et al   2017  and  for linear preferences  by schulze  2011  
notions of fairness over multiple elections among a fixed
set of voters have received considerable attention in previ-
ous years 
this line of work includes  e g   the study of
long-term fairness over different decisions  freeman et al  
2017  lackner  2020   single decisions under changing pref-
erences  tennenholtz  2004  boutilier and procaccia  2012 
parkes and procaccia  2013  oren and lucier  2014  hemas-
paandra et al   2017   and storable votes  casella  2005 
casella  2012   in a practical attempt to avoid the under-
representation of minorities  the live q a app speakup
 www speakup digital  allows audience members to add at-
tributes  relating to  e g   gender or education  to submitted
questions  the moderator can then manually filter questions
with attributes that have been underrepresented in the dis-
cussion  requiring organizers to identify relevant attributes
poses the risk of overlooking important subgroups or intro-
ducing unwanted biases  it also presumes the willingness of
participants to reveal potentially sensitive information 
in
contrast  the ranking algorithms considered in this paper do
not require attributes in order to ensure the representation of
minority opinions 
2
preliminaries
we briefly introduce some basic concepts from the theory of
approval-based preference aggregation  for details  see the
survey by lackner and skowron  2020   let c be a finite
set of candidates and n =  1          n  a finite set of voters 
an  approval  profile a =  a1          an  is a list that con-
tains  for each i ∈ n  the approval set ai ⊆ c of voter i 
given an approval profile a and a candidate c ∈ c  we let
nc =  i ∈ n   c ∈ ai  denote the supporters of c  the
approval score of c is given by |nc|  in the motivating appli-
cation  c consists of all submitted questions and ai contains
the questions that have been upvoted by participant i 
for a finite set s  we let l s  denote the set of all linear or-
ders  or rankings  over s  we often write a ranking r ∈ l s 
as a sequence r =  r1  r2          r|s|   and for j ≤ |s|  we let
r≤j denote the set  r1  r2       rj  of the first j elements in r 
an approval-based ranking rule maps an approval profile
a to a ranking r ∈ l c  of all candidates  we will make use
of the following three  non-dynamic  ranking rules 1
approval voting  av  ranks the candidates according to
their approval score  this rule is not proportional and we
use it mainly as a benchmark 
sequential pav  seqpav  ranks candidates iteratively  in
each iteration choosing an unranked candidate maximizing
the marginal contribution in terms of weighted voter satis-
faction  formally  for a subset s ⊆ c of candidates  de-
fine sc s  = �
i∈n
�|ai∩s|
j=1
1
j   if k candidates have already
been ranked  the marginal contribution of an unranked candi-
date c is given by mc c  = sc r≤k ∪  c   − sc r≤k  
sequential phragm en can be described in terms of voters
buying candidates 2 every candidate costs 1 credit  all voters
start without any credits but earn them continuously over time
 at a constant and identical rate   as soon as a group of voters
who all approve the same candidate c together own 1 credit 
they immediately buy that candidate  at this point  their bal-
ance is reset to 0 and candidate c is added in the next position
of the ranking  this is done until all candidates are ranked 
3
dynamic ranking rules
in this section  we formally introduce the setting of dynamic
ranking rules and we adapt existing  non-dynamic  ranking
rules to this setting  the input of a dynamic ranking rule
consists of two parts  an approval profile and a  potentially
empty  sequence of candidates that have already been  im-
plemented  or  executed   the output is a ranking of all not-
yet-implemented candidates  to formalize this notion  we let
x =  x1  x2          xj  denote the sequence of implemented
candidates  where j ∈  0          |c| − 1    whenever the order
of elements in x does not matter  we slightly abuse notation
and treat x as the set x =  x1  x2          xj  
definition 1  an  approval-based  dynamic ranking rule r
maps a profile a and a sequence x =  x1  x2          xj  of
candidates to a ranking r a  x  ∈ l c \ x  
applying a dynamic ranking rule to a sequential selection
process  as outlined in the introduction  is now straightfor-
ward  at the beginning  when no candidate has yet been im-
plemented  x =    and the ranking r a      ranks all can-
didates in c  given this ranking  a decision maker  dm 
selects an alternative x1 ∈ c to be implemented 
the
updated ranking of the remaining candidates is then given
by r a   x1    and the process is repeated 
at iteration
t ∈ n  when t − 1 candidates have been implemented and
1all rules may encounter ties  we assume that a priority ordering
over candidates is used as a tiebreaker  in the motivating example 
the submission time of a question yields a natural priority ordering 
2another  equivalent  formulation of this method is in terms of a
load balancing procedure  janson  2016  brill et al   2017  
proceedings of the thirtieth    ijcai-21 
262
 thus x =  x1  x2          xt−1   we let rt denote the ranking
r a  x  ∈ l c\x  from which the dm can make a choice 
we will sometimes make the assumption that the dm only
ever implements alternatives that appear near the top of the
ranking  in this depth-restricted setting  we are given a natu-
ral number h and we assume that xt ∈ rt
≤h for all time steps t 
this setting models situations in which the dm does not have
the resources  or the ability  to consider the whole ranking 
the straightforward ranking rule av trivially translates to
the dynamic setting  when a candidate is implemented  it
is simply removed from the ranking  the order between the
remaining candidates does not change  av is used in all of the
live q a platforms mentioned in section 1  in the following 
we propose dynamic variants of other ranking rules 
dynamic seqpav 
for this straightforward dynamization of
seqpav  we modify the notion of marginal contribution to
also take into account the satisfaction derived from previously
implemented candidates 
mcdyn c  = sc x ∪ r≤k ∪  c   − sc x ∪ r≤k  
dynamic seqpav ranks candidates iteratively  adding in each
round a candidate c maximizing mcdyn c  
dynamic phragm en 
our first dynamization of sequential
phragm en works in two phases  as before  voters buy can-
didates and every candidate has a cost of 1 credit  voters do
not start with 0 credits  however  they may have an initial
debt due to previously implemented candidates they approve 
the debts of voters are determined in the first phase  which
iterates through the sequence x  starting with x1  and  for
each implemented candidate xj ∈ x  divides the cost of 1
among the voters in nxj  more precisely  this assignment of
debts is done in such a way that  in each iteration j  the max-
imum total debt across all voters in nxj is as small as possi-
ble   the assignment of debts  therefore  mimics the assign-
ment of loads in the load-balancing formulation of sequential
phragm en   we let di ≥ 0 denote the total debt of voter i ∈ n
resulting from this first phase  in the second phase  we run se-
quential phragm en to obtain the desired ranking of candidates
in c \ x  at the beginning of this phase  each voter i has a
credit balance of −di ≤ 0  as in sequential phragm en  voters
continuously earn credits  and voters starting with debts can
only participate in the purchase of a candidate once they have
a positive balance  voters are not allowed to go into debt for
buying candidates 
these dynamic rules rank candidates in the same fash-
ion as their non-dynamic counterparts  while taking the se-
quence x of previously implemented candidates into ac-
count   note that the implementation order matters for dy-
namic phragm en  but not for dynamic seqpav   in particular 
both dynamic rules coincide with their non-dynamic counter-
part when x =     moreover  the ranking among the remain-
ing candidates does not change whenever the top-ranked can-
didate is implemented  if rt =  r1  r2  r3         and xt = r1 
then rt 1 =  r2  r3         
we also consider two  myopic  dynamic ranking rules 
myopic seqpav 
in this myopic dynamization of seqpav 
we compute the marginal contribution of each candidate c ∈
c \ x only with respect to the set x of previously imple-
mented candidates  i e   mcmyopic c  = sc x ∪  c   − sc x  
then  we simply rank those candidates according to decreas-
ing mcmyopic c -value 
myopic phragm en 
in this myopic dynamization of se-
quential phragm en  we first run the first phase of dynamic
phragm en in order to determine the debts  di i∈n of voters 
then  for each candidate c ∈ c \ x  we compute the voter
debts that would result from adding candidate c to x  and
running the first phase for one more iteration   let the debts
induced by candidate c be  dc
i i∈n  myopic phragm en ranks
the candidates in c \ x according to increasing maxi∈nc dc
i 
breaking ties according to the second highest debt  and so on 
intuitively  myopic seqpav and myopic phragm en rank
candidates according to their suitability of being the next im-
plemented candidate  in contrast to dynamic seqpav and dy-
namic phragm en  this way of comparing candidates does not
lead to rankings that are representative by themselves  in par-
ticular  both myopic rules coincide with av when x =    
we illustrate these rules with a simple example 
example 2  let c =  a  b  c  d  e  and assume alphabetic
tiebreaking  consider a set of 9 voters with the following
approval sets 
5 ×  a  b  
3 ×  c  d  
1 ×  e  
let v denote the group consisting of the 5  a  b -voters
and v ′ the group consisting of the 3  c  d -voters  first  con-
sider dynamic seqpav and dynamic phragm en  in the first
iteration  both rules output r1 =  a  c  b  d  e   effectively al-
ternating between candidates supported by voter groups v
and v ′ 
let us assume that the dm implements candi-
date x1 = b  i e   x =  b   then  the two rules output
r2 =  c  a  d  e  
next  consider myopic seqpav and myopic phragm en  in
the first iteration  both rules  and av  rank the candidates
according to their approval scores  r1 =  a  b  c  d  e   after
the implementation of b  both rules output r2 =  c  d  a  e  
which differs from the av ranking r2 =  a  c  d  e  
in this example  all of our ranking rules demote candidate a
in r2 because voter group v is already  partially  satisfied
with x =  b   the myopic rules even rank both c and d
higher than a in r2  since implementing either c or d would
yield a more proportional sequence x than choosing a would 
all presented ranking rules can be computed in polynomial
time  see the full version of this paper for an asymptotic run-
time analysis and pseudocode 
4
monotonicity of voter satisfaction
we start our analysis of dynamic ranking rules by consider-
ing the satisfaction of voters during the sequential selection
process  in doing so  we assume that voters derive satisfac-
tion not only from implemented candidates they approve  but
also—possibly to a lesser extent—from approved candidates
appearing near the top of the ranking  high positions in the
ranking come with increased attention  and  presumably  high
selection probabilities in future iterations  for the respective
proceedings of the thirtieth    ijcai-21 
263
 candidates  in particular  improved ranking positions of sup-
ported candidates can be viewed as a kind of compensation
for  groups of  voters who are not  yet  well-represented by
the implemented alternatives  to make this concrete  con-
sider an iteration t  where the dm is confronted with rank-
ing rt and chooses to implement candidate xt  following
the logic outlined above  it might be natural to expect that
voters not approving xt  or  more precisely  the candidates
approved by these voters  should get a  boost  in the rank-
ing  at the very least  it seems reasonable to expect that the
satisfaction of such voters with the new ranking rt 1 is at
least as high as with the old ranking rt  av trivially satis-
fies this property  which we informally refer to as satisfaction
monotonicity  somewhat surprisingly  however  the following
simple example demonstrates that this intuitive monotonicity
notion is not achievable for dynamic ranking rules that satisfy
a minimal degree of representativeness 3
example 3  consider the following profile with 7 voters 
1 ×  a  
3 ×  b  
3 ×  a  c  
all rules considered in this paper rank the approval winner a
first in r1  if the dm chooses to implement candidate x1 = c 
all of our rules—except av—output r2 =  b  a  in the second
iteration  intuitively  the rules give more voting power to the
3 supporters of b  all of which are unrepresented by c  than to
the 4 supporters of a  3 of which are already partially repre-
sented   observe that the satisfaction of the voter approving
a decreases when going from r1 to r2  despite the fact that
this voter does not approve the candidate being implemented 
the following definition is motivated by the question
whether monotonicity failures can be prevented by moving to
the depth-restricted setting and putting lower bounds on the
size of voter groups for which monotonicity should hold  to
measure satisfaction of a group v ⊆ n of voters with a set
s ⊆ c of candidates  we use the average satisfaction of v
with s  i e   avgv  s  =
1
|v | · �
i∈v |ai ∩ s| 
definition 4  for h ≥ 1 and α ∈  0  1   a dynamic ranking
rule satisfies  h  α -monotonicity if  for all profiles and all
groups of voters v ⊆ n of size |v | ≥ α · |n|  the following
holds for every iteration t 
if xt /∈
�
i∈v
ai  then avgv  rt 1
≤h   ≥ avgv  rt
≤h  
that is   h  α -monotonicity requires that satisfaction
monotonicity holds for groups that make up at least an α-
fraction of the electorate  and when measuring average satis-
faction with respect to the first h positions in a ranking 
av trivially satisfies  h  α -monotonicity for all h and
all α  on the other hand  all other considered rules violate
this notion unless we consider rather large groups of voters 
proposition 5  consider the depth-restricted setting for some
h ≥ 3  then  dynamic seqpav and dynamic phragm en fail to
satisfy  h  α -monotonicity for all α <
6
2h 5 
3example 3 can be turned into an impossibility result  every
dynamic ranking rule that  i  ranks the approval winner at the top in
the first iteration and  ii  gives priority to less satisfied voter groups
fails satisfaction monotonicity 
furthermore  myopic seqpav and myopic phragm en fail to
satisfy  h  α -monotonicity for all α < 1
h 
the monotonicity requirement can be weakened further by
only requiring satisfaction monotonicity in cases in which the
implemented candidate is never co-approved with any candi-
date that is approved by a member of the group under con-
sideration  i e   there is no c ∈ �
k∈v ak with  c  xt  ⊆ ai
for some i ∈ n   both myopic rules satisfy this weak imple-
mentation monotonicity  whereas the two dynamic versions
fail it  for a thorough discussion of this weaker version of
monotonicity  we refer to the full version of this paper 
despite the negative results in this section  we rarely found
monotonicity violations of any kind in our experiments  see
section 6  
5
proportional representation
we now turn to analyzing the proportional representativeness
that is provided by our dynamic ranking rules  the following
two sections capture different perspectives on representation 
focusing on the representativeness of the ranking rt at any
given iteration t  section 5 1  and on the representativeness
of the set x of implemented candidates  section 5 2  
5 1
proportionality of rankings
in certain applications of dynamic ranking rules  such as the
live q a platforms mentioned in the introduction  it is desir-
able for the ranking rt to provide a representative overview
of the opinions of the voters at any given iteration t  in this
section  we prove proportionality guarantees that are satisfied
by ranking rt for any fixed iteration t 
measures for the proportionality of a ranking have been
proposed by skowron et al   2017   in particular  κ-group
representation measures  informally speaking  how far down
in the ranking a group of voters needs to look in order to
obtain a given amount of satisfaction  in order to adapt the
notion of κ-group representation to the dynamic ranking set-
ting  we need the following notation 
for iteration t  let
xt =  x1          xt−1  denote the set of candidates imple-
mented in the first t − 1 rounds and  for a group v ⊆ n of
voters  let λt v   = | �
i∈v ai \ xt| denote the cohesiveness
of v with respect to the remaining candidates c \ xt 
definition 6  group representation   let κ α  λ  be a func-
tion from   0  1  ∩ q  × n  to n  a dynamic ranking rule sat-
isfies κ-group representation if the following holds for all pro-
files a  groups of voters v ⊆ n  rational numbers α ∈  0  1  
and integers λ  t ≤ |c| 
if |v | ≥ α · n and λt v   ≥ λ  then avgv  rt
≤κ α λ   ≥ λ 
in words  if a group v of voters makes up an α-fraction
of the electorate and has at least λ commonly approved can-
didates remaining at iteration t  then this group derives an
average satisfaction of at least λ from the candidates ranked
in the top κ α  λ  positions of ranking rt 4
4a natural lower bound for κ α  λ  is given by ⌈λ/α⌉  note that
the κ functions used in this section not only depend on α and λ  but
also on the set v and on the sequence x of previously implemented
candidates  in an attempt to simplify notation  we decided to not
make this dependencies explicit in definition 6 
proceedings of the thirtieth    ijcai-21 
264
 our first result in this section is for dynamic phragm en 
we recall that di denotes the initial debt of voter i at the end
of the first phase of the method  and let dv
avg =
1
|v |
�
i∈v di
denote the average debt of voters in v  
theorem 7  dynamic phragm en satisfies κ-group represen-
tation for
κ α  λ  =
�2 λ   m   1    s · |v |
α
�
 
where m = | �
i∈v ai ∩ x| and s = �
i∈v  di − dv
avg 2 
observe that this function is increasing both in the num-
ber m of already implemented candidates that are approved
by some voter in v and in the variance s of debts of voters
in v   for the special case x =     theorem 7 implies a
group representation of
� 2λ 2
α
�
for  non-dynamic  sequential
phragm en  for λ ≥ 2  this is an improvement over the κ-
group representation bound of
� 5λ
α2   1
α
�
proved by skowron
et al   2017  
the proof of theorem 7 employs the notion of proportion-
ality degree  skowron  2018   in particular  we first prove a
bound on the proportionality degree of dynamic phragm en 
using a potential function approach that is similar to the one
used by skowron  2018  for the non-dynamic setting  then 
we establish a relationship between the proportionality degree
and group representation  and use it to translate the bound on
the former into a bound on the latter 
for dynamic seqpav we prove the following generalisation
of theorem 3 by skowron et al   2017   the latter theorem
corresponds to the special case x =    
theorem 8  dynamic seqpav satisfies κ-group representa-
tion for
κ α  λ  =
�2 λ   1   avgv  x  2
α2
�
 
av does not perform any different in the dynamic rank-
ing setting compared to the non-dynamic one  thus  it satis-
fies the same bounds on group representation as those stated
in theorem 2 by skowron et al   2017   since myopic seq-
pav and myopic phragm en both agree with av in the case
x =     the same bounds hold for these two rules 
proposition 9  myopic seqpav and myopic phragm en fail κ-
group representation for κ α  λ  ≤
�
λ·α
2α−1
�
− 1 and for all
functions κ α  λ  if α ≤ m 1
m 2  where m = | �
i∈v ai ∩ x| 
5 2
proportionality of implemented candidates
in this section  we study worst-case bounds on the represen-
tativeness of the set x of implemented candidates  clearly 
no non-trivial bounds are obtainable without restricting the
selection behavior of an adversarial dm  therefore  we will
make the following two assumptions throughout this section 
 a1  the dm is depth-restricted and always implements a
candidate from the top h positions of the ranking 
 a2  every candidate c ∈ c has sufficiently5 many  clones  
i e   candidates c′ with identical supporter set nc′ = nc 
5given an upper bound t on the number of iterations  h   t − 1
clones suffice  as at least h clones will always remain in the ranking  
assumptions  a1  and  a2  together ensure that the dm can
be forced to implement a candidate approved by a voter  by
populating the top h positions exclusively with such candi-
dates  arguably the most natural way to ensure  a2  is to
assume that we are in the party-approval setting  brill et al  
2020   where candidates are interpreted as parties and can be
selected arbitrarily often  in the motivating example of live
q a platforms  party-approval preferences could result from
assigning attributes to questions and eliciting participants  ap-
proval preferences over attributes 
recall that xt 1 denotes the set containing the imple-
mented candidates from the first t rounds 
the following
property is a natural adaption of the well-studied propor-
tionality axiom proportional justified representation  pjr 
 s anchez-fern andez et al   2017  
definition 10  a dynamic ranking rule satisfies proportional
justified selection  pjs  if the following holds for all t  ℓ ∈ n
and for all groups v ⊆ n of voters  if |v | ≥ ℓ
t · |n| and
| �
i∈v ai| ≥ ℓ  then |xt 1 ∩ �
i∈v ai| ≥ ℓ 
a weaker version of this axiom is obtained by fixing ℓ = 1 
in analogy to a well-known notion due to aziz et al   2017  
we refer to the resulting property as justified selection  js  
we prove the following theorem by treating the set xt 1
of implemented alternatives as a committee and using the fact
that sequential phragm en satisfies pjr  brill et al   2017  
theorem 11  under assumptions  a1  and  a2   myopic
phragm en satisfies pjs 
analogously  we can translate a representation guarantee
for sequential pav  s anchez-fern andez et al   2017  into a
guarantee for myopic seqpav 
proposition 12  under assumptions  a1  and  a2   myopic
seqpav satisfies js for t ≤ 5 
similar positive results are not possible for the other rules we
consider 
proposition 13  dynamic seqpav and dynamic phragm en
fail to satisfy js  even under assumptions  a1  and  a2  and
for t = 2 
6
experimental evaluation
in order to better understand the behavior of the dynamic
ranking rules considered in this paper  we conducted compu-
tational experiments using randomly generated approval pro-
files  since we were mainly interested in the proportional rep-
resentation of groups of voters with similar preferences  we
generated profiles according to two probabilistic models that
lead to polarized electorates with easily identifiable groups 
we measured  1  how the satisfaction of a voter group with
the set of implemented candidates varies with the size of the
group  and  2  how the satisfaction of a voter group with the
current ranking varies over time 
setup 
all of our profiles consist of 60 voters and 20 can-
didates  and the approval sets are generated according to two
different models  in the blurred parties model  we assign each
voter and each candidate to one of two parties  the size of the
voter group v associated with the first party varies over the
experiments  the candidates are always divided equally  each
proceedings of the thirtieth    ijcai-21 
265
 voter approves a candidate from their own party with 95 
probability and a candidate of the other party with 5  prob-
ability  the spatial model is an adaption of the 4-gaussian
model used by elkind et al   2017  for linear preferences 
voters and candidates correspond to points in the euclidean
plane and voters approve nearby candidates  there are three
parties with equidistant center locations  and candidates as
well as voters get sampled as points around the party centers
according to a normal distribution  we let the size of the voter
group v associated with the first party grow  and divide the
remaining voters equally among the two remaining parties 
there are 7 candidates associated with the first party  the
selection behavior of the dm is modeled via google click-
through rates  in particular  the probability of selection de-
creases when going down the ranking  in figure 1 we plot
the averages of 100 generated elections  more details about
the setup can be found in the full version of this paper 
satisfaction with implemented candidates 
we measure
the average satisfaction of voter group v ⊆ n with xk 1 
where k is the number of candidates associated with that
group  i e   k = 10 for the blurred parties model and k = 7
for the spatial model   we plot this value against the relative
size α = |v |/|n| of the group v   the graphs in the first
row of figure 1 show that for both models  av is not propor-
tional  avgv  xk 1  starts out very low and only jumps up
as soon as v becomes the biggest group  which happens at
α = 1/2 and α = 1/3  respectively   in other words  av un-
derrepresents minorities and overrepresents majorities  the
performance of the other four rules are indistinguishable  as
all yield proportionally increasing satisfaction values 
satisfaction with rankings 
the graphs in the second row
of figure 1 depict the average satisfaction of a group v of
size α = 1/4 with the first 5 candidates of the ranking over
the first 11 iterations  again  av behaves poorly  as it gives
satisfaction to v only once the larger groups have been sat-
isfied  the satisfaction values under the two myopic rules
jump heavily from one iteration to the next  as these rules
tend to mainly represent one group of voters per iteration  on
the other hand  the two dynamic rules keep the satisfaction
of v relatively constant at around one fourth of the maxi-
mum possible satisfaction  these rules provide proportional
representation in each single iteration  which is in line with
the theoretical results in section 5 1 
7
conclusion
motivated by the problem of how submitted questions in a
live q a session can be ranked in a more representative
way  we have introduced dynamic ranking rules  we pro-
posed two paradigms of dynamizing existing ranking rules 
under the dynamic paradigm  we target proportional repre-
sentation of voter interests at each individual time step  un-
der the myopic paradigm  we try to make the set of imple-
mented candidates as representative as possible  while the
former approach lends more flexibility for the decision maker
and guarantees a proportional exposure of candidates in each
ranking  the latter approach is computationally more efficient
and yields stronger selection guarantees  our experimental
0 0
0 2
0 4
0 6
0 8
1 0
α
2
3
4
5
6
7
8
avgv x11 
0 0
0 2
0 4
0 6
0 8
1 0
α
0 5
1 0
1 5
2 0
2 5
3 0
3 5
avgv x8 
1
2
3
4
5
6
7
8
9 10 11
t
0 5
1 0
1 5
2 0
2 5
3 0
avgv rt
≤ 5 
1
2
3
4
5
6
7
8
9 10 11
t
0 4
0 6
0 8
1 0
1 2
1 4
1 6
1 8
avgv rt
≤ 5 
figure 1  experimental results for the blurred parties model  left 
and the spatial model  right   the graphs in the first row show the
average satisfaction of v with the first k implemented candidates 
for relative group size α ∈  0  1   the graphs in the second row
show the average satisfaction of v with rt
≤5  for 1 ≤ t ≤ 11 
results illustrate the difference between the two approaches 
and verify that both approaches lead to proportional results 
the application of live q a platforms gives rise to some
interesting extensions of our model  in realistic scenarios 
neither the electorate nor the set of candidates is static  as
people enter or leave the audience and new questions come
up continuously  moreover  participants can change their ap-
proval preferences throughout the event  our approach can
take these dynamic aspects into account in a straightforward
manner  after each implementation  we can apply our rank-
ing rules to the current set of not-yet-implemented candidates
and to the current approval preferences—the only necessary
information from previous iterations is the sequence of im-
plemented candidates 
the dynamic ranking rules proposed in this paper are appli-
cable to a wide variety of sequential selection procedures in
which proportional representation is desired and  at the same
time  some flexibility on the part of the decision maker is nec-
essary  e g   think of human-in-the-loop decision support sys-
tems for hiring or budgeting decisions   other applications of
dynamic ranking rules include committee election scenarios
in which some part of the committee is fixed  e g   due to ex-
ternal constraints  and the remaining seats need to be filled in
such a way that the committee as a whole is representative 
acknowledgments
we would like to thank the anonymous reviewers for their in-
sightful comments  this work was partially supported by the
deutsche forschungsgemeinschaft under grant br 4744/2-1 
we thank paula blechschmidt  cristina cornelio  benny
kimelfeld  phokion kolaitis  kunal relia  and julia stoy-
anovich for helpful comments and discussions 
proceedings of the thirtieth    ijcai-21 
266
 references
 aziz et al   2017  haris
aziz 
markus
brill 
vincent
conitzer  edith elkind  rupert freeman  and toby walsh 
justified representation in approval-based committee
voting  social choice and welfare  48 2  461–485  2017 
 boutilier and procaccia  2012  craig boutilier and ariel
procaccia 
a dynamic rationalization of distance ratio-
nalizability  in proceedings of the 26th aaai conference
on artificial intelligence  aaai   pages 1278–1284  aaai
press  2012 
 brill et al   2017  markus brill  rupert freeman  svante
janson  and martin lackner  phragm en s voting methods
and justified representation 
in proceedings of the 31st
aaai conference on artificial intelligence  aaai   pages
406–413  aaai press  2017 
 brill et al   2020  markus brill  paul g¨olz  dominik peters 
ulrike schmidt-kraepelin  and kai wilker 
approval-
based apportionment 
in proceedings of the 34th aaai
conference on artificial intelligence  aaai   pages 1854–
1861  aaai press  2020 
 casella  2005  alessandra casella  storable votes  games
and economic behavior  51 2  391–419  2005 
 casella  2012  alessandra casella  storable votes  protect-
ing the minority voice  oxford university press  2012 
 elkind et al   2017  edith elkind  piotr faliszewski  jean-
franc¸ois laslier  piotr skowron  arkadii slinko  and nim-
rod talmon  what do multiwinner voting rules do  an
experiment over the two-dimensional euclidean domain 
in proceedings of the 31st aaai conference on artificial
intelligence  aaai   pages 494–501  aaai press  2017 
 faliszewski et al   2017  piotr faliszewski  piotr skowron 
arkadii slinko  and nimrod talmon  multiwinner voting 
a new challenge for social choice theory  in u  endriss 
editor  trends in computational social choice  chapter 2 
2017 
 freeman et al   2017  rupert freeman  seyed majid za-
hedi  and vincent conitzer  fair social choice in dynamic
settings  in proceedings of the 26th international joint
conference on artificial intelligence  ijcai   pages 4580–
4587  ijcai  2017 
 hemaspaandra et al   2017  edith
hemaspaandra 
lane
a  hemaspaandra  and j¨org rothe 
the complexity of
controlling candidate-sequential elections 
theoretical
computer science  678 14–21  2017 
 israel and brill  2021  jonas
israel
and
markus
brill 
dynamic proportional rankings 
technical report 
arxiv 2105 08043  cs gt   2021 
 janson  2016  svante janson 
phragm en s and thiele s
election methods 
technical report  arxiv 1611 08826
 math ho   2016 
 janson  2018  svante janson  thresholds quantifying pro-
portionality criteria for election methods  technical report 
arxiv 1810 06377  cs gt   2018 
 lackner and skowron  2020  martin
lackner
and
piotr
skowron 
approval-based committee voting 
ax-
ioms  algorithms  and applications 
technical report 
arxiv 2007 01795  cs gt   2020 
 lackner  2020  martin lackner  perpetual voting  fairness
in long-term decision making  in proceedings of the 34th
aaai conference on artificial intelligence  aaai   pages
2103–2110  aaai press  2020 
 monroe  1995  burt l  monroe 
fully proportional rep-
resentation 
the american political science review 
89 4  925–940  1995 
 oren and lucier  2014  joel oren and brendan lucier  on-
line  budgeted  social choice  in proceedings of the 28th
aaai conference on artificial intelligence  aaai   pages
1456–1462  aaai press  2014 
 parkes and procaccia  2013  david parkes and ariel pro-
caccia  dynamic social choice with evolving preferences 
in proceedings of the 27th aaai conference on artificial
intelligence  aaai   pages 767–773  aaai press  2013 
 peters and skowron  2020  dominik
peters
and
piotr
skowron  proportionality and the limits of welfarism  in
proceedings of the 21st acm conference on economics
and computation  acm-ec   pages 793–794  acm
press  2020 
 phragm en  1894  l  edvard phragm en 
sur une m ethode
nouvelle pour r ealiser  dans les  elections  la repr esentation
proportionnelle des partis 
¨ofversigt af kongliga
vetenskaps-akademiens f¨orhandlingar  51 3  133–137 
1894 
 s anchez-fern andez et al   2017  luis s anchez-fern andez 
edith elkind  martin lackner  norberto fern andez garc ıa 
jes us a  fisteus  pablo basanta val  and piotr skowron 
proportional justified representation  in proceedings of the
31st aaai conference on artificial intelligence  aaai  
pages 670–676  aaai press  2017 
 schulze  2011  markus schulze  free riding and vote man-
agement under proportional representation by the single
transferable vote  http //m-schulze 9mail de/schulze2 pdf 
2011  accessed  2021-01-21 
 skowron et al   2017  piotr
skowron 
martin
lackner 
markus brill  dominik peters  and edith elkind  propor-
tional rankings  in proceedings of the 26th international
joint conference on artificial intelligence  ijcai   pages
409–415  ijcai  2017 
 skowron  2018  piotr skowron  proportionality degree of
multiwinner rules 
technical report  arxiv 1810 08799
 cs gt   2018 
 tennenholtz  2004  moshe tennenholtz  transitive voting 
in proceedings of the 5th acm conference on electronic
commerce  acm-ec   pages 230–231  acm press  2004 
 thiele  1895  thorvald n  thiele  om flerfoldsvalg  over-
sigt over det kongelige danske videnskabernes selskabs
forhandlinger  pages 415–441  1895 
proceedings of the thirtieth    ijcai-21 
267
 "
None,2021,https-www-ijcai-org-proceedings-2021-0038-pdf,"A Polynomial-time, Truthful, Individually Rational and Budget Balanced Ridesharing Mechanism","Tatsuya Iwase, Sebastian Stein, Enrico H. Gerding",None,https://www.ijcai.org/proceedings/2021/0038.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0038-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0038-pdf.pdf,"a polynomial-time  truthful  individually rational and budget balanced
ridesharing mechanism
tatsuya iwase1   sebastian stein2   enrico h  gerding2
1toyota motor europe nv/sa  zaventem  belgium
2university of southampton  southampton  united kingdom
tiwase@mosk tytlabs co jp   ss2  eg @ecs soton ac uk
abstract
ridesharing has great potential to improve trans-
portation efficiency while reducing congestion and
pollution  to realize this potential  mechanisms are
needed that allocate vehicles optimally and provide
the right incentives to riders  however  many ex-
isting approaches consider restricted settings  e g  
only one rider per vehicle or a common origin
for all riders  
moreover  naive applications of
standard approaches  such as the vickrey-clarke-
groves or greedy mechanisms  cannot achieve a
polynomial-time  truthful  individually rational and
budget balanced mechanism  to address this  we
formulate a general ridesharing problem and apply
mechanism design to develop a novel mechanism
which satisfies all four properties and whose social
cost is within 8 6  of the optimal on average 
1
introduction
ridesharing can meet more traffic demand with fewer vehi-
cles than existing taxi services or privately-owned vehicles 
at the same time  it can reduce traffic congestion  energy con-
sumption and pollution  moreover  with the introduction of
autonomous vehicles  unused vehicles become active trans-
portation resources  and ridesharing can further increase uti-
lization of such vehicles  spieser et al   2014  
broadly 
there are two research streams addressing
ridesharing problems  the first one focuses on algorithms
for assigning vehicles to riders while solving the routing
problem in an optimal way  cordeau and laporte  2007 
hasan et al   2018  chen et al   2019   however  none of
these studies consider incentives and whether it is in the best
interest of riders to follow the proposed solution and to report
their preferences truthfully  especially when the origins and
destinations of the riders are different  they are sometimes re-
quired to detour to share the vehicle with others  hence  there
may be an incentive to misreport time constraints and prefer-
ences to prevent detours 
to address this  the second research stream focuses on
mechanism design approaches  which incentivize truthful re-
porting and avoid strategic manipulation  in addition to this
an extended version including technical appendices is available
at https //arxiv org/abs/2105 11292 
property  which is called incentive compatibility  ic   other
desirable properties include  weak  budget balance  bb  i e  
the system does not require an outside subsidy   individual
rationality  ir  i e   an individual is never worse off partici-
pating in the mechanism  and scalability  i e   the allocation
and any payments can be computed in polynomial time   an
early approach uses a second price auction  kleiner et al  
2011   but their work is limited to single riders per vehi-
cle and does not allow cooperation between drivers   shen
et al   2016  propose an online posted-price mechanism but
they only consider autonomous vehicles  vehicles can move
without any riders allocated  and their approach is not scal-
able  furthermore   cheng et al   2014  propose a mechanism
that satisfies ic  bb and ir  but they assume all riders depart
from the same origin and so their method does not coordi-
nate the pickup of riders at different locations   zhao et al  
2014  propose a vickrey–clarke–groves  vcg  mechanism 
but their approach is not scalable and bb is only satisfied
when there is no detour  more recent work on mechanism
design  e g    rheingans-yoo et al   2019  lu et al   2018 
ma et al   2019   only focuses on drivers and does not con-
sider rider incentives  also  none of the above consider set-
tings where riders can switch vehicles which can enable more
efficient solutions  especially in settings with limited vehicles
as in suburban areas 
in short  to date there exist no scalable mechanisms for
general ridesharing settings that satisfy ic  ir and bb  to
address this shortcoming  we make the following novel con-
tributions 
• we formulate a more general ridesharing problem com-
pared to existing approaches  in particular  this is the
first model that considers both autonomous and non-
autonomous vehicles and where riders can switch be-
tween vehicles if it is beneficial to do so 
• we prove that  unsurprisingly  computing the optimal al-
location is np-hard  nevertheless  by introducing some
weak assumptions  we show that it can be to reduced to
a polynomial-time linear program 
• we show that approaches based on vcg mechanisms or
naive greedy  where riders are allocated in order of their
marginal cost  do not satisfy the necessary properties 
specifically  the standard vcg approach does not sat-
isfy bb and a modified  budged balanced  version can-
proceedings of the thirtieth    ijcai-21 
268
 not be computed efficiently using our novel polynomial-
time reduction  also  naive greedy violates a property
called monotonicity  meaning it fails to satisfy ic 
• to address this  we propose a general methodology to
design monotone greedy allocation mechanisms 
we
then apply this theory to produce a novel two-stage
mechanism with carefully designed payments to ensure
both ir and bb  as well as ic and scalability 
• we empirically evaluate the performance of different
mechanisms and show the advantages of our methods 
our monotone greedy mechanism satisfies all desirable
properties with typically less than a 9  social cost in-
crease compared to the optimal allocation 
in what follows  section 2 introduces the ridesharing model
and its mechanism design formulation  section 3 considers
the vcg mechanism and its budget balanced version  sec-
tion 4 studies the greedy mechanisms  section 5 provides an
empirical evaluation of the mechanisms and section 6 con-
cludes  due to space limitations  most proofs for the theoret-
ical results are provided in the extended version of the paper 
2
the model
in this section  we first provide a formal model of the
ridesharing problem followed by an example  we then for-
mulate this as a mechanism design problem 
2 1
the ridesharing  rs  problem
we assume finite time steps t =  0  1          t   set of rid-
ers n =  1  2          n  and vehicles k =  1  2          k  
let w ∈ n  denote the vehicle capacity  i e   the maximum
number of riders in a vehicle   the road network is repre-
sented by a directed graph g =  v  e   where edges e de-
note road segments  vertices v denote locations  and loops
 v  v  ∈ e are used to model stationary vehicles  the length
of an edge e ∈ e is given by le and denotes the travel dis-
tance  for simplicity we assume l v v′  = 1 if v ̸= v′  and
l v v  = 0  ∀ v  v′  ∈ e 1 let op
i   dp
i ∈ v denote the origin
and the destination of rider i ∈ n  also  let oc
k denote the
initial location of vehicle k ∈ k  which does not have to be
where riders are  in case of autonomous vehicles   we denote
by p the set of all paths in g  a path is a vector of size s 
denoted by ⟨v⟩s ≡ ⟨v1          vs⟩  where an element vs ∈ v
is the s-th location in the path and  vs  vs 1  ∈ e  ∀s < s 
since paths do not include information of time  we define a
route as a tuple of vectors ⟨⟨v⟩s  ⟨t⟩s⟩ where the path de-
parts from location vs at time ts  route ⟨⟨v⟩s  ⟨t⟩s⟩ satisfies
ts 1 = ts   l vs vs 1  if vs ̸= vs 1  if vs = vs 1  it means
the rider or vehicle stays at vs for an amount of time given
by ts 1 − ts  e g   to wait for a vehicle or because they al-
ready arrived at the destination   the set of routes is denoted
by r  the route of rider i and the route of vehicle k are de-
noted by rp
i   rc
k ∈ r  respectively  we let edge r  t  ∈ e be
1the former ensures that a rider is always at a vertex at each
time step  furthermore  since le is used to compute costs  discussed
below   the latter ensures that stationary vehicles do not incur fuel
costs  longer roads can be represented by joining multiple edges 
a function that returns the edge in route r that the rider or ve-
hicle is traversing at t  e g   edge ⟨⟨a  b  c⟩  ⟨0  1  2⟩⟩  1  =
 b  c   similarly  loc r  t  ∈ v returns the location at t  e g  
loc ⟨⟨a  b  c⟩  ⟨0  1  2⟩⟩  1  = b  riders cannot move with-
out vehicles but vehicles can move without riders if they are
autonomous  if they are not autonomous  then they need at
least one rider 
we denote the assignment of vehicles to riders with tensor
b ∈ b =  0  1 t ×n×k  b t  i  k  = 1 is possible only if the
path of rider i is the same as vehicle k at time t  the assign-
ment may change over time  which means a rider can switch
vehicles on the way2  we do not specifically distinguish be-
tween drivers and riders  any rider in a vehicle can be a driver
if the vehicle is not autonomous  furthermore  riders can use
a taxi as the outside option  b t  i  k  = 0  ∀t ∈ t   k ∈ k 
if it is more beneficial than using ridesharing  we assume
that the waiting time for a taxi is zero and the taxi takes the
shortest path between the origin and destination of the rider 
however  a rider cannot combine a taxi with ridesharing 
an overall allocation is denoted by π = ⟨rp  rc  b⟩ ∈
rn × rk × b  where rp = ⟨rp
i ⟩i∈n   rc = ⟨rc
k⟩k∈k are
the routes for riders and vehicles  respectively  we will also
use rp
i  π   rc
k π  to denote a route for rider i and vehicle k
given allocation π  an allocation is feasible if  for each rider
i  the route rp
i consist of a path between op
i and dp
i   and the
vehicle capacity is not exceeded  formally  the set of feasible
allocations is defined by 
π = ⟨rp  rc  b⟩ ∈ rn × rk × b|
∀t ∈ t   i ∈ n  k ∈ k  rp
i   rc
k ∈ r  
loc rp
i   0  = op
i   loc rp
i   t  = dp
i   loc rc
k  0  = oc
k 
b t  i  k  = 1 ⇒ edge rc
k  t  = edge rp
i   t  
∃t′ ∈ t   ∀k′ ∈ k    b t′  i  k′  = 0  ledge rp
i  t′  > 0 
⇒ b t  i  k  = 0 
�
i′∈n
b t  i  k  ≤ w  
 1 
the first line of constraints specifies origins and destinations
of the routes  the second constraint is the definition of b 
the third constraint means that a taxi cannot be combined
with ridesharing  if riders traverse an edge using a taxi  they
always use a taxi   the fourth is the capacity constraint 
if vehicles are not autonomous or have no dedicated
driver  π needs an additional condition that any moving
vehicle needs at least one rider 
ledge rc
k t 
>
0
⇒
�
j∈n b t  j  k >0 
now that we have defined the allocation  we proceed
with defining the costs which the system aims to minimise 
these costs include travel and waiting time  fuel costs and
taxi labour costs 
formally  the travel time of rider i in-
cluding waiting time is denoted by ti π  = min ts|rp
i =
⟨⟨v⟩s  ⟨t⟩s⟩  vs = dp
i    which is the earliest time to reach
the destination  furthermore  let t 0
i denote the travel time
2in practice  this can take time  but we ignore this for simplicity 
the model can easily be extended by introducing waiting times for
vehicles when riders switch at some designated safe areas 
proceedings of the thirtieth    ijcai-21 
269
 for rider i using the shortest path  e g   taxi   the travel time
of vehicle k is denoted by t c
k π  = �
t∈t ledge rc
k π  t   fur-
thermore  let α  β ∈ r denote the  additional  labour cost
per time step for a taxi driver and fuel cost per distance for
a vehicle  respectively  let γi ∈ γ =  0  γmax  represent
the value of time  i e   a subjective cost rider i is willing to
pay to avoid a unit of travel time  then the cost of rider
i is  ci π  = c0
i =  α   β   γi t 0
i when using a taxi 
and ci π  = γiti π  when using ridesharing  in addition 
the fuel cost of the ridesharing system is calculated sepa-
rately and is given by cf  π  = �
k∈k βt c
k π   given this 
the ridesharing  rs  problem is to find a feasible allocation
π ∈ π that minimizes the social cost including fuel cost
cf  n  π  = �
i∈n ci π    cf  π  
to illustrate the model  figure 1 shows an example with
n
= 2  k
= 2 and t
= 5 
the two figures show
two possible allocations  in left figure  for example  rp
1 =
⟨⟨a  a  b⟩  ⟨0  3  4⟩⟩ and rp
2 = ⟨⟨b  b  c⟩  ⟨0  1  2⟩⟩  rider
2 is assigned to vehicle 1 at t = 1  i e   b 1  2  1  = 1
while rider 1 is not assigned to vehicle 2 until t = 3  i e  
b 3  1  2  = 1  if γ1 = 2 and γ2 = 1  then the optimal allo-
cation is the one on the right  with ti = t c
k = 3 and social
cost cf = 15 
2 2
mechanism design formulation
a mechanism takes reports from riders on their privately-
known types as input  and computes the allocation and pay-
ment as output  in our model  we assume op
i and dp
i are easy
to track with gps and so γi is the only private information 
which is referred to as rider i s type  let γ ∈ γn be the type
profile of all riders  −i the set of riders except for i  and γ−i
the types of all riders except i  for simplicity  we assume
that all riders and vehicles are ready to depart at t = 0  but
this can be easily extended  a mechanism is then defined as
a function m   γn → π × rn  that computes a feasible al-
location π ∈ π from a given type profile and payment vector
x π  ∈ rn  where xi π  is the payment of rider i to the sys-
tem  we sometimes use π γ  to emphasize the dependence
on γ  if i chooses a taxi  xi π  = 0  sometimes we use short-
hand notation π γi  = π γi  γ−i   given this  the utility of
rider i is defined as ui π  = −ci π  − xi π  
in practice  the ridesharing mechanism may work as in the
following example  first  rider i reports their type γi using a
slider in a suitable smartphone app  along with op
i and dp
i  
note that γi is not necessarily truthful  once the report profile
γ is obtained  the mechanism computes π γ  and x π   and
reveals them to riders before travel  finally  xi is charged
after the travel  to this end  the mechanism needs to achieve
the following properties 
budget balance  bb   which is formulated as 
�
i∈n
xi π  ≥ cf  π  
 2 
individual rationality  ir   which is formulated as 
ui π  ≥ −c0
i   ∀i ∈ n 
 3 
dominant-strategy incentive compatibility  dsic   or
truthfulness  which is formulated as 
ui π γi  γ−i   ≥ ui π γ′
i  γ−i   
∀γ′
i ∈ γ  ∀i ∈ n  ∀γ−i ∈ γn−1 
 4 
3
the vcg mechanisms
next  we will show that the well-known vcg mechanism
 shoham and leyton-brown  2008  does not achieve bb and
polynomial-time computation at the same time when applied
to the rs problem  this mechanism first computes an opti-
mal allocation π γ  given  reported  type profile γ and then it
computes the payment x π  as the externality that each rider
imposes on other riders  specifically  for our rs problem  the
objective is to minimize cf  n  π   and so the vcg payment
is computed as xi π  = cf  −i  π γ   − cf  −i  π γ−i   
as a result  the optimal allocation π and the payment x guar-
antee dsic and ir  in the extended version  we show that
the rs problem is np hard by reducing the travelling sales-
man problem  however  with a mild assumption  an algo-
rithm based on integer linear program  ilp  can solve it in
polynomial time  the algorithm relaxes the ilp into a linear
program  lp   that outputs an integer solution of the origi-
nal ilp  the detail of the algorithm and proofs are also in the
extended version  however  vcg has the following issue 
proposition 1 vcg does not satisfy bb in the rs problem 
proof  suppose both riders 1 and 2 have the same origin o
and destination d  which are directly connected with an edge 
vcg allocates the vehicle to both riders for sharing  since the
absence of either rider does not change the allocation and cost
of the other rider  the vcg payment is zero for both riders 
this means the fuel cost of the vehicle is not recovered 
despite this negative result  we show it is possible to mod-
ify vcg to satisfy bb by sacrificing polynomial-time com-
putation  as follows 
let ki π  =  k ∈ k|b t  i  k  =
1  ∃t ∈ t   denote the set of vehicles that rider i uses  then 
the total fuel costs of all rides that a rider i is involved in
is ci
f  π  = �
k∈ki βt c
k π   we then define an imaginary
system cost by redundantly counting the fuel costs of vehi-
cles as follows  ci π  = �
i∈n ci
f  π   the total social cost
including this imaginary cost is then given by ci n  π  =
�
i∈n ci π    cf  π    ci π   given this  we have a budget
balanced vcg  bvcg  by replacing the objective function
of vcg with ci 
proposition 2 assuming autonomous vehicles  bvcg sat-
isfies dsic  ir and bb 
briefly  this is because the payment is computed based on
the imaginary cost ci  which is redundant and larger than
cf   autonomous vehicles guarantee the feasibility of vehi-
cle routing even when i is absent in the payment computa-
tion  however  scalability is an issue  since the new objective
function with ci is a non-linear function  we cannot use the
ilp based polynomial-time algorithm 
4
greedy mechanisms
to address the issues with vcg mechanisms  we consider
greedy mechanisms in this section  to this end  we first show
that a naive greedy approach does not satisfy ic and we pro-
pose a general theory to design greedy dsic mechanisms
based on the concept of monotonicity  then  we apply our
theory to design a greedy dsic ridesharing mechanism 
proceedings of the thirtieth    ijcai-21 
270
 figure 1  example showing how monotonicity is achieved with our
mechanism and violated with a naive greedy mechanism  dp
1 =
b  dp
2 = c  oc
1 = c  oc
2 = d  assume le = 1  ∀e ∈ e and
expensive taxi α = 10 and β = 1 
4 1
monotonicty and violation with naive greedy
 myerson  1981  archer and tardos  2001  showed that  for
single-valued domains  monotonicity of the allocation func-
tion π γ  is a necessary and sufficient condition for the exis-
tence of payments x π  satisfying dsic  using notation from
our model  monotonicity is defined as follows 
γi ≤ γ′
i ⇒ vi π γi   ≤ vi π γ′
i    ∀γi  γ′
i ∈ γ 
 5 
where  in general  vi   π → r is the amount allocated  and
referred to as work in  archer and tardos  2001  and  for our
setting  vi = −ti π  corresponds to the negative travel time 
although monotonicity plays a key role in designing dsic
mechanism  finding appropriate monotone allocation func-
tions π is non-trivial  here  we show that a naive approach
fails to implement a dsic mechanism  we define a naive
greedy allocation as follows  first  all riders are assigned to a
taxi by default  then  for each iteration it chooses rider i who
minimizes the marginal social cost  given by ci − c0
i   cf  
without changing the allocation in riders allocated so far  and
computes the best allocation for the current rider 
proposition 3 mechanisms based on the naive greedy al-
location do not satisfy monotonicity or dsic 
proof  figure 1 also shows a counterexample whereby a
naive greedy allocation fails to satisfy monotonicity 
let
γ2 = 4  if γ1 = 3  the naive greedy allocates vehicle 1
to rider 2 in the first iteration because the rider brings the
lowest cost γ2t2 −  α   β   γ2 t 0
2   cf = −5  left fig-
ure   however  if γ1 = 1  the cost of the rider decreases
as γ1t1 −  α   β   γ1 t 0
1   cf = −6 and rider 1 is al-
located first  right figure   then  the lower γ1 results in the
earlier allocation and larger v1 = −t1  which is the viola-
tion of the monotonicity  5   this violation of monotonicity
means mechanisms with the naive greedy allocation also vio-
late dsic  since this is a necessary condition for dsic 
4 2
design of monotone greedy allocation
to address the issue above  we propose a characterisation
that is useful for designing monotone allocation functions for
greedy mechanisms  as we saw  the naive greedy violates
monotonicity by giving priority to the riders with lower γi 
instead  we allocate agents in descending order of their  re-
ported  type γi  in what follows  we use the index to denote
the order in which agents are allocated  i e   j < i implies
γj ≥ γi and that j is allocated before i  let π≤i denote the
allocation up to and including i  with remaining agents allo-
cated arbitrarily or  e g   in the context of ride sharing  allo-
cated to a taxi   also  let π≤i π≤i−1  or simply π≤i denote
the set of possible allocations given π≤i−1  keeping agents
j < i fixed  given this  we define a class of greedy alloca-
tions with decreasing choices  gadc  as follows 
π≤i = argmin
π∈π≤i
j π 
 6 
subject to π≤i ⊆ π≤j if j < i  here  j   π → r is an objec-
tive function  in words  gadc captures allocation functions
which compute the optimal allocation for each i individually
given a set of possible allocations  and this set reduces as i
reports a smaller γi  and so appears later in the sequence  
theorem 1 let π≤i γa   π≤i γb  denote i s allocation
when reporting γa γb respectively  a gadc satisfies mono-
tonicity if and only if  ∀γa  γb  i ∈ n 
j π≤i γa   ≤ j π≤i γb   ⇒ vi π≤i γa   ≥ vi π≤i γb   
 7 
intuitively  this means that  the more an agent contributes
to decreasing the global objective  in our case  minimising
the social cost   the better their allocation should be  in our
case  the lower the travel time  
4 3
monotonic greedy ridesharing mechanism
we now apply theorem 1 to our setting  first  we customize
gadc from section 4 2 for our ridesharing problem  in par-
ticular  π≤i π  is redefined as follows 
π≤i ⟨rp  rc  b⟩  =  ⟨r′p  r′c  b′⟩ ∈ π|
∀t ∈ t   j < i  j′ > i  k ∈ k  
b′ t  j  k  = b t  j  k   r′p
j = rp
j  
 8 
b t  j′  k  = 0  
 9 
this means that  when computing i s allocation  the alloca-
tion of the prior riders j < i are not changed  with this defi-
nition  the assumption π≤i ⊆ π≤j holds  because constraint
 8  shrinks the set  then  a greedy allocation for rideshar-
ing is obtained by applying equation  6   with the objective
function j π  = �
i∈n ci π   in addition  to obtain mono-
tonicity   7  must be satisfied  to this end  we will show that
we require an additional constraint whereby riders cannot be
allocated to a taxi  i e   their outside option   although this
constraint seems restrictive  we will relax this again later so
that riders can use taxis if this is in their best interest  to sat-
isfy ir   in the following  we refer to this setting as greedy al-
location for ridesharing with no-taxi constraint or gars-n 
formally 
π≤i = argmin
π∈πi
�
i′∈n
ci′ π 
s t  ledge rp
i  t  > 0 ⇒ �
k∈k
b t  i  k  = 1  ∀t ∈ t  
 10 
lemma 1 gars-n satisfies monotonicity 
briefly  this is because minimizing j coincides with mini-
mizing ci for each rider i  since the constraints  8  and  9  do
not allow i to change the allocations and costs of other riders 
if riders do not use a taxi  vi = −ti is proportional to ci and
the equivalent condition of monotonicity in theorem 1 is sat-
isfied  with the case in figure 1  gars-n allocates rider 1
proceedings of the thirtieth    ijcai-21 
271
 first  right figure  when γ1 = 5 and γ2 = 4  and then t1 = 3 
meanwhile  if γ1 = 1  rider 2 is allocated first  left figure 
and then t1 = 4  contrary to the naive greedy  the higher γ1
results in the earlier allocation and larger v1  and this satis-
fies monotonicity  note that  without the no-taxi constraint 
monotonicity can be violated as follows  if a taxi is cheap
 α = 1   then rider 1 uses a taxi when γ1 = 1  resulting
in t1 = 1  which violates monotonicity  also  note that the
no-taxi constraint does not help naive greedy because nobody
uses a taxi in the proof of proposition 3 
next  we consider the computation of the payment  let
ˆti π  = ti π  − t 0
i denote the normalized travel time  fol-
lowing  myerson  1981   the unique payment satisfying dsic
is given by 
xi = x0
i  
� γi
0
γ d
dγ
ˆti π γ  dγ
 11 
where x0
i is a value which is independent of i s report  solv-
ing the integral is challenging in general since it is necessary
to recompute the allocations given all possible types of the
rider whose payment we are computing  however  in our
case  because ˆti π  only depends on the order of the allo-
cation  it is sufficient to vary the position in the ordering 
we refer to the gars-n allocation with this payment as the
gars-n mechanism  also  this mechanism can be computed
in polynomial-time using the same technique in section 3 
lemma 2 the gars-n mechanism is dsic and can be
computed in polynomial-time 
to ensure bb  we compute the base payment x0
i based on
report independent parameters t 0  ˆt min and cf ub  where t 0
is a vector of t 0
i   furthermore  ˆt min is a vector of normal-
ized minimal travel times  which is computed by solving the
following allocation problem 
π = argmin
π′∈π
�
i∈n
ˆti π′ 
s t  ledge rp
i  t  > 0 ⇒ �
k∈k
b t  i  k  = 1  ∀t ∈ t   ∀i ∈ n 
finally  cf ub is an upper bound on the fuel cost cf of
gars-n  we assume that this parameter is given  in the
experimental section  we explain how this is computed in
our experimental setting   the base payment is computed by
splitting cf ub among riders  proportional to each agent i s rel-
ative shortest travel time  t 0
i − ˆtmin i − minj t 0
j − ˆtmin j  
since this base payment covers cf ub  gars-n is bb 
lemma 3 if cf ub is given  the gars-n mechanism is bud-
get balanced 
we now discuss ir  since the no-taxi constraint restricts
outside options  it can cause the violation of ir in some set-
tings  to address this issue  we use the following lemma 
lemma 4 the gars-n mechanism satisfies ir if
ˆti π 0   ≤   α   β t 0
i − x0
i  /γmax  ∀i ∈ n 
 12 
briefly   12  shows the lower bound of the cost that satisfies
ir  we can now define the gars-n mechanism with indi-
vidual rationality  gars-nir  as follows  before executing
algorithm 1 gars-nir
1  procedure π =gars-nir γ  n 
2 
nir =   
3 
for i ∈ n
4 
if i satisfies  12  then
5 
nir append i 
6 
else
7 
b t  i  k  = 0  ∀t ∈ t   ∀k ∈ k
8 
return gars-n γ  nir 
algorithm 2 gars-n
1  procedure  π  x  =gars-n γ  n 
2 
ˆ
n =sorted n in descending order of γi
3 
π = greedyalloc γ  ˆ
n 
4 
ti = ˆti π   ∆xi = 0  ∀i ∈ n
5 
for i ∈ n
6 
for orderi ∈   ˆ
n index i           n 
7 
n ′ = ˆ
n  γ′ = γ
8 
j = ˆ
n orderi 
9 
n ′ pop  ˆ
n index i  
10 
n ′ insert orderi  i 
11 
γ′
i = γj
12 
π′ = greedyalloc γ′  n ′ 
13 
∆xi = ∆xi     ˆti π′  − ti γj
14 
ti = ˆti π′ 
15 
xi = ∆xi   x0
i
gars-n  riders that violate condition  12  are excluded from
the mechanism  and are allocated to a taxi  this process is re-
peated until there is no violation  then gars-n is executed
with the remaining riders  since no riders violate  12   this
mechanism satisfies ir 
algorithm 1 shows the pseudocode of gars-nir  using
python-like list operations   it filters out riders who violate
ir condition  12  in line 4 and allocates them to a taxi  line
7   then  gars-n in algorithm 2 computes the allocation
for riders who satisfy  12   first  it sorts riders in descending
order of reported γi  line 2   then it computes an allocation
by greedyalloc  line 3   from line 4 to 15  it computes
the second term of xi in  11   by changing the order of riders 
in line 4  variables are initialized  for each rider i  line 5   it
changes the order of the rider  line 6 to 10  and the report with
a consistent value γ′
i  line 11   and computes an allocation
with the new order n ′  line 12   thus  the integral term in
 11  is computed  line 13   and the payment xi is given by
adding the base payment x0
i  line 15   the greedyalloc
function  algorithm 3  computes the allocation for each rider
one by one by solving  10  in line 3 
now we have the following result 
theorem 2 the gars-nir mechanism satisfies dsic 
ir  bb and can be computed in polynomial-time 
although gars-nir is not optimal  also note that no
mechanism can simultaneously achieve optimality  dsic  ir
and bb  myerson and satterthwaite  1983   hence obtain-
proceedings of the thirtieth    ijcai-21 
272
 algorithm 3 greedy allocation
1  procedure π =greedyalloc γ  n 
2 
for i ∈ n
3 
compute π≤i by  10 
4 
return π≤i
mechanism
opt
dsic
ir
bb
poly
vcg
y
y
y
n
y
bvcg
n
y
y
y
n
hungarian
n
y
y
n
y
gars-nir
n
y
y
y
y
table 1  characteristics of mechanisms 
ing three of these properties is the best one can achieve  it is
also difficult to bound the efficiency of gars-nir  because
we cannot use the standard bounding technique with naive
greedy allocations  nemhauser et al   1978   for the reason
we discussed in proposition 3  determining theoretical effi-
ciency bounds remains an open problem for future work 
5
experimental results
given that we do not have formal efficiency bounds  we
evaluate the mechanisms empirically using simulations us-
ing both synthetic and real data  for the former  we generate
random road networks of 4 degrees maximum and average
results over 32 simulations for each setting  for the latter 
we use the new york taxi data set  nyc-opendata  2018  
we assume autonomous vehicles for all our experiments  we
vary the taxi cost α and choose these loosely based on prices
from london taxis  if we normalize the fuel cost to be β = 1 
then α = 5 is considered a moderate value and α = 1 is
cheap  as for the value of time  we set γi = γmax ∗ i/n
to simulate heterogeneous riders  cf ub is estimated by sam-
pling solutions of gars-n with different allocation orders 
and multiplying the maximum fuel cost among the solutions
with a constant coefficient  further details are provided in the
extended version 
in what follows we first compare the performance of all
mechanisms on a small setting to enable comparison with
non-scalable mechanisms such as bvcg  we then evaluate
the scalability of the greedy mechanism to larger settings 
since gars-nir computes all possible ways for a rider to
switch between vehicles  this turns out to be time consuming
computationally  also  in practice  such switches are often
not desirable  hence  for large settings  we modify the fea-
sible set π of gars-nir to allow a rider to use only a sin-
gle vehicle  sgars-nir   this version still satisfies the same
properties as gars-nir 
5 1
small setting
we compare vcg  bvcg  gars-nir  the hungarian mech-
anism and the outside option  table 1   the hungarian mech-
anism computes an optimal 1-to-1 matching between riders
and vehicles  including taxis  using the hungarian algorithm 
and then applies payments similar to vcg  the mechanism
figure 2  comparison of mechanisms with different taxi costs 
α = 5  top   α = 1  bottom  
is also dsic  bb and ir  but does not support multiple rid-
ers per vehicle  for bvcg  a brute force search is used to
compute vehicle allocations  figure 2  top  shows the results
for n = 3  k = 2  t = 4  v = 4 and α = 5 and the er-
ror bars show the 95  confidence intervals  here  social cost
is the ratio of cf  n  π  over the cost of the optimal alloca-
tion  furthermore  ir cost refers to −ui π /c0
i   if this value
is above 1  it means that ir is violated  bb coverage shows
 �
i∈n xi π  /cf  π   a value less than 1 means bb is vio-
lated  however  a value close to 1 is preferred  as long as it is
over 1  meaning that riders are not over paying   share rate
shows �
k∈k tk/ �
i∈n ti  a smaller value means rideshar-
ing needs fewers vehicles to cover the trips of riders 
here  bvcg is budget balanced without a large increase in
social cost  a 6 4  increase   meanwhile  vcg recovers only
52  of the fuel costs on average in payments  however  a dis-
advantage of bvcg is its computational complexity when us-
ing the brute force search  instead  gars-nir  and sgars-
nir  can be computed efficiently while satisfying dsic  ir
and bb  and still keeping social cost near optimal  an 8 6 
increase compared to optimal   also  it shows that the per-
formance of sgars-nir is close to gars-nir  although
the vehicle-switching behaviors of gars-nir are practical
in suburban areas  it may not be so practical in urban areas 
however  the result shows only 1
6 of riders switch vehicles 
besides  it is possible to extend the model to introduce a wait-
ing time for switching vehicles  and this can reduce the num-
ber of the cases  also  it is easy to extend the model by mix-
ing gars-nir with the version without switching  sgars-
nir   and letting riders choose if they want to switch or not 
in comparison  figure 2  bottom  shows the result when the
proceedings of the thirtieth    ijcai-21 
273
 figure 3  runtime of sgars-nir 
figure 4  figure showing a breakdown of the runtime  as can be
seen  most of the runtime is spent constructing lp object  instead of
solving it 
outside option is cheap  α = 1   in this case  the ir cost
comes closer to 1 for all mechanisms because of the incentive
to opt out  bb coverage also decreases for some mechanisms
because as more riders opt out  there is less opportunity to
split the fuel cost  meanwhile  the increase in social cost is
not large in gars-nir  4 5   because riders properly opt
out if taxi is better  while 1 07 passengers ride on a vehicle
on average in case of α = 1  it is 1 23 passengers in case of
α = 5  this demonstrates that more expensive taxis lead to a
higher usage of ridesharing  enabled by gars-nir satisfy-
ing ir of riders 
5 2
scalability
next  we evaluate the scalability of sgars-nir  since other
mechanisms such as bvcg are not scalable  we do not in-
clude them here  figure 3 shows the runtime of the mech-
anism with different n using parallel computation with 16
cores  since the payment computation consists of indepen-
dent computations of allocations with different orders of rid-
ers  it can be easily parallelized  for other parameters we
use k = n/2  t = 15  v = 10  α = 5  β = 1  sgars-nir
takes less than 14 minutes when n = 40  figure 4 shows that
more than 99  of the computation time is spent constructing
cplex lp objects  hence  much of this can be precomputed
and addressed with specalised implementation 
figure 5  performance as the number of riders  n  increases 
5 3
experiments with real-world data
in addition to using synthetic data  we also conduct exper-
iments using the new york taxi data set  nyc-opendata 
2018   we analyse the traffic demands in the central manhat-
tan area  which consists of 19 zones  a single trip data point
includes the origin zone  the destination zone  departure and
arrival time  we randomly generate trip demands with the
trip distribution from february 2019  all riders are assumed
to be picked up and dropped off at the center of their zones 
we set k = 20  t = 15  v = 19  α = 5  β = 1 and vary n 
figure 5 shows the ratio of social cost compared to the taxi
cost  ir cost  bb coverage and share rate of sgars-nir  the
share rate is improved as n increases since this increases the
chance of sharing vehicles  however  with k fixed  increas-
ing n causes a lack of vehicles and thus an increase in the ir
cost and the social cost  this can be solved by providing an
appropriate number of vehicles  the bb coverage shows over
payment of riders with large n  but they still save compared
to taking a taxi 
6
conclusions
we propose a flexible ridesharing model that includes au-
tonomous vehicles  the goal is to find allocation and payment
mechanisms which are dominant-strategy incentive compati-
ble  budget balanced  individually rational  can be computed
in polynomial time and achieve high social welfare  to this
end  we show that both the vcg and naive greedy mecha-
nisms do not meet these requirements  we then present a
characterisation for monotone greedy allocations and use this
to develop a novel greedy mechanism which satisfies all of the
desirable properties  in addition  through numerical simula-
tions we show that our monotone greedy mechanism achieves
close to optimal allocations 
future directions include envy-free mechanisms and im-
proving the implementation of the algorithm so it scales to
even larger settings  as well as providing theoretical perfor-
mance bounds for our greedy approach 
proceedings of the thirtieth    ijcai-21 
274
 ethical impact
our work has positive ethical impacts on society  first  our
mechanism provides a fair ridesharing service in the sense
that people get compensated for their detour  second  the in-
centive compatibility of our mechanism maximizes the utility
of individuals  third  our ridesharing mechanism can benefit
society and the environment by meeting more traffic demand
with fewer vehicles than existing taxi services or privately-
owned vehicles  a possible negative impact is that people
might perceive the mechanism as unfair because the pay-
ments for a given service may differ depending on the other
participants  we could address this by looking into envy-free
mechanisms in future work 
references
 archer and tardos  2001  aaron archer and éva tardos 
truthful mechanisms for one-parameter agents  in pro-
ceedings 42nd ieee symposium on foundations of com-
puter science  pages 482–491  ieee  2001 
 chen et al   2019  mengjing
chen 
weiran
shen 
pingzhong tang  and song zuo 
dispatching through
pricing  modeling ride-sharing and designing dynamic
prices 
in proceedings of the twenty-eighth interna-
tional joint conference on artificial intelligence  pages
165–171  2019 
 cheng et al   2014  shih-fen cheng  duc thien nguyen 
and hoong chuin lau 
mechanisms for arranging ride
sharing and fare splitting for last-mile travel demands  in
proceedings of the 2014 international conference on au-
tonomous agents and multi-agent systems  pages 1505–
1506  2014 
 cordeau and laporte  2007  jean-françois
cordeau
and
gilbert laporte 
the dial-a-ride problem  models and
algorithms  annals of operations research  153 1  29–46 
2007 
 hasan et al   2018  mohd hafiz hasan  pascal van henten-
ryck  ceren budak  jiayu chen  and chhavi chaudhry 
community-based trip sharing for urban commuting  in
thirty-second aaai conference on artificial intelligence 
pages 6589–6597  2018 
 kleiner et al   2011  alexander kleiner  bernhard nebel 
and vittorio amos ziparo 
a mechanism for dynamic
ride sharing based on parallel auctions  in twenty-second
  
pages 266–272  2011 
 lu et al   2018  alice lu  peter i  frazier  and oren kislev 
surge pricing moves uber s driver-partners  in proceed-
ings of the 2018 acm conference on economics and com-
putation  2018 
 ma et al   2019  hongyao ma  fei fang  and david c
parkes  spatio-temporal pricing for ridesharing platforms 
in proceedings of the 2019 acm conference on eco-
nomics and computation  pages 583–583  2019 
 myerson and satterthwaite  1983  roger b myerson and
mark a satterthwaite 
efficient mechanisms for bilat-
eral trading  journal of economic theory  29 2  265–281 
1983 
 myerson  1981  roger b myerson  optimal auction design 
mathematics of operations research  6 1  58–73  1981 
 nemhauser et al   1978  george l nemhauser  laurence a
wolsey  and marshall l fisher  an analysis of approxima-
tions for maximizing submodular set functions—i  math-
ematical programming  14 1  265–294  1978 
 nyc-opendata  2018  nyc-opendata  2018 yellow taxi
trip data 
https //data cityofnewyork us/transportation/
2018-yellow-taxi-trip-data/t29m-gskq 
2018 
ac-
cessed  2020-04-01 
 rheingans-yoo et al   2019  duncan
rheingans-yoo 
scott duke kominers  hongyao ma  and david c parkes 
ridesharing with driver location preferences  in proceed-
ings of the twenty-eighth international joint conference
on artificial intelligence  pages 557–564  2019 
 shen et al   2016  wen shen  cristina v  lopes  and ja-
cob w  crandall  an online mechanism for ridesharing
in autonomous mobility-on-demand systems  in proceed-
ings of the twenty-fifth international joint conference on
artificial intelligence  pages 475–481  2016 
 shoham and leyton-brown  2008  yoav
shoham
and
kevin leyton-brown  multiagent systems  algorithmic 
game-theoretic  and logical foundations 
cambridge
university press  2008 
 spieser et al   2014  kevin spieser  kyle treleaven  rick
zhang  emilio frazzoli  daniel morton  and marco
pavone  toward a systematic approach to the design and
evaluation of automated mobility-on-demand systems   a
case study in singapore 
in road vehicle automation 
pages 229–245  springer  2014 
 zhao et al   2014  dengji zhao  dongmo zhang  enrico h
gerding  yuko sakurai  and makoto yokoo 
incentives
in ridesharing with deficit control  in proceedings of the
2014 international conference on autonomous agents and
multi-agent systems  pages 1021–1028  2014 
proceedings of the thirtieth    ijcai-21 
275
 "
None,2021,https-www-ijcai-org-proceedings-2021-0039-pdf,Participatory Budgeting with Project Groups,"Pallavi Jain, Krzysztof Sornat, Nimrod Talmon, Meirav Zehavi",None,https://www.ijcai.org/proceedings/2021/0039.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0039-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0039-pdf.pdf,"participatory budgeting with project groups
pallavi jain1   krzysztof sornat2   nimrod talmon3 and meirav zehavi3
1indian institute of technology jodhpur  india
2mit csail  usa
3ben-gurion university  israel
pallavi@iitj ac in  sornat@mit edu   talmonn  meiravze @bgu ac il
abstract
we study a generalization of the standard approval-
based model of participatory budgeting  pb   in
which voters are providing approval ballots over
a set of predefined projects and—in addition to a
global budget limit—there are several groupings of
the projects  each group with its own budget limit 
we study the computational complexity of identify-
ing project bundles that maximize voter satisfaction
while respecting all budget limits  we show that
the problem is generally intractable and describe
efficient exact algorithms for several special cases 
including instances with only few groups and in-
stances where the group structure is close to being
hierarchical  as well as efficient approximation al-
gorithms  our results could allow  e g   municipal-
ities to hold richer pb processes that are themati-
cally and geographically inclusive 
1
introduction
in the standard approval-based model of participatory bud-
geting  pb   cabannes  2004  shah  2007   specifically  the
model of combinatorial pb  aziz and shah  2021   we are
given a set of m projects  each with its cost  n approval
votes  i e   each voter provides a subset of projects she ap-
proves   and a budget limit  the task is to aggregate the votes
to select a bundle  i e   a subset  of projects that respects
the budget limit 
pb has caught quite considerable atten-
tion lately  aziz et al   2018  talmon and faliszewski  2019 
aziz and shah  2021  as it is being used around the world
to decide upon the spending of public  mostly municipal 
money  indeed  while other ballot types are also natural  most
real-world pb processes use approval ballots 
here we consider a setting of participatory budgeting in
which the projects are classified into groups that might be in-
tersecting  and each group comes with its own budget con-
straint  so that the result of the pb—i e   the aggregated
bundle—shall respect not only the global budget limit  but
also the limits of each of the groups  to make things con-
crete and formal  below is the decision version of our problem
 in the optimization version of group-pb  denoted max-
group-pb  the goal is to maximize the utility  
group-pb
input 
a set p of projects with their cost function
c  p → n  a set v of voters with their approval ballots
e =  pv ⊆ p   v ∈ v   a family of groups of projects
f ⊆ 2p with their budget function b  f → n  a global
budget limit b  and a desired utility value u 
question  is there a set of projects x ⊆ p such that
�
v∈v |pv ∩ x| ≥ u  �
p∈x c p  ≤ b  and for every set
f ∈ f  �
p∈f ∩x c p  ≤ b f  
w l o g   we assume b f  ≤ b for every f ∈ f  and that
no two sets in f are identical  i e   for all s1  s2 ∈ f  s1 ̸=
s2  also  w l o g   we assume that every project in p is ap-
proved by at least one voter   note that voter utility equals the
number of approved projects that are funded  this is the most
popular definition of utility in pb however other definitions
exist  some of which we discuss later  
example 1  let p =  p1  p2  p3  p4   let the cost of projects
be as follows  c p1  = 2  c p2  = 1  c p3  = 3  c p4  = 1 
suppose that we have only two voters  say v  v′ and pv =
 p1  p2  p3   pv′ =  p3  p4   let f =  f1 =  p1  p3   f2 =
 p2  p4    let b f1  = 3  b f2  = 2  note that we are
allowed to take only one project from f1  let b = 5 and
u = 3  let x =  p3  p4   note that |pv ∩ x| = 1 and
|pv′ ∩x| = 2  thus  �
v∈v |pv ∩x| = 3 = u  furthermore 
c p3    c p4  = 4 ≤ b  and the costs of projects from sets
f1 and f2 are 3 and 1  respectively  that is  �
p∈f1 c p  =
3 = b f1  and �
p∈f2 c p  = 1 ≤ b f2  
our work is motivated mainly by the following use-cases 
1  geographical budgeting  consider a city  say  paris  
consisting of several districts  to not spend all public
funds on projects from  say  only one district  group-
pb is useful  group projects according to districts and
select appropriate budget limits  making sure that  e g  
none of paris s 20 districts would use more than 10 
of the total budget   indeed  for other cities the num-
ber of districts may be smaller  e g   jerusalem has four
districts   a more fine-grained solution  incorporating
neighborhoods  streets  etc   is also possible  currently 
such geographic inclusiveness is usually achieved ad hoc
by holding separate per-district elections 
2  thematic budgeting  projects usually can be naturally
grouped into types  e g   educational projects  recre-
proceedings of the thirtieth    ijcai-21 
276
 ational projects  and so on  note that  in such cases it
might be that groups do intersect  e g   a recreational
park might be of recreational purposes as well as for
environmental purposes  thus contained in two sets of
projects  group-pb is useful here  group projects ac-
cordingly  making sure that not all the budget is being
spent on  say  projects of only one type 
3  non-budgeting use-cases  group-pb is useful in con-
texts other than pb  e g   to decide which processes to
run on a time-limited computing server  where available
processes can be naturally grouped into types and it is
not desired to use all computing power for  say  pro-
cesses of only one type   in this examples  voters may
be various stakeholders  
remark 2  note that in some settings the groups may or not
intersect  indeed  even if the groups do not intersect  we ar-
gue that it is better to hold the election as one global election 
and consider the groupings of the projects as we do in our
model  this is so  as it provides more flexibility of effectively
dividing the global budget between the groups  based on voter
preferences  and not based on some preliminary decision  on
a related note  some projects indeed may be of use to  say 
several districts  e g   a park positioned in one specific dis-
trict but enjoyed by residents from several districts   in such
cases it might be better to  say  not include such a project
in the group-wise budget of any district  or  consider a more
fine-grained model in which such a project may be counted
partially to each of the districts that are relevant to it—we do
not consider such generalizations of our model here 
1 1
our contributions
we introduce and study group-pb  first demonstrating its
computational intractability even for some very restricted
cases  theorem 10  theorem 14  
interestingly  group-
pb can be solved in polynomial-time if a project belongs
to at most one group  but becomes np-hard as soon as a
project can belong to two groups  theorem 14   positively 
we show that group-pb can be solved in polynomial-time
for a constant number of groups  theorem 17  and for in-
stances with hierarchical group structure  i e   any pair of
groups must be either non-intersecting or in containment rela-
tion  lemma 11   note that in some cases  e g   when group-
ing projects by geographical regions/districts/neighborhoods 
the group structure is indeed hierarchical 
we extend our study to parameterized algorithms  we con-
sider the following parameters  the number of projects  m  
the number of voters  n   the maximum size of an approval
set  app   the budget  b   the maximum size of a group in
the family f  s   the utility  u   the layerwidth  ℓ   see def-
inition 4 for layerwidth   the size of the family f  g   and
bmax = maxf ∈f b f   and obtain both tractability and in-
tractability results  the motivation for considering these is
the following  the number of voters  n  can be small in cases
when we do pb by the council or in a small community  m is
sometimes quite small  e g   the pb instances of stanford par-
ticipatory budgeting platform1 usually consist of only 10–20
1https //pbstanford org/
result
parameters
reference
paranp-hard
bmax   s   app   ℓ
theorem 10
paranp-hard
bmax   s   n   ℓ
theorem 10
w 1 -hard
bmax   s   app   u
theorem 10
w 1 -hard
bmax   s   n   u
theorem 10
paranp-hard
ℓ   dg
theorem 14
fpt
dp
theorem 16
xp
g
theorem 17
fpt
g   u
corollary 19
fpt
g   n
theorem 20
fpt
g   b
theorem 21
table 1  parameterized complexity of group-pb wrt  bmax =
max b f    f ∈ f   s = max |f|   f ∈ f   the maximum
number app of projects a voter approves  the layerwidth ℓ  see def-
inition 4   the number n of voters  the required utility u  the number
dg  dp  of groups  resp   projects  to delete to get a hierarchical
structure  the number of groups g = |f|  and the total budget b 
upper-bound on g
approximation ratio
o 1 
p
log4 log mo 1  
ptas
any g
g   2
table 2  achieved approximation ratios  in polynomial-time  de-
pending on the number g of groups  the smaller g compared to m 
the better approximation for max-group-pb we can achieve  the
results are proved in the full version of the paper  jain et al   2020b  
lower-bound on g
inapproximability
3
2m
no ptas
m2
no g
1
2 −ϵ-approximation algorithm
m2
no m1−ϵ-approximation algorithm
table 3  achieved polynomial-time inapproximability results de-
pending on the number g of groups  the larger g compared to m  the
higher is the approximation ratio excluded  the results are proved
in the full version of the paper  jain et al   2020b  
projects   ℓ and bmax can be set by designer—they are gen-
erally not small  yet we add them for completeness  b and
u are also generally not small  but added for completeness 
app  s and g can be set by the designer  and they are usually
rather small  e g  5 to 10 
since the problem can be solved in polynomial-time on hi-
erarchical instances  we also consider two distance parame-
ters to a hierarchical instance  dp and dg  the minimum num-
ber of projects  respectively  groups  whose deletion leads
to a hierarchical instance  finding efficient algorithms for
such distance parameters implies that not only hierarchical
instances can be solved efficiently  but also instances that are
close to being such  this is particularly useful in the pres-
ence of a few outliers  due to this  distance parameters are
studied frequently in parameterized complexity  including in
voting theory  bredereck et al   2014  gupta et al   2020a 
gupta et al   2020b   
proceedings of the thirtieth    ijcai-21 
277
 in particular  the main focus of our paper is on adding a
group structure on top of a standard pb instance  from this
point of view  pb election designers can choose how com-
plex they want the group structure to be  thus  studying the
complexity of group-pb wrt  our parameters—in particu-
lar  the parameter g and the distance parameters—sheds light
on the effect of adding groups on the complexity of the prob-
lem  which is polynomial-time solvable when there are no
groups   following our parameterized tractability results  a
pb election designer can practically use our group structures 
albeit perhaps not with an arbitrary number of groups of un-
limited structural complexity 
table 1 lists most of our complexity results  parameter-
ized complexity wrt  g is open  open question 18   however
we have an approximation scheme that is fpt wrt  g  theo-
rem 22   tables 2 and 3 summarize our  in approximability
results that we present in the full version of the paper  jain et
al   2020b  
remark 3  while some city planners may not care for com-
plexity results  we are personally aware of some that are hes-
itant to use algorithmic methods that may not be efficient and
thus may require extensive computational resources 2 thus 
in addition to being of theoretical interest  our complexity
analysis results have practical implications regarding the fea-
sibility of adding group-wise budget upper bounds to pb   at
least  as much as theoretical results imply practical feasibil-
ity  
initial observations 
for completeness  we mention that
group-pb is trivially fpt wrt  m  by a brute-force algo-
rithm in o∗ 2m  time3  and  as the exponential time hy-
pothesis implies a lower bound of 2o |v |  for independent
set  we conclude a lower bound of 2o m  following the re-
duction in the proof of theorem 10   furthermore  group-
pb is fpt wrt  app   n as every project is approved by at
least one voter  implying m ≤ app · n 
road map 
in section 2 we consider a structural property
of family of sets  useful for obtaining a polynomial-time al-
gorithm for hierarchical families and may also be of inde-
pendent interest  then  in section 3  we present intractability
results of group-pb  sections 4 and 5 are devoted to param-
eterized analysis of group-pb  due to space constraints 
some results  proofs or proof details are deferred to the full
version of the paper  jain et al   2020b  
1 2
related work
the literature on pb is quite rich  aziz et al   2018   for-
mally  we generalize the framework of talmon and fal-
iszewski  2019  by adding group structures to approval-based
pb  jain et al   2020a  and patel et al   2021  also consider—
albeit significantly simpler—group structures  with layer-
width 1  see definition 4  
fairness constraints are stud-
ied  e g   in the contexts of influence maximization  tsang
2in particular  one of the authors  while trying to convince a
deputy mayor of a medium-sized city to implement a participatory
budgeting process  faced significant criticism regarding the worry of
the need of using extensive computational resources 
3o∗ hides factors that are polynomial in the input size 
et al   2019   clustering  chierichetti et al   2017   and allo-
cation problems  benabbou et al   2018   our focus is on
fairness in pb  e g   not spending all funds on one district  
recently  hershkowitz et al   2021  introduced a district-
fairness notion  allowing projects to have different utility for
different districts  researchers have also studied fairness and
group structures for multiwinner elections  izsak et al   2018 
celis et al   2018  yang and wang  2018  ianovski  2019 
gupta et al   2020b   which is a special case of pb 
technically  group-pb is a special case of the d-
dimensional knapsack problem  d-dk   kellerer et al  
2004  section 9   given a set of items  each having a d-
dimensional size-vector and its utility  a d-dimensional knap-
sack capacity vector β with an entry for each dimension  and
required integer utility—with all input numbers being non-
negative integers—the goal is to choose a subset of the items
with at least the required total utility and such that the sum
of the chosen items  sizes is bounded by the knapsack ca-
pacity  in each dimension  d-dk generalizes group-pb 
items in d-dk correspond to projects  fix an order on f  i e  
 f1  f2          fg   resulting in d = g   1 many dimensions 
a  g   1 -dimensional size vector γ for an item p ∈ p  de-
fined by γp i  = c p  if p ∈ fi and γp i  = 0 otherwise 
γp g   1  = c p  for every p ∈ p  corresponding to a global
budget  utility of an item p ∈ p equals its approval score  re-
quired utility in d-dk equals u  and the  g   1 -dimensional
bin β is defined via β i  = b fi  for i ∈  1  2          g   with
β g   1  = b  so  group-pb is an instance of  g   1 -
dk where each item p ∈ p has only two possible sizes over
dimensions  i e   0 and c p   crucially  as our model is a spe-
cial case we can use our special instance structure  hence  we
treat results for d-dk as a good benchmark  in particular  the
 in approximability results for d-dk  kellerer et al   2004  
2
layer decompositions
definition 4  a layer decomposition of a family of sets f
is a partition of the sets in f such that every two sets in a
part are disjoint  each part is a layer  the width of a layer
decomposition is the number of layers in it  the layerwidth
of a family of sets f  denoted by ℓ f   or simply ℓ if f
is clear from the context   is the minimum width among all
possible layer decompositions of f 
given a family f of sets and an integer ℓ  the decision
problem layer decomposition asks for the existence of
a layer decomposition with width at most ℓ  the following
hardness result follows a reduction from edge coloring 
theorem 5  layer decomposition is np-hard even
when ℓ = 3 and s = 2 
a reduction to 2-graph coloring gives a polynomial-
time algorithm for layerwidth 2 
theorem 6  there exists a polynomial-time algorithm that
finds a layer decomposition of layerwidth two  if it exists 
we discuss hierarchical families of sets  also known as
laminar families  
definition 7  a family of sets f is called hierarchical  if
every two sets f1 and f2 in the family f are either disjoint
or f1 ⊂ f2 or f2 ⊂ f1 
proceedings of the thirtieth    ijcai-21 
278
 theorem 8  there exists a polynomial-time algorithm that
solves a given instance  f  ℓ  of layer decomposition
when f is a hierarchical family 
remark 9  the general idea of the algorithm described in
the proof of theorem 8 is to build a graph with one vertex
for each group and edges corresponding to group intersec-
tions  followed by traversing the graph in topological order
and constructing the corresponding hierarchical tree  note
that  conveniently  the algorithm can be modified to construct
an ordered layer decomposition such that every set in the i-th
layer is a subset of a set in the  i − 1 -th layer 
3
intractability of general instances
next we prove intractability  showing that group-pb is
np-hard even when some of the input parameters are con-
stant  note  importantly  that we can solve the standard pb
problem—without project groups—in polynomial-time  as it
can be solved using dynamic programming via equivalence to
unary knapsack  talmon and faliszewski  2019   
the following result is obtained via reductions from the
independent set  is  problem on 3-regular 3-edge col-
orable graphs 
theorem 10  group-pb is np-complete even when bmax =
1  s = 2  app = 1  and ℓ = 3  and even when bmax = 1 
s = 2  n = 1  and ℓ = 3  furthermore  group-pb is w 1 -
hard wrt  u even when bmax = 1  s = 2  and app = 1  and
even when bmax = 1  s = 2  and n = 1 
4
tractability of hierarchical instances
we start our quest for tractability by considering group-
pb instances whose group structure is hierarchical  when f
is hierarchical  we refer to the group-pb problem as
hierarchical-pb  fortunately  such instances can be
solved in polynomial-time  practically  hierarchical instances
are appropriate  e g   when considering disjoint geographical
districts of a city 
lemma 11  there exists a polynomial-time algorithm that
solves hierarchical-pb 
proof  let  v  p  e  f  c  b  b  u  be a given instance of
hierarchical-pb  w l o g   assume that p is a set in the
family f  otherwise  add it to f and set b p  = b   using
remark 9  let l be an ordered layer decomposition of f such
that every set is a subset of some set in the preceding layer 
and note that the first layer is  p   let s be a set in some
layer  say li  such that |s| > 1  suppose that there exists a
project p ∈ s such that p is not in any set of li 1  we add
the set  p  to f and li 1  and set b  p   = c p   if the layer
li 1 does not exist  then we add this new layer   note that
we might increase the number of layers by 1  let ℓ be the
number of layers 
now  we solve the problem using dynamic programming 
for a set s ∈ f in the i-th layer  where i ∈  ℓ − 1   such
that |s| > 1  let parts denote the partition of a set s such
that every part in parts is a set in the  i   1 -th layer  for
a singleton set s  parts =  s   for every set s ∈ f  we
order the parts in parts arbitrarily  let |parts| denote the
number of parts in parts and let parts i  denote the i-th
part in parts  our dp table entries are defined as follows 
for every set s ∈ f  j ∈ |parts|  and utility z ∈  u  
t s  j  z  = minimum cost of a subset of projects in first j
parts in parts that has utility z 
for a project p  let a p  denote the number of voters who
approve the project p  approval score  
for a set s  let
a s  = �
p∈s a p   we compute the table entries level-wise
in bottom-up order  that is  we first compute the value corre-
sponding to sets at lower levels 
base case  for every set s  where s = ∅ or s ∈ f and
0 ≤ z ≤ u
t s  0  z  =
�0
if z = 0 
∞
otherwise 
recursive step  for every set s ∈ f  j ∈  |parts|   and
0 ≤ z ≤ u  we compute as follows 
t s  j  z  =
min
0≤z′≤z t s  j − 1  z − z′ 
  t parts j   |parts j |  z′   
correctness proof can be found in  jain et al   2020b  
some instances might not be hierarchical but only close to
being such  thus we study two distance parameters  namely 
the minimum number dg of groups and the minimum number
dp of projects  respectively  whose deletion results in a hier-
archical instance  indeed  having efficient algorithms for such
instances means that even more instances can be efficiently
solved  e g   instances with group structures corresponding to
thematic districts in which some projects fit several groups  
we have the following lemmas—used later in the proofs
for the parameterized complexity of group-pb wrt  dg  
s and dp—which are concerned with computing the set of
groups/projects whose deletion leads to hierarchical instance 
their proofs follow branching arguments  as  for dg  at least
one set from each pair of conflicting groups shall be deleted 
and  for dp  for a pair of conflicting groups g1  g2  either
g1 \ g2 or g2 \ g1 or g1 ∩ g2 shall be removed 
lemma 12  there exists an algorithm  running in o∗ 2dg 
time  that finds a minimum-sized set of groups whose deletion
results in a hierarchical instance 
lemma 13  there exists an algorithm  running in o∗ 3dp 
time  that finds a minimum-sized set of projects whose dele-
tion results in a hierarchical instance 
unfortunately  we have the following intractability result 
theorem 14  group-pb is np-hard even when dg = 2
and ℓ = 2 
nevertheless  combining with s helps 
theorem 15  group-pb is fpt wrt  dg   s 
in contrast to theorem 14  parametrization by the delete-
project-distance of an instance to be hierarchical is tractable 
theorem 16  group-pb is fpt wrt  dp 
proceedings of the thirtieth    ijcai-21 
279
 5
tractability with few groups
next we concentrate on the number g of groups as a parame-
ter as  indeed  the groups are the new ingredient we bring to
the standard model of pb  practically  the number g of groups
may be set by the entity organizing the pb process  thus can
be as small as the organizer wishes  first  we have the follow-
ing result for the parameter g  the proof follows an algorithm
that considers 2g  types  of projects  guesses the joint utility
achieved from projects of each type  and finds corresponding
bundles using dynamic programming 
theorem 17  group-pb is xp wrt  g 
unfortunately  we do not know whether group-pb is
fpt wrt  g  indeed  this is the main question left open 
open question 18  is group-pb fpt wrt  g 
note  however  that in  jain et al   2020b  we provide a
proof of w 1 -hardness wrt  g  albeit for a slightly more gen-
eral problem  in which we are also given utility requirements
for each group  next we consider combined parameters  the
next result follows the proof of theorem 17 
corollary 19  group-pb is fpt wrt  g   u 
careful mixed integer linear programming  milp  for-
mulation implies the following 
theorem 20  group-pb is fpt wrt  g   n 
proof  recall that w l o g  we assume that every project is
approved by at least one voter 
we construct a milp by
defining a type of a project by a pair  r  w   where r ⊆ f
and w ∈  n   a project of type  r  w  belongs to all the
groups in r  and to none of the groups in f \ r  and it is
approved by exactly w voters  note that we have n · 2g types
of projects  we define an integer variable xr w for all r ⊆ f
and w ∈  n   meaning how many projects of type  r  w  are
in a solution  let | r  w | be the number of projects of type
 r  w  
next  we split xr w into a sum of | r  w | real variables 
xr w =
�
i∈ | r w | 
yr w i 
where yr w i ∈  0  1  is a continuous extension of a bi-
nary variable that indicates whether we take the i-th cheap-
est projects of type  r  w  to a solution  from equation  5 
we get also xr w ∈  0  1          | r  w |   note that we have
�
r⊆f
�
w∈ n  | r  w | = m real variables yr w i because
each project has exactly one type  we implement the budget
function by writing a constraint for each group f ∈ f 
�
r f ∈r⊆f
�
w∈ n 
�
i∈ | r w | 
yr w i · c r  w  i  ≤ b f  
where c r  w  i  is the cost of the i-th cheapest project of type
 r  w   we add a global budget limit constraint as follows 
�
r⊆f
�
w∈ n 
�
i∈ | r w | 
yr w i · c r  w  i  ≤ b 
the objective function is 
max
�
r⊆f
�
w∈ n 
w · xr w 
any optimal solution  x∗  y∗  of the milp can be trans-
formed into an optimal solution  x∗  yint  consisting of inte-
ger variables only  define yint
r w i = 1 for i ∈  1          x∗
r w 
and yint
r w i = 0 for i ∈  x∗
r w   1          | r  w |  
a proof that  x∗  yint  is a feasible and an optimal solution
can be found in  jain et al   2020b   our milp can be solved
in o∗ 2n log n ·2o g   time  lenstra  1983  bredereck et al  
2020  
also combining g with the budget b helps  as we can use
the dp for  g   1 -dk  which runs in time upper-bounded
by o∗ n ·  bmax   1 g b   1   ≤ o∗ n ·  b   1  g 1  
 kellerer et al   2004  section 9 3 2  
theorem 21  group-pb is fpt wrt  g   b 
5 1
fpt approximation scheme for g
recall that group-pb is xp wrt  g  theorem 17  and re-
call our open question regarding whether group-pb is fpt
wrt  g  open question 18   next we show an approximation
scheme for max-group-pb that is fpt wrt  g  compare
this result also to that described in  jain et al   2020b   show-
ing that there does not exist a constant-factor approximation
algorithm unless p = np  even if g is as small as m2  
in particular  our approximation notion is the following 
an algorithm has an approximation factor α ≥ 1 if it always
outputs a solution that has at most α factor less utility than
the optimal solution 
theorem 22  there exists an algorithm that for any fixed
ϵ > 0 finds a  1   ϵ -approximate solution to max-group-
pb in fpt time wrt  g 
proof  the idea of the algorithm is as follows 
first  we
reduce the given instance of group-pb to an instance of
group-pb with an additional feasibility restriction  in par-
ticular  such that a feasible solution has to contain exactly one
project from each project type  where a type of a project is
uniquely defined by the family of groups to which the project
belongs  the reduction  shown below  takes fpt time wrt 
g  in the second step we will round down the approval score
of each project to the closest multiplicity of  1   ϵ   in effect
bounding the number of different approval scores of a project
to the logarithmic function of the input size  then we will
apply a brute-force enumeration that runs in fpt time wrt  g 
more formally  let us fix ϵ > 0 and an instance i =
 v  p  e  f  c  b  b  of max-group-pb  recall that w l o g 
we assumed that each project is approved by at least one
voter  let a  p →  1  2          |v|  be an approval score func-
tion  i e   a p  = | v ∈ v   p ∈ pv |  notice that the ap-
proval score function a ·  can be encoded in unary  instead
of having voters explicitly   let a be the total approval score
of all the projects  e g   a = �
p∈p a p   let u∗ i  be the
value  total utility  of an optimal solution to i  to avoid triv-
iality  w l o g  we assume u∗ i  > 0 
now  given a subfamily r ⊆ f  we say that a project p
is of type r if it belongs to all the groups in r and to none
of the groups in f \ r  so every project has an unique type  
we have at most 2g types of projects  first  we fix an optimal
solution x∗ and we do the following preprocessing on the
proceedings of the thirtieth    ijcai-21 
280
 instance i  for every project type  we guess whether at least
one project of the type is contained in x∗  and if none  we
delete all projects of that type  we can do this preprocessing
in o∗ 22g  time  note that  after this step  the number of
project types cannot increase because the number of projects
cannot increase   as this is just a preprocessing  in our next
steps we override the notation and use p for the set of projects
after the preprocessing   we define the number of project
types after the preprocessing as t  with t ≤ 2g 
for every project type r ⊆ f we run a dynamic pro-
gramming procedure that outputs the following  for every
value v ∈  1  2          a   we compute cost r  v   which is
the minimum cost of a subset of projects of type r whose
total value is exactly v  it is equal to ∞ if there is no such
subset   also we store a bundle of projects  bundle r  v  
that realizes the minimum cost cost r  v  
we can com-
pute cost r  v  together with bundle r  v  in time upper-
bounded by o∗ t · a · |p|  = o∗ 2g  
now  we create a new instance i′ =  v′  p ′  e′  f′  c′ 
b′  b′  of group-pb as follows 
for every project type
r ⊆ f and every value v
∈  1  2          a  such that
cost r  v  is not ∞  we define a project proj r  v  ∈ p ′
of cost c′ proj r  v   = cost r  v  and approval score
a′ proj r  v   that is equal to v  equivalently  we can de-
fine a many voters in v′  where the i-th voter approves all
the projects proj r  v  such that v ≥ i   we define the type
of all the projects proj r  v   v ∈  1  2          a   as r  note
that a project proj r  v  corresponds to a bundle of projects
of type r from the original instance 
we keep the same global budget limit  i e   b′ = b  for
every group f ∈ f  we define a group tf ∈ f′ that contains
all projects proj r  v  whose type r contains the group f 
i e   tf =  proj r  v    f ∈ r   we define b′ tf   = b f  
we show correspondence of feasible solutions in both in-
stances  let i′
1 be the instance i′ of group-pb restricted to
solutions containing exactly one project of each type 
lemma 23  every feasible solution to i′
1 can be trans-
formed into a feasible solution to i with the same utility in
polynomial-time 
lemma 24  we have u∗ i  ≤ u∗ i′
1  
note that from lemma 23 and lemma 24 we could de-
rive u∗ i  = u∗ i′
1   although the crucial ingredient of
lemma 23 is that we can transform a feasible solution to i′
1
into a feasible solution to i  keeping the value of the solution 
in polynomial-time  in the second step  called bucketing  we
round down the approval score of each project to the closest
multiple of  1   ϵ   let i′′
1 be an instance after the bucketing
procedure  note that we do not change costs and budget limits
when bucketing the approval scores  
lemma 25  we have u∗ i′′
1   ≥ u∗ i′
1 
1 ϵ  
because of bucketing  it is possible that two projects of
the same type but with different approval scores are rounded
down to the same value 
hence we keep the project of
minimum cost 
so  overall  after bucketing we have at
most log1 ϵ a  projects of each type 
for each project
type  we branch on which project of that type is selected
and we store the best solution x′′  it has utility u∗ i′′
1    
this takes o∗  log1 ϵ a  t  time  which can be bounded by
o∗ 2
1
2 ·4g   i e   the algorithm runs in fpt time wrt  g  note
that ϵ  which is a fixed constant  is present only in the poly-
nomial on the input size term 
the solution x′′ is feasible to i′
1  hence using lemma 23
we can construct a feasible solution to i with utility equal to
u∗ i′′
1   ≥ u∗ i′
1 
1   ϵ ≥ u∗ i 
1   ϵ  
where the first inequality follows from lemma 25 and the
second inequality follows from lemma 24 
6
outlook
motivated by pb scenarios in which it is useful to consider
geographic constraints and thematic constraints  we enriched
the standard approval-based model of pb by introducing a
group structure over the projects and requiring group-specific
budget limits for each group  we have showed that  while
being computationally intractable in general  the enriching
pb instances with such group structure and its correspond-
ing budget constraints comes at essentially no computational
cost if there are not so many such groups or if the structure of
these groups is hierarchical or close to being such  we com-
plemented our analysis with lower bounds and approximation
algorithms  practically  while our focus is on a theoretical un-
derstanding of the combinatorial structure of our problems 
some of our results are already showing efficient complex-
ity and thus can be used practically as they are  other re-
sults giving an evidence of being in fpt or xp  while having
rather high complexity  e g   double exponential dependency
on the relevant parameter   show nevertheless that efficient al-
gorithms may exist  thus more research might be instructive
in finding algorithms with even better running time 
further research may concentrate on  solving our open
question regarding the complexity of group-pb wrt  g  con-
sidering other relevant parameters  study group-wise lower
bounds  instead of upper bounds  as we do here   and enrich-
ing group-pb by considering project interactions  e g   in
the spirit of jain et al   2020a   
acknowledgements
k  sornat was partially supported by the foundation
for polish science  fnp  within the start programme 
the national science centre  poland  ncn  grant no 
2018/28/t/st6/00366  and the israel science foundation
 isf  grant no  630/19   n  talmon was supported by the is-
rael science foundation  isf  grant no  630/19   m  zehavi
was supported by the israel science foundation  isf  grant
no  1176/18  and the united states-israel binational science
foundation  bsf  grant no  2018302   this project has re-
ceived funding from the european research council  erc 
under the european union s horizon 2020 research and inno-
vation programme  erc  grant no  101002854  
proceedings of the thirtieth    ijcai-21 
281
 references
 aziz and shah  2021  haris aziz and nisarg shah  partic-
ipatory budgeting  models and approaches 
in tam as
rudas and g abor p eli  editors  pathways between so-
cial science and computational social science  theories 
methods  and interpretations  pages 215–236  springer 
2021 
 aziz et al   2018  haris aziz  barton e  lee  and nimrod
talmon  proportionally representative participatory bud-
geting  axioms and algorithms  in proceedings of aa-
mas 18  pages 23–31  2018 
 benabbou et al   2018  nawal
benabbou 
mithun
chakraborty 
xuan-vinh ho 
jakub sliwinski 
and
yair zick 
diversity constraints in public housing allo-
cation 
in proceedings of aamas 18  pages 973–981 
2018 
 bredereck et al   2014  robert bredereck  jiehua chen  pi-
otr faliszewski  jiong guo  rolf niedermeier  and ger-
hard j  woeginger  parameterized algorithmics for compu-
tational social choice  nine research challenges  tsinghua
science and technology  19 4  358–373  2014 
 bredereck et al   2020  robert
bredereck 
piotr
fal-
iszewski  rolf niedermeier  piotr skowron  and nimrod
talmon  mixed integer programming with convex/concave
constraints  fixed-parameter tractability and applications
to multicovering and voting 
theor  comput  sci  
814 86–105  2020 
 cabannes  2004  yves cabannes  participatory budgeting 
a significant contribution to participatory democracy  en-
vironment and urbanization  16 1  27–46  2004 
 celis et al   2018  l  elisa celis  lingxiao huang  and
nisheeth k  vishnoi 
multiwinner voting with fairness
constraints  in proceedings of ijcai 18  pages 144–151 
2018 
 chierichetti et al   2017  flavio chierichetti  ravi kumar 
silvio lattanzi  and sergei vassilvitskii  fair clustering
through fairlets  in proceedings of nips 17  pages 5029–
5037  2017 
 gupta et al   2020a  sushmita gupta  pallavi jain  sanjukta
roy  saket saurabh  and meirav zehavi  gehrlein stability
in committee selection  parameterized hardness and algo-
rithms  auton  agents multi agent syst   34 1  27  2020 
 gupta et al   2020b  sushmita gupta 
pallavi jain 
and
saket saurabh  well-structured committees  in proceed-
ings of ijcai 20  pages 189–195  2020 
 hershkowitz et al   2021  d 
ellis
hershkowitz 
anson
kahng  dominik peters  and ariel d  procaccia  district-
fair participatory budgeting  in proceedings of aaai 21 
2021 
 ianovski  2019  egor ianovski  electing a committee with
constraints  corr  abs/1902 05909  2019 
 izsak et al   2018  rani izsak  nimrod talmon  and ger-
hard j  woeginger  committee selection with intraclass
and interclass synergies  in proceedings of aaai 18  pages
1071–1078  2018 
 jain et al   2020a  pallavi jain  krzysztof sornat  and nim-
rod talmon  participatory budgeting with project interac-
tions  in proceedings of ijcai 20  pages 386–392  2020 
 jain et al   2020b  pallavi jain  krzysztof sornat  nimrod
talmon  and meirav zehavi  participatory budgeting with
project groups  corr  abs/2012 05213  2020 
 kellerer et al   2004  hans kellerer  ulrich pferschy  and
david pisinger  knapsack problems  springer  2004 
 lenstra  1983  hendrik w  lenstra  integer programming
with a fixed number of variables 
math  oper  res  
8 4  538–548  1983 
 patel et al   2021  deval patel  arindam khan  and anand
louis  group fairness for knapsack problems  in proceed-
ings of aamas 21  pages 1001–1009  2021 
 shah  2007  anwar shah  editor  participatory budgeting 
public sector governance and accountability 
world
bank  2007 
 talmon and faliszewski  2019  nimrod talmon and piotr
faliszewski  a framework for approval-based budgeting
methods  in proceedings of aaai 19  pages 2181–2188 
2019 
 tsang et al   2019  alan tsang  bryan wilder  eric rice 
milind tambe  and yair zick  group-fairness in influence
maximization  in proceedings of ijcai 19  pages 5997–
6005  2019 
 yang and wang  2018  yongjie yang and jianxin wang 
multiwinner voting with restricted admissible sets  com-
plexity and strategyproofness  in proceedings of ijcai 18 
pages 576–582  2018 
proceedings of the thirtieth    ijcai-21 
282
 "
None,2021,https-www-ijcai-org-proceedings-2021-0040-pdf,Interaction Considerations in Learning from Humans,"Pallavi Koppol, Henny Admoni, Reid Simmons",None,https://www.ijcai.org/proceedings/2021/0040.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0040-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0040-pdf.pdf,"interaction considerations in learning from humans
pallavi koppol∗   henny admoni   reid simmons
carnegie mellon university
 pkoppol  hadmoni  rsimmons @andrew cmu edu
abstract
the ability to learn from large quantities of com-
plex data has led to the development of intelli-
gent agents such as self-driving cars and assis-
tive devices  this data often comes from people
via interactions such as labeling  providing rewards
and punishments  and giving demonstrations or cri-
tiques  however  people s ability to provide high-
quality data can be affected by human factors of an
interaction  such as induced cognitive load and per-
ceived usability  we show that these human factors
differ significantly between interaction types  we
first formalize interactions as a markov decision
process  and construct a taxonomy of these inter-
actions to identify four archetypes  showing  cat-
egorizing  sorting  and evaluating  we then run a
user study across two task domains  our findings
show that evaluating interactions are more cogni-
tively loading and less usable than the others  and
categorizing and showing interactions are the least
cognitively loading and most usable 
1
introduction
intelligent agents such as self-driving cars  recommendation
engines  and assistive devices are becoming fixtures in ev-
eryday society due to their growing ability to learn from
large-scale data and to personalize based on data from in-
dividuals 
approaches to collecting data from people in-
clude asking for annotations on video and images  real et
al   2017   ratings of behavior  daniel et al   2015   task
demonstrations  abbeel and ng  2004   critiques or cor-
rections of proposed trajectories  cui and niekum  2018 
bajcsy et al   2018   and preferences between options  sadigh
et al   2017   distinctions between these techniques have led
to a growing body of work on understanding them relative to
each other  different interaction types can be used in combi-
nation to accelerate learning  palan et al   2019   better lever-
age people as teachers  bullard et al   2018   and differ in
the amount of implicit information they encode  jeon et al  
2020   learning interactions are often selected based on how
∗contact author
informative they are for a learner  without examining how hu-
man teachers may differently perceive and respond to those
interactions  however  people s experiences with different in-
teractions can affect the data they provide 
in order to collect high-quality data  whether via active
learning or curated training sets  i e  passive learning  it is
necessary to leverage data collection processes that accom-
modate people s limitations  people provide noisy data  are
biased towards providing positive rewards  and get fatigued
 amershi et al   2014   several of the shortcomings in peo-
ple s teaching capabilities may relate to the fact that as the
cognitive load  i e  the portion of working memory being
utilized  on an individual increases  they grow more easily
distracted and have worse task performance  sweller  1988  
interaction design can be used to modulate cognitive load in
human learners  chandler and sweller  1991   that is  the way
a task is presented can affect how burdensome it is and may
ultimately affect the quality of the data it produces 
our key insights are twofold  first  that we can formal-
ize interactions as a markov decision process  mdp  and
taxonomize them based on how data is provided to and acted
upon by human teachers  this taxonomy allows us to analyze
groups of similar interactions  it also enables us to empiri-
cally evaluate our second insight  these groups of interaction
types result in differences in human factors such as cognitive
load  such factors are important to characterize  as they may
lead to downstream data quality effects 
we present a model-agnostic mdp to formalize interac-
tions  and a taxonomy of interaction types for human-agent
learning using four features  the amount of data the user is
asked to respond to  the amount of the data the user provides
in their response  the granularity of the user s response  and
the responses the user can choose from  we analyze cur-
rent paradigms for learning from people  and find four dis-
tinct interaction archetypes  showing  categorizing  sorting 
and evaluating  we also present results from a user study
designed to identify differences between interaction types in
terms of human factors related to data quality  such as cog-
nitive load  confidence  and subjective usability  we find that
evaluating interaction types  where people identify good be-
havior  are the most cognitively loading and least usable in
both of the study s task domains  categorizing  i e   assign-
ing a positive or negative reward  and showing  i e   giving
demonstrations  are less cognitively loading and more usable 
proceedings of the thirtieth    ijcai-21 
283
 figure 1  we identify and evaluate four interaction archetypes for sequential decision making  sdm  top  and classification  bottom  tasks 
2
related work
quality control research for data collection investigates how
users  often crowd workers  can provide good data via incen-
tives and task design  lease  2011  kittur et al   2013   our
research differs in that we study how human factors  such as
cognitive load and usability  differ between various interac-
tion types  the correlations between cognitive load  usabil-
ity  and task performance  e g  providing good data  have
been observed and studied throughout cognitive psychology
 sweller  1988   human-computer  longo  2018  and human-
robot interaction  prewett et al   2010  
researchers categorized the questions people ask while
learning into three interaction types  labels  demonstrations 
and feature queries  cakmak and thomaz  2012   additional
research into developing learning agents that emulate the rich
learning interactions people use has involved combining mul-
tiple interaction types  bullard et al   2018  to better leverage
human teachers  leveraging trade-offs between interactions
 palan et al   2019   and exploring explicit and implicit in-
formation transfer  jeon et al   2020  
our research extends this body of work by providing a
general taxonomy of interaction types as well as a princi-
pled framework for representing model-agnostic interactions 
based on our taxonomy  justified in section 3   we discuss
four categories of interactions 
showing 
inverse reinforcement learning  irl  is a learn-
ing from demonstration technique for recovering a reward
function from which to train a policy  ng et al   2000 
abbeel and ng  2004  
behavioral cloning learns a pol-
icy directly  bain and sammut  1995  schaal  1999   while
demonstrations can be highly informative  people are limited
in the number of examples they can provide and by their ex-
pertise 
categorizing 
this type of learning is commonly used for
classification and regression  for example  computer vision
leverages popular large-scale labeled datasets  deng et al  
2009  everingham et al   2010  lin et al   2014   labels also
include the assignment of rewards to actions  as in bandit
problems and reinforcement learning with human feedback
 kober et al   2013  daniel et al   2015   the informativeness
of labels is limited by the size of the label set  and people are
known to give both overly positive rewards  amershi et al  
2014  and shifting ratings  o connor and cheema  2018  
sorting 
preference elicitation is an active area of re-
search  especially in recommendation engines  f¨urnkranz
and h¨ullermeier  2011   comparison and ranking-based ap-
proaches for learning reward functions are increasingly com-
mon  sadigh et al   2017  bıyık et al   2020  wirth et al  
2017   these interactions are precise  and thought to be low
user effort  the technique is good at fine-tuning  but the in-
formation that can be gained from each query is limited 
evaluating 
corrections are feedback on a proposed set of
actions either during or after task execution  these can be
physical or simulated  bajcsy et al   2018  jain et al   2015  
users can also mark good or bad regions of a trajectory via
critiques  cui and niekum  2018   credit-assignment inter-
actions  such as the one posed in  jeon et al   2020   can be
construed as a form of critique where the user is limited to
identifying only one good region  off-switch games can be
considered as another special case of critiques where trajecto-
ries are segmented into a singular allowed section preceding
a singular disallowed section  hadfield-menell et al   2016  
3
taxonomy of interaction types
many interaction types share fundamental similarities in how
people interface with them  by taxonomizing the space of
interaction types along those lines  we can more tractably
compare clusters of interactions  we construct a novel tax-
onomy that characterizes interaction types along four dimen-
sions  the action batch size of the learner s queries  the action
batch size of the user s responses  the number of intervention
opportunities available to the user per query  and the num-
ber of response choices available for a user to select from
per query  we identify four interaction archetypes  termed 
showing  categorizing  sorting  and evaluating 
3 1
representing model-agnostic interactions
in order to represent interactions  we must first introduce
some terminology  let a query q refer to data that the user
is prompted to respond to  an annotation is the feedback that
the user gives in response to a query  an interaction type is
proceedings of the thirtieth    ijcai-21 
284
 interactions
query size
response size
intervention options
response choice
space
references
showing
demonstrations
0
t
0
|al|t
 ng
et
al  
2000 
abbeel and ng 
2004 
ramachandran
and
amir 
2007 
ziebart
et
al  
2008 
bain and sammut  1995 
schaal  1999 
categorizing
labels
t
1
0
|au|
 deng et al   2009  ever-
ingham et al   2010  lin et
al   2014 
reward   punishment
t
1
0
| −1   1 |
 kober
et
al  
2013 
daniel et al   2015 
sorting
rankings
t · n
n
0
n 
 f¨urnkranz
and
h¨ullermeier 
2011 
wirth
et
al  
2017 
bıyık et al   2020 
preferences
t · 2
2
0
2 
 sadigh et al   2017 
evaluating
corrections
t
0 ≤ i ≤ t
2t
|au|i
 bajcsy et al   2018  jain
et al   2015 
critiques
t
0 ≤ i ≤ t
2t
2t
 cui and niekum  2018 
jeon
et
al  
2020 
hadfield-menell
et
al   2016 
table 1  we divide interactions into four clusters  t is the finite time horizon of a presented trajectory  1 in one-shot instances   n is the
number of trajectories of length t in a query or response  au is the set of user actions  al is the set of learner actions  and i is a subset of t 
the format of a query  i e    showing    categorizing    sort-
ing   or  evaluating    an interaction instance is a specific
query  e g   should the label be  library  or  bookshop    fi-
nally  an interaction session is a series of interaction instances
of a particular interaction type  and associated annotations 
we choose to model interaction sessions as markov deci-
sion processes  mdps  for several reasons  mdps provide
a sequential decision-making paradigm that captures how  in
active and passive learning  people provide a series of an-
notations over the course of an interaction session 
fur-
thermore  with this paradigm  we can treat human teachers
as agents making decisions over their own action and state
spaces  rather than as oracles in possession of data that is al-
ways equally accessible  this allows us to account for im-
perfect decision-making due to human factors  i e  cognitive
load  usability   finally  this enables us to analyze interaction
types separately from any underlying learning models  the
interaction type is a means to obtain data  and the learning
model  e g  gaussian process  neural network  q-learning 
consumes that data  this distinction enables us to discuss in-
teraction types in terms of the user s actions and the learner s
actions  to analyze both passive and active data collection 
and to assess interactions regardless of learning objectives 
we subsequently define this mdp in further detail  first 
we define a user u as an agent interacting with a learner l
via queries  the interactions between u and l can be situ-
ated in passive or active learning contexts  let al define the
set of actions available to the learner l and at ∈ al the ac-
tion taken at time t  for example  in an autonomous driving
task  al consists of available steering controls  let st ∈ sl
denote the state at time t  e g  the position of the car   a tra-
jectory is a series of state-action pairs  ξ =  st  at t
t=0  where
t is some finite task horizon  this notation holds for one-
shot tasks such as accepting or rejecting an image annotation 
s0 is the image  and a0 is the suggested annotation 
now  we describe an interaction session i as an mdp
 =  su  au  t   r   let au define the set of actions avail-
able to the user  e g  the feedback a user can give in a partic-
ular interaction type  for example  in a reward-punishment
interaction  au =  −1   1   note that au and al need not
be distinct  for demonstrations  the user may have the same
action space as the learner  this is sufficient notation for dis-
cussing the curation of training sets for passive learning  for
active learning  we define the state σi ∈ su as the param-
eterization of l at the ith query  as made visible to the user
via means such as model weights  this is distinct from the
state of the underlying learner s environment st  as discussed
previously  the transition t is a property of l  e g   gradient
descent if the model is a neural network   and can be opaque
to the user  the reward r   su �→ r minimizes the differ-
ence between the desired and true output of l 
3 2
features of the taxonomy
query size  actions  
the batch size of a query is deter-
mined by the number of actions a ∈ al it contains  and is
given by n · t  a query q consists of one or more trajecto-
proceedings of the thirtieth    ijcai-21 
285
 ries ξ with finite time horizon t such that q =  ξ0      ξn−1  
where n is the number of options presented to the user  in
the reward-punishment interaction we have been referring to 
the query presented to the user is a single  n = 1  example
of a trajectory  q =  ξ0   if we were to instead use a prefer-
ence interaction  the user would select one of two trajectories
presented to them  such that n = 2 and q =  ξ0  ξ1  
response size  actions  
the number of actions a ∈ au
that a user provides in response to a query q is variable in size 
in the reward-punishment case  the user provides one action 
either a reward  or a punishment  if we were to use a prefer-
ence interaction instead  the user would provide two actions
by returning a total ordering over the two options presented
to them 
intervention options 
this quantifies the user s granular-
ity in providing feedback  in both the reward-punishment and
preference interactions we have used as examples  the expec-
tation is that the user must respond to the entirety of the query
q  therefore  the space of their intervention choices is 0  it is
a coarse response  however  some interactions  such as cor-
rections  bajcsy et al   2018  allow the user to select subsets
of q =  ξ0  to modify  in the lunar lander case  a user could
select the entirety of ξ0 as good and make no modifications  or
adjust some chunk of i < t actions  the user s intervention
choice is 2t because they have the opportunity to intervene
at each time step 
response choice space 
this is the number of possible re-
sponses that a user can provide  given a query q  and is related
to au  in the reward-punishment example  the user can give
|au| = | −1   1 | = 2 possible responses  more generally 
a user has as many response options as they have potential
rewards or labels to assign  on the other hand  if we were
to use a preference interaction  then |au| = 2  more gener-
ally  in ranking n options  users have n  orderings to choose
from 
4
user study
we designed a mixed-design user study to find empirical dif-
ferences in cognitive load and usability between interaction
types  our within-subjects independent variable  interaction
type  had four levels  showing  categorizing  sorting  and
evaluating  our between-subjects independent variable  task
domain  had two levels  sequential decision making  hence-
forth sdm   and classification 
to enable comparisons between interaction types  we se-
lected similarly complex examples from each cluster and
minimized presentation differences  we made the assump-
tion that salient differences in user attitudes manifest even
between low-complexity interactions  e g  differences would
be present between reward-punishment and 2-way preference
comparisons  not just rating scales and n-way rankings   we
chose the lowest-complexity  non-trivial examples of each in-
teraction type  demonstrations with a manageable |al| = 4
for showing  reward   punishment for categorizing  prefer-
ence comparisons for sorting  and credit assignment  a sub-
category of critiques  for evaluating  figure 1   we also stan-
dardized the interaction interface  e g  the number of buttons 
duration of tasks  available controls  as much as possible to
minimize their impact on user attitudes 
the sdm task involved piloting a lunar lander to land up-
right between flag posts  participants supplied or responded
to a trajectory  we manually created trajectories to show to
participants  and ensured an equal distribution of successful
and failed trajectories  for showing  participants used key-
board inputs  |al| = 4  to provide example trajectories  for
categorizing  participants labeled a video of a potential lu-
nar lander trajectory with a thumbs-up or thumbs-down  for
sorting  participants were shown two videos of potential tra-
jectories for a lunar lander  and chose the better one  finally
for evaluating  participants were given one video of a poten-
tial lunar lander trajectory  and used a double-ended slider to
select the best portion of the trajectory 
the classification task consisted of a series of images to
be annotated  users provided or responded to one-word cap-
tions  we used 20 images from pascal voc 2012  evering-
ham et al   2010  by randomly selecting one image from each
of its classes  captions to be evaluated were generated by
a keras inceptionv3  szegedy et al   2016  model trained
on imagenet  deng et al   2009   for showing  participants
were given an image and typed a caption of their own choos-
ing into a textbox  for categorizing  participants labeled an
image-caption pair as thumbs-up or thumbs-down  for sort-
ing participants were shown two potential captions for a given
image  and chose the one they felt was better  finally  for
evaluating  participants were given one image-caption pair 
and used a grid to select the parts of the image that best justi-
fied the proposed caption 
hypotheses
we hypothesize that interaction types are not interchangeable
with respect to their human factors 
h1 cognitive load differs between interaction types
h2 task completion times differ between interaction types
h3 user confidence varies between interaction types
h4 subjective usability differs between interaction types
h5 preferred interaction types differ between tasks
our study is designed to identify significant differences  not
to find causal relationships  but we expect that as response
choice space and response size increase  cognitive load will
increase  while usability and performance suffer 
4 1
measures
we collected metrics on cognitive load  m1  m2   perfor-
mance  m3  m4   and usability  m5-m9   as well as partic-
ipants  responses  and any button toggles or video replays 
participants had the opportunity to provide additional feed-
back  and were asked to report their age and gender 
m1 - secondary task performance 
during each interac-
tion  participants pressed a key every time a color-changing
circle turned pink  figure 2   the longer the participants 
reaction time  the greater the cognitive load  deleeuw and
mayer  2008  
proceedings of the thirtieth    ijcai-21 
286
 m2 - paas subjective rating scale 
after each interaction
section  participants responded to the prompt  how much
mental effort did this interaction type demand   using a 9-
point likert scale  paas  1992   
m3 - primary question response time 
we recorded the
time between when the participant was given the stimulus
 e g  began the lunar lander game  or was first presented with
an image to label  and when they submitted their response 
m4 - self-reported confidence per query 
for each query 
participants responded to the prompt  how confident are
you in your answer to the primary question  not the color-
changing circle  above   with a 4-point likert scale  we did
not include a neutral option 
m5 - frustration 
after each interaction section  par-
ticipants responded to the nasa tlx  hart and stave-
land  1988  prompt  how insecure  discouraged  irritated 
stressed  and annoyed were you   on a 9-point likert scale 
m6 - complexity 
after each interaction section  par-
ticipants responded to the system usability scale  sus 
 brooke  1996  prompt   i found this interaction type un-
necessarily complex  with a 5-point likert scale 
m7 - ease of use 
after each interaction section  partici-
pants responded to the sus prompt   i thought this interac-
tion type was easy to use  with a 5-point likert scale 
m8 - overall confidence 
after each interaction section 
participants responded to the sus prompt   i felt very confi-
dent using this interaction type  with a 5-point likert scale 
m9 - forced ranking 
at the study s conclusion  users an-
swered  my nth choice interaction type would be        for
their first  second  third  and fourth choice interactions 
4 2
procedure
participants were fully counterbalanced between all orderings
of interaction types within a task domain  participants were
given instructions describing the study  they then practiced
responding to the secondary task  at the beginning of each
interaction type s section  participants were presented with
instructions describing the interaction  and an example of a
figure 2  participants responded to primary tasks described in sec-
tion 4 1  a secondary task  m1   and a confidence assessment  m4  
good response  participants then practiced the interaction  in-
cluding the secondary task and confidence assessment  each
interaction type s section comprised five questions presented
in a sequential  but randomized  order 
5
results
we collected data from 150 prolific workers over the age of
18 and with approval ratings ≥ 98   partial or duplicate task
completions were discarded  leaving us with 144 participants 
72 per task domain  61 1  of the participants self-identified
as male  37 5  as female  and 1 39  as non-binary  their
ages ranged from 18 to 70  m = 26 71  sd = 9 45   this
study and recruitment procedure was approved by our insti-
tutional review board  we analyzed the effects of interaction
types in each domain separately  and opted not to evaluate in-
teraction effects between domains for two reasons  first  we
use likert-type scale data which is subject to interpersonal
variance and cannot be reliably compared between separate
populations  second  our goal is not to identify differences
between these specific domains  but to show that task domain
can affect participants  preferences 
we analyzed all ordinal data using a friedman test fol-
lowed by a post-hoc wilcoxon signed-rank test  bonferonni
correction α = 0 0083   numerical data was analyzed with
a one-way repeated measures anova and post-hoc pairwise
tukey analyses  we used α = 0 05 for our analyses  because
we used only portions of nasa-tlx and sus to avoid par-
ticipant fatigue  we treat each question as an individual item 
h1  cognitive load differs between interaction types 
a
one-way repeated measures anova revealed a statistically
significant difference in secondary task reaction times  m1 
figure 3a  between interaction types  f 3  213  = 6 57  p <
0 001 in sdm  and f 3  213  = 20 04  p < 0 001 in classi-
fication   in sdm  secondary reaction time was significantly
longer in showing as compared to categorizing  p < 0 05  
in classification  secondary task reaction time during evalu-
ating was significantly less than in showing  sorting or cat-
egorizing  p < 0 01   for completeness  we repeated this
analysis after performing outlier rejection for samples more
than three standard deviations from the mean  no differences
were found in our results 
differences were also found in participants  subjective as-
sessments of the mental effort each interaction type required
 m2  figure 3b  in both domains  χ2 3  = 1 3 × 10−13  p <
0 001 in sdm  and χ2 3  = 4 44 × 10−15  p < 0 001 in
classification   in sdm  participants felt that sorting was
significantly harder than categorizing  p < 0 006   and that
evaluating was significantly harder than showing  sorting 
and categorizing  p < 0 001 in all cases   in classifica-
tion  participants rated evaluating as significantly harder than
showing  sorting  and categorizing  p < 0 001 in all cases  
the data supports h1 
h2  task completion times differ between interaction
types 
statistically significant differences were found in re-
sponse times  m3  figure 4  between interaction types in
both domains  f 3  213  = 28 79  p < 0 001 in sdm 
f 3  213  = 166 29  p < 0 001 in classification   in sdm 
proceedings of the thirtieth    ijcai-21 
287
  a  objective cognitive load  higher values indicate greater load 
 b  subjective cognitive load  darker values indicate greater load 
figure 3  cognitive load  h1  was measured both objectively  sec-
ondary task reaction time  and subjectively 
response times were significantly greater in sorting as com-
pared to showing and categorizing  and in evaluating as
compared to any other interaction type  p < 0 01 for both  
in classification  participants  response times to evaluating
were significantly greater than to any other interaction type
 p < 0 01 in all cases   figure 4 demonstrates these findings
visually  when we repeated this analysis after performing
outlier rejection for samples more than three standard devi-
ations from the mean  our results largely stayed the same 
we additionally found that showing interactions in the clas-
sification domain took significantly longer than categorizing
 α < 0 05   the data supports h2 
h3  user confidence varies between interaction types 
median per-trial confidence scores  m4  figure 5  were sig-
nificantly different between interaction types in both do-
mains  χ2 3  = 49 24  p < 0 001 in sdm  and χ2 3  =
102 91  p < 0 001 in classification   in sdm  participants
were significantly more confident in their responses to show-
ing and categorizing than sorting or evaluating  p < 0 01 in
all cases   in classification  participants were more confident
in their responses to showing than to any other interaction
 p < 0 01 in all cases   they were also more confident in
their responses to categorizing than to sorting and evaluat-
ing  p < 0 01 in both cases   the data supports h3 
figure 4  time taken to complete the primary interaction task  h2  
figure 5  per-trial confidence in response quality  h3  
h4  subjective usability differs between interaction types 
significant differences were found in participants  ratings of
frustration  χ2 3  = 27 07  p < 0 001 in sdm  χ2 3  =
50 94  p < 0 001 in classification   perceptions of com-
plexity  χ2 3  = 41 68  p < 0 001 in sdm  and χ2 3  =
69 30  p < 0 001 in classification   ease of use  χ2 3  =
33 14  p < 0 001 in sdm  and χ2 3  = 54 19  p < 0 001
in classification   and confidence with the interaction type
 χ2 3  = 28 66  p < 0 001 in sdm  and χ2 3  = 55 63  p <
0 001 in classification   these results  corresponding to m5
through m8  are shown in figures 6 through 9 
participants felt more frustrated by evaluating than any
other interaction in both task domains  p < 0 00145 in all
cases  
they perceived evaluating as more unnecessarily
complex than any other interaction in both task domains as
well  p < 0 001 in all cases   in classification  they also per-
ceived sorting as unnecessarily more complex than catego-
rizing  p < 0 00785   correspondingly  participants found
evaluating to be less easy to use than any other interaction
type in both task domains  p < 0 001 in all cases   in sdm 
participants were more confident with showing  sorting  and
categorizing over evaluating  p < 0 001 in all cases   in
classification  participants felt more confident using show-
proceedings of the thirtieth    ijcai-21 
288
 figure 6  responses to subjective measures of frustration  h4  
darker colors denote greater frustration 
figure 7  responses to subjective measures of complexity  h4  
darker colors denote higher perceived complexity 
ing than sorting  p < 0 00230  or evaluating  p < 0 001  
they also felt more confident using either sorting or catego-
rizing over evaluating  p < 0 001 in both cases   the data
supports h4 
h5 
preferred interaction types differ between tasks 
we tallied participants  preferred interaction types  m9  us-
ing a condorcet method  we found that in sdm  participants
preferred showing  sorting  categorizing  and then evaluat-
ing  in classification  they preferred categorizing  sorting 
showing  and then evaluating  the data supports h5 
6
discussion
our results show that interaction types are differently cog-
nitively loading and usable  and may variably impact per-
figure 8  responses to subjective measures of ease of use  h4  
darker colors denote greater ease of use 
figure 9  responses to subjective measures of confidence  h4  
darker colors denote greater perceived confidence 
formance as estimated via task completion times and self-
assessed confidence  participants rated evaluating interac-
tions as requiring the most cognitive effort  being the most
frustrating  the most unnecessarily complex  least easy to use 
and inspiring the least confidence  objectively  they also took
the longest time to complete evaluating tasks  in sdm  sort-
ing took longer than showing and categorizing  in classifi-
cation  participants felt sorting was more unnecessarily com-
plex than categorizing and were less confident using it than
showing 
this suggests that categorizing is preferable to
sorting  which is preferable to evaluating  this corresponds
to our expectation that as an interaction s response choice
space and response size increases  its usability decreases 
unexpectedly  showing  has the largest response choice
space and was among the easiest to use  this may be due
proceedings of the thirtieth    ijcai-21 
289
 to cognitive shortcuts  when guiding the lunar lander  users
may not be processing all possible trajectories  nor are they
thinking of every word they know in order to caption images 
thus  our big-o estimates may have been too coarse to cap-
ture the nuances of a user s perceived response space 
we also found a disagreement between participants  sub-
jective assessment of mental effort and their objective sec-
ondary task performance  as in prior work  deleeuw and
mayer  2008   this could indicate that there are additional 
unknown factors that affect perceived mental effort  we did
also observe a relationship between participants  primary task
reaction times and subjective assessments of cognitive load 
indicating that they took longer on cognitively loading tasks 
this may have given them more opportunities to respond to
the secondary task  influencing their reaction times 
pre-existing notions that interaction types such as evaluat-
ing and sorting might be more user-friendly than others  par-
ticularly showing   because they require fewer inputs from a
user  were not supported in the two domains we evaluated 
furthermore  differences existed in participants  preferred in-
teractions between the task domains  despite our standardiza-
tion of interaction types within and between them  future
work is required to understand how properties of a task do-
main influence interactions 
this work is one step towards developing a principled un-
derstanding of the algorithmic and human-factors compo-
nents of learning interactions 
in particular  it is a neces-
sary step towards understanding the trade-off between the ex-
pected informativeness of a learning interaction  and a user s
ability to provide high quality feedback  as data-gathering
needs increase in scale and across domains  understanding
this relationship will expand our ability to design learning in-
teractions that not only accommodate the needs of learning
agents  but also leverage the capabilities of human teachers 
acknowledgements
we thank our anonymous reviewers  as well as aditya
dhawale  tesca fitzgerald  misha khodak  ada taylor and
the harp lab at cmu for their feedback and advice  we
also thank meghna behari for helping with coding the user
study during her internship  this work is supported in part by
the office of naval research  n00014-18-1-2503   the clas-
sification image in figure 1 is  inside whitehaven library  by
librariesteam and is licensed with cc by 2 0  creative com-
mons  2004  
references
 abbeel and ng  2004  pieter abbeel and andrew y ng 
apprenticeship learning via inverse reinforcement learn-
ing  in proceedings of the twenty-first international con-
ference on machine learning  page 1  acm  2004 
 amershi et al   2014  saleema amershi  maya cakmak 
william bradley knox  and todd kulesza  power to the
people  the role of humans in interactive machine learn-
ing  ai magazine  35 4  105–120  2014 
 bain and sammut  1995  michael bain and claude sam-
mut  a framework for behavioural cloning  in machine
intelligence 15  pages 103–129  1995 
 bajcsy et al   2018  andrea bajcsy  dylan p losey  mar-
cia k o malley  and anca d dragan  learning from phys-
ical human corrections  one feature at a time  in proceed-
ings of the 2018 acm/ieee international conference on
human-robot interaction  pages 141–149  acm  2018 
 bıyık et al   2020  erdem
bıyık 
malayandi
palan 
nicholas c landolfi  dylan p losey  dorsa sadigh 
et al  asking easy questions  a user-friendly approach to
active reward learning  in conference on robot learning 
pages 1177–1190  2020 
 brooke  1996  john brooke  sus  a  quick and dirty  us-
ability scale  in p  w  jordan  b  thomas  b  a  weerd-
meester  and a  l  mcclelland  editors  usability evalua-
tion in industry  london  taylor and francis  1996 
 bullard et al   2018  kalesha bullard  andrea l thomaz 
and sonia chernova 
towards intelligent arbitration of
diverse active learning queries 
in 2018 ieee/rsj in-
ternational conference on intelligent robots and systems
 iros   pages 6049–6056  ieee  2018 
 cakmak and thomaz  2012  maya cakmak and andrea l
thomaz  designing robot learners that ask good questions 
in proceedings of the seventh annual acm/ieee interna-
tional conference on human-robot interaction  pages 17–
24  acm  2012 
 chandler and sweller  1991  paul
chandler
and
john
sweller 
cognitive load theory and the format of in-
struction 
cognition and instruction  8 4  293–332 
1991 
 creative commons  2004  creative commons  attribution
2 0 generic  cc by 2 0   2004   online  accessed 11-may-
2021  
 cui and niekum  2018  yuchen cui and scott niekum  ac-
tive reward learning from critiques  in 2018 ieee inter-
national conference on robotics and automation  icra  
pages 6907–6914  ieee  2018 
 daniel et al   2015  christian
daniel 
oliver
kroemer 
malte viering  jan metz  and jan peters  active reward
learning with a novel acquisition function  autonomous
robots  39 3  389–405  2015 
 deleeuw and mayer  2008  krista
e
deleeuw
and
richard e mayer 
a comparison of three measures of
cognitive load  evidence for separable measures of intrin-
sic  extraneous  and germane load  journal of educational
psychology  100 1  223  2008 
 deng et al   2009  jia deng  wei dong  richard socher  li-
jia li  kai li  and li fei-fei  imagenet  a large-scale
hierarchical image database  in 2009 ieee conference on
computer vision and pattern recognition  pages 248–255 
ieee  2009 
 everingham et al   2010  mark everingham  luc van gool 
christopher ki williams  john winn  and andrew zis-
serman  the pascal visual object classes  voc  challenge 
international journal of computer vision  88 2  303–338 
2010 
proceedings of the thirtieth    ijcai-21 
290
  f¨urnkranz and h¨ullermeier  2011  johannes f¨urnkranz and
eyke h¨ullermeier  preference learning and ranking by
pairwise comparison  pages 65–82  springer berlin hei-
delberg  berlin  heidelberg  2011 
 hadfield-menell et al   2016  dylan hadfield-menell  anca
dragan  pieter abbeel  and stuart russell  the off-switch
game  arxiv preprint arxiv 1611 08219  2016 
 hart and staveland  1988  sandra g hart and lowell e
staveland  development of nasa-tlx  task load index   re-
sults of empirical and theoretical research  in advances in
psychology  volume 52  pages 139–183  elsevier  1988 
 jain et al   2015  ashesh jain  shikhar sharma  thorsten
joachims  and ashutosh saxena 
learning preferences
for manipulation tasks from online coactive feedback  the
international journal of robotics research  34 10  1296–
1313  2015 
 jeon et al   2020  hong jun jeon  smitha milli  and anca d
dragan 
reward-rational  implicit  choice 
a uni-
fying formalism for reward learning 
arxiv preprint
arxiv 2002 04833  2020 
 kittur et al   2013  aniket kittur 
jeffrey v nickerson 
michael bernstein  elizabeth gerber  aaron shaw  john
zimmerman  matt lease  and john horton  the future of
crowd work  in proceedings of the 2013 conference on
computer supported cooperative work  pages 1301–1318 
2013 
 kober et al   2013  jens kober  j andrew bagnell  and jan
peters  reinforcement learning in robotics  a survey  the
international journal of robotics research  32 11  1238–
1274  2013 
 lease  2011  matthew lease  on quality control and ma-
chine learning in crowdsourcing 
human computation 
11 11   2011 
 lin et al   2014  tsung-yi lin  michael maire  serge be-
longie  james hays  pietro perona  deva ramanan  piotr
doll ar  and c lawrence zitnick  microsoft coco  com-
mon objects in context  in european conference on com-
puter vision  pages 740–755  springer  2014 
 longo  2018  luca longo  experienced mental workload 
perception of usability  their interaction and impact on task
performance  plos one  13 8  e0199661  2018 
 ng et al   2000  andrew y ng  stuart j russell  et al  algo-
rithms for inverse reinforcement learning  in icml  vol-
ume 1  page 2  2000 
 o connor and cheema  2018  kieran o connor and amar
cheema  do evaluations rise with experience 
psycho-
logical science  29 5  779–790  2018 
 paas  1992  fred g paas 
training strategies for attain-
ing transfer of problem-solving skill in statistics 
a
cognitive-load approach  journal of educational psychol-
ogy  84 4  429  1992 
 palan et al   2019  malayandi palan  nicholas c landolfi 
gleb shevchuk  and dorsa sadigh  learning reward func-
tions by integrating human demonstrations and prefer-
ences  in robotics  science and systems  rss   2019 
 prewett et al   2010  matthew s prewett  ryan c johnson 
kristin n saboe  linda r elliott  and michael d coovert 
managing workload in human–robot interaction  a re-
view of empirical studies  computers in human behavior 
26 5  840–856  2010 
 ramachandran and amir  2007  deepak
ramachandran
and eyal amir  bayesian inverse reinforcement learning 
in ijcai  volume 7  pages 2586–2591  2007 
 real et al   2017  esteban real  jonathon shlens  stefano
mazzocchi  xin pan  and vincent vanhoucke  youtube-
boundingboxes  a large high-precision human-annotated
data set for object detection in video  in proceedings of the
ieee conference on computer vision and pattern recog-
nition  pages 5296–5305  2017 
 sadigh et al   2017  dorsa sadigh  anca d dragan  shankar
sastry  and sanjit a seshia  active preference-based learn-
ing of reward functions  in robotics  science and systems
 rss   2017 
 schaal  1999  stefan schaal  is imitation learning the route
to humanoid robots 
trends in cognitive sciences 
3 6  233–242  1999 
 sweller  1988  john sweller  cognitive load during prob-
lem solving 
effects on learning 
cognitive science 
12 2  257–285  1988 
 szegedy et al   2016  christian
szegedy 
vincent
van-
houcke  sergey ioffe  jon shlens  and zbigniew wojna 
rethinking the inception architecture for computer vision 
in proceedings of the ieee conference on computer vision
and pattern recognition  pages 2818–2826  2016 
 wirth et al   2017  christian wirth  riad akrour  gerhard
neumann 
and johannes f¨urnkranz 
a survey of
preference-based reinforcement learning methods 
the
journal of machine learning research  18 1  4945–4990 
2017 
 ziebart et al   2008  brian d ziebart  andrew l maas 
j andrew bagnell  and anind k dey  maximum entropy
inverse reinforcement learning  in aaai  volume 8  pages
1433–1438  chicago  il  usa  2008 
proceedings of the thirtieth    ijcai-21 
291
 "
None,2021,https-www-ijcai-org-proceedings-2021-0041-pdf,Two-Stage Facility Location Games with Strategic Clients and Facilities,"Simon Krogmann, Pascal Lenzner, Louise Molitor, Alexander Skopalik",None,https://www.ijcai.org/proceedings/2021/0041.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0041-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0041-pdf.pdf,"two-stage facility location games with strategic clients and facilities
simon krogmann1   pascal lenzner1   louise molitor1 and alexander skopalik2
1hasso plattner institute  university of potsdam
2mathematics of operations research  university of twente
 simon krogmann  pascal lenzner  louise molitor @hpi de  a skopalik@utwente nl
abstract
we consider non-cooperative facility location
games where both facilities and clients act strate-
gically and heavily influence each other  this con-
trasts established game-theoretic facility location
models with non-strategic clients that simply select
the closest opened facility  in our model  every fa-
cility location has a set of attracted clients and each
client has a set of shopping locations and a weight
that corresponds to her spending capacity  facil-
ity agents selfishly select a location for opening
their facility to maximize the attracted total spend-
ing capacity  whereas clients strategically decide
how to distribute their spending capacity among the
opened facilities in their shopping range  we fo-
cus on a natural client behavior similar to classical
load balancing  our selfish clients aim for a distri-
bution that minimizes their maximum waiting times
for getting serviced  where a facility s waiting time
corresponds to its total attracted client weight 
we show that subgame perfect equilibria exist and
give almost tight constant bounds on the price of
anarchy and the price of stability  which even hold
for a broader class of games with arbitrary client
behavior  since facilities and clients influence each
other  it is crucial for the facilities to anticipate the
selfish clients  behavior when selecting their loca-
tion  for this  we provide an efficient algorithm that
also implies an efficient check for equilibrium  fi-
nally  we show that computing a socially optimal
facility placement is np-hard and that this result
holds for all feasible client weight distributions 
1
introduction
facility location problems are widely studied in operations
research  economics  mathematics  theoretical computer
science  and artificial intelligence  in essence  in these prob-
lems facilities must be placed in some underlying space to
serve a set of clients that also live in that space  famous ap-
plications of this are the placement of hospitals in rural areas
to minimize the emergency response time or the deployment
of wireless internet access points to maximize the offered
bandwidth to users  these problems are purely combinato-
rial optimization problems and can be solved via a rich set of
methods  much more intricate are facility location problems
that involve competition  i e   if the facilities compete for the
clients  these settings can no longer be solved via combina-
torial optimization and instead  methods from game theory
are used for modeling and analyzing them 
the first model on competitive facility location is
the famous hotelling-downs model  first introduced by
hotelling  1929  and later refined by downs  1957   their
original interpretations are selling a commodity in the main
street of a town  and parties placing themselves in a po-
litical left-to-right spectrum  respectively 
they assume a
one-dimensional market on which clients are uniformly dis-
tributed and there are k facility agents that each want to place
a single facility on the market  each facility gets the clients 
to which their facility is closest  d¨urr and thang  2007  in-
troduced voronoi games on networks  that move the problem
onto a graph and assume discrete clients on each node 
the models mentioned above are one-sided  i e   only the
facility agents face a strategic choice while the clients simply
patronize their closest facility independently of the choices
of other clients  obviously  realistic client behavior can be
more complex than this  for example  a client might choose
not to patronize any facility  if there is no facility sufficiently
close to her  this setting was recently studied by feldman
et al   2016   shen and wang  2017  and cohen and pe-
leg  2019  albeit with continuous clients on a line  in their
model with limited attraction ranges  clients split their spend-
ing capacity uniformly among all facilities that are within a
certain distance  in contrast to the hotelling-downs model 
pure nash equilibria always exist  in another related variant
by fournier et al   2020   clients that have multiple facili-
ties in their range choose the nearest facilities  another natu-
ral client behavior is that they might avoid crowded facilities
to reduce waiting times  this notion was introduced to the
hotelling-downs model by kohlberg  1983   also on a line 
clients consider a linear combination of both distance and
waiting time  as they want to minimize the total time spent
visiting a facility  this models clients that perform load bal-
ancing between different facilities  peters et al   2018  prove
the existence of subgame perfect equilibria for certain trade-
offs of distance and waiting time for two  four and six facili-
ties and they conjecture that equilibria exist for all cases with
proceedings of the thirtieth    ijcai-21 
292
 an even number of facilities for client utility functions that are
heavily tilted towards minimizing waiting times  feldotto et
al   2019  investigated the existence of approximate pure sub-
game perfect equilibria for kohlberg s model and their results
indicate that 1 08-approximate equilibria exist  the most no-
table aspect of kohlberg s model is that it is two-sided  i e  
both facility and client agents act strategically  this implies
that the facility agents have to anticipate the client behavior 
in particular the client equilibrium  for kohlberg s model
feldotto et al   2019  show that this entails the highly non-
trivial problem of solving a complex system of equations 
in this paper we present a very general two-sided compet-
itive facility location model that is essentially a combination
of the models discussed above  our model has an underlying
host graph with discrete weighted clients on each vertex  the
host graph is directed  which allows to model limited attrac-
tion ranges  and we have facilities and clients that both face
strategic decisions  most notably  in contrast to kohlberg s
model and despite our model s generality  we provide an effi-
cient algorithm for computing the facilities  loads in a client
equilibrium  hence  facility agents can efficiently anticipate
the client behavior and check if a game state is in equilibrium 
1 1
further related work
voronoi games were introduced by ahn et al   2004  on a
line  for the version on networks by d¨urr and thang  2007  
the authors show that equilibria may not exist and that exis-
tence is np-hard to decide  also  they investigate the ratio
between the social cost of the best and the worst equilibrium
state  where the social cost is measured by the total distance
of all clients to their selected facilities  with n the number of
clients and k the number of facilities  they prove bounds of
ω 
�
n/k  and o 
√
kn   while we are not aware of other
results on general graphs  there is work for specific graph
classes  mavronicolas et al   2008  limit their investigation
to cycle graphs and characterize the existence of equilibria
and bound the price of anarchy  poa   koutsoupias and pa-
padimitriou  1999  and the price of stability  pos   anshele-
vich et al   2004  to 9
4 and 1  respectively  additionally  there
are many closely related variants with two agents  restaurant
location games  prisner  2011   a variant by gur et al   2018  
and a multi round version  teramoto et al   2006   moreover 
there are variants played in k-dimensional space  de berg
et al   2019   ahn et al   2004   boppana et al   2016   to
the best of our knowledge  there is no variant with strategic
clients aiming at minimizing their maximum waiting time 
a concept related to our model are utility systems  as intro-
duced by vetta  2002   agents gain utility by selecting a set
of acts  which they choose from a collection of subsets of a
groundset  utility is assigned by a function that takes the se-
lected acts of all agents as an input  two special types are
considered  basic and valid utility systems  for the former  it
is shown that pure nash equilibria  ne  exist  for the latter 
no ne existence is shown but the poa is upper bounded by 2 
we show in the supplementary material that our model with
load balancing clients is a valid but not a basic utility system 
covering games  gairing  2009  correspond to a one-sided
version of our model  i e   where clients simply distribute
their weight uniformly among all facilities in their shopping
range  there  pure ne exist and the poa is upper bounded
by 2  more general versions are investigated by goemans
et al   2006  and brethouwer et al   2018  in the form of
market sharing games  in these models  k agents choose to
serve a subset of n markets  each market then equally dis-
tributes its utility among all agents who serve it  brethouwer
et al   2018  show a poa of 2 − 1
k for their game 
recently schmand et al   2019  introduced a model which
considers an inherent load balancing problem  however  each
facility agent can create and choose multiple facilities and
each client agent chooses multiple facilities 
for further related models we refer to the excellent surveys
by eiselt et al   1993  and revelle and eiselt  2005  
1 2
model and preliminaries
we consider a game-theoretic model for non-cooperative fa-
cility location  called the two-sided facility location game
 2-flg   where two types of agents  k facilities and n clients 
strategically interact on a given vertex-weighted directed host
graph h =  v  e  w   with v =  v1          vn   where w  
v → n denotes the vertex weight  every vertex vi ∈ v cor-
responds to a client with weight w vi   that can be understood
as her spending capacity  and at the same time each vertex is
a possible location for setting up a facility for any of the k fa-
cility agents f =  f1          fk   any client vi ∈ v considers
visiting a facility in her shopping range n vi   i e   her di-
rect closed neighborhood n vi  =  vi  ∪  z |  vi  z  ∈ e  
moreover  let w x  = �
vi∈x w vi   for any x ⊆ v   de-
note the total spending capacity of the client subset x 
in our setting the strategic behavior of the facility and the
client agents influences each other  facility agents select a
location to attract as much client weight as possible  whereas
clients strategically decide how to distribute their spending
capacity among the facilities in their shopping range  more
precisely  each facility agent fj ∈ f selects a single loca-
tion vertex sj ∈ v for setting up her facility  i e   the strategy
space of any facility agent fj ∈ f is v   let s =  s1          sk 
denote the facility placement profile  and let s = v k denote
the set of all possible facility placement profiles  we will
sometimes use the notation s =  sj  s−j   where s−j is the
vector of strategies of all facilities agents except fj  given
s  we define the attraction range for a facility fj on location
sj ∈ v as as fj  =  sj  ∪  vi |  vi  sj  ∈ e   we ex-
tend this to sets of facilities f ⊆ f in the natural way  i e  
as f  =  sj | fj ∈ f  ∪  vi |  vi  sj  ∈ e  fj ∈ f  
moreover  let ws f  = �
vi∈as f  w vi  
we assume that all facilities provide the same service for
the same price and arbitrarily many facilities may be co-
located on the same location  each client vi ∈ v strategically
decides how to distribute her spending capacity w vi  among
the opened facilities in her shopping range n vi   for this 
let ns vi  =  fj | sj ∈ n vi   denote the set of facilities in
the shopping range of client vi under s 
let σ   s × v → rk
  denote the client weight distri-
bution function  where σ s  vi  is the weight distribution of
client vi and σ s  vi j is the weight distributed by vi to fa-
cility fj  we say that σ is feasible for s  if all clients having
at least one facility within their shopping range distribute all
proceedings of the thirtieth    ijcai-21 
293
 0
2
1
0
1
2
0
2
1
0
1
2
figure 1  example of the load balancing 2-flg  the clients  ver-
tices  split their weight  shown by numbers  among the facilities
 colored dots  in their shopping range  the client distributions are
shown by colored pie charts  left  the blue facility receives a load
of 2 while all other facilities get a load of 4
3  the left client with
weight 2 distributes weight 4
3 to the yellow facility and 1
3 to both the
green and the red facility  the state is not in spe as the red facil-
ity can improve her load to 3
2 by co-locating with the blue facility 
right  a spe for this instance  all facilities have a load of 3
2 
their weight to the respective facilities and all other clients
distribute nothing  formally  σ is feasible for s  if for all
vi ∈ v we have �
fj∈ns σ s  vi j = w vi   if ns vi  ̸= ∅ 
and σ s  vi j = 0  for all 1 ≤ j ≤ k  if ns vi  = ∅  we use
the notation σ =  σi  σ−i  and  σ′
i  σ−i  denotes the changed
client weight distribution function that is identical to σ except
for client vi  which plays σ′ s  vi  instead of σ s  vi  
any state  s  σ  of the 2-flg is determined by a facility
placement profile s and a feasible client weight distribution
function σ  a state  s  σ  then yields a facility load ℓj s  σ 
with ℓj s  σ  = �n
i=1 σ s  vi j for facility agent fj  hence 
ℓj s  σ  naturally models the total congestion for the service
offered by the facility of agent fj induced by σ  a facility
agent fj strategically selects a location sj to maximize her
induced facility load ℓj s  σ   we assume that the service
quality of facilities  e g  the waiting time  deteriorates with
increasing congestion  hence  for a client the facility load
corresponds to the waiting time at the respective facility 
there are many ways of how clients could distribute their
spending capacity  as proof-of-concept we consider the load
balancing 2-flg with load balancing clients  i e   a natural
strategic behavior where client vi strategically selects σ s  vi 
to minimize her maximum waiting time 
more precisely 
client vi tries to minimize her incurred maximum facility load
over all her patronized facilities  if any   more formally  let
pi s  σ  =  j | σ s  vi j > 0  denote the set of facilities pa-
tronized by client vi in state  s  σ   then client vi s incurred
maximum facility load in state  s  σ  is defined as li s  σ  =
maxj∈pi s σ  ℓj s  σ   we say that σ∗ is a client equilibrium
weight distribution  or simply a client equilibrium  if for all
vi ∈ v we have that li s   σ∗
i   σ−i   ≤ li s   σ′
i  σ−i   for
all possible weight distributions σ′ s  vi  of client vi  see
figure 1 for an illustration of the load balancing 2-flg 
we define the stable states of the 2-flg as subgame per-
fect equilibria  spe   since we inherently have a two-stage
game  first  the facility agents select locations for their facil-
ities and then  given this facility placement  the clients strate-
gically distribute their spending capacity among the facilities
in their shopping range  a state  s  σ  is in spe  or stable  if
 1  ∀fj ∈ f  ∀s′
j ∈ v   ℓj s  σ  ≥ ℓj  s′
j  s−j   σ  and
 2  ∀s ∈ s  ∀vi ∈ v   li s  σ  ≤ li s   σ′
i  σ−i   for all
feasible weight distributions σ′ s  vi  of client vi 
we say that client vi is covered by s  if ns vi  ̸= ∅  and un-
covered by s  otherwise  let c s  =  vi | vi ∈ v  ns vi  ̸=
∅  denote the set of covered clients under facility place-
ment s  we will compare states of the 2-flg by measuring
their social welfare that is defined as the weighted participa-
tion rate w s  = w c s   = �
vi∈c s  w vi   i e   the total
spending capacity of all covered clients  for a host graph h
and a number of facility agents k  let opt h  k  denote the
facility placement profile that maximizes the weighted par-
ticipation rate w opt h  k   among all facility placement
profiles with k facilities on host graph h 
we measure the inefficiency due to the selfishness of
the agents via the price of anarchy  poa  and the price of
stability  pos   let bestspe h  k   resp  worstspe h  k  
denote the spe with the highest  resp 
lowest  social
welfare among all spes for a given host graph h and
a facility number k 
moreover  let h be the set of all
possible host graphs h 
then the poa is defined as
poa  = maxh∈h k w opt h  k  /w worstspe h  k   
whereas
the
pos
is
defined
as
pos
 =
maxh∈h k w opt h  k  /w bestspe h  k   
we study dynamic properties of the 2-flg  let an im-
proving move by some  facility or client  agent be a strategy
change that improves the agent s utility  a game has the fi-
nite improvement property  fip  if all sequences of improv-
ing moves are finite  the fip is equivalent to the existence of
an ordinal potential function  monderer and shapley  1996  
1 3
our contribution
we introduce and analyze the 2-flg  a general model for
competitive facility location games  where facility agents and
also client agents act strategically  we focus on the load bal-
ancing 2-flg  where clients selfishly try to minimize their
maximum waiting times that not only depend on the place-
ment of the facilities but also on the behavior of all other
client agents 
we show that client equilibria always exist
and that all client equilibria are equivalent from the facility
agents  point-of-view  additionally  we provide an efficient
algorithm for computing the facility loads in a client equi-
librium that enables facility agents to efficiently anticipate
the clients  behavior  this is crucial in a two-stage game-
theoretic setting  moreover  since there are only n possible
locations for facilities  we can efficiently check if a given
state of the load balancing 2-flg is in spe  using a potential
function argument  we can show that a spe always exists 
finally  we consider the 2-flg with an arbitrary feasible
client weight distribution function  for this broad class of
games  we prove that the poa is upper bounded by 2 and
we give an almost tight lower bound of 2 − 1
k on the poa
and pos  this implies an almost tight poa lower bound for
the load balancing 2-flg  furthermore  we show that com-
puting a social optimum state for the 2-flg with an arbitrary
feasible client weight distribution function σ is np-hard for
all feasible σ  hence  also for the load balancing 2-flg 
we refer to krogmann et al   2021  for all details which
were omitted due to space constraints 
proceedings of the thirtieth    ijcai-21 
294
 f1
f4
f2
f3
s1
s2
s3
figure 2  an instance of the load balancing 2-flg with a facility
placement profile marked by dots and 10 clients with weight 1 each 
algorithm 1 successively finds and removes the minimum neighbor-
hood sets s1 =  f1   s2 =  f2  f3  and s3 =  f4  
2
load balancing clients
in this section we analyze the load balancing 2-flg in which
we consider not only strategic facilities that try to get patron-
ized by as many clients as possible but we also have self-
ish clients that strategically distribute their spending capac-
ity to minimize their maximum waiting time for getting ser-
viced  we start with a crucial statement that enables the facil-
ity agents to anticipate the clients  behavior 
theorem 1  for a facility placement profile s  a client equi-
librium σ exists and every client equilibrium induces the same
facility loads  ℓ1 s  σ           ℓk s  σ   
proof  sketch   consider a client weight distribution σ that
minimizes eq σ   = �k
i=1 ℓi s  σ 2  this is an equilibrium
as a profitable deviation would decrease eq  moreover the
kkt conditions of the corresponding convex optimization
problem are precisely the conditions of a client equilibrium 
hence  every equilibrium is an optimal solution of this opti-
mization problem  also  eq is strictly convex in the facili-
ties  loads ℓ1 s  σ           ℓk s  σ  and the set of feasible solu-
tions is compact and convex  thus  the facilities  loads are
identical in every equilibrium 
two facility agents sharing a client have equal load if the
shared client puts weight on both of them 
lemma 1  in the load balancing 2-flg  for a facility place-
ment s  in a client equilibrium σ  if there are two facility
agents fp and fq and a client vi with p  q ∈ pi s  σ   then
ℓp s  σ  = ℓq s  σ  
next  we define a shared client set  which represents a set of
facility agents who share weight of the same clients 
definition 1  for a facility placement profile s  let fp be an
agent  σ be a client equilibrium  we define a shared client set
of facility agents sσ fp   such that  1  fp ∈ sσ fp  and  2 
for two facility agents fq  fr  if fq ∈ sσ fp  and there is a
client vi with q  r ∈ pi s  σ   then fr ∈ sσ fp  
we prove two properties of such a shared client set  first 
all facility agents in a shared client set have the same load 
and second  a client s weight is either completely inside or
completely outside a shared client set in a client equilibrium 
lemma 2  for a facility placement s in a client equilibrium
σ  for every fq  fr ∈ sσ fp  we have ℓq s  σ  = ℓr s  σ  
the next lemma follows from definition 1 
lemma 3  for a facility placement s  in a client equilibrium
σ for every client vi and facility agent fp with p ∈ pi s  σ   
we have that for every facility agent fr /∈ sσ fp  it holds that
r /∈ pi s  σ  
algorithm 1  computeutilities h =  v  e  w   f  s 
1 if f = ∅ then return 
2 m ← computemns h  f  s  
3 for fj ∈ m do
4
ℓj s  σ  ← w as m  
|m|
 
5 h′ ←  v  e  w′  with w′ vi  = 0 if vi ∈ as m  else
w′ vi  = w vi  
6 computeutilities h′  f \ m  s  
additionally  we show that each facility agent s load can only
take a limited number of values 
lemma 4  for a facility placement profile s  in a client equi-
librium σ a facility agent s load can only take a value of the
form x
y for x ≤ ws f  and y ≤ k with x  y ∈ n 
definition 2  for a facility placement profile s  a set of fa-
cility agents ∅ ⊂ m ⊆ f is a minimum neighborhood
set  mns  if for all ∅ ⊂ t ⊆ f 
w as m  
|m|
≤
w as t   
|t |
 
we define the minimum neighborhood ratio  mnr  as ρs  =
w as m  
|m|
  with m being a mns 
we show that a mns receives the entire weight of all clients
within its range and this weight is equally distributed 
lemma 5  for a facility placement profile s  in a client equi-
librium σ  each facility fj ∈ m of a minimum neighborhood
set m has a load of exactly ℓj s  σ  = ρs 
2 1
facility loads in polynomial time
we present a polynomial-time combinatorial algorithm to
compute the loads of the facility agents in a client equilibrium
for a given facility placement profile s  as each facility agent
only has n possible strategies  this implies that the best re-
sponses of facility agents are computable in polynomial time 
algorithm 1 iteratively determines a mns m  assigns to
each facility in m the mnr and removes the facilities and all
client agents in their range from the instance  see figure 2
for an example of a run of the algorithm 
the key ingredient of algorithm 1 is the computation of a
mns in algorithm 2  here  we first identify the mnr by a
reduction to a maximum flow problem  to this end  we con-
struct a graph  where from a common source vertex s demand
flows through the clients to the facility agents in their respec-
tive ranges and then to a common sink t  see figure 3 for
an example of such a reduction  by using binary search  we
find the highest capacity value of the edges from the facility
agents to the sink such that the flow can fully utilize all these
edges  this capacity value is the value of the mnr ρs  note
that by lemma 4 the mnr can only attain a limited number
of values  after determining the mnr  we identify the facil-
ity agents belonging to a mns m by individually increasing
the capacity of the edge to the sink t for each facility agent 
only if this does not increase the maximum flow  a facility
agent belongs to m  by reusing the flow for ρs a search for
an augmenting path with the increased capacity is sufficient
to determine if the flow is increased 
we first prove the correctness of algorithm 2 
proceedings of the thirtieth    ijcai-21 
295
 algorithm 2  computemns h =  v  e  w   f  s 
1 construct directed graph g =  v ′  est ∪ erange  
2 v ′ ←  s  t  ∪ v ∪ f 
3 est ←   s  vi  w vi   | vi ∈ v   ∪   fj  t  0  | fj ∈ f  
4 erange ←   vi  fj  w vi   | vi ∈ v  fj ∈ as vi   
5 possibleutilities ←
sorted  x/y | x  y ∈ n  0 ≤ x ≤ ws f   1 ≤ y ≤ k   
6 for binary search over i ∈ possibleutilities do
7
∀fj ∈ f   capacity  fj  t   ← i 
8
h ← maximum s-t-flow in g 
9
if value h  = i · k then i too small else i too large 
10 t ← ∅  ρ ← highest i ∈ possibleutilities below threshold 
11 for fj ∈ f do
12
∀fp ∈ f   capacity  fp  t   ← ρ 
13
capacity  fj  t   ← ∞ 
14
start with flow from binary search for i = ρ 
15
if ∄ augmenting path in g then
16
t ← t ∪  fj  
17 return t 
theorem 2  for an instance of the load balancing 2-flg  a
facility placement profile s  algorithm 2 computes a mns 
proof  we show that the mnr ρ computed by the algorithm
is correct by proving that ρ is a lower and upper bound for ρs 
we show that for each set of facility agents t  we get ρ ≤
w as t   
|t |
  to this end  consider the maximum flow for i = ρ 
the value of this flow must be value h  = kρ  since ρ is
below the threshold found by the binary search  as the total
capacity of the edges leaving the source s towards vertices
vi ∈ as t  is upper bounded by w as t   and every vertex
fp with fp ∈ t is only reachable via vertices vi ∈ as t   the
total inflow to the vertices fp ∈ t is w as t    furthermore 
the capacity of each edge from a facility vertex to the sink
vertex t is exactly ρ  hence each of these edges carries a flow
of exactly ρ  thus  we get |t|ρ ≤ w as t   for every set of
facility agents t 
for the upper bound  we show that there is a set t for
which ρ ≥
w as t   
|t |
  we consider the flow at i = ρ   δ 
the value immediately above ρ in possibleutilities  we as-
sume that for each set t  ρ   δ ≤ w as t   
|t |
  by lemma 5 
there must be a weight distribution σ  such that every facility
agent receives ρ δ load  thus  setting the flow of every edge
 vi  fj  in h to σ s  vi j for each vi ∈ v  fj ∈ f results in a
flow of  ρ δ k  this leads to ρ δ being below the threshold
and  hence  we have a contradiction  therefore  there must be
a set of facility agents t with ρ δ > w as t   
|t |
  by lemma 4 
there is no value in between ρ and ρ   δ  which w as t   
|t |
can
attain  thus  there must be a set t with ρ ≥ w as t   
|t |
 
it remains to show that the set of facility agents m com-
puted by the algorithm is indeed a mns  by the feasibil-
ity of the total flow of k · ρ for the instance with capacity
bounds of ρ  we have have for every set of facility agents t 
w as t   
|t |
≥ ρ  for every fj /∈ m  there exists an augmenting
v1
fp
v2
v3
fq
s
v1
v2
v3
fp
fq
t
w v1 
w v2 
w v3 
w v1 
w v2 
w v3 
i
i
figure 3  left  an instance of the load balancing 2-flg with the
graph h and the facility placement profile s marked by dots  right 
the maximum flow instance constructed by algorithm 2 
path where the edge  fj  t  has capacity ∞  hence  there is
a total flow strictly larger than k · ρ with flow of exactly ρ
through all fq ̸= fj  as the flow through each fi is bounded
by w as fi    for every t with fj ∈ t 
w as t   
|t |
> ρ 
therefore  fj does not belong to the mns 
for every fj ∈ m  the absence of an augmenting path
certifies that the flow is constrained by capacity representing
the clients  spending capacities  hence  w as t   
|t |
= ρ for
every t ⊆ m 
with that  we bound the runtime of algorithm 2 
lemma 6  algorithm 2 runs in o log ws f k nk n   k   
we return to algorithm 1 and prove correctness and runtime 
theorem 3  given a facility placement profile s  algorithm 1
computes the agent loads for an instance of the load balanc-
ing 2-flg in o log ws f k nk2 n   k   
proof  correctness  by lemma 5 the utilities determined for
the client agents in the mns m are correct for the given in-
stance  also by lemma 5  the client equilibria of f \ m
are independent of the facility agents in m and the clients in
as m   therefore  we can remove m  set the weight of each
client vi ∈ as m  to w vi  = 0 and proceed recursively 
runtime  the recursive function is called at most k times
because the instance size is decreased by at least one facility
agent in each iteration  apart from the call to algorithm 2  all
computations can be done in constant or linear time  there-
fore  the algorithm runs in o log ws f k nk2 n   k   
algorithm 2 implicitly computes a client equilibrium 
corollary 1  a client equilibrium can be constructed by us-
ing the flow values on the edges between a client and the facil-
ity agents of the mnss computed during the binary search in
algorithm 2 as the corresponding client weight distribution 
2 2
existence of subgame perfect equilibria
we show that the load balancing 2-flg always possesses
spe using a lexicographical potential function  for that  we
show that when a facility agent fp changes her strategy  no
other facility agent fq s load decreases below fp s new load 
lemma 7  let s be a facility placement profile and fp
a facility agent with an improving move s′
p such that
ℓp  s′
p  s−p   σ′  > ℓp s  σ   where σ  σ′ are client equi-
libria  for every facility agent fq with ℓq  s′
p  s−p   σ′  <
ℓq s  σ   we have that ℓq  s′
p  s−p   σ′  ≥ ℓp  s′
p  s−p   σ′  
with this lemma  we prove the fip and  hence  existence of a
spe by a lexicographic potential function argument 
theorem 4  the load balancing 2-flg has the fip 
proceedings of the thirtieth    ijcai-21 
296
 proof  let φ s  ∈ rk be the vector that lists the loads
 ℓ1 s  σ   ℓ2 s  σ           ℓk s  σ   in an increasing order 
let s be a facility placement profile and fp a facility agent
with an improving move s′
p such that ℓp  s′
p  s−p   σ′  >
ℓp s  σ   where σ  σ′ are client equilibria 
we show that
φ s′
p  s−i  <lex φ s  
let φ s  be of the form φ s  =
 φ1          φα  ℓp s  σ   φα 1          φβ  φβ 1          φk−1   for
some α ≤ β ≤ k − 1  such that for every 1 ≤ j ≤ β 
φj < ℓp  s′
p  s−p   σ′  and for every j ≥ β   1   φj ≥
ℓp  s′
p  s−p   σ′  
by lemma 7  we have for all facility agents fq with a load
ℓq s  σ  ∈  φ1          φβ  that their loads did not decrease 
and for agents fq with ℓq s  σ  ∈  φβ 1          φk  we have
ℓq  s′
p  s−p   σ′  ≥ ℓp  s′
p  s−p   σ′   with the improvement
of fp  φ s′
p  s−p  >lex φ s  holds  by lemma 4  there is
a finite set of values that the loads can attain  thus  φ is an
ordinal potential function and the game has the fip 
3
arbitrary client behavior
in the following  we investigate the quality of stable states of
the 2-flg with arbitrary client behavior  i e   the client costs
are arbitrarily defined  and provide an upper and lower bound
for the poa as well as a lower bound for the pos  addition-
ally  we show that computing the social optimum is np-hard 
theorem 5  the poa of the 2-flg is at most 2 
proof  fix a 2-flg with k facility players  let opt be a
facility placement profile that maximizes social welfare and
let  spe  σspe  be a spe  let c spe  be the set of clients
vi which are covered in spe and c opt  be the set of
clients vi which are covered in opt  respectively  let un-
cov = c opt  \ c spe  be the set of clients which are
covered in opt but uncovered in spe 
assume
that
w opt 
>
2w spe 
and
hence 
�
v∈uncov w v  > w spe   then  there exists a facility
player fp that receives in opt more than w  spe 
k
load from
the clients in uncov  now consider a facility agent fq with
load ℓq  spe  σspe  ≤ w  spe 
k
  by changing her strategy and
selecting the position of facility agent fp in opt  agent fq
receives the weight of all clients in uncov which are cov-
ered by fp in opt since they are currently uncovered and
therefore  obtains more than w  spe 
k
load  as this contra-
dicts the assumption of  spe  σspe  being a spe  we have
that w opt  ≤ 2w spe  
we contrast the upper bound of the poa with a lower bound
for the poa and pos 
theorem 6  the poa and pos of the 2-flg is at least 2 − 1
k 
proof  we prove the statement by providing an example of an
instance i which has a unique equilibrium  let x ≥ 4  x ∈ n 
we construct a 2-flg with k facility players  a host graph
h v  e  w  with v =  v1          vk  v1 1          v1 x−1  v2 1 
        vk−1 x−1  vk 1          vk kx   for all v ∈ v   w v  = 1 and
e =   vi  vi j  | i ∈  1  k − 1   j ∈  1  x − 1   ∪   vk  vk i  |
i ∈  1  kx   ∪   vk i  vi 1  | i ∈  1  k − 1    see figure 4 
we note that h consists of a large star sk with central ver-
tex vk  leaf vertices  vk 1          vk kx  and k − 1 small stars
vk
vk 1
vk k−1
vk k
vk kx
v1 1
v1
v1 2
v1 x−1
vk−1 1
vk−1
vk−1 2
vk−1 x−1
   
   
   
   
   
   
   
sk
s1
sk−1
figure 4  the host graph h of an instance i of the 2-flg with
arbitrary client behavior with a unique spe 
si for i ∈  1  k − 1  with central vertices vi and leaf vertices
 vi 1          vi x−1   each star si is connected to sk via an edge
between a leaf vertex of sk and si  i e    vk i  vi 1  
if the k facility players are placed on sopt =  v1          vk  
all clients are covered by exactly one facility 
hence 
w opt h  k   = |v | = kx   k    k − 1  x − 1  
in any equilibrium  a facility fj for j ∈  1  k  must receive
a load of at least kx 1
k
= x  1
k as otherwise switching to ver-
tex vk with kx   1 adjacent vertices yields an improvement 
however  any other vertex in h has at most x − 1 adjacent
vertices  hence  every facility player gets a load of at most x 
therefore  the unique spe is sspe =  vk          vk  with
w sspe  = kx   1 and poa = pos = kx k  k−1  x−1 
kx 1
=
 2k−1 x 1
kx 1
  we get lim
x→∞
�
 2k−1 x 1
kx 1
�
= 2k−1
k
= 2− 1
k 
by a reduction from 3sat  we show that computing
opt h  k  is an np-hard problem 
theorem 7  given a host graph h and a number of k
facilities  computing the facility placement maximizing the
weighted participation rate opt h  k   is np-hard 
4
conclusion and future work
we provide a general model for non-cooperative facility lo-
cation with both strategic facilities and clients  our load bal-
ancing 2-flg is a proof-of-concept that even in this more in-
tricate setting it is possible to efficiently compute and check
client equilibria  also  in contrast to classical one-sided mod-
els and in contrast to kohlberg s two-sided model  the load-
balancing 2-flg has the favorable property that stable states
always exist and that they can be found via improving re-
sponse dynamics  moreover  our bounds on the poa and the
pos show that the broad class of 2-flgs is very well-behaved
since the societal impact of selfishness is limited 
the load balancing 2-flg is only one possible realistic in-
stance of a competitive facility location model with strategic
clients  other objective functions are conceivable  e g   de-
pending on the distance and the load of all facilities in their
shopping range  also  besides the weighted participation rate
other natural choices for the social welfare function are pos-
sible  e g   the total facility variety of the clients  i e   for each
client  we count the facilities in her shopping range  this
measures how many shopping options the clients have  more-
over  we are not aware that the total facility variety has been
considered for any other competitive facility location model 
proceedings of the thirtieth    ijcai-21 
297
 references
 ahn et al   2004  hee-kap ahn  siu-weng cheng  otfried
cheong  mordecai golin  and ren e van oostrum  com-
petitive facility location 
the voronoi game 
tcs 
310 1  457 – 467  2004 
 anshelevich et al   2004  elliot anshelevich  anirban das-
gupta  jon kleinberg   eva  tardos  tom wexler  and tim
roughgarden  the price of stability for network design
with fair cost allocation  in focs  pages 295–304  2004 
 boppana et al   2016  meena boppana  rani hod  michael
mitzenmacher  and tom morgan  voronoi choice games 
in icalp  volume 55  pages 23 1–23 13  2016 
 brethouwer et al   2018  jan-tino brethouwer  jasper de
jong  marc jochen uetz  and alexander skopalik  anal-
ysis of equilibria for generalized market sharing games 
in wine  2018 
 cohen and peleg  2019  avi
cohen
and
david
peleg 
hotelling games with random tolerance intervals 
in
wine  pages 114–128  2019 
 de berg et al   2019  mark de berg  s andor kisfaludi-bak 
and mehran mehr 
on one-round discrete voronoi
games  in isaac  volume 149  pages 37 1–37 17  2019 
 downs  1957  anthony downs 
an economic theory of
political action in a democracy 
journal of political
economy  65 2  135–150  1957 
 d¨urr and thang  2007  christoph d¨urr and nguyeb kim
thang  nash equilibria in voronoi games on graphs  in
esa  pages 17–28  2007 
 eiselt et al   1993  horst a  eiselt  gilbert laporte  and
jaques-francois thisse 
competitive location models 
a framework and bibliography  transportation science 
27 1  44–54  1993 
 feldman et al   2016  michal feldman  amos fiat  and
svetlana obraztsova  variations on the hotelling-downs
model  in aaai  pages 496–501  2016 
 feldotto et al   2019  matthias feldotto  pascal lenzner 
louise molitor  and alexander skopalik  from hotelling
to load balancing  approximation and the principle of
minimum differentiation  in aamas  pages 1949–1951 
2019 
 fournier et al   2020  ga¨etan fournier 
karine van der
straeten  and j¨orgen weibull  spatial competition with
unit-demand functions  tse working papers 20-1072 
2020 
 gairing  2009  martin gairing  covering games  approx-
imation through non-cooperation  in wine  pages 184–
195  2009 
 goemans et al   2006  michel goemans  erran li li  ve-
hab s  mirrokni  and marina thottan 
market sharing
games applied to content distribution in ad hoc net-
works 
journal on selected areas in communications 
24 5  1020–1033  2006 
 gur et al   2018  yonatan gur  daniel saban  and nico-
las e  stier-moses 
the competitive facility location
problem in a duopoly  advances beyond trees  oper-
ations research  66 4  1058–1067  2018 
 hotelling  1929  harold hotelling 
stability in competi-
tion  the economic journal  39 153  41–57  1929 
 kohlberg  1983  elon kohlberg  equilibrium store loca-
tions when consumers minimize travel time plus wait-
ing time  economics letters  11 3  211 – 216  1983 
 koutsoupias and papadimitriou  1999  elias
koutsoupias
and christos papadimitriou 
worst-case equilibria 
in
stacs  pages 404–413  1999 
 krogmann et al   2021  simon krogmann  pascal lenzner 
louise molitor  and alexander skopalik  two-stage fa-
cility location games with strategic clients and facilities 
arxiv 2105 01425  cs   2021 
 mavronicolas et al   2008  marios mavronicolas  burkhard
monien  vicky g  papadopoulou  and florian schopp-
mann  voronoi games on cycle graphs  in mfcs  pages
503–514  2008 
 monderer and shapley  1996  dov monderer and lloyd s 
shapley  potential games  games and economic behav-
ior  14 1  124 – 143  1996 
 peters et al   2018  hans peters  marc schr¨oder  and dries
vermeulen 
hotelling s location model with negative
network externalities 
international journal on game
theory  2018 
 prisner  2011  erich prisner  best response digraphs for
two location games on graphs  contributions to game
theory and management  4 0  378–388  2011 
 revelle and eiselt  2005  charles s  revelle and horst a 
eiselt  location analysis  a synthesis and survey  euro-
pean journal of operational research  165 1  1–19  2005 
 schmand et al   2019  daniel schmand 
marc schr¨oder 
and alexander skopalik  network investment games with
wardrop followers  in icalp  volume 132  pages 151 1–
151 14  2019 
 shen and wang  2017  weiran
shen
and
zihe
wang 
hotelling-downs model with limited attraction 
in
aamas  pages 660–668  2017 
 teramoto et al   2006  sachio teramoto  erik d  demaine 
and ryuhei uehara 
voronoi game on graphs and its
complexity  in cig  pages 265–271  2006 
 vetta  2002  adrian vetta  nash equilibria in competitive
societies  with applications to facility location  traffic
routing and auctions  focs  pages 416–425  2002 
proceedings of the thirtieth    ijcai-21 
298
 "
None,2021,https-www-ijcai-org-proceedings-2021-0042-pdf,Fairness in Long-Term Participatory Budgeting,"Martin Lackner, Jan Maly, Simon Rey",None,https://www.ijcai.org/proceedings/2021/0042.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0042-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0042-pdf.pdf,"fairness in long-term participatory budgeting
martin lackner1   jan maly1 and simon rey2∗
1dbai  tu wien  vienna
2institute for logic  language and computation  university of amsterdam  amsterdam
 lackner  jmaly @dbai tuwien ac at  s j rey@uva nl
abstract
participatory budgeting  pb  processes are usu-
ally designed to span several years  with referenda
for new budget allocations taking place regularly 
this paper presents a first formal framework for
long-term pb  based on a sequence of budgeting
problems as main input 
we introduce a theory
of fairness for this setting  focusing on three main
concepts that apply to types  groups  of voters 
 i  achieving equal welfare for all types   ii  min-
imizing inequality of welfare  as measured by the
gini coefficient   and  iii  achieving equal welfare
in the long run  for different notions of welfare 
we investigate under which conditions these crite-
ria can be satisfied  and analyze the computational
complexity of verifying whether they hold 
1
introduction
participatory budgeting  pb  is a democratic tool in which
citizens are asked their opinion on how to spend a public
budget  cabannes  2004  shah  2007   this process is now
applied   which was invented in brazil  is now used in many
cities all around the world  dias et al   2019   the way it is
precisely organized differs from place to place but generally
the same two-stage structure is adopted  shah  2007   first
citizens propose projects and then they vote on these projects 
based on these votes  a set of projects is chosen that can be
implemented with the available budget  importantly  pb is
usually planned to run for several years  for instance  a par-
ticipatory budgeting process in paris spanned 6 years  from
2014 to 2020   city of paris  2020   and new york runs an
ongoing program since 2011  new york city council  2020  
the general idea of pb is to establish it as a regular  ongoing
process for sustained citizen participation 
even though pb has received substantial attention in recent
years through the lens of  computational  social choice  aziz
and shah  2020   its formalizations generally consider pb as
a one-shot process  this assumption significantly limits the
scope of an analysis  in particular  it disregards the possibility
of achieving fair outcomes over time  although a fair solution
may be impossible to obtain in individual pb instances  the
∗contact author
main purpose of our work is to close this gap  we introduce
perpetual participatory budgeting  a formal framework that
encompasses key characteristics of long-term pb 
the long-term perspective of perpetual pb leads to con-
ceptual challenges but brings notable advantages  to high-
light the potential of this approach  we introduce and study
notions of fairness in this setting and analyze to which extent
strong fairness guarantees can be achieved in long-term pro-
cesses  we are mainly concerned with fairness towards types
of voters  a type is a pre-defined subset of voters  for exam-
ple all voters in a certain district or socio-demographic groups
 e g   age  education  income   furthermore  to be able to
speak about fairness  we have to specify how we measure the
welfare of types  we consider three main forms of welfare 
the first is satisfaction  which intuitively corresponds to the
agreement between a voter s ballot and the chosen projects 
weighted by cost  the satisfaction of a type is the average
satisfaction of its voters  the second welfare notion is rela-
tive satisfaction  which is similar to satisfaction but measures
the satisfaction relative to the voter s maximally achievable
satisfaction  the third is the share of a type  which is the
money spent on satisfying this type  it is natural to require
that a type s share is proportional to its size 
in a first step  we define a very strong fairness criterion by
requiring that all types achieve the same welfare  this is not
only unachievable for obvious reasons in single-round pb 
but we can show that there are arbitrary long perpetual pb
instances where equal welfare remains unachievable  how-
ever  while equal welfare is often unattainable  different sets
of projects can lead to vastly different distributions of wel-
fare  thus  as a second fairness criterion  we use the gini
index  a well-known inequality measure for income  to mea-
sure inequality with respect to welfare  this measure can be
used  e g   to analyze real-world budget allocations  in this
paper  we take a computational approach  given a perpetual
pb instance  we can use the gini index as an optimization
goal and search for the least unequal budget allocation  we
show that testing for the optimality of a solution is already
co-np-complete  even in simple settings 
as a third fairness criterion we require that all types have
the same welfare in the long run  i e   they are asymptotically
equal  our main result for this fairness criterion is that it is
always possible to achieve equal relative satisfaction in the
limit if there are only two types  in contrast  equal shares and
proceedings of the thirtieth    ijcai-21 
299
 equal-satisfaction are impossible to achieve even in the long
run  in particular due to inhomogeneous types  it remains an
interesting open problem whether equal relative satisfaction
can be guaranteed in the limit for any number of types 
to sum up  our paper contains two main contributions 
 i  the framework of perpetual participatory budgeting and
 ii  the analytic and computational study of three fairness cri-
teria in this framework  these  strong  fairness criteria cannot
be guaranteed in a single round of pb and thus necessitate our
perpetual setting 
related work 
the standard pb setting from the perspec-
tive of computational social choice has been extensively de-
scribed  lu and boutilier  2011  talmon and faliszewski 
2019  aziz and shah  2020   and has then been extended
in several directions  jain et al   2020  rey et al   2020 
shapiro and talmon  2017  benad e et al   2020  baumeis-
ter et al   2020  peters et al   2020  skowron et al   2020 
laruelle  2021   the main focus of prior works were norma-
tive properties  e g   monotonicity  talmon and faliszewski 
2019   strategy-proofness  goel et al   2019  freeman et al  
2019   the core property  fain et al   2016   and proportion-
ality  aziz et al   2018   a recent study of district fairness
 hershkowitz et al   2021  investigates whether a city-wide
pb can guarantee each district the social welfare they would
have had by running a district-wide pb  while we consider
districts  called types   our notions of fairness differ 
none of the aforementioned works consider participatory
budgeting as a repeating  ongoing process 
we are only
aware of one exception in which the outcome of the previ-
ous year is taken into account to compute a budget allocation
 shapiro and talmon  2017   only for tie-breaking however  
we take previous rounds of pb into account in a more com-
prehensive fashion  finally  let us mention that our  perpet-
ual  perspective has been also considered in classical voting
 lackner  2020  and utility aggregation  freeman et al   2017 
freeman et al   2018  
2
motivating example
let us begin with an example that demonstrates the advan-
tages of taking a long-term perspective for pb 
example 1  imagine a city with five inhabitants  1 to 5  
there are two districts  1  2 and 3 live in the first district  type
t1  and 4 and 5 in the second one  type t2   a pb process will
be run over the next three years with a vote occurring every
year  the following table indicates—per year—the proposed
projects  their cost and the agents  approval ballots  a check
mark    indicates that the agent approves of the project  the
budget limit for every year is 10 
year 1
year 2
year 3
projects
p1
p2 p3
p4
p5
p6
p7
p8
p9
p10
p11
p12
cost
6
2
2
4
5
5
3
2
7
7
4/3
29/3
t1
� 1
2
3




















t2
�
4
5














we assume an online process  when the budgeting decision
has to be made for a given year  only the past is known and
agents have no knowledge about future years 
now  suppose that the municipality wants to select bud-
get allocations that maximize either the total number of ap-
provals1 or the total number of approvals weighted by the
cost2  the most commonly used methods in real-life  aziz and
shah  2020    in both cases  all projects that are boxed in the
table would be selected  if ties are broken accordingly  
it can be argued that these outcomes are not particularly
fair with respects to the two districts  agents in district t1 are
favored by the outcomes  for example  1  2 and 3 approve on
average roughly 90  of the selected projects  while 4 and 5
only roughly 40   as will be shown later in the paper  ex-
amples 2 and 4   it is actually possible to reach a much more
equal treatment of the two districts in the last year  by tak-
ing into account what happened during the first two years  in
this paper  we introduce concepts that make precise in which
sense the modified solutions are fairer than the original one 
and we discuss whether fair solutions are guaranteed to exist 
3
perpetual participatory budgeting
in essence  our framework consists of a sequence of budget-
ing problems over several rounds  let p be the set of all the
projects occurring throughout the process  their cost is given
by the cost function c   p → n  to simplify the notation  we
will write c p  instead of �
p∈p c p  for any p ⊆ p  more-
over  let n be the set of agents taking part in the process  we
assume this set to remain the same in all rounds  every agent
belongs to a type that can represent the district she lives in or
any other characteristics  observe that each agent can have
her own type  all our fairness notions and results extend to
this special case  let t be the set of types  the type function
t   n → t indicates for every agent i ∈ n her type t i  
for simplicity  we will sometimes consider a type t ∈ t as
the set of agents having this type  i ∈ n | t i  = t   in that
respect  |t| denotes the number of agents having type t ∈ t  
definition 1  budgeting problem   a budgeting problem for
round j is defined by the tuple ij = ⟨pj  bj  aj⟩ where 
• pj ⊆ p is the set of available projects 
• bj ∈ n>0 is the available budget 
• aj   n → 2pj is the approval function giving for every
i ∈ n the set of projects aj i  ⊆ pj she approves of 
we also make the assumption that every project is approved
by at least one agent and that every agent approves of at least
one project  projects without approvals as well as agents with
empty ballots can be removed in a pre-processing stage 
the outcome of a budgeting problem ij = ⟨pj  bj  aj⟩ is
a budget allocation πj ⊆ pj  it is feasible if c πj  ≤ bj and
a ij  is the set of all feasible budget allocations for ij  it is
exhaustive if it is feasible and there is no project p ∈ pj \ π
such that c π ∪  p   ≤ bj  we also speak about feasible and
exhaustive ballots using the same definition  feasible ballots
are usually referred to as knapsack ballots 
1the sum of approvals of the selected projects 
2the sum over the selected projects of their cost times approval 
proceedings of the thirtieth    ijcai-21 
300
 a perpetual participatory budgeting instance of length k ∈
n>0 ∪  ∞   or k-ppb instance  is a sequence of k budget-
ing problems i =  i1          ik   a vector π =  π1          πk 
where πj ⊆ pj for every round j ∈  1          k  will be called
a solution for i  it is said to be feasible  resp  exhaustive  for
i if every πj ∈ π is feasible  resp  exhaustive  for ij 3
4
a fairness theory for ppb
solutions can benefit some types while disadvantaging oth-
ers  to be able to reason about the quality of solutions  we
will introduce several fairness criteria  in order to discuss
whether a solution is fair or unfair  we first need a way to
measure the welfare of types 
definition 2  welfare measure   a welfare measure f is a
function taking as inputs a k-ppb instance i  a solution π 
a type t ∈ t and a round j ∈  1          k  and returning the
welfare score f i  π  t  j  ∈ r for type t of the solution π
for the first j rounds of i 
let us begin with fairness criteria  specific welfare mea-
sures are introduced in a second time 
4 1
fairness criteria
the foundation of our fairness theory is that the fairest solu-
tion should be so that all types are treated exactly the same
and thus enjoy the same level of welfare  this requirement is
our first fairness criteria 
definition 3  equal-f   for a welfare measure f  a solution
π for the k-ppb instance i satisfies equal-f at round j ∈
 1          k  if for every two types t  t′ ∈ t   we have 
f i  π  t  j  = f i  π  t′  j  
moreover  a solution π satisfies equal-f if it is equal-f at
round j for all rounds j ∈  1          k  
as equal-f can be too strong of a requirement  we intro-
duce two relaxations in the following 
a first approach when perfect fairness cannot be achieved 
is to try to optimize for it 
this idea is particularly rele-
vant when the long-term perspective is adopted as subsequent
rounds can compensate for unfairness in previous rounds 
we pursue this approach by introducing the gini coefficient
 gini  1912  of a solution—a well-known measure of inequal-
ity given a multi-set of values—that can be used as a min-
imization objective  in the following  we use the standard
formulation  blackorby and donaldson  1978  
definition 4  f-gini   let #»v =  v1          vk  ∈ rk be a
vector ordered in non-increasing order  i e   such that vi ≥ vj
for all 1 ≤ i ≤ j ≤ k  the gini coefficient of #»v is given by 
gini #»v   = 1 −
�k
i=1 2i − 1 vi
k �k
i=1 vi
 
for a welfare measure f  the f-gini coefficient of a solution
π for the k-ppb instance i at round j ∈  1          k  is then 
ginif  i  π  j  = gini #»
f  i  π  j   
3one could weaken the feasibility requirement of solutions by
allowing unused budget to be used in later rounds  for our results  it
is not relevant which definition we take 
where #»
f  i  π  j  is a vector containing f i  π  t  j  for all
types t ∈ t   ordered in non-increasing order 
a solution π is f-gini-optimal at round j with respect to
a set s of solutions for i  if there is no solution π′ ∈ s \  π 
with ginif  i  π′  j  < ginif  i  π  j  
it can be checked that f-gini-optimality is indeed a relax-
ation of equal-f in the sense that for all welfare measure f 
a solution π satisfies equal-f if and only if its f-gini coeffi-
cient reaches 0  the minimum of the f-gini coefficient  
another approach we follow is to require perfect fairness
but only in the long run  for that we introduce convergence to
equal-f which formalizes the idea of asymptotically equaliz-
ing the welfare of the different types 
definition 5  convergence to equal-f   for a welfare mea-
sure f  a solution π for the ∞-ppb instance i converges to
equal-f if for every two types t  t′ ∈ t  
f i  π  t  k 
f i  π  t′  k 
−→
k→ ∞ 1 
we will study the computational complexity of the fol-
lowing problems related to these fairness criteria  note that
this computational analysis does not apply for convergence to
equal-f as we deal with infinite sequences there 
equal-f
input 
a k-ppb instance i =  i1          ik  and a solution
π =  π1          πk−1  
question  is there a non-empty and feasible budget allocation
πk for ik such that  π1          πk−1  πk  provides
equal-f at round k 
f -gini-optimality
input 
a k-ppb instance i =  i1          ik  and a solution
π =  π1          πk  
question  is π gini-optimal at round k w r t  all non-empty 
feasible solutions 
4 2
welfare measures
the first welfare measures we define are based on the satis-
faction of an agent  even though agents can have personal
utility functions to express their satisfaction for a given out-
come  e g   peters et al   2020    this information is usually
private  i e   unknown to the decision maker  we thus need to
approximate the satisfaction of an agent  we use a standard
definition for satisfaction  talmon and faliszewski  2019  
definition 6  satisfaction   let i =  i1          ik  be a k-ppb
instance and π =  π1          πk  a solution for i  for round
j ∈  1          k   whose budgeting problem is ⟨pj  bj  aj⟩  we
define the marginal satisfaction of agent i ∈ n as 
satm
j  i  πj  i  = c πj ∩ aj i   
moreover  the marginal satisfaction and the satisfaction of a
type t ∈ t for round j ∈  1          k  are defined by 
satm
j  i  πj  t  = 1
|t|
�
i∈t
satm
j  i  πj  i 
satj i  π  t  =
�
1≤j∗≤j
satm
j∗ i  πj∗  t  
proceedings of the thirtieth    ijcai-21 
301
 satisfaction
relative satisfaction
share
2 agents
3 agents
> 3 agents
complex 
2 types
> 2 types
complex 
2 agents
> 2 agents
complex 
equal-f



np-c


np-c


np-c
conv  to equal-f

  ex  ballots 

  knap  ballots 
 


f-gini optimality



co-np-c


co-np-c 


co-np-c
table 1  summary of the results  the columns specifying a number of agents/types are for existence guarantees  a  indicates that for all
instances with the specified number of agents/types  there exists a solution satisfying the fairness criteria  and the  the opposite  the tags
 ex  ballots  and  knap  ballots  indicates that the result only holds with exhaustive or knapsack ballots  the column  complex   indicates
the computational complexity of the problems stated in section 4 1 where np-c stands for np complete and co-np-c for co-np complete 
example 2  let us illustrate satisfaction on example 1  it
can be checked that by the end of year 2  the satisfaction of
type t1 is 17   2/3 while that of type t2 is only 8  hence 
selecting only p12 in the last year would lead to a solution
such that both types would have a satisfaction of 17   2/3 
one potential drawback of satisfaction is its strong de-
pendence on voters  approval sets  for example  if agent 1
approves a proper subset of agent 2 s approved projects
 aj 1  ⊂ aj 2   and all their approved projects are funded
 aj 2  ⊆ πj   then agent 2 is more satisfied than agent 1 
however  it can be argued that the welfare of both agents
should be equal as all projects they wanted to be funded have
actually been funded  neither agent 1 or 2 can be made hap-
pier  subject to the available information   to take this into
account  we define relative satisfaction which measures how
close the satisfaction of an agent is to his best-case scenario 
definition 7  relative satisfaction   let i =  i1          ik  be
a k-ppb instance and π =  π1          πk  a solution for i  for
round j ∈  1          k  corresponding to the budgeting prob-
lem ⟨pj  bj  aj⟩  we define the marginal relative satisfaction
of agent i ∈ n as 
rsatm
j  i  πj  i  =
c πj ∩ aj i  
max c a  | a ⊆ aj i  and c a  ≤ bj  
moreover  marginal relative satisfaction and the relative sat-
isfaction of a type t ∈ t for the round j ∈  1          k  are
defined as follows 
rsatm
j  i  πj  t  = 1
|t|
�
i∈t
rsatm
j  i  πj  i 
rsatj i  π  t  =
�
1≤j∗≤j
rsatm
j∗ i  πj∗  t  
example 3  in example 1  the relative satisfaction scores by
the end of year are 23/12 for type t1 and 73/60 for type t2  one
can verify that there is no budget allocation for the third year
that would lead to equal-relative satisfaction 
satisfaction and relative satisfaction are two concepts
which relate to the idea of utilitarianism  indeed  only the
impact of the selected solution on the agents or types is taken
into consideration and not the way the resources were spent 
although utilitarian welfare is attractive  other notions can be
considered in participatory budgeting  the most important
alternative might be distributive welfare which aims at spend-
ing an equal amount of resources on each agent or type  to
account for distributive welfare  we introduce another welfare
measure called the share of a type 
definition 8  share   let i =  i1          ik  be a k-ppb in-
stance with a solution π =  π1          πk   for round j ∈
 1          k  with budgeting problem ⟨pj  bj  aj⟩  the marginal
share of agent i ∈ n is defined as 
sharem
j  i  πj  i  =
�
p∈πj∩aj i 
c p 
| i′ ∈ n | p ∈ aj i′  |
moreover  the marginal share and the share of a type t ∈ t
for round j ∈  1          k  are defined as 
sharem
j  i  πj  t  = 1
|t|
�
i∈t
sharem
j  i  πj  i 
sharej i  π  t  =
�
1≤j∗≤j
sharem
j∗ i  πj∗  t  
example 4  once again coming back to example 1  we can
show that equal-share can be achieved by the end of the last
year  indeed by the end of year 2  the shares are 5  1/3 for t1
and 2 for t2  now  by selecting p10 and p11 in the third year 
we reach a solution where each type has a share of 5   2/3 
observe that trying to equalize the shares of the different
types requires the average share of each type to be equal 
meaning that we require the total share of a type to be propor-
tional to its size  in this sense  the fairness criteria equal-share
can be considered a proportionality concept 
note
that
relative
share—in
contrast
to
relative
satisfaction—is not a very sensible property as distribu-
tive fairness should hardly depend on the ballots 
5
realizing fairness
we will now explore the fairness criteria and the welfare mea-
sures we have defined previously  all our results are summa-
rized in table 1  note that most of the proofs are omitted due
to space constraints but can be found in the appendix 
5 1
achieving perfect fairness  equal-f
we first explore the criteria that we consider to represent a
situation of perfect fairness  equal-f 
unfortunately  it is easy to check that equal-f cannot be
guaranteed even for a single round  except by selecting an
empty budget allocation  for all of our welfare measures 
consider the following example with two agents where no
non-empty solution satisfies either equal-satisfaction  equal-
relative satisfaction or equal-share in any round 
proceedings of the thirtieth    ijcai-21 
302
 example 5  let i be a k-ppb instance with two agents 1 and
2 of types t1 and t2 respectively  furthermore  let bj = 1 for
every round j ∈  1          k  and let c p  = 1 for all p ∈ p 
in the first round  agent 1 approves only of project p1 and
agent 2 only of p2  in all following rounds  they both only
approve of p1  assume w l o g  that p1 is selected in the first
round  then  for every solution π =  π1          πk   at round
j ∈  2          k   we have fj i  π  t1  = 1   fj i  π  t2  for
all three of our welfare measures f 
the example shows that in general  equal-f cannot be sat-
isfied for our welfare measures  however  it could still be
achieved on some specific instances  it turns out that for all
three welfare measures  checking the existence of an equal-f
solution is an np-complete problem 
proposition 1  the equal-satisfaction and equal-
relative
satisfaction
problems
are
strongly
np-
complete even if there is only one round 
proposition 2  the equal-satisfaction and equal-
share problems are weakly np-complete even if there is only
one round and there are only two agents 
proof  sketch   we reduce from subset sum  karp  1972  
i e   the problem of finding a subset z′ of a set z ⊂ z such
that � z′ = 0  consider a pb instance with a project pz
for every z ∈ z such that c pz  = |z|  further  there are
two agents  v  and v− approving all projects pz with z ≥
0 resp  z < 0  we claim that this is a positive instance of
equal-satisfaction and equal-share if and only if z
is a positive instance of subset sum 
we observe that both results still hold if we additionally
require exhaustiveness  i e   if we ask whether there is an ex-
haustive solution that satisfies equal-f 
5 2
optimizing for fairness  f-gini-optimality
let us now turn our attention to f-gini-optimality  note first
that—by definition—there will always be for every instance
at least one solution which is f-gini-optimal  therefore  the
main questions here concern computational problems and are
not about existence guarantees 
we first show that f -gini-optimality is co-np-
complete for both satisfaction and share 
proposition
3 
satisfaction-gini-optimality 
relative-satisfaction-gini-optimality
and
share-gini-optimality
are
weakly
co-np-complete
even if there is only one round and two agents 
we note that it is also co-np-complete to check whether a
solution is gini-optimal among exhaustive solutions  an in-
teresting open question is the complexity of finding a gini-
optimal solution that maximizes the overall welfare of the
population 
5 3
achieving fairness in the long run 
convergence to equal-f
let us conclude our analysis by investigating convergence to
equal-f  we first show that for two agents convergence to
equal-satisfaction can always be guaranteed  under mild ad-
ditional assumptions  
proposition 4  consider an ∞-ppb instance i with two
agents such that there exists a constant b⋆ ∈ n with bj ≤ b⋆
for every round j  furthermore  assume for every round and
both agents that there is a project p with c p  ≤ bj that the
agent approves of  then  there is a non-empty feasible solu-
tion that converges to equal-satisfaction 
proof  call the agents 1 and 2 and assume they belong to
types t1 and t2 respectively  as equal-satisfaction is trivially
satisfied if there is only one type   we claim that there exists
a solution π such that for every round j  we can guarantee 
satj i  π  t1  − b⋆ ≤ satj i  π  t2  ≤ satj i  π  t1    b⋆ 
let us prove the claim by induction  for the first round  it
is clear that whichever non-empty budget allocation has been
chosen  we have 0 ≤ sat1 i  π  t  ≤ b⋆ for t ∈  t1  t2  
now assume the claim holds for round j − 1  w l o g  as-
sume satj−1 i  π  t2  ≤ satj−1 i  π  t1   let p be a project
approved by 2 such that c p  ≤ bj  then  we set πj =  p  
this implies that
satm
j  i  πj  t1  ≤ satm
j  i  πj  t2  ≤ b∗
from this together with the induction hypothesis and the as-
sumption satj−1 i  π  t2  ≤ satj−1 i  π  t1  we can con-
clude that the claim also holds in round j 
now  we know that satj i  π  t1    satj i  π  t2  ≥
�j
j′=1 c πj′  
together with the claim  this implies that
lim
j→ ∞ satj i  π  t1   =
lim
j→ ∞ satj i  π  t2   =  ∞ 
therefore  the proposition follows from the following 
satj i  π  t1  − b⋆
satj i  π  t1 
≤ satj i  π  t2 
satj i  π  t1  ≤ satj i  π  t1    b⋆
satj i  π  t1 
 
unfortunately  this result cannot be generalized—even for
three agents—as the following example shows 
example 6  let i be a ∞-ppb instance with three agents
1  2  3 where agent 1 has type t1 and agents 2 and 3 have
type t2  assume bj = 1 for every round j and c p  = 1 for
all projects p ∈ p  in every round  there are two projects
and agent 1 approves of both  2 approves of only one and 3
of the other one  then  for every non-empty feasible solu-
tion π and every round j  we have satj i  π  t1  = j and
satj i  π  t2  = j
2  therefore  we have
lim
j→ ∞
�satj i  π  t2 
satj i  π  t1 
�
= 1
2 
this counter-example can be avoided if we impose some
restrictions on the ballots the agents may submit  indeed  if
ballots are exhaustive then  for three agents we can always
find a solution that converge to equal-satisfaction 
proposition 5  consider an ∞-ppb instance i with three
agents where the ballot of each agent is exhaustive in every
round and there exists a constant b⋆ ∈ n with bj ≤ b⋆ for
every round j  then  there is a non-empty feasible solution
that converges to equal-satisfaction 
proceedings of the thirtieth    ijcai-21 
303
 however  by increasing the number of agents we again en-
counter an impossibility  even with these restricted ballots 
example 7  let i be a ∞-ppb instance  in every round
j  we have bj = 10  there are eight agents 1          8 such that
1  2  3 have type t1 and 4  5  6  7  8 have type t2  furthermore 
there are six projects p1          p6 such that c p1  = c p2  =
c p3  = 5 and c p4  = c p5  = c p6  = 3  the ballots are
such that  for every round j 
aj 1  =  p1  p4 
aj 2  =  p2  p5 
aj 3  =  p3  p6 
aj 4  =  p1  p2 
aj 5  =  p1  p3 
aj 6  =  p2  p3 
aj 7  =  p4  p5  p6 
aj 8  =  p4  p5  p6 
we leave it to reader to check that for each project the
marginal satisfaction for type t2 is higher than for type t1 
this directly implies that there can be no non-empty solution
converging to equal-satisfaction 
results about convergence to equal-share are very similar
to the ones with equal-satisfaction  by a similar argument
as for proposition 4  we can show that convergence to equal-
share can be achieved for two agents  unfortunately  we can-
not go far beyond this  as the following example shows 
example 8  consider again the same ∞-ppb instance as
in example 7  we claim that for every project  selecting it
would lead to a higher share for type t2 than that of type t1 
for project p1  we have share1 i   p1   t1  = 1
3 · 5
3 = 5
9 but
share1 i   p1   t2  = 1
5  5
3   5
3  = 2
3  the case for p2 and
p3 is similar  for p4  we have share1 i   p4   t1  = 1
3 · 3
3 =
1
3 but share1 i   p4   t2  =
1
5  3
3   3
3  =
2
5  the case for
projects p5 and p6 is similar  it follows that  in this example 
we cannot have convergence to equal shares 
results are more positive when it comes to relative sat-
isfaction  indeed  we can guarantee convergence to equal-
relative satisfaction when there are two types  note that this
result is much more general than lemma 4 as types may con-
tain an arbitrary number of agents  the proof is based on the
following lemma stating that with two types  we can always
favor one type over the other 
lemma 6  let i be a k-ppb instance with non-empty knap-
sack ballots and two types t1 and t2  then  in every round
j ∈  1          k  there are two feasible budget allocations π1
and π2 such that 
0 < rsatm
j  i  π1  t1  ≥ rsatm
j  i  π1  t2 
and
rsatm
j  i  π2  t1  ≤ rsatm
j  i  π2  t2  > 0 
thanks to this lemma  using a similar line of reasoning as
in proposition 4  we can show that for two types we can find
a solution that converges to equal relative satisfaction 
theorem 7  assume that i is an ∞-ppb-instance with non-
empty knapsack ballots such that there are only two types and
a b⋆ such that bj ≤ b⋆ for all rounds j  then  there is a non-
empty feasible solution for i that converges to equal relative
satisfaction 
it is important to mention that the proofs of lemma 6 and
that of theorem 7 are both constructive  in the sense that they
show how to compute the relevant solutions  however  this
construction does not guarantee the solution to be exhaustive 
to achieve this  an additional ballot restriction is necessary 
corollary 8  consider an ∞-ppb instance i that satisfies all
the conditions of theorem 7  then  there exists a non-empty
feasible solution π =  π1  π2          for i that  i  converges to
equal relative satisfaction and  ii  such that for each round j
there is an agent i with aj i  ⊆ πj  in particular  if all
ballots are exhaustive  then every budget allocation in π is
exhaustive 
whether theorem 7 and corollary 8 can be extended to
three and more types remains an important open question 
6
conclusion
in this paper  we have introduced a model of participa-
tory budgeting  called perpetual participatory budgeting  that
takes into account the temporal component of a pb pro-
cess  we have further defined a theory of fairness for this
model by introducing several fairness criteria  we consid-
ered both egalitarian concepts based on voters   relative  sat-
isfaction and a form of proportionality based on shares  for
corresponding axiomatic properties  we studied whether  and
when  we can guarantee these to hold as well as the compu-
tational complexity of verifying them 
we can conclude that taking the long-term viewpoint al-
lows us to approximate forms of fairness that cannot be ob-
tained in single-round pb instances  this was already visible
in our starting example in section 2  beyond that  we have
established three strong fairness concepts that required a thor-
ough analysis to judge their applicability  on the one hand 
we have seen that they cannot be guaranteed in general  on
the other hand  and we have identified special cases where
some of these strong are guaranteed to hold 
several research directions can be pursued within our pro-
posed framework  for instance  it would be interesting to
look for natural pb procedures that compute solutions satisfy-
ing  or approximating  our fairness criteria  in the light recent
works  e g    hershkowitz et al   2021    a relevant question
concerns the price of fairness  i e   how much the satisfaction
has to be reduced in order to achieve fairness  the fairness
criteria we introduced may not be compatible with efficiency
notions such as pareto-optimality  although the tension be-
tween fairness and efficiency is well-known  see  e g    peters
et al   2020    it would be interesting to study the combination
of fairness and efficiency criteria in our setting  moreover  pb
generalizes multi-winner voting in a way that makes it closer
to the fair division of indivisible items  bouveret et al   2016  
this linked was already hinted in example 5 as applying  up-
to-one project  criteria would have made the solution fair  it
would then be interesting to investigate if and how fairness
criteria from fair division  for instance envy-freeness or ef1 
could be successfully adapted and applied to pb  finally  by
considering real-world data of repeated pb referenda one can
analyze the possible gains of taking a long-term perspective
as we propose here 
acknowledgements
this work was supported by the austrian science fund
 fwf   project p31890 
proceedings of the thirtieth    ijcai-21 
304
 references
 aziz and shah  2020  haris aziz and nisarg shah  partic-
ipatory budgeting  models and approaches 
in tam as
rudas and g abor p eli  editors  pathways between so-
cial science and computational social science  theories 
methods and interpretations  springer  2020 
 aziz et al   2018  haris aziz  barton e  lee  and nimrod
talmon  proportionally representative participatory bud-
geting  axioms and algorithms  in proc  of 17th aamas
conference  pages 23–31  2018 
 baumeister et al   2020  dorothea baumeister  linus boes 
and tessa seeger 
irresolute approval-based budgeting 
in proc  of 19th aamas conference  pages 1774–1776 
2020 
 benad e et al   2020  gerdus
benad e 
swaprava
nath 
ariel d  procaccia  and nisarg shah  preference elicita-
tion for participatory budgeting 
management science 
2020 
 blackorby and donaldson  1978  charles
blackorby
and
david donaldson  measures of relative equality and their
meaning in terms of social welfare  journal of economic
theory  18 1  59–80  1978 
 bouveret et al   2016  sylvain bouveret  yann chevaleyre 
and nicolas maudet  fair allocation of indivisible goods 
in felix brandt  vincent conitzer  ulle endriss  j erˆome
lang  and ariel d  procaccia  editors  handbook of com-
putational social choice  chapter 17  cambridge univer-
sity press  2016 
 cabannes  2004  yves cabannes  participatory budgeting 
a significant contribution to participatory democracy  en-
vironment and urbanization  16 1  27–46  2004 
 city of paris  2020  city of paris  paris budget participatif 
https //budgetparticipatif paris fr/bp/  2020  last accessed
on january the 18th 2020 
 dias et al   2019  nelson dias  sahsil enr ıquez  and si-
mone j ulio  editors  the participatory budgeting world
atlas  epopee records  officinal coordination  2019 
 fain et al   2016  brandon fain  ashish goel  and kamesh
munagala  the core of the participatory budgeting prob-
lem  in proc  of 12th wine  pages 384–399  2016 
 freeman et al   2017  rupert freeman  seyed majid za-
hedi  and vincent conitzer  fair and efficient social choice
in dynamic settings  in proc  of 26th ijcai  pages 4580–
4587  2017 
 freeman et al   2018  rupert freeman  seyed majid za-
hedi  vincent conitzer  and benjamin c  lee  dynamic
proportional sharing  a game-theoretic approach 
pro-
ceedings of the acm on measurement and analysis of
computing systems  2 1  3 1–3 36  2018 
 freeman et al   2019  rupert freeman  david m  pennock 
dominik peters  and jennifer wortman vaughan  truthful
aggregation of budget proposals  in proc  of 20th acm-ec
conference  pages 751–752  2019 
 gini  1912  corrado  gini  variabilit a e mutabilit a  con-
tributo allo studio delle distribuzioni e delle relazioni
statistiche  p  cuppini  1912 
 goel et al   2019  ashish goel  anilesh k  krishnaswamy 
sukolsak sakshuwong  and tanja aitamurto  knapsack
voting  voting mechanisms for participatory budgeting 
acm transaction on economics and computation  pages
8 1–8 27  2019 
 hershkowitz et al   2021  d 
ellis
hershkowitz 
anson
kahng  dominik peters  and ariel d  procaccia  district-
fair participatory budgeting  in proc  of 35th aaai con-
ference  2021 
 jain et al   2020  pallavi jain  krzysztof sornat  and nim-
rod talmon  participatory budgeting with project interac-
tions  in proc  of 29th ijcai  pages 386–392  2020 
 karp  1972  richard m  karp  reducibility among combi-
natorial problems  in proc  of symposium on the complex-
ity of computer computations  pages 85–103  springer 
1972 
 lackner  2020  martin lackner  perpetual voting  fairness
in long-term decision making  in proc  of 34th aaai con-
ference  pages 2103–2110  2020 
 laruelle  2021  annick laruelle  voting to select projects in
participatory budgeting  european journal of operational
research  288 2  598–604  2021 
 lu and boutilier  2011  tyler lu and craig boutilier  bud-
geted social choice  from consensus to personalized de-
cision making  in proc  of 22nd ijcai  pages 280–286 
2011 
 new york city council  2020  new york city council 
participatory budgeting 
https //council nyc gov/pb/ 
2020  last accessed on october the 8th 2020 
 peters et al   2020  dominik peters  grzegorz pierczy nski 
and piotr skowron  proportional participatory budgeting
with cardinal utilities  arxiv preprint arxiv 2008 13276 
2020 
 rey et al   2020  simon rey  ulle endriss  and ronald
de haan  designing participatory budgeting mechanisms
grounded in judgment aggregation  in proc  of 17th kr
conference  2020 
 shah  2007  anwar shah  editor  participatory budgeting 
public sector governance and accountability series  the
world bank  washington  dc  2007 
 shapiro and talmon  2017  ehud shapiro and nimrod tal-
mon 
a participatory democratic budgeting algorithm 
arxiv preprint arxiv 1709 05839  2017 
 skowron et al   2020  piotr skowron  arkadii slinko  sta-
nisław szufa 
and nimrod talmon 
participatory
budgeting with cumulative votes 
arxiv preprint
arxiv 2009 02690  2020 
 talmon and faliszewski  2019  nimrod talmon and piotr
faliszewski  a framework for approval-based budgeting
methods  in proc  of 33rd aaai conference  2019 
proceedings of the thirtieth    ijcai-21 
305
 "
None,2021,https-www-ijcai-org-proceedings-2021-0043-pdf,Strategyproof Randomized Social Choice for Restricted Sets of Utility Functions,Patrick Lederer,None,https://www.ijcai.org/proceedings/2021/0043.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0043-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0043-pdf.pdf,"strategyproof randomized social choice for restricted sets of utility functions
patrick lederer
technische universti¨at m¨unchen
ledererp@in tum de
abstract
when aggregating preferences of multiple agents 
strategyproofness is a fundamental requirement 
for randomized voting rules  so-called social de-
cision schemes  sdss   strategyproofness is usu-
ally formalized with the help of utility functions 
a classic result shown by gibbard in 1977 char-
acterizes the set of sdss that are strategyproof
with respect to all utility functions and shows that
these sdss are either indecisive or unfair 
for
finding more insights into the trade-off between
strategyproofness and decisiveness  we propose the
notion of u-strategyproofness which requires that
only voters with a utility function in the set u
cannot manipulate  in particular  we show that if
the utility functions in u value the best alterna-
tive much more than other alternatives  there are u-
strategyproof sdss that choose an alternative with
probability 1 whenever all but k voters rank it first 
we also prove for rank-based sdss that this large
gap in the utilities is required to be strategyproof
and that the gap must increase in k  on the nega-
tive side  we show that u-strategyproofness is in-
compatible with condorcet-consistency if u satis-
fies minimal symmetry conditions and there are at
least four alternatives  for three alternatives  the
condorcet rule can be characterized based on u-
strategyproofness for the set u containing all equi-
distant utility functions 
1
introduction
when a group of agents wants to find a joint decision in a
structured way  they can choose from a multitude of differ-
ent voting rules  however  it is not clear which rule is the
best one as each one has its benefits  this problem lies at
the core of social choice theory which draws increased atten-
tion by computer scientists because it can be used to reason
about computational multi-agent systems  see  e g    cheva-
leyre et al   2007  brandt et al   2013  brandt et al   2016b 
endriss  2017    a fundamental requirement for voting rules
is strategyproofness  i e   agents should not be able to benefit
by lying about their preferences  in a seminal result  gib-
bard  1973  and satterthwaite  1975  have shown that every
deterministic strategyproof voting rule is dictatorial if there
are at least three different outcomes possible 
randomization allows to escape this impossibility the-
orem  and we analyze therefore social decision schemes
 sdss   these functions aggregate the preferences of agents
to lotteries over alternatives which determine for every alter-
native its winning chances  the final winner is then decided
by chance according to these probabilities  while this model
allows to circumvent many impossibilities  it is not straight-
forward how to define strategyproofness because the voters 
preferences over lotteries are unclear  maybe the most promi-
nent approach is to assume that voters use cardinal utility
functions on the alternatives to compare lotteries with respect
to their expected utilities  however  voters still report ordi-
nal preference relations to the sds and hence  strategyproof-
ness is defined by quantifying over utility functions  an sds
is strategyproof if voting honestly maximizes the expected
utility for every voter and every utility function that is con-
sistent with his true preferences  this strategyproofness no-
tion  often called sd-strategyproofness  has been analyzed
by gibbard  1977  and barber a  1979  who prove that all
sd-strategyproof sdss are indecisive because they almost
always randomize over multiple alternatives 
even more 
benoˆıt  2002  has shown that sd-strategyproofness is in-
compatible with the basic democratic idea that an alternative
should be the winner of an election if an absolute majority of
the voters report it as their best alternative 
while it is unfortunate that sd-strategyproofness does not
allow for decisive sdss  this strategyproofness notion seems
also too demanding for because in many applications not all
utility functions are plausible  for instance  when a repre-
sentative body votes about budget proposals  it seems rea-
sonable that similar proposals have similar utilities  thus 
we might neglect utility functions with a large gap between
such options when discussing strategyproofness  this obser-
vation leads to the new notion of u-strategyproofness which
requires that truth telling only maximizes the expected utility
of a voter if his utility function is in the set u  note that u-
strategyproofness does not forbid utility functions u ̸∈ u  but
voters with such utility functions might be able to manipulate 
u-strategyproofness allows for a more detailed analy-
sis than sd-strategyproofness because we can analyze the
exact set of utility functions u for which an sds is u-
strategyproof  conversely  we can also formulate strong im-
proceedings of the thirtieth    ijcai-21 
306
 possibility results based on u-strategyproofness for severely
restricted sets u and thus  we can pinpoint the source of ma-
nipulability far more detailed than with other strategyproof-
ness notions  hence  u-strategyproofness offers both the pos-
sibility of positive results by finding u-strategyproof sdss
for large sets u  and of strong impossibility results by using
only a small number of utility functions  furthermore  in-
formation about u-strategyproofness can also be valuable in
practice  if the social planner can roughly guess the utility
functions of the voters  he might be able to choose an sds
preventing manipulations  even if the social planner does
not have such insights  he might opt for an sds that is u-
strategyproof for a large set u as such an sds is immune to
manipulations from most voters 
other than introducing u-strategyproofness  we use this
new notion to investigate the trade-off between strategyproof-
ness and decisiveness  on the positive side  we show that
there are u-strategyproof sdss that assign an alternative
probability 1 whenever all but k > 0 voters agree that it is the
best option if the utility functions in u value the best alter-
native much more than the other alternatives  moreover  we
prove for rank-based sdss that this gap in the utility func-
tions is required to be strategyproof and that it must increase
in k  on the other hand  we show that condorcet-consistency
is incompatible with u-strategyproofness if the set u satis-
fies minimal symmetry conditions between preference rela-
tions and there are m ≥ 4 alternatives  if there are only three
alternatives and an odd number of voters  the condorcet rule
is characterized by u-strategyproofness for the set u of all
equi-distant utility functions and condorcet-consistency  the
proofs of these theorems and of all propositions are omitted
because of space limitations 
2
related work
to our knowledge  we are the first authors who explicitly in-
vestigate u-strategyproofness  nevertheless  ideas similar to
u-strategyproofness have been used before 
for instance 
sen  2011  and mennle and seuken  2021  define strate-
gyproofness by considering restricted sets of utility functions
and thus  their works can be interpreted as first results on
u-strategyproofness  moreover  in set-valued social choice
 where the outcome of an election is a non-empty set of al-
ternatives instead of a lottery  preferences over sets of alter-
natives are often derived from utility functions  for instance 
duggan and schwartz  2000  and benoˆıt  2002  employ this
approach to motivate their strategyproofness notions  the re-
lationship between these results and u-strategyproofness is
discussed in more detail in section 4 
there are also various results on other strategyproofness
notions in randomized social choice  see  e g    gibbard 
1977  hoang  2017  aziz et al   2018  brandl et al   2018   
many of which are surveyed by brandt  2017   these re-
sults either prove the incompatibility of strategyproofness
with other axioms or characterize specific sdss  our results
differ from previous ones as we investigate a different ques-
tion  instead of asking whether an sds is strategyproof ac-
cording to some definition  we ask for which utility functions
it is strategyproof 
moreover  strategyproofness is often considered for re-
stricted domains of preference profiles  see  e g    ehlers et
al   2002  bogomolnaia et al   2005  chatterji and zeng 
2018    for instance  bogomolnaia et al   2005  discuss an at-
tractive sd-strategyproof sds for dichotomous preferences 
u-strategyproofness can be interpreted similarly  but we fo-
cus on utility functions instead of preference profiles  u-
strategyproof sdss are immune to manipulations if we only
allow utility functions in u 
another field related to u-strategyproofness is cardinal so-
cial choice  where the input of social decision schemes con-
sists of the utility functions of the voters  if we allow all
utility functions as input  every strategyproof cardinal sds
is  under mild additional assumptions  a variant of a random
dictatorship  see  e g    hylland  1980  dutta et al   2007 
nandeibam  2013    as noted by dutta et al   2007   these
negative results break down if the domain of cardinal sdss
is restricted  but this setting is not well understood 
our
results provide insights in this problem because every u-
strategyproof sds can be interpreted as a cardinal sds that
is strategyproof on the domain u 
finally  note that our model assumptions are quite similar
to those used in the analysis of the distortion of sdss  see 
e g    procaccia and rosenschein  2006  gross et al   2017 
abramowitz et al   2019    just as these authors  we assume
that voters only report ordinal preferences but use utility func-
tions to evaluate the quality of a lottery  whereas distortion
focuses on the welfare of sdss  we investigate their resis-
tance to strategic behavior of voters 
3
preliminaries
let n =  1          n  be a finite set of voters and let a be a set
containing m alternatives  a preference relation is an anti-
symmetric  transitive  complete  and reflexive binary relation
on a and ri denotes the preference relation of voter i  we
compactly represent preference relations as comma-separated
lists  let r denote the set of all preference relations on a  a
preference profile r is an n-tuple containing the preference
of every voter i ∈ n  i e   r ∈ rn  when writing preference
profiles  we indicate the corresponding voter directly before
the preference relation to clarify which voter submits which
preference relation  for example  1   a  b  c indicates that
voter 1 reports that he prefers a to b to c 
in this paper  we discuss social decision schemes  sdss  
which are functions that map preference profiles to lotteries
on a  a lottery p is a function from the set of alternatives
a to the interval  0  1  such that �
x∈a p x  = 1  let ∆ a 
denote the set of all lotteries on a  formally  a social decision
scheme is a function f   rn → ∆ a  and we denote with
f r  x  the probability assigned to x by the lottery f r  
the definition of sdss allows for a huge variety of func-
tions  some of which seem not desirable  therefore  we in-
troduce axioms to narrow down the set of sdss  two basic
fairness axioms are anonymity and neutrality  which require
that voter and alternatives  respectively  are treated equally 
more formally  an sds f is anonymous if f r  = f π r  
for all profiles r and permutations π   n → n  and neu-
tral if f r  x  = f τ r   τ x   for all alternatives x ∈ a 
proceedings of the thirtieth    ijcai-21 
307
 profiles r  and permutations τ   a → a 
another nat-
ural axiom is unanimity  which requires of an sds f that
f r  x  = 1 for all preference profiles r in which all voters
agree that x is the best choice  while this axiom is so weak
that is often considered indisputable  it is also irrelevant in
practice as ballots are usually not unanimous  therefore  we
introduce the stronger notion of k-unanimity  an sds f is
k-unanimous if f r  x  = 1 whenever n − k or more vot-
ers report x as the best alternative  by definition  unanim-
ity is equal to 0-unanimity and note that k-unanimity is only
well-defined if k <
n
2   a well-known strengthening of k-
unanimity is condorcet-consistency  for defining this axiom 
let nxy r  = | i ∈ n   xriy | − | i ∈ n   yrix | denote
the majority margin between two alternatives x  y ∈ a in
the preference profile r  an alternative x is the condorcet
winner in a preference profile r if nxy r  > 0 for all other
alternatives y ∈ a\ x   less formally  an alternative x is the
condorcet winner if it is preferred to every other alternative
by a majority of the voters  finally  an sds f is condorcet-
consistent if f r  x  = 1 for all profiles r and alternatives
x ∈ a such that x is the condorcet winner in r 
an important class of sdss are rank-based sdss  the ba-
sic idea of these schemes is that voters assign ranks to the
alternatives and that an sds should only rely on these ranks 
but not on which voter assigns which rank to an alternative 
for formalizing this concept  we denote with r ri  x  =
| y ∈ a  yrix | the rank of alternative x in voter i s prefer-
ence relation  moreover  we define the rank vector r∗ r  x 
as the vector that contains the rank of x with respect to every
voter in increasing order  i e   r∗ r  x i ≤ r∗ r  x i 1 for all
i ∈  1          n − 1   and the rank matrix r∗ r  as the matrix
that contains the rank vectors of all alternative as rows  fi-
nally  we call an sds f rank-based if it only depends on the
rank matrix  i e   f r  = f r′  for all preference profiles r 
r′ with r∗ r  = r∗ r′   the set of rank-based sdss con-
tains many prominent functions such as point scoring rules
and anonymous sdss that only depend on the first-ranked al-
ternatives of the voters 
4
u-strategyproofness
a central problem in social choice is that of manipulability 
voters may lie about their preferences to achieve a better out-
come  while the definition of a manipulation is easy if an
sds never randomizes between multiple alternatives  it is not
clear how to compare non-degenerate lotteries  a classical
approach for this problem is to assume that voters are en-
dowed with utility functions ui   a → r  we impose the
constraint that no voter assigns the same utility to two alter-
natives  i e   ui x  ̸= ui y  for all voters i ∈ n and alterna-
tives x  y ∈ a  to ensure that the ordinal preference relation
induced by a utility function is anti-symmetric  we denote
with u the set of all such utility functions and say that a util-
ity function u ∈ u is consistent with a preference relation r
if u x  ≥ u y  iff xry for all alternatives x  y ∈ a  finally 
each voter i uses his utility function ui to compare lotteries by
their expected utilities e p ui = �
x∈a p x ui x   i e   voter
i prefers lottery p weakly to lottery q if e p ui ≥ e q ui 
even though we assume the existence of utility functions 
voters only report ordinal preferences  consequently  strate-
gyproofness is often defined by quantifying over utility func-
tions  in particular  gibbard  1977  employs this approach to
define sd-strategyproofness  an sds f is sd-strategyproof
if e f r  ui ≥ e f r′  ui for all voters i ∈ n  preference
profiles r  r′  and utility functions ui ∈ u such that ui is
consistent with ri and rj = r′
j for all j ∈ n \  i   while
sd-strategyproofness allows for strong negative results  see 
e g   gibbard  1977  barber a  1979    it lacks relevance for
many practical applications as not all utility functions are
plausible  also  sd-strategyproofness provides often only
shallow theoretical insights as it is not possible to pinpoint
the source of manipulability 
in order to address these problems  we introduce a new
strategyproofness notion by restricting the set of feasible util-
ity functions u beforehand  an sds f is u-strategyproof if
e f r  ui ≥ e f r′  ui for all voters i ∈ n  preference pro-
files r  r′  and utility functions ui ∈ u such that ui is consis-
tent with ri and rj = r′
j for all j ∈ n \  i   less formally 
u-strategyproofness only requires that voters with a utility
function in u cannot increase their expected utility by mis-
representing their preferences  hence  u-strategyproofness
is equal to sd-strategyproofness and smaller sets of utility
functions result in less demanding strategyproofness notions 
note that u-strategyproofness solves both problems of sd-
strategyproofness  we can investigate whether an sds is ma-
nipulable in practice by dismissing implausible utility func-
tions  and we can find the core of impossibility results by
determining the minimally required set of utility functions 
next  we discuss an example to illustrate the difference be-
tween u-strategyproofness and sd-strategyproofness 
example 1  consider the profiles r1 and r2 shown be-
low and let f denote an sds such that f r1  x  =
1
3 for
x ∈  a  b  c  and f r2  b  = 1  moreover  consider the util-
ity functions u1  u2  and u3 with u1 a  = 2  u1 b  = 1 
u1 c  = 0  u2 a  = 3  u2 b  = 1  u2 c  = 0  u3 a  = 3 
u3 b  = 2  and u3 c  = 0  these utility functions are only
consistent with voter 1 s preference relation in r1  and thus 
we can check whether this voter can benefit by deviating to
r2 
a quick calculation shows that e f r1  u1 = 1 =
e f r2  u1  e f r1  u2 =
4
3 > 1 = e f r2  u2  and
e f r1  u3 =
5
3 < 2 = e f r2  u3  hence  voter 1 can
increase his expected utility if his utility function is u3 and
thus  f is sd-manipulable  in contrast  voter 1 does not ben-
efit from deviating to r2 if his utility function is u1 or u2 
since the preferences of the other voters are not consistent
with u1  u2  and u3  it follows that f is  u1  u2 -strategyproof
on these two profiles 
r1 
1  a  b  c
2  b  c  a
3  c  a  b
r2 
1  b  a  c
2  b  c  a
3  c  a  b
in our results  we always consider u-strategyproofness for
symmetric sets u  i e   we assume that u ∈ u implies that
uπ = u ◦ π ∈ u for every permutation π on a 
this
formalizes the natural condition that all preference relations
should be treated equally  moreover  the symmetry condition
is rather weak since every neutral sds is u ′-strategyproof for
a symmetric set u ′ if it is u-strategyproof for a set u ̸= ∅ 
proceedings of the thirtieth    ijcai-21 
308
 proposition 1  if a neutral sds is u-strategyproof for a set
u ̸= ∅  it is u ′-strategyproof for a symmetric set u ′ with
u ⊆ u ′ 
a special case of our symmetry assumption is that u con-
sists of a single utility function u and its renamings  i e   that
u =  u ◦ π  π ∈ π   where π denotes the set of all permu-
tations on a  in this case  we write uπ-strategyproofness in-
stead of u-strategyproofness  note that uπ-strategyproofness
associates every preference relation with exactly one utility
function  whereas  u -strategyproofness  i e   strategyproof-
ness for a single utility function u  only affects a single pref-
erence relation  since the utility of an alternative only de-
pends on its rank for uπ-strategyproofness  we often write
u k  to denote the utility of the k-th best alternative of a
voter  as the next proposition shows  it suffices to consider
uπ-strategyproofness or even  u -strategyproofness because
for every sds f and every preference relation ri  the set of
utility functions u that are consistent with ri and for which
f is strategyproof is convex 
proposition 2  for every sds f and preference relation ri 
the set uri =  u ∈ u   u is consistent with ri and f is
 u -strategyproof  is convex 
we can use this proposition to show that an sds is u-
strategyproof for a large set u by proving that it is uπ
i -
strategyproof for a few utility functions ui ∈  u1          ul  
assuming that u1          ul are all consistent with a preference
relation ri  it follows then from proposition 2 that the sds is
ˆuπ-strategyproof for every utility function ˆu that can be rep-
resented as a convex mixture of u1          ul  which means that
it is u-strategyproof for a large set u 
next  note that u-strategyproofness inherits many attrac-
tive properties from sd-strategyproofness  for instance  the
convex combination of u-strategyproof sdss is itself u-
strategyproof  i e   the set of u-strategyproof sdss is con-
vex for every set u  as a consequence of this observation  it
is often possible to construct an anonymous u-strategyproof
sds based on a non-anonymous u-strategyproof sds 
another similarity between u-strategyproofness and sd-
strategyproofness is that both axioms disincentivize even ma-
nipulations from groups of voters with the same preferences 
finally  observe that u-strategyproofness can be used to
transfer results from set-valued social choice to the proba-
bilistic setting  we explain this relation using the impossibil-
ity result of benoˆıt  2002  as example  this theorem states
that strategyproofness is incompatible with 1-unanimity for
set-valued social choice functions if voters prefer every sub-
set of their best two alternatives to every other set and other in
our model negligible conditions are satisfied  for formulating
this result for sdss  we have to compare lotteries only based
on their support supp p  =  x ∈ a  p x  > 0   hence 
let ϵf = minx∈a r∈rn f r x >0 f r  x  denote the smallest
non-zero probability assigned to an alternative by the sds f
and note that ϵf is well-defined since sdss are defined for
a fixed set of alternatives and voters  given this probabil-
ity  we derive that every voter whose utility function u sat-
isfies u 2  >  1 − ϵf u 1    ϵfu 3  prefers every lottery
that randomizes only over his best two alternatives to every
other lottery  after rearranging this equation  we can formu-
late benoˆıt s impossibility as follows 
proposition 3  no sds f satisfies both uπ-strategyproofness
and 1-unanimity if u 1 −u 2  <
ϵf
1−ϵf  u 2 −u 3    m ≥ 3 
and n ≥ 3 
note that proposition 3 highlights the central requirement
of benoˆıt s impossibility theorem  voters must be close to
indifferent between their best two alternatives  this refines
benoˆıt s reasoning who justifies his strategyproofness notion
with voters who  like his or her two favorite alternatives
 much more  than the rest of the alternatives  1 based on
this approach  we can also formalize other impossibility re-
sults from set-valued social choice with u-strategyproofness 
5
results
in the sequel  we employ u-strategyproofness to analyze
the trade-off between strategyproofness and decisiveness 
in particular  we investigate two decisiveness axioms  k-
unanimity and condorcet-consistency 
the first axiom al-
lows for positive results if suitable utility functions are con-
sidered  whereas condorcet-consistency is incompatible with
uπ-strategyproofness for every utility function u ∈ u 
5 1
k-unanimity
a central result of gibbard  1977   who attributes it to hugo
sonnenschein  is that the sds called random dictatorship
 henceforth rd  is the only sd-strategyproof sds that sat-
isfies unanimity and anonymity 
this sds assigns an al-
ternative x in a profile r the probability
p l r x 
n
  where
pl r  x  = | i ∈ n   ∀y ∈ a   xriy | denotes the plu-
rality score of alternative x  a common method for executing
rd is to choose a voter uniformly at random and to return
his most preferred alternative as winner  while rd is one
of the most attractive sd-strategyproof sdss  it violates k-
unanimity for k > 0  even more  benoˆıt  2002  has shown
that every sd-strategyproof sds fails k-unanimity for k > 0 
however  we can define a variant of rd that satisfies both
k-unanimity for an arbitrary k ∈  0          ⌊ n−1
2 ⌋  and u-
strategyproofness for a large set of utility functions u  hence 
consider the following sds  which we call k-random dicta-
torship  abbreviated by rdk   if at least n − k voters agree
that alternative x is the best choice  assign alternative x a
probability of 1  otherwise  return the outcome of rd  as
we show in theorem 1  rdk satisfies u-strategyproofness
for u =  u ∈ u   u 1  − u 2  ≥ k u 2  − u m     i e   if
voters have a strong preference for the first alternative  rdk
is strategyproof  unfortunately  the definition of u depends
on k  i e   for large values of k  there must be an extremely
large gap between u 1  and u 2   another variant of rd 
which we refer to as omni ∗  solves this problem 
this
sds assigns probability 1 to an alternative x if more than
half of the voters report x as their best alternative  and oth-
erwise randomizes uniformly among all alternatives that are
1benoˆıt  2002  also discusses a variant for sdss in which he uses
the minimal non-zero probability assigned to an alternative  how-
ever  benoˆıt only gives an example showing that there is a suitable
utility function such that the required preferences over sets extend to
preferences over lotteries 
proceedings of the thirtieth    ijcai-21 
309
 at least once top-ranked  this sds is u-strategyproof for
u =  u ∈ u   u 1  − u 2  ≥ �m
i=3 u 2  − u i    while
omni ∗ satisfies ⌊ n−1
2 ⌋-unanimity for all numbers of voters
and alternatives  the condition on u seems only realistic if
there are few alternatives 
theorem 1  for every k ∈  1          ⌊ n−1
2 ⌋   rdk satis-
fies u-strategyproofness for u =  u ∈ u   u 1  − u 2  ≥
k u 2  − u m    and violates  u -strategyproofness for ev-
ery utility function u ̸∈ u 
moreover  omni ∗ satisfies
u-strategyproofness for u =  u ∈ u   u 1  − u 2  ≥
�m
i=3 u 2 −u i   and violates  u -strategyproofness for ev-
ery utility function u ̸∈ u 
the constraint on the set u for rdk arises naturally by
considering the preference profile in which n − k − 1 voters
top-rank the second best alternative of voter i and the remain-
ing k voters top-rank voter i s least preferred alternative  in
this situation  voter i can ensure that his second best alterna-
tive is chosen with probability 1 by reporting it as his best
one  solving the corresponding inequality required by u-
strategyproofness leads to the bound on u  a similar worst-
case analysis can be applied for omni ∗ 
while it is positive that k-unanimity and u-strategy-
proofness can be simultaneously satisfied at all  the bounds
on the sets u in theorem 1 become increasingly worse with
large k and m  this raises the question for less demanding
bounds on the utility functions  as our next theorem shows 
the approach used for defining rdk and omni ∗ has not
much space for improvement as both sdss are rank-based 
theorem 2  there is no rank-based sds that satisfies uπ-
strategyproofness and k-unanimity for 0 < k < n
2 if m ≥ 3 
n ≥ 3  and u 1  − u 2  < �m
i=max 3 m−k 1  u 2  − u i  
the proof of theorem 2 works by contradiction  we as-
sume that there is a k-unanimous rank-based sds f that
satisfies uπ-strategyproofness for a utility function u with
u 1  − u 2  < �m
i=max 3 m−k 1  u 2  − u i   moreover 
let k∗ = min k  m − 2   our analysis then starts at a pro-
file r where n − k∗ voters favor a the most  which implies
that f r  a  = 1 due to k-unanimity  the central argument
is a rather involved construction that shows that a voter can
weaken alternative a from the first rank to the second one
without affecting the outcome  by repeatedly applying this
construction  we eventually arrive at a profile r′ where only
k∗ voters top-rank a and the remaining voters top-rank b 
but f r′  a  = 1  this is in conflict with k-unanimity as
n−k∗ ≥ n−k voters report b as best choice but f r′  b  ̸= 1 
remark 1 
a computer-aided approach has shown that
there are rather technical sdss that satisfy k-unanimity and
uπ-strategyproofness for utility functions u with u 1  −
u 2  < �m
i=max 3 m−k 1  u 2  − u i  if we dismiss rank-
basedness and m ≤ 4  hence  rank-basedness is required
for theorem 2 
moreover  most bounds of the theorem
are tight 
if m = 2  omni ∗ and rdk are even sd-
strategyproof  and if n = 2  k-unanimity is not well-defined
for k > 0  furthermore  the condition on the utility func-
tions is almost tight  rd1 shows that the bound is tight for
1-unanimity  and omni ∗ shows that the bound is tight if
k
u 1 
1
2
3
4
5
3
6
9
12
no rank-based
sdss
rd
rd1
rd2
omni ∗
u 2 
figure 1  illustration of theorem 1 and theorem 2  we assume
that there are 5 alternatives and consider a utility function u with
u 2  = 3  u 3  = 2  u 4  = 1  and u 5  = 0 
the figure
shows for which values of u 1  the sdss rd  blue area   rd1
 green area   rd2  magenta area   and omni ∗  orange area  are
uπ-strategyproof on the vertical axis  the horizontal axis illustrates
the values of k for which these sdss are k-unanimous  the red area
displays the impossibility of theorem 2 and the gray area marks the
values of u 1  with u 1  < u 2  
k ≥ m − 2  finally  rdk shows that no constraint of the
type u 1  − u 2  ≤ �m
i=m−k 1 u 2  − u i    ϵ with ϵ > 0
can result in an impossibility because we can always find a
utility function u such that �m
i=m−k 1 u 2  − u i    ϵ ≥
u 1  − u 2  ≥ k u 2  − u m   by making the difference be-
tween u i  and u m  for i ≥ 3 sufficiently small  neverthe-
less  it remains open to find rank-based sdss that satisfy u-
strategyproofness and k-unanimity for u =  u ∈ u   u 1  −
u 2  = �m
i=m−k 1 u 2  − u i   and 2 ≤ k ≤ m − 3 
remark 2 
theorem 1 and theorem 2 have an intuitive in-
terpretation  if voters strongly prefer their best alternative  it
becomes possible to achieve strategyproofness and decisive-
ness  this follows as strategyproofness is compatible with k-
unanimity if there is a sufficiently large gap between u 1  and
u 2   in contrast  it is impossible that an sds satisfies both
axioms if voters are close to indifferent between their best
two alternatives  for the class of general sdss  this is shown
by benoˆıt  2002   and for the class of rank-based sdss  the-
orem 2 significantly weakens the requirements on the utility
functions 
remark 3 
figure 1 illustrates the results of this section 
for this figure  we assume that there are 5 alternatives and
a large number of voters n ≥ 11  and we fix all utilities
but u 1  
hence  we can compute the values of u 1  for
all sdss of theorem 1 such that the considered sds is uπ-
strategyproof  the figure shows that for rdk  the required
value of u 1  increases in k and the bound of omni ∗ is in-
dependent of k  moreover  the required values of u 1  are
quite large compared to u 2  for all sdss but rd  however 
the red area shows the values of u 1  for which theorem 2 ap-
plies and hence  these large values are indeed required  the
white area shows that there is a small gap between the posi-
tive results in theorem 1 and the impossibility in theorem 2 
proceedings of the thirtieth    ijcai-21 
310
 5 2
condorcet-consistency
as there are even rank-based sds that are k-unanimous and
u-strategyproof for large sets u  the question arises whether
stronger decisiveness notions can be achieved by dismissing
rank-basedness  unfortunately  we find a negative answer to
this question by considering condorcet-consistency 
theorem 3  there is no condorcet-consistent sds that sat-
isfies uπ-strategyproofness regardless of the utility function u
if m ≥ 4  n ≥ 5 and n ̸= 6  n ̸= 8 
the proof of this result works by contradiction and relies
on a case distinction on the utility function u  if u 1 −u 2  <
u 2 −u m   the utility of the second best alternative is larger
than the average utility  which means that a voter can manipu-
late by making his second best alternative into the condorcet
winner  if u 1  − u m − 1  > u m − 1  − u m   voters
value their second worst alternative less than the uniform lot-
tery  as a consequence  there is a voter who can manipu-
late by weakening his second worst alternative such that it
is no longer the condorcet winner  finally  note that these
two cases are exhaustive  the strictness of the utility func-
tion u entails that u m − 1  − u m  < u 1  − u m − 1  if
u 1  − u 2  ≥ u 2  − u m  and m ≥ 4 
a close inspection of the proof shows that the impossibil-
ity also holds if m = 3 unless u only contains equi-distant
utility functions  i e   utility functions with u 1  − u 2  =
u 2  − u 3  
this raises the question whether there is a
u-strategyproof sds that satisfies condorcet-consistency in
this special case  indeed  the condorcet rule  abbreviated by
cond   which assigns probability 1 to the condorcet win-
ner whenever it exists and returns the uniform lottery over all
alternatives otherwise  satisfies u-strategyproofness for this
set  even more  the condorcet rule is uniquely characterized
by these axioms if n is odd 
theorem 4  cond is the only condorcet-consistent sds
that satisfies u-strategyproofness for u =  u ∈ u   u 1  −
u 2  = u 2  − u 3   if m = 3 and n is odd 
it is easy to show that the condorcet-rule is u-
strategyproof for u =  u ∈ u   u 1  − u 2  = u 2  − u 3  
if m = 3 because the uniform lottery on all three alternatives
has for every voter the expected utility of u 2   hence  the
proof mainly focuses on why no other condorcet-consistent
sds f satisfies u-strategyproofness for this set u  for this 
we show that there is a profile r and a voter i such that voter
i s expected utility e f r  u is less than u 2   moreover  this
voter can either make his second best alternative into the con-
dorcet winner or revert to a preference profile in which each
alternative is chosen with a probability of 1
3  as both cases
yield an expected utility of u 2  for voter i  we have found a
contradiction to u-strategyproofness 
remark 4 
the condorcet rule is also u-strategyproof for
the set of equi-distant utility functions if m = 3 and n is even 
however  other sdss satisfy condorcet-consistency and u-
strategyproofness for even n  too  for instance  the sds that
assigns the condorcet winner probability 1 whenever it exists
and uniformly randomizes among the top-ranked alternatives
otherwise satisfies also all required axioms  the proof for this
claim relies on the insight that every voter has a utility of at
least u 2  in the absence of a condorcet winner 
remark 5 
a well-known class of sdss are tournament so-
lutions which only depend on the majority relation rm =
  x  y  ∈ a2   nxy r  ≥ nyx r   of the input profile r to
compute the outcome  for these sdss  unanimity and uπ-
strategyproofness entail condorcet-consistency  thus  there
are no unanimous and uπ-strategyproof tournament solu-
tions  regardless of the utility function u  if m ≥ 4  this is
in harsh contrast to results for set-valued social choice  where
attractive tournament solutions satisfy various strategyproof-
ness notions  see  e g    brandt et al   2016a   
remark 6 
the proof of theorem 3 also reveals more
insights about the compatibility of k-unanimity and uπ-
strategyproofness for general sdss 
in particular  the
first case shows that no ⌈ n
3 ⌉-unanimous sds can be uπ-
strategyproof for a utility function u with u 1  − u 2  <
u 2  − u m  if m ≥ 4 and n ≥ 3 
6
conclusion and discussion
we
study
a
new
strategyproofness
notion
called
u-
strategyproofness 
whereas the common notion of sd-
strategyproofness is derived by quantifying over all utility
functions  u-strategyproofness is derived by quantifying only
over the utility functions in a specified set u  this new strate-
gyproofness notion arises from practical observations as often
not all utility functions are plausible  and also has theoretical
advantages because it allows for a much finer analysis than
sd-strategyproofness  furthermore  we analyze the compat-
ibility of u-strategyproofness and decisiveness axioms such
as k-unanimity and condorcet-consistency  in particular  we
discuss sdss that satisfy k-unanimity for any k with 0 < k <
n/2 and u-strategyproofness if the set u only contains utility
functions u for which u 1 −u 2  is sufficiently large  more-
over  we show for rank-based sdss that the large gap between
u 1  and u 2  is required to be strategyproof and has to in-
crease in k  we also prove that u-strategyproofness is incom-
patible with condorcet-consistency if the set u is symmetric
and m ≥ 4  this impossibility also holds if m = 3 unless
the utility functions in u are equi-distant  in this special case
and if n is odd  the condorcet rule can be characterized by
u-strategyproofness and condorcet-consistency 
our results have a very intuitive interpretation  strate-
gyproofness is only compatible with decisiveness if each
voter has a clear best alternative  even more  the more de-
cisiveness is required  the stronger voters have to favor their
best alternative 
this conclusion is highlighted by theo-
rems 1 and 2 as well as the impossibility of benoˆıt  2002  
moreover  it coincides with the informal argument that it is
easier to manipulate for a voter who deems many alternatives
acceptable as he can just report another acceptable alternative
as his best one  hence  our results show that the main source
of manipulability are voters who are close to indifferent be-
tween some alternatives 
acknowledgments
this work was supported by the deutsche forschungsge-
meinschaft under grant br 2312/12-1  i thank the anony-
mous reviewers and felix brandt for helpful comments 
proceedings of the thirtieth    ijcai-21 
311
 references
 abramowitz et al   2019  ben abramowitz  elliot anshele-
vich  and whennan zhu  awareness of voter passion
greatly improves the distortion of metric social choice 
in proceedings of the 15th international conference
on web and internet economics  pages 3–16  springer 
2019 
 aziz et al   2018  haris aziz  florian brandl  felix brandt 
and markus brill  on the tradeoff between efficiency
and strategyproofness 
games and economic behav-
ior  110 1–18  2018 
preliminary results appeared in
the proceedings of aaai-2013 and aamas-2014 
 barber a  1979  salvador barber a  majority and positional
voting in a probabilistic framework 
review of eco-
nomic studies  46 2  379–389  1979 
 benoˆıt  2002  jean-pierre benoˆıt 
strategic manipulation
in voting games when lotteries and ties are permitted 
journal of economic theory  102 2  421–436  2002 
 bogomolnaia et al   2005  anna
bogomolnaia 
herv e
moulin  and richard  stong  collective choice under
dichotomous preferences  journal of economic theory 
122 2  165–184  2005 
 brandl et al   2018  florian brandl  felix brandt  manuel
eberl  and christian geist  proving the incompatibil-
ity of efficiency and strategyproofness via smt solving 
journal of the acm  65 2  1–28  2018  preliminary re-
sults appeared in the proceedings of ijcai-2016 
 brandt et al   2013  felix brandt  vincent conitzer  and
ulle endriss  computational social choice  in g  weiß 
editor  multiagent systems  chapter 6  pages 213–283 
mit press  2nd edition  2013 
 brandt et al   2016a  felix brandt  markus brill  and paul
harrenstein 
tournament solutions 
in felix brandt 
vincent conitzer  ulle endriss  j erˆome lang  and
ariel d  procaccia  editors  handbook of computa-
tional social choice  chapter 3  cambridge university
press  2016 
 brandt et al   2016b  felix brandt  vincent conitzer  ulle
endriss  j erˆome lang  and ariel d  procaccia  editors 
handbook of computational social choice  cambridge
university press  2016 
 brandt  2017  felix brandt  rolling the dice  recent re-
sults in probabilistic social choice  in u  endriss  edi-
tor  trends in computational social choice  chapter 1 
pages 3–26  ai access  2017 
 chatterji and zeng  2018  shurojit chatterji and huaxia
zeng 
on random social choice functions with the
tops-only property 
games and economic behavior 
109 413–435  2018 
 chevaleyre et al   2007  yann chevaleyre 
ulle endriss 
j erˆome lang  and nicolas maudet  a short introduc-
tion to computational social choice  in proceedings of
the 33rd conference on current trends in theory and
practice of computer science  sofsem   volume 4362
of lecture notes in computer science  lncs   pages
51–69  springer-verlag  2007 
 duggan and schwartz  2000  john duggan and thomas
schwartz 
strategic manipulability without resolute-
ness or shared beliefs  gibbard-satterthwaite general-
ized  social choice and welfare  17 1  85–93  2000 
 dutta et al   2007  bhaskar
dutta 
hans
peters 
and
arunava
sen 
strategy-proof
cardinal
decision
schemes  social choice and welfare  28 1  163–179 
2007 
 ehlers et al   2002  lars ehlers  hans peters  and ton stor-
cken  strategy-proof probabilistic decision schemes for
one-dimensional single-peaked preferences  journal of
economic theory  105 2  408–434  2002 
 endriss  2017  ulle endriss  editor 
trends in computa-
tional social choice  ai access  2017 
 gibbard  1973  allan gibbard 
manipulation of voting
schemes  a general result  econometrica  41 4  587–
601  1973 
 gibbard  1977  allan gibbard 
manipulation of schemes
that mix voting with chance  econometrica  45 3  665–
681  1977 
 gross et al   2017  stephen gross  elliot anshelevich  and
lirong xia  vote until two of you agree  mechanisms
with small distortion and sample complexity  in pro-
ceedings of the 31st aaai conference on artificial in-
telligence  aaai   pages 544–550  2017 
 hoang  2017  lˆe nguyˆen hoang  strategy-proofness of the
randomized condorcet voting system 
social choice
and welfare  48 3  679–701  2017 
 hylland  1980  aanund hylland  strategyproofness of vot-
ing procedures with lotteries as outcomes and infinite
sets of strategies  mimeo  1980 
 mennle and seuken  2021  timo mennle and sven seuken 
partial strategyproofness  relaxing strategyproofness
for the random assignment problem  journal of eco-
nomic theory  191 105–144  2021 
 nandeibam  2013  shasikanta nandeibam  the structure of
decision schemes with cardinal preferences  review of
economic design  17 3  205–238  2013 
 procaccia and rosenschein  2006  ariel d  procaccia and
jeffrey s  rosenschein  the distortion of cardinal pref-
erences in voting  in proceedings of 10th international
workshop on cooperative information agents  pages
317––331  springer  2006 
 satterthwaite  1975  mark allen satterthwaite 
strategy-
proofness and arrow s conditions  existence and cor-
respondence theorems for voting procedures and so-
cial welfare functions 
journal of economic theory 
10 2  187–217  1975 
 sen  2011  arunava sen  the gibbard random dictatorship
theorem  a generalization and a new proof  series 
2 4  515–527  2011 
proceedings of the thirtieth    ijcai-21 
312
 "
None,2021,https-www-ijcai-org-proceedings-2021-0044-pdf,Budget-feasible Mechanisms for Representing Groups of Agents Proportionally,"Xiang Liu, Hau Chan, Minming Li, Weiwei Wu",None,https://www.ijcai.org/proceedings/2021/0044.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0044-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0044-pdf.pdf,"budget-feasible mechanisms for representing groups of agents proportionally
xiang liu1   hau chan2   minming li3 and weiwei wu1 ∗
1southeast university  china
2university of nebraska–lincoln  nebraska  usa
3city university of hong kong  hong kong sar  china
xiangliu@seu edu cn  hchan3@unl edu  minming li@cityu edu hk  weiweiwu@seu edu cn
abstract
in this paper  we consider the problem of designing
budget-feasible mechanisms for selecting agents
with private costs from various groups to ensure
proportional representation  where the minimum
proportion of the selected agents from each group
is maximized  depending on agents  membership
in the groups  we consider two main models  single
group setting where each agent belongs to only one
group  and multiple group setting where each agent
may belong to multiple groups  we propose novel
budget-feasible proportion-representative mecha-
nisms for these models  which can select repre-
sentative agents from different groups  the pro-
posed mechanisms guarantee theoretical properties
of individual rationality  budget-feasibility  truth-
fulness  and approximation performance on propor-
tional representation 
1
introduction
selecting a proper number of agents from each group to
fairly represent the population of each group has received
increased attention in recent years  for instance  selecting
a committee consisting of members from different groups
or hiring a set of workers of diverse attributes require mak-
ing selection decisions on a given set of population  e g  
see  bredereck et al   2018  cahuc and postel-vinay  2002 
lang and manove  2011    fair representations also can be
applied to the context of political poll or survey sampling
in which the organizer wishes to obtain a diverse set of re-
sponses from various groups of populations  bradburn et al  
2004  jackson et al   2020  
in fact  the consequences of
inadequate group representation can result in inaccurate ac-
counts/analysis  e g   inaccurate poll predictions due to lacks
of representative samples  jackson et al   2020   and discrim-
ination  e g   group discrimination when hiring workers  lang
and manove  2011    in various domains 
in addition to the challenge of achieving fair representa-
tion  in many settings  there is an inherited private agent cost
associated with selecting each agent  e g   salary in job hir-
ing or cost for conducting the survey  and the cost is internal
∗corresponding author
or not visible to the social planner  ideally  the planner elicits
cost information from the agents  determines the agents to se-
lect  and derives appropriate compensation or payment to the
selected agents  however  the agents can be strategic and do
not necessarily report their true cost  as a result  the social
planner must take into account whom to select to represent
groups when taking costs into consideration to ensure that
the total payment to all agents does not exceed the available
budget  e g   the budget for hiring or conducting studies  
the problem in hand can be cast naturally into a budget-
feasible mechanism design setting  singer  2010  where the
social planner seeks to design a computationally efficient
mechanism that elicits truthful cost information from the
agents  selects representative agents to represent each group
fairly  and ensures the total payment to the agents is no more
than the budget  more specifically  can we design a budget-
feasible mechanism which fairly selects agents from different
groups and guarantees desirable economic properties  while
guaranteeing a bounded total payment from the planner 
our contribution 
we consider the problem of design-
ing budget-feasible mechanisms for representing groups of
agents proportionally satisfying standard properties  i e   in-
dividual rationality  budget feasibility  and truthfulness   we
first adopt and formulate our objective to select agents that
maximizes the minimum proportion ratio of the selected
agents from each group  based on a well-studied notion of
proportional representation  e g   in electoral systems  
we consider two general models depending on whether
each agent belongs to  1  one group or  2  multiple groups
 in which the agents can be  2a  counted exactly once or
 2b  multi-counted  and design proportional representation
budget-feasible mechanisms for the models under our objec-
tive  the proposed mechanisms guarantee desirable theoret-
ical properties including budget feasibility  individual ratio-
nality  truthfulness  and approximation guarantee 
in particular  for  1   we construct a novel greedy mecha-
nism that considers all possible proportion ratios and appro-
priate payment schemes that select agents from each group
satisfying the ratios and ensuring budget feasibility  the pro-
posed mechanism achieves approximation performance that
depends on the size of the largest and smallest groups  more-
over  we show the asymptotic matching lower bound that
no budget-feasible proportion-representative mechanisms can
achieve better performance asymptotically 
proceedings of the thirtieth    ijcai-21 
313
 for the multiple group setting  2a  or  2b   we construct
a novel mechanism that leverages the max-flow algorithm to
test the proportional representation in the maximum matching
under a given agent set  in which we can find the candidate
agent set with the greatest proportional representation within
the budget constraint  we then apply the minimum weight
matching to identify the final selected agents from candidate
agents  whereby the tested maximum proportional represen-
tation can be obtained and the corresponding payment de-
termined  the designed mechanisms in this setting can also
achieve approximation performance that depends on the size
of groups 
related work  since the seminal work of  singer  2010  
many research efforts have been invested to design budget-
feasible mechanisms for various planner s valuation func-
tions   chen et al   2011  further develop improved mech-
anisms with better approximation ratio for the submodu-
lar value function  while  amanatidis et al   2017  consider
symmetric submodular valuations  a prominent class of non-
monotone submodular functions   anari et al   2014  design a
constant-approximation budget-feasible mechanism for large
markets where sellers  costs are far less than the buyer s bud-
get and show that it is impossible to achieve bounded ap-
proximation ratio without large market assumption when sell-
ers  items are divisible   singer and mittal  2013  focus on
designing pricing mechanisms with the objective to maxi-
mize the number of tasks while guaranteeing budget feasibil-
ity  these mechanisms in existing literature do not perform
well for our settings directly as they do not consider groups
and ensure proportional representation  several works take
the group attributes into account and consider the diversity
fairness when designing auction mechanisms  ilvento et al  
2020  kuo et al   2020  chawla and jagadeesan  2020   how-
ever  they all ignore the planner s budget constraint and can-
not guarantee the budget-feasibility  in this work  we want to
design proportion-representative mechanisms while ensuring
the budget constraint 
rather than the incentive mechanism design setting ad-
dressed in this paper  we note that proportional representation
has been studied from the optimization or algorithmic per-
spective in various areas such as voting and electoral systems 
for example   procaccia et al   2008  focus on analyzing the
complexity of achieving proportional representation   buis-
seret and prato  2020  consider the voter preferences in pro-
portional representation systems to understand the candidate
selection and behavior  in addition  there are works consider-
ing diversity fairness in matching/allocation problems  ben-
abbou et al   2020  ahmadi et al   2019  
2
preliminaries
in this section  we define the proportion-representative selec-
tion settings and the desirable properties of the mechanisms 
2 1
the model
we consider a scenario with a planner a and a set of n agents
s =  s1  s2       sn   the agents have group attributes  speci-
fying one or more groups the agent belongs to based on  e g  
genders  ages  ethnicities  regions and educational levels  the
agents are divided into m groups g =  g1  g2       gm  
each group gj is a subset of s  i e   ∅ ̸= gj ⊆ s  and
g1 ∪ g2 ∪ · · · ∪ gm = s  let g si  denote the set of groups
that agent si belongs to  the agents are to be selected by the
planner for proportional representation 
the planner has a budget b ∈ r  and each agent si has
a private cost ci ∈ r   e g   her required cost for time  pri-
vacy or fees  when selected to represent her group  we use
c =  c1  c2       cn  to denote agents  costs  let c−i de-
note all costs except si s cost ci  let nj be the total num-
ber of agents in group gj  i e   |gj| = nj 
denote by
nmin and nmax the minimum and maximum total number
of agents among all the groups respectively  i e   nmin =
min1≤j≤m nj  nmax = max1≤j≤m nj  the agents may act
strategically to maximize their own utilities by misreporting
their costs  each agent bids a cost bi that may be different
from her real cost ci in order to maximize her utility  defined
below   let b =  b1  b2       bn  denote agents  bid profile
and b−i denote all bids except si s bid bi  we sometime use
 bi  b−i  to represent b as to highlight si s bid 
2 2
the mechanism
a mechanism m =  x  p  consists of an allocation rule x
deciding the selected agents  who are chosen by the plan-
ner  and a payment scheme p deciding the payment to each
agent 
denote by sw the selected agent set 
the alloca-
tion function x maps a set of bids b to the selected agent
set sw = x b1       bn  ⊆ s  we use xi ∈  0  1  to in-
dicate whether agent si is chosen by the planner and pi to
denote the payment to agent si  let x =  x1  x2       xn 
and p =  p1  p2       pn  denote the allocation and payment
profile  respectively  given a mechanism m  the utility of
agent si is defined as the difference between the payment she
receives and her true cost  i e  
ui bi  b−i  m  = pi − xi · ci 
 1 
we consider both the single group setting problem  sgp 
where each agent only belongs to one group  and the multiple
group setting problem  mgp  where agents may belong to
multiple groups  let qj denote the number of selected agents
in group gj  next  we define two main group setting models 
single group setting problem  sgp   since each agent
belongs to only one group  we have |g si | = 1  then  the
number of selected agents in group gj is qj = �
si∈gj xi 
multiple group setting problem  mgp   in this setting 
an individual agent may belong to multiple groups  i e   1 ≤
|g si | ≤ m  depending on whether each selected agent can
be counted into all groups  we further consider two cases 
single counting  mgp-sc  case where a selected agent is
counted just once in one of the groups she belongs to and
multiple counting  mgp-mc  case where a selected agent
is counted in all groups she belongs to  for example  when
forming a committee  the agent selected can only represent
one of groups to which she belongs  or when she is selected 
all the groups to which the agent belongs are happy 
 1  mgp-sc  each selected agent is only included in the
selected agents of the group she is matched to  let xij = 1
indicate that agent si is matched to group gj ∈ g si   oth-
erwise  xij = 0 
we also have xi = �
j gj∈g si  xij ≤
proceedings of the thirtieth    ijcai-21 
314
 1 where xij ∈  0  1   ∀i ≤ n 
thus  we have qj =
�
si∈gj xij   2  mgp-mc  each selected agent is counted
in all groups she belongs to  thus  we have qj = �
si∈gj xi 
to obtain a proportion-representative selection of agents 
we define the selection ratio of group gj as qj
nj   representing
the ratio between the number of selected agents and the to-
tal number of agents in group gj  as such  the mechanisms
we design aim to consider the objective of maximizing the
minimum selection ratio of groups  i e   max min1≤j≤m
qj
nj  
we
consider
budget-feasible
proportion-representative
mechanism m that has the following properties 
• budget feasibility  the total payment of the planner
does not exceed her budget b  i e   �
1≤i≤n pi ≤ b 
• individual rationality  the utility of each agent si is
non-negative  i e   ui ci  b−i  m  ≥ 0 
• truthfulness  each agent achieves the maximum util-
ity by bidding her real cost  i e   ui ci  b−i  m  ≥
ui bi  b−i  m  
• computational efficiency  the output of the mecha-
nism can be computed in polynomial time 
• approximation  let alg i  be the minimum selec-
tion ratio among groups of the proposed mechanism m
on input instance i  we compare the output of the mech-
anism with the optimal achievable selection ratio when
agents  costs are known in advance  we say that a mech-
anism is α-approximate if alg i  ≥ 1
αopt i  for any
instance i 
3
mechanism for single group settings
we introduce a budget-feasible proportion-representative
mechanism for the single group setting  bpsg  below 
the main idea of mechanism bpsg is as follows  we first
generate a virtual ratio set which contains all possible selec-
tion ratios for each group when selecting different number of
agents from this group  in order to maximize the minimum
selection ratio among all groups within the budget constraint 
we find all feasible virtual ratios which ensure that the selec-
tion ratio for each group does not fall below that ratio and the
current total payment does not exceed the budget  specif-
ically  the payments for the selected agents depend on the
the bids of agents after the last selected agent in each group 
among all these feasible virtual ratios  we find the maximum
one as the final selection ratio for all groups 
the detail of mechanism bpsg is shown in algorithm
1  in order to distinguish the agents belonging to different
groups  we use bj
i to denote the i-th agent s  agent sj
i  bid in
group gj  we sort all agents in the same group gj 1≤j≤m in
the non-decreasing order of their bids  i e   bj
1 ≤ bj
2 ≤ · · · ≤
bj
nj   denote by pj
i the payment for agent sj
i  we then gener-
ate a virtual ratio set r which consists of possible selection
ratios among all groups  i e  
r = ∪0≤i≤nj 1≤j≤m  i/nj 
 2 
we remove duplicate elements from r and sort all ratios in
the non-decreasing order of their values where γl is the l-th
element in r  i e   γ1 < γ2 < · · · < γl < · · · < γ|r| 
denote by rf the final base selection ratio as the minimum
selection ratio among groups in the final solution 
to find the final base selection ratio  we iteratively con-
sider ratios in r starting with the first ratio γ11  suppose
that we are now considering ratio γl 
let ij γl  denote
the minimum number of agents which ensures that the se-
lection ratio in group gj is at least γl  and we thus have
ij γl  = ⌈γl · nj⌉ 
specifically  mechanism bpsg will
select up to nj − 1 agents from each group gj  as to en-
sure truthfulness   thus  when trying ratio γl  bpsg will
terminate and output γl−1 as the final base selection ratio if
there exists group gj with ij γl  = nj  line 6   if we have
ij γl  < nj  ∀j ≤ m  we compute the current payment for
each of the first ij γl  agents in group gj as the bid of agent
sj
ij γl  1  i e   pj
i = bj
ij γl  1  ∀i ≤ ij γl   thus  when all
groups have a selection ratio of at least γl  the total payment 
denoted by pγl  is
pγl =
�
1≤j≤m
ij γl  · bj
ij γl  1 
 3 
it is easy to see that pγl is increasing with γl  if pγl ≤ b  we
continue to try the next ratio γl 1  otherwise  the final base
selection ratio is rf = γl−1 
once deciding the final base selection ratio  we determine
the final selected agents and corresponding payments  let
kj denote the number of selected agents in group gj  i e  
kj = ij rf  = qj  in each group gj  the first kj agents are
selected  i e   sj
i ∈ sw  ∀i ≤ kj  and we have kj < nj  then
we have
pj
i =
�bj
kj 1 
if sj
i ∈ sw
0 
otherwise 
 4 
running example 
we now show a running example of
mechanism bpsg  suppose there are nine agents who can
be divided into two groups g1 and g2 
group g1 has
four agents g1 =  s1
1  s1
2  s1
3  s1
4  with costs  1  1 5  3  4 
and group g2 has five agents g2
=  s2
1  s2
2  s2
3  s2
4  s2
5 
with costs  0 5  1 5  2  3  5  
thus 
we have n1
=
4 and n2
=
5 
the virtual ratio set is r
=
 0  0 2  0 25  0 4  0 5  0 6  0 75  0 8  1   the planner has bud-
get b = 10  we now try virtual ratios by starting from the
first non-zero ratio 0 2 
 1  try ratio 0 2  we have i1 0 2  = 1 and i2 0 2  = 1 
thus  we will select s1
1 from g1 and pay her 1 5  and select
s2
1 from g2 and pay her 1 5  then  the total payment is 3 <
b = 10 and we will try next ratio 0 25 
 2  try ratio 0 25  we have i1 0 25  = 1 and i2 0 25  =
2  thus  we will select s1
1 from g1 and pay her 1 5  and
select s2
1  s2
2 from g2 and pay each of them 2  then  the total
payment is 5 5 < 10 and we will try next ratio 0 4 
 3  try ratio 0 4  we have i1 0 4  = 2 and i2 0 4  = 2 
thus  we will select s1
1  s1
2 from g1 and pay each of them 3 
and select s2
1  s2
2 from g2 and pay each of them 2  then  the
total payment is 10 = b and we will try next ratio 0 5 
 4  try ratio 0 5  we have i1 0 5  = 2 and i2 0 5  = 3 
thus  we will select s1
1  s1
2 from g1 and pay each of them 3 
1note that the first virtual ratio in r is 0  at such a ratio  we
select no agents and pay each agent zero 
proceedings of the thirtieth    ijcai-21 
315
 algorithm 1  mechanism bpsg b  b  s  g 
input  b  b  s  g 
output  p  sw
1 p ← 0  sw ← ∅ 
2 sort agents in gj ∀1 ≤ j ≤ m   in the non-decreasing
order of their bids bj
1 ≤ bj
2 ≤ · · · ≤ bj
nj and generate the
virtual ratio set r with value sorted and indexed by γl s 
3 // determine the final base selection ratio 
4 for 1 ≤ l ≤ |r| do
5
compute ij γl  = ⌈γl · nj⌉ for any 1 ≤ j ≤ m 
6
if ij γl  < nj  ∀j ≤ m then
7
compute the payment pγl according to  3  
8
if pγl ≤ b then
9
l ← l   1 
10
else
11
break 
12
end
13
else
14
break 
15
end
16 end
17 rf ← γl−1 
18 // agent selection and payment scheme 
19 add agent sj
i ∀j ≤ m  with i ≤ kj = ij rf  into the
selected agent set sw 
20 decide the payments to agents according to  4  
21 return p  sw
and select s2
1  s2
2  s2
3 from g2 and pay each of them 3  then 
the total payment is 15 > b = 10 
then  mechanism bpsg terminates with the final base
selection ratio 0 4 
the selected agent set is sw
=
 s1
1  s1
2  s2
1  s2
2  with payments p1
1 = 3  p1
2 = 3  p2
1 = 2  p2
2 =
2  while the payments for unselected agents are zero 
next  we analyze the performance of mechanism bpsg 
theorem 1  mechanism bpsg guarantees individual ratio-
nality  budget feasibility  and computational efficiency 
proof  1  individual rationality  since mechanism bpsg is
truthful  proved below   we have bj
i = cj
i where cj
i is the true
cost of agent sj
i  for each selected agent sj
i  we have bj
i ≤
bj
kj 1 where i ≤ kj in group gj  and her payment is bj
kj 1
which implies that her utility is bj
kj 1 − cj
i = bj
kj 1 − bj
i ≥ 0
which is non-negative  2  budget feasibility  after deter-
mining the selection ratio  it is easy to see that the total pay-
ment is �
1≤j≤m kj · bj
kj 1 ≤ b which is no greater than the
budget b  3  computational efficiency  the running time of
mechanism bpsg is dominated by the sorting  line 2  and the
loop in determining the final base selection ratio  line 4-15 
as shown in algorithm 1  therefore  the total computational
complexity is o n2   this completes the proof 
we first provide a well-known myerson s characterization
for truthful mechanisms in the single parameter domain 
theorem 2   monotone theorem   myerson  1981   in the
single parameter domains  a mechanism m =  x  p  guar-
antees sellers  truthfulness if and only if 
 1  x is monotone  ∀si ∈ s  if bi ≤ ci  then si ∈
x ci  c−i  implies si ∈ x bi  c−i  for every c−i 
 2  winners are paid threshold payments  the payment
to each winning bidder is the critical value inf ci   i /∈
x ci  c−i   
we prove the truthfulness of mechanism bpsg by leverag-
ing the theorem above  suppose that the final base selection
ratio is the l-th element in virtual set r  i e   rf = γl 
theorem 3  mechanism bpsg guarantees truthfulness 
proof  sketch   depending on the final base selection ratio 
we consider the following two cases 
case 1  there exists no group gj in which when try-
ing the next virtual ratio γl 1  we select all its agents  i e  
ij γl 1  < nj  ∀1 ≤ j ≤ m  1  we first show that if the
selected agent sj
i in group gj  i e   i ≤ kj  reports a lower
cost bj
i′ < bj
i ≤ bj
kj 1  she will still be selected  thus  bpsg
is monotone  2  if agent sj
i with i ≤ kj reports a cost higher
than her payment bj
i′ > bj
kj 1  we prove that sj
i will not be
selected with zero utility  thus  the selected agents are paid
threshold payments 
case 2  there exists a group gj in which when try-
ing the next virtual ratio γl 1  we select all its agents  i e  
∃1 ≤ j ≤ m  ij γl 1  = nj  we similarly prove that mech-
anism bpsg is monotonic and the selected agents are paid
threshold payments 
therefore  mechanism bpsg guarantees truthfulness 
next  we introduce a useful property of mechanism bpsg 
let rj γl  denote the selection ratio of group gj after
selecting kj agents  i e   rj γl 
=
kj
nj  
we use rmax
and rmin to denote the maximum and minimum selec-
tion ratios among groups when the final base selection ra-
tio is γl  i e   rmax = max1≤j≤m rj γl   and rmin =
min1≤j≤m rj γl    specifically  we have rmin = γl = rf
since there must exist at least one group gj whose selection
ratio is rj γl  = γl due to the generation of r in  2   denote
by α the ratio between nmax and nmin  i e   α = nmax
nmin  
lemma 1  mechanism bpsg has the following two prop-
erties   1  γh 1 − γh ≤
1
nmax   ∀1 ≤ h ≤ |r| − 1   2 
rmax − rmin <
1
nmin  
given the above lemma  we consider the approximation
guarantee of bpsg  let alg and opt denote the minimum
selection ratio of mechanism bpsg and the optimal solution 
respectively  our analysis considers two separate cases  in
the first case when bpsg is able to select at least one agent
from each group  we show that bpsg obtains an approxima-
tion ratio that depends on the ratio between the maximum and
minimum number of agents among groups  in fact  the ratio
is asymptomatically tight as we showed later  if mechanism
bpsg cannot select at least one agent from each group  we
show that no budget-feasible proportion-representative mech-
anisms can output a better solution than bpsg 
theorem 4   1  mechanism bpsg achieves  3   α -
approximation ratio if bpsg selects at least one agent from
each group  i e   alg ≥
1
nmax   where α = nmax
nmin  
proceedings of the thirtieth    ijcai-21 
316
  2  no budget-feasible proportion-representative mecha-
nism m can achieve algm ≥ θ for any θ > 0 where
algm is the solution of m if mechanism bpsg cannot se-
lect at least one agent from each group  i e   alg = 0 
proof  sketch   recall that the final base selection ratio is γl 
i e   alg = γl  we have nj ≥ 2  ∀j ≤ m since bfsg
can select at least one agent from each group  depending
on the conditions at the termination of bpsg  we consider
two cases  i  there exists group gj in which we select all
agents  i e   ∃j ≤ m  ij γl 1  = nj  when trying the next
virtual ratio γl 1 
we prove that γl · nj = nj − 1 and
op t
alg ≤ 1/ 1 −
1
nj   ≤ 2  ii  next  we focus on the case that
not all agents are selected from any group gj when trying
γl 1  i e   ij γl 1  < nj  ∀j ≤ m  let g′ denote the set of
all groups that can choose exactly rf · nj = kj agents mak-
ing the selection ratio in group gj equal to rf  ∀gj ∈ g′ 
depending on whether the next ratio γl 1 is generated from a
group in g′ or not  we consider the following two sub-cases 
sub-case 1  the virtual ratio γl 1 is generated from
the group gj /∈ g′  we divide agents into two parts  ˜s =
 sj
i|i ≤ kj  ∀gj /∈ g′  ∪  sj
i|i ≤ kj   1  ∀gj ∈ g′  and
s \ ˜s for further analysis 
for set ˜s  the optimal solution can select all agents in ˜s
with cost zero in the best case and spend the budget on the
remaining agents in s \ ˜s  we show that after opt chooses
all agents in ˜s  the maximum selection ratio among all groups
is rmin  
1
nmin   and the minimum selection ratio is γl 1 
for set s \ ˜s  we show that the optimal solution can select
kj agents from the remaining agents after skj from group gj
for any gj /∈ g′  and kj   1 agents from the group gj ∈ g′
with budget b  thus  we prove that the minimum selection
ratio among groups by selecting these numbers of agents is
γl 1 and the maximum selection ratio is rmin  
1
nmin  
thus  by combining the set ˜s and s \ ˜s  we have
opt ≤ rmin  
1
nmin
  γl 1 ≤ 2rf  
1
nmax
 
1
nmin
 5 
due to lemma 1 
sub-case 2  the virtual ratio γl 1 is generated from
the group gj ∈ g′  we can similarly prove that opt ≤
2rf  
1
nmax  
1
nmin  
therefore  we have opt
≤ 2alg  
1
nmin  
1
nmax  
specifically  if alg ≥
1
nmax   we have op t
alg ≤ 3   α which
means bpsg achieves  3   α -approximation ratio 
next  we provide an asymptotic tight lower bound for all
of budget-feasible proportion-representative mechanisms 
theorem 5  no budget-feasible proportion-representative
mechanism obtains an approximation ratio better than ω α  
in particular  it is worth stating that this lower bound also
applies to the multiple group setting 
4
mechanisms for multiple group settings
in this section  we consider the multiple group setting where
each agent si might belong to multiple groups  i e   1 ≤
algorithm 2  mechanism bpmg-s b  b  s  g 
input  b  b  s  g 
output  p  sw
1 p ← 0  sw ← ∅ 
2 sort all agents in the non-decreasing order of their
bids bi  i e   b1 ≤ b2 ≤ · · · ≤ bn 
3 // determine the candidate agent set 
4 for 1 ≤ i ≤ n do
5
compute r si  according to  6  
6
f si  ← �
1≤j≤m⌈r si  · nj⌉ 
7
if bi · f si  ≤ b then
8
i ← i   1 
9
else
10
break 
11
end
12 end
13 k ← i − 1 
14 // agent selection and payment scheme 
15 x  sw ← agentselect sk  
16 the payment for si ∈ sw is pi = min 
b
f  sk   bk 1  
|g si | ≤ m  we distinguish two sub-cases according to
whether the contribution of the agent is counted only once or
not  single-counting case and multiple-counting case  in the
single counting case  the selection ratio in one of the groups
g si   say gj  would increase by
1
nj where nj = |gj| if si is
selected and contributes to gj  while in the multiple counting
case  the selection ratios of all groups in g si  would increase
by
1
nj for any gj ∈ g si   once si is selected 
4 1
single counting case
in this section  we introduce a budget-feasible proportion-
representative mechanism for the multiple group setting in
single counting case  called bpmg-s 
intuitively  we measure the supply of agents for a given
fixed payment  given all agents who have bids lower than
this payment  we can compute the solution that maximizes
the minimum selection ratio among groups  this minimum
ratio will increase and reflect the supply as the number of
agents increases  we then try to find the payment which can
maximize such a ratio and ensure the budget feasibility  si-
multaneously 
in detail  we first sort all the agents according to their non-
decreasing order of bids b1 ≤ b2 ≤ b3 ≤ · · · ≤ bn  let xij =
1 indicate that agent si is matched to group gj  otherwise 
xij = 0  agent si can only be matched to at most one group 
i e   �
j≤m xij ≤ 1  ∀i ≤ n  denote by s sh  =  si|i ≤ h 
the set containing agents before agent bh 1 
before introducing our mechanism  we first introduce an
important component  an integer programming formulation
to compute a matching result under a given agent set s sh  
that maximizes the minimum selection ratio among groups
while ignoring the costs and budget constraint  denoted by
proceedings of the thirtieth    ijcai-21 
317
 𝑮𝟏
𝑮𝒋
𝑮𝒎
𝒔𝟏
𝒔𝟐
𝒔𝒊
𝒔𝒏 𝟏
𝒔𝒏
⋯
⋯
⋯
⋯
⌈𝒓𝒔 ⋅ 𝒏𝒋⌉
𝟏
𝟏
𝒔
𝒕
⌈𝒓𝒔 ⋅ 𝒏𝟏⌉
⌈𝒓𝒔 ⋅ 𝒏𝒎⌉
𝟏
𝟏
𝟏
𝟏
𝟏
𝟏
𝟏
𝟏
figure 1  an example of a flow network under ratio rs 
ilp sh  as follows 
max min
1≤j≤m
�
i≤h xij
nj
s t  
�
j≤m
xij ≤ 1  ∀i ≤ h
xij ∈  0  1   ∀i ≤ h  gj ∈ g si 
xij = 0  ∀i ≤ h  gj /∈ g si 
 6 
where these three conditions indicate that agents in s sh  can
only be matched to at most one of the groups they belong to 
notice that the optimal solution in  6  can be computed in
polynomial time by constructing max-flow networks as fol-
lows  in detail  given agent set s sh   all possible selection
ratios for group gj are in ∪y≤|s sh ∩gj|  y
nj    thus  the op-
timal selection ratio in the solution of  6  must be one of the
ratios in r = ∪y≤|s sh ∩gj| j≤m  y
nj    particularly  we re-
move duplicate elements in r  we say a ratio rs ∈ r is
feasible if we can find a matching result ensuring that the se-
lection ratio in each group is at least rs and satisfying all con-
ditions in  6   to find the optimal solution  we take rs ∈ r
as an input and construct a flow network based on such a ra-
tio  as shown in fig  1  we use blue  red and black circles to
represent source node s/terminal node t  groups and agents 
respectively  specifically  there exists a directed edge from
source s to each group gj  an edge from each gj to si if
si ∈ gj  and from each agent si to terminal node t  each
edge from s to gj is assigned with a capacity ⌈rs · nj⌉  while
the capacity of each directed edge from gj to sj and from
si to t is 1  if the maximum flow on this network equals
�
j≤m⌈rs · nj⌉  then rs is a feasible ratio  we can find the
optimal solution in  6  by testing every possible input of rs
and validating its feasibility  i e   the maximum one among
all feasible ratios is the desired optimal solution 
let x sh  denote the solution of ilp sh   and r sh  is
the minimum selection ratio among groups under x sh   de-
note by f sh  the total number of agents under ratio r sh  
i e  
f sh  =
�
1≤j≤m
⌈r sh  · nj⌉ 
 7 
it is obvious that f sh  ≤ |s sh | 
candidate agent selection 
now we are ready to select
agents  we first decide on a set of candidate agents  from
which we select agents  we iteratively test each agent s bid
algorithm 3  function agentselect  s  g  k 
input  s  g  k 
output  x  sw
1 x ← 0  sw ← ∅ 
2 assign each agent si a weight wi = 2zi where
zi ∈ n  is an arbitrary integer such that no two
agents have the same weight  i e   zi ̸= zi′ for any
i ̸= i′ 
3 compute the final allocation xw sk  according to  8  
4 x ← xw sk  
5 add agent si ∀1 ≤ i ≤ n  into sw if �
j≤m xij = 1 
starting from the first agent s bid b1  suppose that we are now
trying agent si and calculate the value of f si  by equation
 7   if bi ·f si  ≤ b  we consider the next agent si 1  other-
wise  we select agents from the previous i−1 agents s si−1  
assume that sk is the last agent who satisfies bk · f sk  ≤ b
which implies bk 1 · f sk 1  > b  after determining the
value k  we define agent set s sk  =  si   i ≤ k  as the
candidate agent set  where |s sk | ≥ f sk  follows 
agent selection and payment scheme 
now we select
agents from the candidate agent set s sk   first  we assign
each agent si a weight wi = 2zi where zi ∈ n  is an arbi-
trary integer such that no two agents have the same weight 
i e   zi ̸= zi′ for any i ̸= i′ 
then  we use the function
agentselect s  g  k  to select f sk  agents from s sk  
the detail of agentselect s  g  k  is shown in algorithm 3 
we try to find a minimum weight matching between agents
and groups that can minimize the total weight of matched
agents satisfying that each group gj is matched ⌈r sk  · nj⌉
agents from set s sk  as follows  denoted by ilpw sk 2 
min
�
1≤i≤k
�
1≤j≤m
wixij
s t  
�
1≤j≤m
xij ≤ 1  ∀i ≤ k
�
1≤i≤k
xij = ⌈r sk  · nj⌉  ∀j ≤ m
xij ∈  0  1   ∀i ≤ k  gj ∈ g si 
xij = 0  ∀i ≤ k  gj /∈ g si  
 8 
since we assign agents exponential weights  there is a unique
matching result in  8   let xw sk  denote the solution of
ilpw sk   if agent si i≤k is matched to one of the groups 
i e   �
1≤j≤m xij = 1  then she is selected  i e   si ∈ sw  the
payment for each selected agent is pi = min 
b
f  sk   bk 1 
while the payments for unselected agents are zero3 
next we analyze the performance of mechanism bpmg-s 
theorem 6  mechanism bpmg-s guarantees individual ra-
tionality  budget feasibility and computational efficiency 
we prove the truthfulness of mechanism bpmg-s by
showing that it satisfies theorem 2 
2this problem can be similarly solved in polynomial time by
constructing max-flow min-cost networks 
3the payment for each selected agent is
b
f  sk  if k = n 
proceedings of the thirtieth    ijcai-21 
318
 theorem 7  mechanism bpmg-s guarantees truthfulness 
let opts and algs denote the optimal solution and the
solution of bpmg-s  respectively 
we show that bpfg-
s generally achieves an approximation ratio with respect to
the size of groups when at least one agent is selected in
each group  while there is a small gap between bpfg-s and
any other budget-feasible proportion-representative mecha-
nism when bpfg-s cannot select at least one agent from each
group 
theorem 8   1  mechanism bpmg-s achieves  mα α  
2    1 -approximation ratio if bpmg-s can select at least
one agent from each group  i e   algs ≥
1
nmax   where
α = nmax
nmin  
 2  no budget-feasible proportion-representative mecha-
nism m′ can obtain algm′ ≥ θ for any θ >
1
nmin where
algm′ is the solution of m′ if mechanism bpmg-s cannot
select at least one agent from each group  i e   algs = 0 
4 2
multiple counting case
in this section  we consider the multiple counting case where
the selection ratio of each group gj in g si  can increase
by
1
nj for gj ∈ g si  when si is selected  we propose a
modified version of mechanism bpmg-s  called bpmg-m 
in general  mechanism bpmg-m applies the methodolog-
ical framework in mechanism bpmg-s  we first sort all
the agents according to their non-decreasing order of bids
b1 ≤ b2 ≤ b3 ≤ · · · ≤ bn  we then use an integer pro-
gramming formulation to compute a result given an agent set
s sh  =  si   i ≤ h   that maximizes the minimum selec-
tion ratio among groups  denoted by ilp m sh  as follows 
max min
j≤m
�
si∈gj xi
nj
s t   xi ∈  0  1   ∀i ≤ h
xi = 0  ∀i > h
 9 
where the two conditions mean that we only consider agents
in s sh   similar to that of  6   we can solve this problem by
using the max-flow method  let xm sh  denote the solution
of ilp m sh   and rm sh  denote the minimum selection ra-
tios under xm sh   we denote fm sh  as the total counted
number of selected agents among groups by ratio rm sh   i e  
fm sh  = �
j≤m⌈rm sh  · nj⌉ 
candidate agent selection 
we also decide on a set of can-
didate agents by iteratively testing each agent s bid starting
from the first agent s bid b1  that is  we find the last agent sk
who ensures bk · fm sk  ≤ b and bk 1 · fm sk 1  > b 
then  the agent set s sk  is the candidate agent set 
agent selection and payment scheme 
similar to the agent
selection function agentselect sk  g  b   we assign each
agent si a weight wi = 2zi where zi ∈ n  is an arbitrary
integer such that no two agents have the same weight  i e  
zi ̸= zi′ for any i ̸= i′  we try to select agents with the mini-
mum total weight satisfying that each group gj is selected at
least ⌈rm sk  · nj⌉ agents from set s sk  as follows  denoted
by ilp m
w  sk  
min
�
i≤k
wixi
s t  
�
i∈gj
xi ≥ ⌈rm sk  · nj⌉  ∀j ≤ m
xi ∈  0  1   ∀i ≤ k
xi = 0  ∀i > k
 10 
let xm
w  sk  denote the solution of ilp m
w  sk  
if
xi = 1  agent si is selected and her payment is pi =
min 
b
fm sk   bk 1   otherwise  pi = 0 
theorem 9  mechanism bpmg-m guarantees individual
rationality  budget feasibility  computational efficiency and
truthfulness 
let algm denote the solution of mechanism bpmg-m 
theorem 10   1  mechanism bpmg-m achieves  mα α  
2    1 -approximation ratio if bpmg-m can obtain at least
one agent from each group  i e   algm ≥
1
nmax   where α =
nmax
nmin  
 2  no budget-feasible proportion-representative mecha-
nism m′′ can obtain algm′′ ≥ θ for any θ >
2m
nmin
where algm′′ is the solution of m′′ if mechanism bpmg-
m cannot select at least one agent from each group  i e  
algm = 0 
5
conclusion
we consider the proportion representation budget-feasible
mechanism design problem where agents may have diverse
group attributes 
we focus on designing budget-feasible
mechanisms that can select appropriate proportions of agents
from various groups satisfying individual rationality  budget
feasibility  and truthfulness under several settings  for the
single group setting  we propose mechanism bpsg  which it-
eratively tests each virtual ratio generated by the distribution
of agents across groups and finds the maximum one as the
base selection ratio for all groups  for the multiple group set-
ting  we first consider the single counting case by proposing
mechanism bpmg-s  which leverages max-flow solution to
measure the supply of agents under a fixed payment and finds
the payment which can maximize the minimum selection ra-
tio among groups  we then extend bpmg-s to the multiple
counting case 
acknowledgements
this work was supported in part by the national key re-
search and development program of china under grant no 
2019yfb2102200  natural science foundation of china un-
der grant no  61902062  61672154  61972086  the project
11771365 supported by nsfc  the postgraduate research  
practice innovation program of jiangsu province of china
 kycx19 0089   and partially sponsored by key laboratory
of computer network and information integration  southeast
university   ministry of education 
proceedings of the thirtieth    ijcai-21 
319
 references
 ahmadi et al   2019  saba ahmadi  faez ahmed  john p
dickerson  mark fuge  and samir khuller  an algorithm
for multi-attribute diverse matching  arxiv  pages arxiv–
1909  2019 
 amanatidis et al   2017  georgios amanatidis 
georgios
birmpas  and evangelos markakis 
on budget-feasible
mechanism design for symmetric submodular objectives 
in international conference on web and internet eco-
nomics  pages 1–15  springer  2017 
 anari et al   2014  nima anari  gagan goel  and afshin
nikzad  mechanism design for crowdsourcing  an opti-
mal 1-1/e competitive budget-feasible mechanism for large
markets  in 2014 ieee 55th annual symposium on foun-
dations of computer science  pages 266–275  ieee  2014 
 benabbou et al   2020  nawal
benabbou 
mithun
chakraborty 
xuan-vinh ho 
jakub sliwinski 
and
yair zick  the price of quota-based diversity in assign-
ment problems 
acm transactions on economics and
computation  teac   8 3  1–32  2020 
 bradburn et al   2004  norman m bradburn  seymour sud-
man  and brian wansink  asking questions  the definitive
guide to questionnaire design–for market research  politi-
cal polls  and social and health questionnaires  john wi-
ley   sons  2004 
 bredereck et al   2018  robert
bredereck 
piotr
fal-
iszewski  ayumi igarashi  martin lackner  and piotr
skowron 
multiwinner elections with diversity con-
straints 
in proceedings of the aaai conference on
artificial intelligence  volume 32  2018 
 buisseret and prato  2020  peter buisseret and carlo prato 
voting behavior under proportional representation  jour-
nal of theoretical politics  32 1  96–111  2020 
 cahuc and postel-vinay  2002  pierre cahuc and fabien
postel-vinay  temporary jobs  employment protection and
labor market performance  labour economics  9 1  63–
91  2002 
 chawla and jagadeesan  2020  shuchi chawla and meena
jagadeesan  fairness in ad auctions through inverse pro-
portionality  arxiv preprint arxiv 2003 13966  2020 
 chen et al   2011  ning chen  nick gravin  and pinyan lu 
on the approximability of budget feasible mechanisms  in
proceedings of the twenty-second annual acm-siam sym-
posium on discrete algorithms  pages 685–699  siam 
2011 
 ilvento et al   2020  christina ilvento  meena jagadeesan 
and shuchi chawla  multi-category fairness in sponsored
search auctions  in proceedings of the 2020 conference on
fairness  accountability  and transparency  pages 348–
358  2020 
 jackson et al   2020  natalie jackson  michael s lewis-
beck  and charles tien 
pollster problems in the 2016
us presidential election 
vote intention  vote predic-
tion 
quaderni dell osservatorio elettorale qoe-ijes 
83 1  17–28  2020 
 kuo et al   2020  kevin kuo  anthony ostuni  elizabeth
horishny  michael j curry  samuel dooley  ping-yeh chi-
ang  tom goldstein  and john p dickerson  proportionnet 
balancing fairness and revenue for auction design with
deep learning  arxiv preprint arxiv 2010 06398  2020 
 lang and manove  2011  kevin lang and michael manove 
education and labor market discrimination 
american
economic review  101 4  1467–96  2011 
 myerson  1981  roger b myerson  optimal auction design 
mathematics of operations research  6 1  58–73  1981 
 procaccia et al   2008  ariel d procaccia  jeffrey s rosen-
schein  and aviv zohar  on the complexity of achieving
proportional representation  social choice and welfare 
30 3  353–362  2008 
 singer and mittal  2013  yaron singer and manas mittal 
pricing mechanisms for crowdsourcing markets  in pro-
ceedings of the 22nd international conference on world
wide web  pages 1157–1166  2013 
 singer  2010  yaron singer  budget feasible mechanisms 
in 2010 ieee 51st annual symposium on foundations of
computer science  pages 765–774  ieee  2010 
proceedings of the thirtieth    ijcai-21 
320
 "
None,2021,https-www-ijcai-org-proceedings-2021-0045-pdf,Improving Welfare in One-Sided Matchings using Simple Threshold Queries,"Thomas Ma, Vijay Menon, Kate Larson",None,https://www.ijcai.org/proceedings/2021/0045.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0045-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0045-pdf.pdf,"improving welfare in one-sided matchings using simple threshold queries
thomas ma1   vijay menon2   kate larson2∗
1department of computer science  university of toronto
2david r  cheriton school of computer science  university of waterloo
thomas ma@mail utoronto ca   vijay menon  kate larson @uwaterloo ca
abstract
we study one-sided matching problems where each
agent must be assigned at most one object 
in
this classic problem it is often assumed that agents
specify only ordinal preferences over objects and
the goal is to return a matching that satisfies some
desirable property such as pareto optimality or
rank-maximality  however  agents may have car-
dinal utilities describing their preference intensities
and ignoring this can result in welfare loss  we
investigate how to elicit additional cardinal infor-
mation from agents using simple threshold queries
and use it in turn to design algorithms that return a
matching satisfying some desirable matching prop-
erty  while also achieving a good approximation to
the optimal welfare among all matchings satisfy-
ing that property  overall  our results show how we
can improve welfare by even non-adaptively ask-
ing agents for just one bit of extra information per
object 
1
introduction
one-sided matching scenarios are ubiquitous in multiagent
resource-allocation settings and have been well-studied  es-
pecially as the housing allocation or housing market prob-
lem both in economics  shapley and scarf  1974  hyl-
land and zeckhauser  1979  roth and postlewaite  1977 
abdulkadiro˘glu and s¨onmez  1998  abdulkadiro˘glu and
s¨onmez  1999  s¨onmez and ¨unver  2010  and in computer
science  abraham et al   2004  irving  2004  abraham et al  
2006  filos-ratsikas et al   2014  amanatidis et al   2021  
other examples include assigning faculty members to school
committees  workers to tasks  etc 
much of the literature assumes that agents have an accept-
able set of objects and that they submit an  ordinal  prefer-
ence order over this set  given this  the standard objective
is to come up with an assignment of objects to agents  i e  
a matching  that satisfies some desirable property like pareto
optimality  shapley and scarf  1974  abraham et al   2004 
or rank maximality  irving  2004  irving et al   2006  
∗contact author
although matchings that satisfy such desirable proper-
ties are better than arbitrary ones  one key drawback is that
they may not take into account agents  preference intensi-
ties  to illustrate this  consider the following simple example
where there are three agents  a1  a2  a3  and three objects
 o1  o2  o3   assume all agents agree that o1 is preferred to
o2 which is preferred to o3  but have different preference in-
tensities  i e   cardinal utilities  for the objects  in particular 
a1 and a2 assign utility 0 9 to o1 and 0 1 to o2 while a3 as-
signs utility 0 51 to a1 and 0 49 to o2  all agents assign zero
utility for o3  if only ordinal preferences are considered then
any matching is  for example  pareto optimal  however  any
matching that assigns o3 to a3 leads to significant loss in over-
all social welfare compared to other pareto optimal matchings
and so is  in some sense  less desirable 
the observation that there might be a loss in welfare due
to ignoring preference intensities  henceforth  cardinal utili-
ties  is not new  and in particular  has been a much debated
issue surrounding various school-choice mechanisms    ab-
dulkadiro˘glu et al   2011  abdulkadiro˘glu et al   2015    this
has also lead to proposals for new school choice mechanisms
that ask agents to provide some extra information along with
their ordinal preferences  abdulkadiro˘glu et al   2015   our
work here is partially motivated by this line of work  but takes
a more computational approach that is similar in style to the
work that looks at distortion—which is essentially the cost
of using only ordinal information—in various settings  pro-
caccia and rosenschein  2006  boutilier et al   2015  an-
shelevich and sekar  2016  anshelevich and zhu  2017 
goel et al   2017  abramowitz and anshelevich  2018  
given a one-sided matching instance  the set of agents 
objects  and agents  ordinal preferences   our goal is to find
matchings that satisfy some particular property  say  x  while
also accounting for agents  cardinal utilities  we accomplish
this by designing algorithms that are guaranteed to return
matchings that satisfy property x while also achieving a good
approximation to the optimal welfare amongst all matchings
that satisfy x  one way to achieve this is to ask agents to
directly provide their cardinal utilities for objects  such an
approach  however  places a high burden on the agents them-
selves as they are required to articulate and communicate
precise cardinal information  instead we propose a middle-
ground and use simple binary queries to elicit relevant infor-
mation from agents  our goal is to ask each agent a small
proceedings of the thirtieth    ijcai-21 
321
 number of such queries and return a matching that achieves a
good approximation as described above 
in particular 
we consider the following four well-
studied matching properties  pareto optimal matchings  rank-
maximal matchings  max-cardinality rank-maximal match-
ings  and fair matchings  and two rich cardinal utility mod-
els  unit-sum and unit-range valuations  
we first explore
adaptive algorithms—algorithms that are able to change their
queries depending on how agents answer previous queries—
and show how for each of the properties mentioned above
and for any ϵ > 0  there is a deterministic algorithm that asks
o c log n  queries per agent  where c =
�
log n2·1/ϵ 
log  1 ϵ/2 
�
  and
returns a matching that achieves a  1   ϵ -approximation to
the optimal welfare among all matchings that satisfy the prop-
erty of interest  we then focus on non-adaptive algorithms
which  we argue  have many practical advantages over adap-
tive algorithms  and explore what is possible to achieve in the
special case where the algorithm is allowed at most one query
per  agent  object  pair  table 1 summarizes our results 
related research 
motivation for our work is derived from
the school choice problem which addresses the loss in wel-
fare due to not taking preference intensities into account
 abdulkadiro˘glu et al   2011  abdulkadiro˘glu et al   2015  
our concern here is similar  but we take a computational
approach  reminiscent to the work on distortion  procac-
cia and rosenschein  2006  anshelevich and zhu  2017 
abramowitz and anshelevich  2018   however  unlike this
body of work which aims to calculate the worst-case loss
in welfare due to only having ordinal preferences  we as-
sume that  in addition to ordinal preferences  it is also
possible to obtain information about agents  cardinal utili-
ties 
this in turn is similar to an approach that has been
explored in the voting context  abramowitz et al   2019 
amanatidis et al   2020   and one-sided matching  amana-
tidis et al   2021   while this latter work also looks at one-
sided matching  the objective is different with its focus on
distortion  as opposed to finding  good  matchings satisfy-
ing certain properties  we also observe that the query models
used differ  with ours being significantly weaker  
our work is also related to the study of communication
complexity of voting protocols  mandal et al   2020   to the
work on participatory budgeting which compares different
elicitation methods based on the distortion achieved   goel
et al   2019  benade et al   2020    and is more broadly in
line with the growing body of work that explicitly aims to
make mechanisms or algorithms more robust  by either mak-
ing use of coarse preference information  chiesa et al   2012 
chiesa et al   2014  menon and larson  2019   or by mak-
ing sure that the algorithms designed produce solutions that
work  well   in the approximation sense  even under slightly
modified inputs  shiryaev et al   2013  bredereck et al   2017 
menon and larson  2018  chen et al   2019  
2
model
for k ∈ z   let  k  denote the set  1          k   we use n 
where |n| = n  to denote the set of agents  a1          an   and
h  where |h| = n  to denote the set of objects  h1          hn  
we refer to ai as agent i and hj as object j  every agent ai
has a weak order  pi  over a subset of objects ai ⊆ h  where
ai  |ai| ≥ 1  is the set of objects ai is willing to be matched
to  the acceptable set of ai  we use p =  p1          pn  to
refer to the weak orders of all the agents in n and refer to p
as the preference profile of the agents  for an agent ai  and for
two objects hj  hk ∈ ai  we use hj ≻i hk to denote that ai
strictly prefers hj over hk  and use hj ⪰i hk to indicate that
hj is either strictly preferred or considered to be equivalent
to hk  we refer to i =  n  h  p =  p1          pn   as an
instance  which encodes all the information about the agents 
objects  and the agents  preferences  and use i to denote the
set of all possible instances 
given an instance i =  n  h  p   gi =  n ∪ h  e 
is the induced bipartite graph with edges  ai  hj  ∈ e if
hj ∈ ai  we refer to e =  ai  hj  ∈ e as a rank-k edge
if |uij| = k − 1  where uij =  hℓ ∈ ai | hℓ ≻i hj   we
also use rank ai  hj  to denote the k such that  ai  hj  is a
rank-k edge and refer to an object hj as ai s rank-k object if
rank ai  hj  = k 
we additionally assume that each agent ai has a cardi-
nal utility function vi   h →  0  1   which is consistent with
the preference order pi  meaning  h1 ⪰i h2 ⇔ vi h1  ≥
vi h2    we assume that if h /∈ ai  then vi h  = 0  we use
v =  v1          vn  to denote the valuation profile of agents and
vi to denote the set of all possible valuation profiles that are
consistent with the given preference profile in i  in this work
we consider two specific classes of valuation functions 
unit-sum valuations  for each agent i  vi is such that
�
h∈h vi h  = 1 
unit-range valuations  agents are said to have unit-range
valuations if for each agent i  there exists hj  hk ∈ ai
such that hj ≻i hk  and maxh∈ai vi h  = 1 and
minh∈ai vi h  = 0  in words  the most preferred ob-
jects have value 1  the least preferred objects have value
0  and every other acceptable object has value between
0 and 1 
note that information about the cardinal utilities is not part
of an instance i  given i  we are interested in matchings
of agents to objects  namely bijections µ  n → h  for c ∈
n ∪h  we refer to µ c  as c s partner in µ or as c s allocation
in µ  alternatively  a matching is also defined as a collection
of edges µ in gi such that each vertex is part of at most one
edge in µ  we use mgi to denote the set of all possible
matchings in gi 
2 1
pareto optimal and signature-based
matchings
although for a given instance there are several possible
matchings  we are interested in matchings which also satisfy
some additional desirable property  in particular  we consider
the following well-studied properties  pareto optimal match-
ings  shapley and scarf  1974  abraham et al   2004   rank-
maximal matchings  irving  2004  irving et al   2006   max-
cardinality rank-maximal matchings  mehlhorn and michail 
2005  abraham et al   2006   and fair matchings  mehlhorn
and michail  2005  huang et al   2013  
the latter three
proceedings of the thirtieth    ijcai-21 
322
 ordinal
algorithms
adaptive threshold
query algorithms
�
for any ϵ > 0  o c log n  queries
per agent  where c =
�
log n2·1/ϵ 
log  1 ϵ/2 
��
non-adaptive threshold
query algorithms
�
at most 1 query
per  agent  object  pair
�
unit-sum valuations
ub  o n2 
 theorem 1 
lb  ω n2 
 theorem 1 
1   ϵ
 theorem 3 
ub  o n2/3 
 theorems 5 and 4 
lb  ω √n 
 theorem 8 
unit-range valuations
ub  o n 
 theorem 1 
lb  ω n 
 theorem 1 
1   ϵ
 theorem 3 
ub  o √n 
 theorems 6 and 7 
lb  ω √n 
 theorem 8 
table 1  summary of our results  for x  where x is one of the properties in the set  pareto optimal  rank-maximal  max-cardinality rank-
maximal  fair   an upper bound  ub  of α indicates that there is a deterministic algorithm that always produces a matching that satisfies x
and achieves an α-approximation to the optimal welfare among matchings that satisfy x  a lower bound  lb  of β indicates that there is no
deterministic algorithm that produces a matching that satisfies x and achieves a β-approximation to the optimal welfare among matchings
that satisfy x 
are different ways to strengthen pareto optimality and are to-
gether referred to as signature-based matchings 
definition 1  given an instance i =  n  h  p   a matching
µ ∈ mgi is pareto optimal  po  w r t  i if ∀µ′ ∈ mgi
 ∃ai ∈ n  µ′ ai  ≻i µ ai   ⇒  ∃aj ∈ n  µ′ aj  ≺j µ aj  
definition 2  given an instance i =  n  h  p   and a
matching µ ∈ mgi  let si denote the number of agents that
are matched to a rank-i edge in µ  then  µ is
• rank-maximal if µ maximizes the number of agents who
are matched to a rank-1 edge and  subject to that  it max-
imizes the number of agents who are matched to rank-2
edges  and so on  formally  for each µ′ in mgi define
its signature to be the n-tuple sµ′ =  s1          sn   then
µ is the matching with the lexicographically optimal sig-
nature 
• max-cardinality rank-maximal if µ is a maximum car-
dinality matching and  subject to that  is also rank-
maximal  formally  for each µ′ in mgi define its signa-
ture to be the  n   1 -tuple  �n
i=1 si  s1          sn   then
µ is the matching with the lexicographically optimal sig-
nature 
• fair if µ is a maximum cardinality matching and  sub-
ject to that  minimizes the number of agents who are
matched to a rank-n edge and  subject to that  min-
imizes the number of agents who are matched to a
rank- n − 1  edge  and so on  formally  for each µ′
in mgi define its signature to be the  n   1 -tuple
 �n
i=1 si  −sn  −sn−1          −s1   then µ is the match-
ing with the lexicographically optimal signature 
signature-based matchings can be reduced to an instance
of the following problem  which we refer to as priority-p
matchings  for a given p =  p1  · · ·   pn   irving  2004 
irving et al   2006  mehlhorn and michail  2005  huang et
al   2013  michail  2007  
definition 3  given an instance i
=
 n  h  p
=
 p1          pn   and a priority vector p =  p1          pn   where
∀i ∈  n   pi ∈ z≥0 and ∃j  k ∈  n  such that pj ̸= pk  a
matching µ ∈ mgi is said to be a priority-p matching if µ
is a matching of maximum weight in mgi  where a rank-r
edge in gi is assigned the weight pr 
in particular  given an instance i  we can show that 1
• when pj = n2 n−j 1  for all j ∈  n   a matching is
a priority-p matching if and only if it is rank-maximal
matching w r t  i 
• when pj = n2n n2 n−j  for all j ∈  n   a matching is a
priority-p matching if and only if it is a max-cardinality
rank-maximal matching w r t  i 
• when pj = 4n2n − 2nj−1 for all j ∈  n   a matching is
a priority-p matching if and only if it is a fair matching
w r t  i 
for ease of exposition  we sometimes use priority-p  where
pi = 0 for all i ∈  n  to refer to pareto optimal matchings 
note that this is purely for notational convenience since the
algorithms we discuss in the context of pareto optimal match-
ings are extensions to the ones for priority-p matchings  we
also use p to denote the set of priority vectors of interest 
2 2
worst-case welfare lost
given an instance i  we are interested in deterministic al-
gorithms which return a matching that satisfies one of the
properties just defined  however  such matchings may not
be unique 
we argue that a principled way of select-
ing amongst all such matchings is to consider the cardi-
nal utilities of the agents  returning a matching with small
worst-case welfare loss  formally  for an instance i  con-
sider the set of matchings s ⊆ mgi such that s is the
set of all pareto optimal/rank-maximal/max-cardinality rank-
maximal/fair matchings in gi  next  for a matching µ ∈ s 
v ∈ vi  and for an edge e =  ai  hj  ∈ µ  let value e  =
1the proof of this can be found in the full version of the paper
 arxiv 2011 13977  
proceedings of the thirtieth    ijcai-21 
323
 algorithm 1 welfare optimal priority-p matching
1  input  i =  n  h  p   priorities p =  p1          pn   and v =
 v1          vn   where vi   h →  0  1 
2  output  welfare-optimal priority-p matching w r t  i
3  gi =  n ∪ h  e  ← graph induced by i
4  for e =  ai  hj  ∈ e do
5 
r ← rank ai  hj 
6 
we ← pr   vi hj 
7  end for
8  µ ← max-weight matching in gi with weights  we e∈e
9  return µ
vi hj  and sw µ | v  = �
e∈µ value e   the social welfare
of µ given the valuations v 2 given this  consider a determin-
istic algorithm a where  for all i ∈ i  a i  ∈ s and let
l a   which we refer to as the worst-case welfare loss of a 
be defined as l a   = maxi∈i l a  i   where
l a  i   = sup
v∈vi
max
µ∗∈s sw µ∗ | v 
sw a i  | v   
the objective is to design algorithms that return a match-
ing with the desired property and minimize l a   through-
out this paper  we say that  for an α ≥ 1  an algorithm a
achieves an α-approximation to the optimal social welfare
among pareto-optimal/rank-maximal/max-cardinality rank-
maximal/fair matchings if l a  ≤ α 
we first observe that any purely ordinal algorithm  that is
an algorithm that uses only the ordinal preferences of the
agents  performs poorly with respect to worst-case welfare
loss  due to space limitations all proofs are in the full version
 arxiv 2011 13977  
theorem 1  let x denote one of the properties in the
set  pareto-optimal  rank-maximal  max-cardinality rank-
maximal  and fair   let a be a deterministic ordinal algo-
rithm that always produces a matching that satisfies property
x  if there are n agents with unit-sum valuation functions 
then l a  ∈ ω n2   if there are n agents with unit-range
valuation functions then l a  ∈ ω n  
moreover  these
bounds are asymptotically tight 
at the other extreme  an algorithm may have access to
all utility information from the agents and  thus  is capable
of returning the welfare-optimal matching subject to the un-
derlying desired property  in particular  given an instance
i =  n  h  p  and valuation functions of the agents v =
 v1          vn   where vi   h →  0  1   the welfare-optimal
priority-p problem is to find a matching of maximum welfare
among the set of priority-p matchings  we observe that this
reduces to an instance of the max-weight matching problem
on gi 
theorem 2  given an instance i =  n  h  p   a vec-
tor of priorities p =  p1          pn   where p ∈ p  and
v =  v1          vn   where vi   h →  0  1   algorithm 1 returns
a welfare-optimal priority-p matching w r t  i 
2for notational convenience  when v is clear from the context 
we just write sw µ  instead of sw µ | v  
3
binary threshold queries
in this section we look at the central question of this paper 
how can one improve social welfare in one-sided matching
problems by asking only a small number of queries 
we
believe that asking directly for cardinal utility information
places a high cognitive burden on agents  therefore  we aim
for a middle-ground between solely ordinal and fully cardinal
algorithms  we do this by analysing the power of using very
simple queries  namely binary threshold queries 
definition 4  for an agent ai  object hj  and a real num-
ber tk ∈  0  1   a binary threshold query  q ai  hj  tk   asks
agent ai to return 1  alternatively  asks them to say  yes  
if vi hj  ≥ tk  and 0  alternatively  asks them to say  no  
otherwise 
given an instance i and answers to a certain number of
binary threshold queries  our goal is to design deterministic
algorithms a that minimize the worst-case welfare loss l a 
and  for all i ∈ i  produces a matching in s  i e   a i  ∈ s  
where s is the set of all pareto optimal/rank-maximal/max-
cardinality rank-maximal/fair matchings in gi 
towards
this end  we begin by considering adaptive algorithms—
algorithms that are allowed to change its queries based on the
agents  responses—and show how  when considering each
of the four properties of interest  one can obtain a  1   ϵ -
approximation to the optimal welfare 
following this  we
look at  what we believe is the more interesting and practi-
cal  case of non-adaptive algorithms  in particular  we restrict
ourselves to algorithms that can ask at most one query per
 agent  object  pair and show upper and lower bounds on the
approximation achievable  unless explicitly specified  all re-
sults hold for both unit-sum and unit-range valuations 
3 1
adaptive algorithm to achieve
 1   ϵ -approximation
given an instance i and a property encoded as a priority-
vector  algorithm 2 returns a matching with the desired prop-
erty  the high-level idea behind the algorithm is straightfor-
ward  for a specific choice of parameter c  it associates a
partition of objects with every agent  where for k ∈  c   an
object is in eik if agent ai s value for the object is within
some defined interval bk  using these partitions  carefully
computed weights are assigned to the edges in the induced
bipartite graph  gi  a max-weight matching on the result-
ing weighted graph is then computed  below we show for
c =
�
log n2·1/ϵ 
log  1 ϵ/2 
�
  this results in an  1   ϵ -approximation
algorithm that uses o c log n  queries per agent  in particu-
lar  this means that one can achieve a 2-approximation using
o log2 n  queries per agent 
theorem 3  given an ϵ > 0  an instance i =  n  h  p  
and a priority vector p
=
 p1          pn   algorithm 2
adaptively asks o c log n  queries per agent  where c =
�
log n2·1/ϵ 
log  1 ϵ/2 
�
  and returns a
1  pareto optimal matching µ that achieves a  1   ϵ -
approximation to the optimal welfare among all pareto
optimal matchings when pi = 0 for all i ∈  n  
proceedings of the thirtieth    ijcai-21 
324
 algorithm 2
1  input  ϵ > 0  i =  n  h  p   and p =  p1          pn 
2  output  a po matching when pi = 0 for all i ∈  n  and a
priority-p matching when p ∈ p
3  gi =  n ∪ h  e  ← graph induced by i
4  c ←
�
log n2·1/ϵ 
log  1 ϵ/2 
�
5  ti ←  
2
2 ϵ i  for i ∈  c 
6  for ai ∈ n do
7 
for k ∈  c  do
8 
eik ←   ai  hj  ∈ e | q ai  hj  tk  = 1 and  if k ≥
2  q ai  hj  tk−1  = 0 
9 
for e =  ai  hj  ∈ eik do
10 
r ← rank ai  hj 
11 
value′ e  ← tk
12 
we ← pr   value′ e 
13 
end for
14 
end for
15  end for
16  µ ← max-weight matching in gi with weights  we e∈e
17  if pi = 0 for all i ∈  n  then
18 
µ ← run top-trading cycles  ttc  algorithm with µ  from
line 16  as the initial endowment
19  end if
20  return µ
2  priority-p matching µ that achieves a  1   ϵ -
approximation to the optimal welfare among all priority-
p matchings when p ∈ p 
we observe that theorem 3 immediately informs us about
distortion 
any algorithm that returns a pareto-optimal
matching and achieves an α-approximation to the optimal
welfare amongst all pareto-optimal matchings must have dis-
tortion of α since welfare-optimal matchings are necessarily
pareto-optimal  thus  we are able to automatically confirm
and extend earlier distortion results  amanatidis et al   2021  
using a weaker query model  furthermore  we again empha-
size our interest in broader classes of matchings 
3 2
non-adaptive algorithms  asking one query
per  agent  object  pair
we now turn our attention to non-adaptive algorithms  in par-
ticular looking at algorithms that can only ask one query per
 agent  object  pair and cannot change these queries depend-
ing on earlier responses  we believe that this is the more in-
teresting and practical setting to consider for this problem 
since such an algorithm does not have to wait for the agents
to respond and also does not require an agent to answer mul-
tiple queries with respect to the same object—doing which
would in turn entail that the agent is somewhat sure about
their cardinal utilities 
we present two algorithms for when agents have unit-sum
valuations  first in the context of priority-p matchings and
second for pareto optimal matchings  the latter is an exten-
sion of the former  in algorithm 3  first the thresholds for
the queries are carefully chosen  then  in the induced bi-
partite graph  gi  weights for the edges are determined by
agents  responses to queries  a max-weight matching in this
graph is returned and is guaranteed to be a priority-p match-
ing  if a pareto-optimal matching is required then a little bit
algorithm 3
1  input 
an instance i
=
 n  h  p  and priorities p
=
 p1          pn 
2  output  a priority-p matching when p ∈ p
3  gi =  n ∪ h  e  ← graph induced by i
4  t1 ←
1
n1/3
5  ti ←
1
min i n1/3 ·n2/3   for all i ∈  2          n 
6  for e =  ai  hj  ∈ n × h do
7 
r ← rank ai  hj 
8 
if q ai  hj  tr  then
9 
we ← pr   tr
10 
else
11 
we ← pr
12 
end if
13  end for
14  µ ← max-weight matching in gi  where weights are  we e∈e
15  return µ
algorithm 4
1  input  an instance i =  n  h  p =  p1          pn  
2  output  a pareto optimal matching
3  µ′
mm ← matching returned by alg 3 on i and p =  0          0 
4  µmm ← µ′
mm \  e ∈ µmm | we = 0 
5  if |µmm| == 0 then
6 
µ′
aux ← matching in gi that maximizes the number of
agents who are matched with an edge of rank at most
⌊ 3√n/2⌋
7  else
8 
µ′
aux ← matching in gi where as many agents as possible
to a rank-1 edge
9  end if
10  µaux
←
µ′
aux
\
  a  o 
|
 a  o 
∈
µ′
aux and either a or o is matched in µmm 
11  µrest ← arbitrarily match the acceptable  agent  object  pairs
that are not matched in µmm ∪ µaux
12  µ ← run ttc with µmm ∪ µaux ∪ µrest as initial endowments
and return the resulting matching 
13  return µ
of additional work is needed to handle the situation where
algorithm 3 returns a matching where not all agents and ob-
jects are matched  algorithm 4 is the extension that handles
this case  by carefully handling the initial unmatched agents
through the construction of an auxiliary matching 
theorem 4  given an instance i =  n  h  p  and a vector
of priorities p =  p1          pn   where p ∈ p  algorithm 3
asks one non-adaptive query per  agent  object  and returns a
priority-p matching that achieves an o n2/3 -approximation
to the optimal welfare among all priority-p matchings for the
case when agents have unit-sum valuations 
theorem 5  given an instance i =  n  h  p   algorithm 4
asks one non-adaptive query per  agent  object  pair and re-
turns a pareto optimal matching that achieves an o n2/3 -
approximation to the optimal welfare among all pareto opti-
mal matchings for the case when agents have unit-sum valu-
ations 
finally  we also consider the case when agents have unit-
range valuations and show that it is possible to obtain an
o √n -approximation to the optimal social welfare among
proceedings of the thirtieth    ijcai-21 
325
 pareto optimal and priority-p matchings  the algorithms and
analyses for this case share similarities with algorithms 3
and 4  and can be found in the full version  arxiv 2011 
13977  
theorem 6  given an instance i
=  n  h  p  and a
vector of priorities p =  p1          pn   where p ∈ p 
there exists an algorithm that asks one non-adaptive query
per  agent  object  and returns a priority-p matching that
achieves an o √n -approximation to the optimal welfare
among all priority-p matchings for the case when agents have
unit-range valuations 
theorem 7  given an instance i =  n  h  p   there exists
an algorithm that asks one non-adaptive query per  agent 
object  and returns a pareto optimal matching that achieves
an o √n -approximation to the optimal welfare among all
pareto optimal matchings for the case when agents have unit-
range valuations 
lower bounds
we finally turn our attention to lower bounds for the
case when an algorithm can ask at most one query per
 agent  object  
we show that  for the unit-sum and unit-
range valuation cases  any deterministic algorithm a that
asks at most one query per  agent  object  pair and pro-
duces a pareto-optimal/rank-maximal/max-cardinality rank-
maximal/fair matching has a worst-case welfare loss of
ω √n   i e   l a  ∈ ω √n  
theorem 8  let x denote one of the properties in the
set  pareto-optimal  rank-maximal  max-cardinality rank-
maximal  and fair   let a be a non-adaptive determinis-
tic algorithm that always produces a matching that satisfies
property x and asks at most one query per  agent  object 
pair  if there are n agents with unit-sum valuation functions
or unit-range valuations  then l a  ∈ ω √n  
4
discussion
we investigated the benefit of eliciting a small amount of in-
formation about agents  cardinal utilities in the context of
one-sided matching  we designed algorithms that used sim-
ple threshold queries and returned a matching satisfying some
desirable matching property  while also achieving a good ap-
proximation to the optimal welfare among all matchings sat-
isfying that property  our results show how we can improve
welfare by even non-adaptively asking agents for just one bit
of extra information per object  given a one-sided matching
instance  there are often multiple matchings of interest and
we view the methodology we presented here as providing a
principled way of tie-breaking 
while adaptive algorithms provide better approximation
guarantees  we believe the benefits of non-adaptive ap-
proaches outweigh the negatives  the argument for not in-
sisting agents reveal full and exact cardinal utility informa-
tion in the first place is that this places too high a cognitive
demand on the agents  our non-adaptive approach  which
asks for only one bit of information for each  agent  object 
pair  could be implemented using a simple menu – reducing
the time and effort an individual agent must interact with the
matching process 
there are a number of future research directions that this
work can take  for example  we may want multiple agents to
be assigned the same object  like when assigning students to
courses or schools  only minimal modifications are needed
to address this case  in particular  every time we construct
a graph in any of the algorithms  all that needs to be done
is to create kj copies for the node that corresponds to ob-
ject hj  other open algorithmic problems include address-
ing the gap between the upper and lower bounds for the non-
adaptive algorithms  expanding the set of properties of inter-
est to include  for example  popular matchings  abraham et
al   2007   or asking similar questions in the context of two-
sided matching problems  finally  we are interested in bet-
ter understanding the implications of deploying such an ap-
proach in practice  including evaluating how interface-design
might best support queries  as well as better understanding
what matching properties are deemed to be most important
by users and designers of systems 
references
 abdulkadiro˘glu and s¨onmez  1998  atila
abdulkadiro˘glu
and tayfun s¨onmez  random serial dictatorship and the
core from random endowments in house allocation prob-
lems  econometrica  66 3  689–701  1998 
 abdulkadiro˘glu and s¨onmez  1999  atila
abdulkadiro˘glu
and tayfun s¨onmez  house allocation with existing ten-
ants  journal of economic theory  88 2  233–260  1999 
 abdulkadiro˘glu et al   2011  atila abdulkadiro˘glu  yeon-
koo che  and yosuke yasuda  resolving conflicting pref-
erences in school choice  the  boston mechanism  re-
considered  american economic review  101 1  399–410 
2011 
 abdulkadiro˘glu et al   2015  atila abdulkadiro˘glu  yeon-
koo che  and yosuke yasuda 
expanding  choice  in
school choice  american economic journal  microeco-
nomics  7 1  1–42  2015 
 abraham et al   2004  david
j 
abraham 
katar ına
cechl arov a  david f  manlove  and kurt mehlhorn 
pareto optimality in house allocation problems 
in
proceedings of isaac-2004  pages 3–15  2004 
 abraham et al   2006  david j  abraham  ning chen  vijay
kumar  and vahab s mirrokni  assignment problems in
rental markets  in proceedings of wine-2006  pages 198–
213  2006 
 abraham et al   2007  david j  abraham  robert w  irving 
telikepalli kavitha  and kurt mehlhorn  popular match-
ings 
siam journal on computing  37 4  1030–1045 
2007 
 abramowitz and anshelevich  2018  ben abramowitz and
elliot anshelevich  utilitarians without utilities  maxi-
mizing social welfare for graph problems using only or-
dinal preferences 
in proceedings of aaai-2018  pages
894–901  2018 
 abramowitz et al   2019  ben abramowitz  elliot anshele-
vich  and wennan zhu  awareness of voter passion greatly
proceedings of the thirtieth    ijcai-21 
326
 improves the distortion of metric social choice  in pro-
ceedings of wine-2019  pages 3–16  2019 
 amanatidis et al   2020  georgios
amanatidis 
geor-
gios birmpas  aris filos-ratsikas  and alexandros
a  voudouris 
peeking behind the ordinal curtain  im-
proving distortion via cardinal queries  in proceedings of
aaai-2020  pages 1782–1789  2020 
 amanatidis et al   2021  georgios
amanatidis 
geor-
gios birmpas  aris filos-ratsikas  and alexandros
a  voudouris  a few queries go a long way  information-
distortion tradeoffs in matching 
in proceedings of
aaai-2021  2021 
 anshelevich and sekar  2016  elliot
anshelevich
and
shreyas sekar  blind  greedy  and random  algorithms for
matching and clustering using only ordinal information 
in proceedings of aaai-2016  pages 383–389  2016 
 anshelevich and zhu  2017  elliot anshelevich and wen-
nan zhu  tradeoffs between information and ordinal ap-
proximation for bipartite matching 
in proceedings of
sagt-2017  pages 267–279  2017 
 benade et al   2020  gerdus
benade 
swaprava
nath 
ariel d  procaccia  and nisarg shah  preference elicita-
tion for participatory budgeting 
management science 
articles in advance  pages 1–15  2020 
 boutilier et al   2015  craig boutilier  ioannis caragiannis 
simi haber  tyler lu  ariel d  procaccia  and or sheffet 
optimal social choice functions  a utilitarian view  artifi-
cial intelligence  227 190–213  2015 
 bredereck et al   2017  robert
bredereck 
piotr
fal-
iszewski 
andrzej
kaczmarczyk 
rolf
niedermeier 
piotr skowron  and nimrod talmon  robustness among
multiwinner voting rules  in proceedings of sagt-2017 
pages 80–92  2017 
 chen et al   2019  jiehua chen  piotr skowron  and manuel
sorge  matchings under preferences  strength of stability
and trade-offs  in proceedings of acm ec-2019  pages
41–59  2019 
 chiesa et al   2012  alessandro chiesa  silvio micali  and
zeyuan allen zhu  mechanism design with approximate
valuations  in proceedings of itcs-2012  pages 34–38 
2012 
 chiesa et al   2014  alessandro chiesa  silvio micali  and
zeyuan allen zhu  knightian self uncertainty in the vcg
mechanism for unrestricted combinatorial auctions 
in
proceedings of acm ec-2014  pages 619–620  2014 
 filos-ratsikas et al   2014  aris
filos-ratsikas 
søren
kristoffer stiil frederiksen  and jie zhang  social welfare
in one-sided matchings  random priority and beyond  in
proceedings of sagt-2014  pages 1–12  2014 
 goel et al   2017  ashish goel  anilesh k  krishnaswamy 
and kamesh munagala  metric distortion of social choice
rules  lower bounds and fairness properties  in proceed-
ings acm ec-2017  pages 287–304  2017 
 goel et al   2019  ashish goel  anilesh k  krishnaswamy 
sukolsak sakshuwong  and tanja aitamurto  knapsack
voting for participatory budgeting  acm transactions on
economics and computation  7 2  1–27  2019 
 huang et al   2013  chien-chung
huang 
telikepalli
kavitha  kurt mehlhorn  and dimitrios michail 
fair
matchings and related problems 
in iarcs annual
conference on foundations of software technology and
theoretical computer science  fsttcs   2013 
 hylland and zeckhauser  1979  aanund
hylland
and
richard zeckhauser 
the efficient allocation of indi-
viduals to positions 
journal of political economy 
87 2  293–314  1979 
 irving et al   2006  robert w  irving  telikepalli kavitha 
kurt mehlhorn  dimitrios michail  and katarzyna e 
paluch  rank-maximal matchings  acm transactions on
algorithms  2 4  602–610  october 2006 
 irving  2004  robert w  irving 
greedy matchings 
tr-
2004-177  university of glasgow  computing science de-
partment research report  2004 
 mandal et al   2020  debmalya mandal  nisarg shah  and
david p  woodruff 
optimal communication-distortion
tradeoff in voting  in proceedings of acm-ec 2020  pages
795–813  2020 
 mehlhorn and michail  2005  kurt mehlhorn and dimitrios
michail  network problems with non-polynomial weights
and applications  manuscript  2005 
 menon and larson  2018  vijay menon and kate larson 
robust and approximately stable marriages under partial
information  in proceedings of wine-2018  pages 341–
355  2018 
 menon and larson  2019  vijay menon and kate larson 
mechanism design for locating a facility under partial in-
formation  in proceedings of sagt-2019  pages 49–62 
2019 
 michail  2007  dimitrios michail  reducing rank-maximal
to maximum weight matching  theoretical computer sci-
ence  389 1-2  125–132  2007 
 procaccia and rosenschein  2006  ariel d  procaccia and
jeffrey s rosenschein  the distortion of cardinal prefer-
ences in voting  in international workshop on cooperative
information agents  pages 317–331  2006 
 roth and postlewaite  1977  alvin e  roth and andrew
postlewaite 
weak versus strong domination in a mar-
ket with indivisible goods  journal of mathematical eco-
nomics  4 2  131–137  1977 
 shapley and scarf  1974  lloyd shapley and herbert scarf 
on cores and indivisibility  journal of mathematical eco-
nomics  1 1  23–37  1974 
 shiryaev et al   2013  dmitry shiryaev  lan yu  and edith
elkind  on elections with robust winners  in proceedings
of aamas-2013  pages 415–422  2013 
 s¨onmez and ¨unver  2010  tayfun s¨onmez and m  utku
¨unver  house allocation with existing tenants  a char-
acterization  games and economic behavior  69 2  425–
445  2010 
proceedings of the thirtieth    ijcai-21 
327
 "
None,2021,https-www-ijcai-org-proceedings-2021-0046-pdf,Generalized Kings and Single-Elimination Winners in Random Tournaments,"Pasin Manurangsi, Warut Suksompong",None,https://www.ijcai.org/proceedings/2021/0046.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0046-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0046-pdf.pdf,"generalized kings and single-elimination winners in random tournaments
pasin manurangsi1 and warut suksompong2
1google research  usa
2school of computing  national university of singapore  singapore
pasin@google com  warut@comp nus edu sg
abstract
tournaments can be used to model a variety of
practical scenarios including sports competitions
and elections  a natural notion of strength of al-
ternatives in a tournament is a generalized king  an
alternative is said to be a k-king if it can reach every
other alternative in the tournament via a directed
path of length at most k  in this paper  we provide
an almost complete characterization of the proba-
bility threshold such that all  a large number  or a
small number of alternatives are k-kings with high
probability in two random models  we show that 
perhaps surprisingly  all changes in the threshold
occur in the range of constant k  with the biggest
change being between k = 2 and k = 3  in addi-
tion  we establish an asymptotically tight bound on
the probability threshold for which all alternatives
are likely able to win a single-elimination tourna-
ment under some bracket 
1
introduction
social choice theory is the study of how to aggregate in-
dividual preferences and opinions of agents on a set of al-
ternatives in order to reach a collective decision  in many
practical situations  the relationship between the alternatives
is represented by a dominance relation  which specifies the
relative strength of the alternatives in any pairwise compari-
son  for example  in sports competitions the dominance rela-
tion signifies the match outcome when two players or teams
play each other  while in elections the relation represents the
pairwise majority comparisons among the candidates  the
structure consisting of the alternatives and their dominance
relation is called a tournament  and the analysis of tourna-
ment winner selection methods—also known as tournament
solutions—has received significant attention from researchers
in the past few decades  laslier  1997  brandt et al   2016 
suksompong  2021  
among the vast array of tournament solutions proposed in
the literature  two of the earliest and best-known ones are the
top cycle  good  1971  schwartz  1972  miller  1977  and the
uncovered set  fishburn  1977  miller  1980   an alternative
belongs to the top cycle if it can reach every other alternative
via a directed path in the tournament  note that if the tourna-
ment contains n alternatives  any such path has length n−1 or
less  the length of a path refers to the number of edges in the
path  1 similarly  the uncovered set—also known as the set
of kings  maurer  1980 —consists of the alternatives that can
reach every other alternative via a path of length at most two 
it is clear from the definitions that the uncovered set is always
a subset of the top cycle  moreover  both tournament solu-
tions can be viewed as special cases of a generalized notion
of kings called k-kings  which correspond to the alternatives
that can reach every other alternative via a path of length at
most k  indeed  the uncovered set is the set of 2-kings  while
the top cycle contains precisely the  n − 1 -kings 
given that tournament solutions are meant to distinguish
the best alternatives from the rest  it is natural to ask how se-
lective each tournament solution is  moon and moser  1962 
and fey  2008  addressed this question and showed that the
top cycle and the uncovered set are likely to include all al-
ternatives when the tournament is large  in particular  their
results hold under the uniform random model  wherein each
edge is oriented in one direction or the other with equal prob-
ability independently of other edges 
saile and suksom-
pong  2020  extended these results to the generalized random
model  in which the orientation of each edge is determined by
probabilities within the range  p  1 − p  for some parameter
p ≤ 1/2  and these probabilities may vary across edges  the
generalized random model allowed these authors to demon-
strate a difference between the two tournament solutions—
while the top cycle almost never excludes any alternative as
long as p ∈ ω 1/n   the uncovered set is likely to select all
alternatives only when p ∈ ω 
�
log n/n   so the two thresh-
olds differ by roughly θ √n   this raises the following ques-
tion  how does the probability threshold change as we tran-
sition from k = 2 to k = n − 1  does it already decrease
at around k = √n  or does it remain the same until  say 
k ≈ n/2 
in this paper  we show that  perhaps surprisingly  all of
the changes in the probability threshold occur when k is con-
stant  in fact  when k = 6  all alternatives are already likely
1the bound n − 1 cannot be improved  to see this  consider a
tournament with alternatives x1          xn such that xi dominates xj
if i − j ≥ 2 or j − i = 1  alternative x1 can reach every other
alternative  but it cannot reach xn via a path of length n − 2 or less 
proceedings of the thirtieth    ijcai-21 
328
 tournament solution
condorcet random model
generalized random model
k-kings
k = 2
ω 
�
log n/n   saile and suksompong  2020 
ω 
�
log n/n   saile and suksompong  2020 
3 ≤ k ≤ 4
ω log n/n   thm  3 1  3 3 
ω log n/n   thm  3 1  3 3 
k = 5
ω 1/n   thm  3 4 
ω log log n/n   thm  3 8 
6 ≤ k ≤ n − 1
ω 1/n   thm  3 5 
ω 1/n   thm  3 5 
single-elimination winners
ω log n/n   kim et al   2017 
ω log n/n   thm  4 3 
table 1  summary of the bounds on the probability p at which the respective tournament solutions select all alternatives with high probability
under the corresponding random model  all bounds are asymptotically tight except the bound for k = 5 with the generalized random model 
where there is a gap between ω log log n/n  and ω 1/n   the results with ω ·  hold when the associated constant term is sufficiently large 
to be k-kings provided that p ∈ ω 1/n   the same thresh-
old as k = n − 1—this significantly strengthens the re-
sult of saile and suksompong  2020  on the top cycle  for
k = 3 and 4  we establish an asymptotically tight bound of
p ∈ ω log n/n   while for k = 5 we leave the only  small 
gap between ω log log n/n  and ω 1/n   besides the gen-
eralized random model  we consider a more specific model
which has nevertheless been studied in several papers called
the condorcet random model  in this model  there is a pa-
rameter p and a linear order of alternatives from strongest to
weakest  and the probability that a stronger alternative dom-
inates a weaker one is 1 − p  independently of other pairs of
alternatives 2 for the condorcet random model  we show that
the threshold for k = 5 is ω 1/n   whereas the thresholds for
other values of k remain tight  our results are summarized in
table 1 and presented in section 3  taken together  they re-
veal the intriguing facts that  i  the uncovered set is distinctly
more selective than k-kings for k ≥ 3   ii  3-kings and 4-
kings are slightly more selective than higher-order kings  and
 iii  there is virtually no difference in discriminative power
from k = 5 all the way to k = n − 1 
in addition to k-kings  we also consider the set of
single-elimination winners  which are alternatives that can
win a  balanced  single-elimination tournament under some
bracket  where the match outcomes in the single-elimination
tournament are determined according to the dominance re-
lation in the original tournament 3 kim et al   2017  showed
that all alternatives are likely to be single-elimination winners
in the condorcet random model as long as p ∈ ω log n/n  
and this bound is tight 4 for the generalized random model 
they established an analogous statement in the range p ∈
ω 
�
log n/n   we close this gap by proving that even for the
generalized random model  p ∈ ω log n/n  already suffices
2the uniform random model corresponds to taking p = 1/2  for
any p  the condorcet random model with parameter p is a special
case of the generalized random model with the same p  hence  a
positive result for the generalized random model carries over to the
condorcet random model  while a negative result transfers in the
opposite direction 
3following prior work on single-elimination tournaments  we as-
sume that the number of alternatives is a power of two 
4if p ∈ o log n/n   the weakest alternative dominates o log n 
alternatives in expectation  this is insufficient since winning log2 n
matches is required to win a single-elimination tournament 
for all alternatives to be single-elimination winners with high
probability  moreover  a winning bracket for each alternative
can be computed in polynomial time  our result  which can
be found in section 4  further lends credence to the obser-
vation that real-world tournaments can be easily manipulated
 mattei and walsh  2016  
finally  in section 5  we move beyond the question of
when all alternatives are likely to be selected by a tourna-
ment solution  and instead ask when this is the case for a large
or small number of alternatives  for the uncovered set  even
though p ∈ ω 
�
log n/n  is required in order for all alterna-
tives to be chosen with high probability  saile and suksom-
pong  2020   we show that most of them are already likely
to be included as long as p ∈ ω log n/n   this threshold
is exactly where the transition occurs  if p ∈ o log n/n  
we prove that the uncovered set almost surely contains only a
small fraction of the alternatives  furthermore  for any k ≥ 3 
we establish that a large fraction of alternatives are likely to
be k-kings provided that p ∈ ω 1/n   these results illustrate
the probability range under which each tournament solution
is discriminative  and again exhibit a clear difference between
the uncovered set and higher-order kings 
1 1
related work
tournament solutions have been extensively studied for the
past several decades  we refer to the surveys by laslier  1997 
and brandt et al   2016   there are several containment re-
lations among common tournament solutions  for example 
the copeland set  slater set  markov set  and banks set are
all contained in the uncovered set  which is in turn contained
in the top cycle—this provides a range of options in terms of
discriminative power and other properties  even though k-
kings admit a simple and elegant definition generalizing the
top cycle as well as the uncovered set  and have attracted in-
terest from graph theorists  petrovic and thomassen  1991 
tan  2006  brcanov and petrovic  2010   as far as we know 
they have not been studied in the social choice context until
recently  kim and vassilevska williams  2015  and kim et
al   2017  identified conditions under which a 3-king can win
a single-elimination tournament  brill et al   2020  showed
that computing the  margin of victory  of k-kings can be
done efficiently for k ≤ 3 but becomes np-hard for k ≥ 4 
brill et al   2021  illustrated through experiments that the
margin of victory of 3-kings behaves much more similarly to
proceedings of the thirtieth    ijcai-21 
329
 that of the top cycle than to the corresponding notion of the
uncovered set  our results therefore complement theirs by ex-
hibiting that analogous behavior can be observed with respect
to discriminative power 
as we mentioned earlier  the study of tournament so-
lutions under the probabilistic lens was initiated by moon
and moser  1962   who showed that the top cycle is likely
to choose all alternatives when the tournament is generated
by the uniform random model  fey  2008  and scott and
fey  2012  established the same property for the uncovered
set as well as two other tournament solutions  the banks set
and the minimal covering set  while fisher and ryan  1995 
showed that the bipartisan set includes half of the alternatives
on average 5 the condorcet random model has been ana-
lyzed  among others  by frank  1968   łuczak et al   1996  
vassilevska williams  2010   and kim et al   2017   with the
last paper also proposing the generalized random model  as
saile and suksompong  2020  pointed out  the condorcet ran-
dom model suffers from limitations such as using the same
probability for all pairs of alternatives  regardless of the ex-
tent to which one alternative is stronger than the other  or not
allowing for  bogey teams   i e   weak teams that often beat
certain stronger teams   the generalized random model only
assumes that each match is sufficiently random  and therefore
does not have these limitations 
finally  single-elimination tournaments have constituted a
popular topic of study in the past decade  see the surveys by
vassilevska williams  2016  and suksompong  2021   in par-
ticular  even though the problem of determining whether an
alternative can win a single-elimination tournament is known
to be np-hard  aziz et al   2018   a wide range of algorithmic
and complexity results have been developed by this active line
of work 
2
preliminaries
a tournament t consists of a set v =  x1          xn  of ver-
tices  also called alternatives  and a set e of directed edges 
for any two alternatives xi  xj ∈ v   there exists either an
edge from xi to xj or an edge from xj to xi  but not both 
the edges represent a dominance relation between the alter-
natives  an edge from xi to xj means that xi dominates xj  a
relation which we denote by xi ≻ xj  the outdegree  resp  
indegree  of an alternative xi is the number of alternatives
that xi dominates  resp   that dominate xi   we extend the
dominance relation to sets of alternatives  for v1  v2 ⊆ v  
we write v1 ≻ v2 to mean that x ≻ x′ for all x ∈ v1 and
x′ ∈ v2  and v1 ≻ x′ to mean that x ≻ x′ for all x ∈ v1  a
set v ′ ⊆ v is called a dominating set if for every x ∈ v \v ′ 
there exists x′ ∈ v ′ such that x′ ≻ x 
we can now define the key notions of this paper 
• for any integer k ≥ 2  an alternative is said to be a k-
king if it can reach every other alternative via a directed
path of length at most k 
5brandt et al   2018  showed that any tournament solution that
satisfies an attractive property called stability  including the top cy-
cle  the minimal covering set  and the bipartisan set  must choose at
least half of the alternatives on average 
• suppose that n = 2r for some nonnegative integer r 
an alternative is said to be a single-elimination winner
if it wins a  balanced  single-elimination tournament un-
der some bracket  where the outcome of each match is
determined according to the dominance relation 6
we will consider two random models for generating tour-
naments  in the condorcet random model  there is a param-
eter 0 ≤ p ≤ 1/2  for i < j  alternative xj dominates
xi with probability p  so xi dominates xj with probability
1 − p   independently of other pairs of alternatives  in the
generalized random model  there is a parameter pi j for each
pair i ̸= j  where pi j   pj i = 1  for any pair i  j  alter-
native xi dominates xj with probability pi j  independently
of other pairs  we will generally allow each probability pi j
to be chosen from the range  p  1 − p  for a given parame-
ter 0 ≤ p ≤ 1/2  before a tournament is generated from
the generalized random model  the expected outdegree of xi
is defined as �
j̸=i pi j  following standard terminology in
probability theory  we say that an event whose probability de-
pends on n occurs  with high probability  if the probability
that it occurs approaches 1 as n → ∞ 
we now list two well-known probabilistic statements that
will be used multiple times in this paper  the first statement
provides an upper bound on the probability that a sum of in-
dependent random variables is far from its expectation 
lemma 2 1  chernoff bound   let x1          xk be indepen-
dent random variables taking values in  0  1   and let x  =
x1   · · ·   xk  then  for any δ ∈  0  1  
pr x ≥  1   δ e x   ≤ exp
�−δ2e x 
3
�
and
pr x ≤  1 − δ e x   ≤ exp
�−δ2e x 
2
�
 
the second statement is a simple upper bound on the ex-
pression 1   x 
lemma 2 2  for every real number x  we have 1   x ≤ ex 
we end this section with a lemma on the degree of alterna-
tives in a tournament 
lemma 2 3  let 1 ≤ r ≤ n  for any tournament t  the
average outdegree and the average indegree of the alterna-
tives in any subset of size r are at least  r − 1 /2  similarly 
the average expected outdegree of the alternatives in such a
subset is at least  r − 1 /2 
proof  we prove the statement for the average outdegree  the
proofs for the average indegree as well as the average ex-
pected outdegree are similar  in a subset of alternatives of
size r  there are a total of r r − 1 /2 edges  hence  the sum
of the outdegrees of the r alternatives is at least r r − 1 /2 
implying that their average is at least  r − 1 /2 
unless a base is explicitly specified  log refers to the nat-
ural logarithm  all omitted proofs can be found in the full
version of our paper  manurangsi and suksompong  2021  
6see  e g    aziz et al   2018  for formal definitions 
proceedings of the thirtieth    ijcai-21 
330
 3
generalized kings
recall the result of saile and suksompong  2020  that in the
generalized random model  all alternatives are 2-kings  i e  
belong to the uncovered set  with high probability only if p ∈
ω 
�
log n/n   for our first result  we show that 3-kings are
not as selective  even when p ∈ ω log n/n   it is already
likely that none of the alternatives is excluded by this set 
theorem 3 1  assume that a tournament t is generated ac-
cording to the generalized random model  and that pi j ∈
 30 log n/n  1 − 30 log n/n  for all i ̸= j  then with high
probability  all alternatives in t are 3-kings 
to prove this theorem  we establish a rather general lemma
on the probability of one set dominating another  which will
also be useful in our analysis of 5-kings later 
lemma
3 2 
let
t0
be
a
tournament
consisting
of
n0
alternatives
v0
 =
 x1          xn0  
and
let
q1 1  q1 2          qn0 1  qn0 2 ∈
�
10λ
n0   1
�
for some 1 ≤ λ ≤ n0
10  
suppose that we randomly create a set s1 by including each
alternative xi independently with probability qi 1  and a
set s2 by including each alternative xi independently with
probability qi 2  then  pr s1 ∩ s2 = ∅ and s1 ≻ s2  ≤ e−λ 
lemma 3 2 allows for a short proof of theorem 3 1 
proof of theorem 3 1  fix a pair of distinct alternatives
xi  xj  we first bound the probability that xj cannot reach
xi via a directed path of length at most three 
consider the tournament t 0 defined by restricting t to
v 0  = v \  xi  xj   let s1 denote the set of alternatives
in v 0 that dominate xi with respect to t  and let s2 denote
the set of alternatives in v 0 that are dominated by xj with re-
spect to t  notice that if s1 ∩ s2 ̸= ∅ or s1 ̸≻ s2  then there
is a path of length at most three from xj to xi  furthermore 
from the assumption of the theorem  each alternative belongs
to each of s1 and s2 independently with probability at least
30 log n
n
  which is at least 25 log n
|v 0|
for any sufficiently large n 
as a result  we may apply lemma 3 2 with λ = 2 5 log n 
which gives
pr there is no path of length at most three from xj to xi 
≤ pr s1 ∩ s2 = ∅ and s1 ≻ s2 
≤ e−λ = 1/n2 5 
finally  applying the union bound over all  ordered  pairs
of alternatives xi ̸= xj  the probability that some alterna-
tive cannot reach some other alternative via a directed path of
length at most three is no more than 1/n0 5  which converges
to 0 as n goes to infinity 
next  we show that in the condorcet random model  if p ∈
θ log n/n  and the associated constant is low enough  there
is likely to be an alternative that is not a 4-king  combined
with theorem 3 1  this implies that the bound θ log n/n  is
asymptotically tight for both 3- and 4-kings in both random
models that we consider 
theorem 3 3  assume that a tournament t is generated
according to the condorcet random model  and that p ≤
0 1 log n/n  then with high probability  there exists an al-
ternative in t that is not a 4-king 
our results so far demonstrate that k-kings for any k ≥ 3
are much closer to the top cycle  i e    n−1 -kings  than to the
uncovered set  i e   2-kings  in terms of discriminative power 
in the remainder of this section  we show that there is virtually
no difference in selectiveness between k-kings for k ≥ 6 and
the top cycle  we begin by showing that in the condorcet ran-
dom model  all alternatives are likely to be 5-kings provided
that p ∈ ω 1/n —this gives a complete characterization of
the probability threshold for the condorcet random model 
theorem 3 4  assume that a tournament t is generated
according to the condorcet random model  and that p ∈
ω 1/n   then with high probability  all alternatives in t are
5-kings 
for the generalized random model  we show that as long as
p ∈ ω 1/n   all alternatives are likely to be 6-kings 
theorem 3 5  assume that a tournament t is generated ac-
cording to the generalized random model  and that pi j ∈
ω 1/n  for all i ̸= j  then with high probability  all alterna-
tives in t are 6-kings 
in light of theorem 3 5  the only remaining gap in our
probability threshold characterization is for 5-kings in the
generalized random model 
we conjecture that the true
threshold is ω 1/n   but our proof of theorem 3 4 relies
on the ordering of the alternatives in the condorcet random
model and cannot be easily extended  instead  we present
a slightly weaker bound of ω log log n/n —this shows that
5-kings are closer to 6-kings than to 4-kings with respect to
selective power  to establish this bound  we need a lemma on
generalized dominating sets 
definition 3 6  given a positive integer r  a set of alternatives
d is said to be an r-dominating set of a tournament t if every
alternative x /∈ d is dominated by at least r alternatives in d 
lemma 3 7  for any tournament t and any positive inte-
ger r  there exists an r-dominating set of t of size at most
r⌈log2 n⌉ 
proof  let us start with d = ∅ and repeat the following pro-
cedure r times  find a minimum dominating set s of the
restriction of t on v \ d  and update d to d ∪ s  it is
clear that the final set d is an r-dominating set of t  fur-
thermore  it is well-known  megiddo and vishkin  1988  fact
2 5  that any tournament has a dominating set of size at most
⌈log2 n⌉  which implies that the final set d is of size at most
r⌈log2 n⌉ 
we are now ready to establish our result on 5-kings 
theorem 3 8  assume that a tournament t is generated ac-
cording to the generalized random model  and that pi j ∈
 50 log log n /n  1 − 50 log log n /n  for all i ̸= j  then
with high probability  all alternatives in t are 5-kings 
proof  define a tournament t ′ on alternatives x1          xn so
that for each pair i ̸= j  we have xi ≻ xj if pi j > 1/2 
then  our tournament t is generated by reversing the edges
of t ′ so that the edge between xi and xj is reversed with
probability qi j  = min pi j  1 − pi j  ≤ 1/2  independently
of other edges  for each alternative x  let i x  denote the set
of alternatives that dominate x in t ′ 
proceedings of the thirtieth    ijcai-21 
331
 let r = ⌈1 1 log2 n⌉  and let d and dinv be a minimum
r-dominating set of the tournament t ′ and its  inverse  con-
structed by reversing all edges in t ′  respectively 
from
lemma 3 7  we have |d|  |dinv| ≤ r⌈log2 n⌉  which is at
most 2 3 log n 2 for any sufficiently large n 
we define the following three events in t 
• e1  for every xm ̸∈ d  there exists xi ∈ d such that
xi ≻ xm 
• e2  for every xℓ ̸∈ dinv  there exists xj ∈ dinv such
that xℓ ≻ xj 
• e3  for every xi ∈ d and xj ∈ dinv  there exists a
directed path of length at most three from xj to xi 
similarly to the proof of theorem 3 4  when e1  e2  and e3
all occur  every alternative is a 5-king  as a result  it suf-
fices to show that each of the three events occurs with high
probability 
for e1  we have
pr ¬e1  = pr ∃xm ̸∈ d  ∀xi ∈ d  xm ≻ xi 
≤
�
xm̸∈d
pr ∀xi ∈ d  xm ≻ xi 
≤
�
xm̸∈d
pr ∀xi ∈ d ∩ i xm   xm ≻ xi 
=
�
xm̸∈d
�
xi∈d∩i xm 
pr xm ≻ xi 
=
�
xm̸∈d
�
xi∈d∩i xm 
qi m
≤
�
xm̸∈d
 1/2 |d∩i xm |
≤
�
xm̸∈d
 1/2 r
≤
�
xm̸∈d
1/n1 1
∈ o 1  
where the first inequality follows the union bound and the
fourth inequality from the fact that d is an r-dominating set
in t ′  an analogous argument shows that e2 also occurs with
high probability 
finally  consider e3  since both d and dinv are of size
o  log n 2   by the union bound  it suffices to show that for
each fixed pair xi ∈ d and xj ∈ dinv  a path of length at most
three from xj to xi exists with probability 1 − o 1/ log n 4  
to prove this  consider the tournament t 0 defined by re-
stricting t to v 0  = v \  d ∪ dinv   let s1 denote the set of
alternatives in v 0 that dominate xi with respect to t  and let
s2 denote the set of alternatives in v 0 that are dominated by
xj with respect to t  notice that if s1 ∩ s2 ̸= ∅ or s1 ̸≻ s2 
then there is a path of length at most three from xj to xi 
furthermore  from the assumption of the theorem  each alter-
native belongs to each of s1 and s2 independently with prob-
ability at least 50 log log n
n
  which is at least 45 log log n
|v 0|
for any
sufficiently large n  as a result  we may apply lemma 3 2
with λ = 4 5 log log n  which gives
pr there is no path of length at most three from xj to xi 
≤ pr s1 ∩ s2 = ∅ and s1 ≻ s2 
≤ e−λ
= 1/ log n 4 5
∈ o 1/ log n 4  
which concludes our proof 
4
single-elimination winners
in this section  we consider single-elimination winners and
derive a tight bound of ω log n/n  for the generalized ran-
dom model  thereby strengthening the bound ω 
�
log n/n 
of kim et al   2017  and matching their bound for the con-
dorcet random model  as in previous work on this subject 
we assume for simplicity that n = 2r for some positive inte-
ger r  so r = log2 n  in order to construct a winning bracket 
a useful notion is that of a  superking   introduced by vas-
silevska williams  2010  
definition 4 1  given a tournament t  an alternative x is said
to be a superking if for every alternative x′ such that x′ ≻ x 
there exist at least log2 n alternatives x′′ such that x ≻ x′′
and x′′ ≻ x′ 
lemma 4 2  vassilevska williams  2010    in any tourna-
ment  every superking is a single-elimination winner  and its
winning bracket can be computed in polynomial time 
before we proceed to our result  let us briefly recap the
proofs of the two aforementioned results by kim et al   2017  
and explain why they cannot be used to establish our de-
sired strengthening  in order to show that all alternatives are
single-elimination winners with high probability when p ∈
ω 
�
log n/n   these authors showed that all alternatives are
likely to be superkings in this range  it is not difficult to verify
that this condition no longer holds when p ∈ o 
�
log n/n  
for the ω log n/n  bound in the condorcet random model 
they argued that the weakest alternative x is likely to domi-
nate one of the top n/6 alternatives  and constructed a win-
ning bracket for this latter alternative y among the top half
of the alternatives  so that x can play y in the final round and
win the single-elimination tournament  since there is no clear
notion of strength in the generalized random model  indeed 
all alternatives may be roughly equally strong  with no linear
order   this approach also does not work for our purpose 
at a high level  our proof proceeds by choosing r = log2 n
alternatives that our desired winning alternative x dominates 
in order to ensure that x can play against these alternatives
in the r rounds  we partition the r alternatives along with the
remaining alternatives into subsets of size 1  2          2r−1  so
that the r alternatives are superkings in the respective sub-
tournament and can therefore win a single-elimination tour-
nament with respect to their subset by lemma 4 2 
theorem 4 3  assume that a tournament t is generated ac-
cording to the generalized random model  and that pi j ∈
 80 log n/n  1 − 80 log n/n  for all i ̸= j  then with high
proceedings of the thirtieth    ijcai-21 
332
 probability  all alternatives in t are single-elimination win-
ners  and a winning bracket of each alternative can be com-
puted in polynomial time 
5
number of kings
so far  we have addressed the question of when each tourna-
ment solution is likely to select all alternatives  i e   the case
where the solution is decidedly not useful  in this section  we
move beyond this question  which is also the focus of several
previous works  and ask when a small or large number of al-
ternatives are chosen  our first result shows that even though
p ∈ ω 
�
log n/n  is required for the uncovered set to choose
all alternatives with high probability  saile and suksompong 
2020   the smaller threshold of p ∈ ω log n/n  suffices in
order for most of the alternatives to be included 
theorem 5 1  assume that a tournament t is generated ac-
cording to the generalized random model  and that pi j ∈
 50 log n/n  1 − 50 log n/n  for all i ̸= j  then with high
probability  at least 0 9n alternatives in t are 2-kings 
proof  assume without loss of generality that the alternatives
before the tournament t is generated are x1          xn in non-
increasing order of expected outdegree  let r = ⌈0 9n⌉  and
consider any 1 ≤ i ≤ r  we will show that the probability
that xi is a 2-king in t is at least 1 − o 1/n   the union
bound then implies that with high probability  at least 0 9n
alternatives in t are 2-kings 
to show that pr xi is a 2-king in t  is at least 1 − o 1/n  
the union bound again implies that it suffices to prove that
pr there is no path of length at most two from xi to xj  is at
most o 1/n2  for each alternative xj ̸= xi 
we henceforth fix 1 ≤ i ≤ r and xj ̸= xi  by lemma 2 3
on xi  xi 1          xn  the expected outdegree of xi is at least
 n−i /2  which is at least 0 045n for any sufficiently large n 
as a result  for large enough n  we have
pr there is no path of length at most two from xi to xj 
= pr xj ≻ xi  · pr ∀k /∈  i  j   xk ≻ xi or xj ≻ xk 
=  1 − pi j  ·
�
k/∈ i j 
pr xk ≻ xi or xj ≻ xk 
=  1 − pi j  ·
�
k/∈ i j 
 1 − pi kpk j 
≤ exp −pi j  ·
�
k/∈ i j 
exp −pi kpk j 
≤ exp
�
−50 log n
n
· pi j
�
·
�
k/∈ i j 
exp
�
−50 log n
n
pi k
�
= exp
�
�−50 log n
n
�
��
k̸=i
pi k
�
�
�
�
≤ exp
�
−50 log n
n
· 0 045n
�
= 1/n2 25
∈ o 1/n2  
we use lemma 2 2 for the first inequality  and the assumption
that the expected outdegree of xi is at least 0 045n for the last
inequality  this concludes our proof 
our next result establishes the asymptotic tightness of the
threshold in theorem 5 1 
theorem 5 2  assume that a tournament t is generated
according to the condorcet random model  and that p ≤
0 1 log n/n  then with high probability  at most √n log n al-
ternatives in t are 2-kings 
finally  we show that as long as p ∈ ω 1/n   a large num-
ber of alternatives are already likely to be 3-kings  and there-
fore k-kings for every k ≥ 3   this bound is again tight 
when p ∈ o 1/n  and the tournament is generated from the
condorcet random model  there is at least a constant probabil-
ity that the strongest alternative dominates all remaining al-
ternatives  in which case it is the only k-king for each k ≥ 2  
theorem 5 3  assume that a tournament t is generated ac-
cording to the generalized random model  and that pi j ∈
ω 1/n  for all i ̸= j  then with high probability  at least
0 9n alternatives in t are 3-kings 
6
concluding remarks
in this paper  we have extensively investigated the behavior
of generalized kings and single-elimination winners in ran-
dom tournaments in view of their discriminative power  our
results reveal surprisingly clear distinctions between the un-
covered set and k-kings for k ≥ 3  and illustrate why ma-
nipulating a single-elimination tournament is often possible
in practice despite the problem being np-hard  all of the
bounds that we obtained are asymptotically tight except for
the bound for 5-kings in the generalized random model  the-
orem 3 8   one could try to close this gap 
an exciting future direction in our view is to study k-kings
and single-elimination winners with respect to axiomatic and
computational properties  as is commonly done for other tour-
nament solutions  laslier  1997  brandt et al   2016   for
example  the uncovered set is known to be the finest tour-
nament solution satisfying condorcet consistency  neutrality 
and expansion  moulin  1986   which axioms does the set of
3-kings satisfy  and can we characterize it by a collection of
axioms  one could also study the relationship between these
tournament solutions and traditional ones—this was partially
done by kim et al   2017   who showed for instance that
any alternative in the copeland set or the slater set can al-
ways win a single-elimination tournament  another possi-
ble avenue is to extend our results to other stochastic models
for tournaments—several interesting models have been stud-
ied experimentally by brandt and seedig  2016  and brill et
al   2021   such questions illustrate the richness of tourna-
ments and probabilistic models  which we expect to give rise
to further fruitful research 
acknowledgments
this work was partially supported by an nus start-up grant 
we would like to thank the anonymous reviewers for their
valuable comments 
proceedings of the thirtieth    ijcai-21 
333
 references
 aziz et al   2018  haris
aziz 
serge
gaspers 
simon
mackenzie  nicholas mattei  paul stursberg  and toby
walsh  fixing balanced knockout and double elimination
tournaments  artificial intelligence  262 1–14  2018 
 brandt and seedig  2016  felix brandt and hans georg
seedig  on the discriminative power of tournament solu-
tions  in selected papers of the international conference
on operations research  or2014  pages 53–58  2016 
 brandt et al   2016  felix brandt  markus brill  and paul
harrenstein  tournament solutions  in felix brandt  vin-
cent conitzer  ulle endriss  j erˆome lang  and ariel d 
procaccia  editors  handbook of computational social
choice  chapter 3  pages 57–84  cambridge university
press  2016 
 brandt et al   2018  felix brandt  markus brill  hans georg
seedig  and warut suksompong  on the structure of stable
tournament solutions  economic theory  65 2  483–507 
2018 
 brcanov and petrovic  2010  dejan brcanov and vojislav
petrovic 
toppling kings in multipartite tournaments
by introducing new kings 
discrete mathematics 
310 19  2550–2554  2010 
 brill et al   2020  markus brill  ulrike schmidt-kraepelin 
and warut suksompong  refining tournament solutions
via margin of victory  in aaai  pages 1862–1869  2020 
 brill et al   2021  markus brill  ulrike schmidt-kraepelin 
and warut suksompong 
margin of victory in tourna-
ments  structural and experimental results  in aaai  2021 
 fey  2008  mark fey  choosing from a large tournament 
social choice and welfare  31 2  301–309  2008 
 fishburn  1977  peter c  fishburn  condorcet social choice
functions 
siam journal on applied mathematics 
33 3  469–489  1977 
 fisher and ryan  1995  david c  fisher and jennifer ryan 
tournament games and positive tournaments  journal of
graph theory  19 2  217–236  1995 
 frank  1968  o  frank  stochastic competition graphs  re-
view of the international statistical institute  36 3  319–
326  1968 
 good  1971  irving john good  a note on condorcet sets 
public choice  10 1  97–101  1971 
 kim and vassilevska williams  2015  michael p  kim and
virginia vassilevska williams 
fixing tournaments for
kings  chokers  and more  in ijcai  pages 561–567  2015 
 kim et al   2017  michael p  kim  warut suksompong  and
virginia vassilevska williams 
who can win a single-
elimination tournament  siam journal on discrete math-
ematics  31 3  1751–1764  2017 
 laslier  1997  jean-franc¸ois laslier  tournament solutions
and majority voting  springer-verlag  1997 
 łuczak et al   1996  tomasz łuczak 
andrzej ruci nski 
and jacek gruszka  on the evolution of a random tour-
nament  discrete mathematics  148 1–3  311–316  1996 
 manurangsi and suksompong  2021  pasin manurangsi and
warut suksompong 
generalized kings and single-
elimination winners in random tournaments 
corr 
abs/2105 00193  2021 
 mattei and walsh  2016  nicholas mattei and toby walsh 
empirical evaluation of real world tournaments  corr 
abs/1608 01039  2016 
 maurer  1980  stephen b  maurer  the king chicken theo-
rems  mathematics magazine  53 2  67–80  1980 
 megiddo and vishkin  1988  nimrod
megiddo
and
uzi
vishkin  on finding a minimum dominating set in a tour-
nament  theoretical computer science  61 2–3  307–316 
1988 
 miller  1977  nicholas r  miller 
graph-theoretic ap-
proaches to the theory of voting 
american journal of
political science  21 4  769–803  1977 
 miller  1980  nicholas r  miller 
a new solution set
for tournaments and majority voting 
further graph-
theoretical approaches to the theory of voting  american
journal of political science  24 1  68–96  1980 
 moon and moser  1962  john w  moon and leo moser  al-
most all tournaments are irreducible  canadian mathe-
matical bulletin  5 1  61–65  1962 
 moulin  1986  herv e moulin  choosing from a tournament 
social choice and welfare  3 4  271–291  1986 
 petrovic and thomassen  1991  vojislav
petrovic
and
carsten thomassen 
kings in k-partite tournaments 
discrete mathematics  98 3  237–238  1991 
 saile and suksompong  2020  christian saile and warut
suksompong  robust bounds on choosing from large tour-
naments  social choice and welfare  54 1  87–110  2020 
 schwartz  1972  thomas schwartz 
rationality and the
myth of the maximum  noˆus  6 2  97–117  1972 
 scott and fey  2012  alex scott and mark fey  the mini-
mal covering set in large tournaments  social choice and
welfare  38 1  1–9  2012 
 suksompong  2021  warut suksompong 
tournaments in
computational social choice  recent developments  in ij-
cai  2021 
 tan  2006  b  p  tan 
on the 3-kings and 4-kings
in multipartite tournaments 
discrete mathematics 
306 21  2703–2710  2006 
 vassilevska williams  2010  virginia vassilevska williams 
fixing a tournament  in aaai  pages 895–900  2010 
 vassilevska williams  2016  virginia vassilevska williams 
knockout tournaments  in felix brandt  vincent conitzer 
ulle endriss  j erˆome lang  and ariel d  procaccia  ed-
itors  handbook of computational social choice  chap-
ter 19  pages 453–474  cambridge university press  2016 
proceedings of the thirtieth    ijcai-21 
334
 "
None,2021,https-www-ijcai-org-proceedings-2021-0047-pdf,Almost Envy-Freeness for Groups: Improved Bounds via Discrepancy Theory,"Pasin Manurangsi, Warut Suksompong",None,https://www.ijcai.org/proceedings/2021/0047.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0047-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0047-pdf.pdf,"almost envy-freeness for groups  improved bounds via discrepancy theory
pasin manurangsi1 and warut suksompong2
1google research  usa
2school of computing  national university of singapore  singapore
pasin@google com  warut@comp nus edu sg
abstract
we study the allocation of indivisible goods among
groups of agents using well-known fairness notions
such as envy-freeness and proportionality  while
these notions cannot always be satisfied  we pro-
vide several bounds on the optimal relaxations that
can be guaranteed  for instance  our bounds im-
ply that when the number of groups is constant
and the n agents are divided into groups arbitrar-
ily  there exists an allocation that is envy-free up to
θ √n  goods  and this bound is tight  moreover 
we show that while such an allocation can be found
efficiently  it is np-hard to compute an allocation
that is envy-free up to o √n  goods even when a
fully envy-free allocation exists  our proofs make
extensive use of tools from discrepancy theory 
1
introduction
resource allocation problems arise in numerous facets of
modern society  from allotting supplies to neighborhoods in
a city to distributing personnel among governmental organi-
zations  a principal consideration when allocating resources
is fairness  the society is better off when all parties involved
feel that they receive a fair share of the resource  it there-
fore comes as no surprise that the study of how to allocate
resources fairly—commonly referred to as fair division—has
received substantial attention in economics and  as societies
becomes more interconnected and applications grow in scale 
in computer science  brams and taylor  1996  moulin  2003 
thomson  2016  moulin  2019 
the vast majority of the fair division literature assumes that
each involved party consists of a single agent  yet  in many
resource allocation scenarios  especially large-scale ones  re-
sources are allocated to groups of agents—even though the
agents in each group share the same set of goods  they may
have varying preferences over different goods in the set  in-
deed  some citizens of a neighborhood may benefit from new
books allotted to the public library  while others would rather
have additional fitness equipment in their local park  simi-
larly  members of an organization may have diverse opinions
about the new personnel that they would like to have in their
organization  these scenarios cannot be captured by the tra-
ditional fair division setting  in which each recipient of a bun-
dle of goods is represented by a single preference 
the group aspect of fair division has been addressed in
a number of recent papers  manurangsi and suksompong 
2017  ghodsi et al   2018  suksompong  2018  segal-halevi
and nitzan  2019  segal-halevi and suksompong  2019 
kyropoulou et al   2020   most of these papers studied the
important fairness notion of envy-freeness  an agent is said to
be envy-free if she values the goods allocated to her group at
least as much as those allocated to any other group  when
goods are discrete—books  personnel  fitness equipment  and
many other common supplies fall into this category—envy-
freeness cannot always be satisfied even when allocating the
goods among individual agents  indeed  this can be easily
seen when there is a single valuable good and at least two
agents  this observation has motivated relaxing the envy-
freeness criterion to envy-freeness up to c goods  efc   which
means that any agent s envy toward another group can be
eliminated by removing at most c goods from that group s
bundle  where c ≥ 1 is an integer parameter 
when allocating goods among individual agents  an ef1
allocation can be found regardless of the number of agents
 lipton et al   2004   however  the picture for group allo-
cation is much less clear  even in the simplest case of two
groups  segal-halevi and suksompong  2019  showed that
if the two groups contain n agents in total and the agents
have additive valuations  then an efn allocation is guar-
anteed to exist 
their result follows by applying a clas-
sic theorem on consensus halving  i e   a partition of a set
of divisible goods into two parts such that every agent val-
ues both parts equally  since there is always a consensus
halving in which at most n goods are divided  alon  1987 
simmons and su  2003   rounding such a consensus halving
yields an efn allocation 1 on the other hand  kyropoulou
et al   2020  prop  3 5  gave a simple example showing that
it is impossible to ensure efc for c ∈ o log n   thereby leav-
ing an exponential gap in this fundamental question  can we
always achieve an impressive fairness guarantee of mere log-
arithmic envy  or does the envy scale linearly with the number
of agents in the worst case 
1in fact  segal-halevi and suksompong  2019  gave a slightly
better guarantee of ef n−1   this guarantee was obtained by find-
ing a consensus halving for n − 1 of the agents  and letting the re-
maining agent choose the part that she prefers 
proceedings of the thirtieth    ijcai-21 
335
 1 1
our results
in this paper  we give a precise answer to the above question 
and much more  we consider a general setting with n =
n1   · · ·   nk agents distributed into k ≥ 2 groups consisting
of n1          nk ≥ 1 agents  respectively  as is common in
fair division  we assume that the agents have additive utilities
over the goods  besides efc  we investigate relaxations of
two other important fairness notions  proportionality—every
agent believes that the share allocated to her group is worth
at least 1/k of the entire set of goods—and consensus 1/k-
division—each agent finds all k bundles to be of equal value 2
the precise definitions can be found in section 2 1 
for each fairness notion and each n1          nk  we are inter-
ested in the smallest positive value c such that an allocation
satisfying that notion up to c goods always exists for agents
with arbitrary additive utilities  for envy-freeness and pro-
portionality  we denote this value of c by cef n1          nk 
and cprop n1          nk   respectively  on the other hand  for
consensus 1/k-division  the partition of agents into groups is
inconsequential  so we use the notation ccd
k  n   our main
results provide bounds on these values 
theorem 1 1  for any k  n1          nk ∈ n 
o √n  ≥ cef n1          nk 
≥ ω 
�
max n1          nk /k3  
theorem 1 2  for any k  n1          nk ∈ n 
o √n  ≥ cprop n1          nk 
≥ ω 
�
max n1          nk /k3  
theorem 1 3  for any n  k ∈ n 
o √n  ≥ ccd
k  n  ≥ ω 
�
n/k  
note that since max n1          nk  ≥ n/k  all three bounds
are asymptotically tight when k is constant  in particular 
theorem 1 1 answers the question that we posed earlier  tak-
ing k = 2  we find that the optimal envy-freeness guarantee
for two groups is efc where c ∈ θ √n   this significantly
improves upon the lower bound of ω log n  and upper bound
of o n  from prior work  and implies that a decent  though
not outstanding  fairness guarantee can be obtained  we es-
tablish theorem 1 3 along with the upper bounds of theo-
rems 1 1 and 1 2 in section 3  and the lower bounds of theo-
rems 1 1 and 1 2 in section 4 
our main tools and techniques throughout this work come
from discrepancy theory  an area of mathematics that stud-
ies how much deviation from the desired state is necessary
in various settings—we provide the relevant background in
section 2 2  the tools that we use imply that for each of the
fairness notions  an allocation satisfying the corresponding
upper bound in theorems 1 1–1 3 can be found efficiently  in
light of this  a natural question is whether we can compute an
allocation improving upon these bounds if such allocations
are known to exist in a given instance  in section 5  we pro-
vide a strong negative answer to this question  for example 
2when k = 2  consensus 1/k-division is better known as con-
sensus halving  simmons and su  2003  
we show that even if a fully envy-free allocation is known to
exist for a certain instance  it is still np-hard to find an allo-
cation that is envy-free up to o √n  goods for that instance 
1 2
further related work
while fair division has a long and storied history  several fair-
ness notions for the indivisible goods setting  including envy-
freeness relaxations  have only been proposed and studied in
the past few years  bouveret et al   2016  markakis  2017  
in the group setting  kyropoulou et al   2020  showed that
ef1 can be guaranteed for all agents only when the groups
are small—for instance  with two groups  an ef1 alloca-
tion does not always exist when both groups have size at
least three  segal-halevi and suksompong  2019  investi-
gated democratic fairness  where the goal is to satisfy a cer-
tain fraction of the agents in each group  they showed that
for two groups with any number of agents  there exists an
allocation that is ef1 for at least half of the agents in each
group—this ratio is tight in the worst case  and continues to
be tight even if we relax ef1 to efc for any constant c 
besides the model that we consider  a number of papers
have studied related models and notions  ghodsi et al   2018 
addressed rent division among groups  where in addition to
deciding the allocation of the rooms  the agents must de-
termine how to split the rent of their apartment  benabbou
et al   2019  examined a group setting where the goods allo-
cated to each group are further divided among the members
of the group  so in contrast to our setting  each agent does
not derive full utility from the bundle of her group  several
authors studied individual resource allocation using fairness
notions relating different groups of agents  for example no-
tions aiming to minimize envy that arises between groups
 berliant et al   1992  husseinov  2011  todo et al   2011 
aleksandrov and walsh  2018  conitzer et al   2019  aziz
and rey  2020  
like fair division in general  consensus 1/k-division and
consensus halving have been studied by mathematicians and
economists for several decades  hobby and rice  1965 
alon  1987  simmons and su  2003   and attracted re-
cent interest from computer scientists in light of new com-
putational complexity results  filos-ratsikas and goldberg 
2018  filos-ratsikas et al   2020  goldberg et al   2020 
deligkas et al   2021   in particular  filos-ratsikas and gold-
berg  2018  proved that approximate consensus halving of
a one-dimensional heterogeneous divisible resource is ppa-
complete—this constituted the first ppa-completeness result
for a problem that is  natural  in the sense that its description
does not involve a polynomial-sized circuit 
2
preliminaries
let g =  m  be the set of goods  where  r   =  1  2          r 
for any positive integer r  there are n = n1   · · ·   nk
agents divided into k ≥ 2 groups  where group i con-
tains ni ≥ 1 agents 
denote by a i j  the jth agent in
group i  the utility of a i j  for good ℓ is given by u i j  ℓ  
we assume that the agents  utilities are additive  that is 
u i j  g′  = �
ℓ∈g′ u i j  ℓ  for every g′ ⊆ g  an allo-
cation  a1          ak  is an ordered partition of the goods into
proceedings of the thirtieth    ijcai-21 
336
 k bundles  where bundle ai is allocated to group i  in partic-
ular  a1 ∪ · · · ∪ ak = g and ai ∩ aj = ∅ for i ̸= j 
2 1
fairness notions
we are interested in the following fairness notions 
definition 2 1  let c be a nonnegative integer  an allocation
 a1          ak  is said to be
• envy-free up to c goods  efc  if  for every agent a i j 
and every i′ ̸= i  there exists a set b ⊆ ai′ with |b| ≤ c
such that u i j  ai  ≥ u i j  ai′ \ b  
• proportional up to c goods  propc  if  for every agent
a i j   there exists a set b ⊆ g \ ai with |b| ≤ c such
that u i j  ai  ≥ u i j  g /k − u i j  b  
• a consensus 1/k-division up to c goods if  for every
agent a and every pair of bundles ai  ai′  there exists
b ⊆ ai′ with |b| ≤ c such that a values ai no less than
ai′ \ b 
note that unlike the first two notions  the third notion
does not depend on how the agents are distributed across
groups  for each k  n1          nk  let cef n1          nk   resp  
cprop n1          nk   denote the smallest value of c such that
an efc  resp   propc  allocation is guaranteed to exist for
agents with additive utilities  similarly  let ccd
k  n  denote
the analogous value for consensus 1/k-division up to c goods
when there are n agents and k bundles  we have the following
relations between these values 
proposition 2 2  for any k  n′  n1          nk ∈ n  we have
 a  cef n1          nk  ≤ ccd
k  n1   · · ·   nk  
 b  cprop n1          nk  ≤ cef n1          nk  
 c  cef n′          n′  ≥ ccd
k  n′   where there are k copies of
n′ on the left-hand side 
proof  we prove the three relations in turn 
 a  this follows immediately from the observation that a
consensus 1/k-division up to c goods for n1   · · ·   nk
agents is also envy-free up to c goods for these agents
regardless of how the agents are distributed into groups 
 b  it suffices to show that for any c  every efc allocation
is also propc  let  a1          ak  be an efc allocation 
and consider agent a i j   by definition of efc  for each
i′ ̸= i  there exists bi′ ⊆ ai′ with |bi′| ≤ c such that
u i j  ai  ≥ u i j  ai′ \ bi′  
let b denote the set of the c most valuable goods for
a i j  outside of ai  breaking ties arbitrarily  we have
u i j  b  ≥ u i j  bi′  for all i′ ̸= i  letting bi = ∅ 
we have
u i j  ai  ≥ 1
k
�
i′∈ k 
u i j  ai′ \ bi′ 
≥ 1
k
�
i′∈ k 
�
u i j  ai′  − u i j  b 
�
= u i j  g /k − u i j  b  
hence  the allocation is propc  as desired 
 c  given n′ agents  we make a copy of each agent in each
of the k groups  any efc allocation with respect to these
groups is also a consensus 1/k-division for the original
agents  the conclusion follows 
2 2
discrepancy theory
in this section  we outline the tools from discrepancy theory
that we will use in this work  intuitively  a basic connection
between discrepancy theory and our group fair division set-
ting is the following  discrepancy theory considers a setting
where there is a collection of subsets  also known as a set
system  and we want to color the elements of the ground set
in two colors so that each subset contains roughly the same
number of elements of each color  the elements of the ground
set correspond to the goods in our setting  while each subset
represents an agent and its elements correspond to the goods
that the agent values  the goal of discrepancy theory is there-
fore similar to that of dividing the goods into two sets so that
each agent values the two sets almost equally 
in this work  we view a vector v ∈ rk also as a column
matrix v ∈ rk×1  we use 1k to denote the k-dimensional
all-1 vector  when the dimension is clear from context  we
may drop the subscript and simply write 1  furthermore  for
a set s ⊆  k   we write 1 s  ∈  0  1 k to denote the indicator
vector of s  i e    1 s  i = 1 if and only if i ∈ s 
for every p ∈  1  ∞   we use ∥v∥p to denote the ℓp norm of
v  defined by
��
i∈ k  |vi|p�1/p
  the ℓ∞ norm of v  denoted
by ∥v∥∞  is maxi∈ k  |vi|  the hamming norm of v  denoted
by ∥v∥0  is the number of non-zero coordinates of v 
2-color discrepancy
as mentioned earlier  a classic scenario in discrepancy the-
ory is when there is a set system and the goal is to color the
elements in two colors in such a way that each subset con-
tains roughly the same number of elements of each color 
as lov asz et al   1986  noted  this notion generalizes natu-
rally to any matrix  specifically  the discrepancy of a matrix
a ∈ rn×m is defined as
disc a   =
min
x∈ 0 1 m ∥a 0 5 · 1 − x ∥∞ 
here x can be thought of as a 2-coloring and the quantity
∥a 0 5 · 1 − x ∥∞ measures how  unbalanced  it is 
let
discmax n   = sup
m∈n
sup
a∈ 0 1 n×m disc a  
a priori  discmax n  might even be infinite since we allow
a to have an arbitrary number of columns  remarkably  how-
ever  it is known3 4 that discmax n  is bounded by o √n  
lemma 2 3   alon and spencer  2000  corollary 12 3 4   
for any n ∈ n  discmax n  ≤ o √n  
3we note here that some of the bounds we refer to are stated only
for 0-1 matrices a  however  one can check that they also hold for
any matrix a ∈  0  1 n×m  see also the full version of our paper
where we sketch how the constructive versions of these bounds can
be derived  manurangsi and suksompong  2021  
4see also  spencer  1985  on which this bound is based 
proceedings of the thirtieth    ijcai-21 
337
 the above bound is also known to be asymptotically tight 
lemma 2 4   spencer  1985    for any n ∈ n  it holds that
discmax n  ≥ ω √n  
weighted discrepancy 
the p-weighted discrepancy  do-
err and srivastav  2003  is a generalization of discrepancy
where 0 5 is replaced by some p ∈  0  1  
wdiscp a   =
min
x∈ 0 1 m ∥a p · 1 − x ∥∞ 
similarly to above  let
wdiscmax
p
 n   = sup
m∈n
sup
a∈ 0 1 n×m wdiscp a  
using standard techniques in discrepancy theory  we can
prove the following lower bound on wdiscmax
p
 n  
 this
bound was also implicit in the work of doerr and srivastav  
proposition 2 5  for any p ∈  0  1/2  and any n ∈ n such
that n ≥ 16/p  we have wdiscmax
p
 n  ≥ ω √pn  
the proof of proposition 2 5  as well as all omitted proofs 
can be found in the full version of our paper  manurangsi and
suksompong  2021  
multi-color discrepancy
we will also use the extension of the 2-color definition to
multi-color cases due to doerr and srivastav  2003   recall
that a k-coloring of  m  is a function χ    m  →  k   the
k-color discrepancy of a is defined as
disc a  k   =
min
χ  m → k  max
s∈ k 
����a
�1
k · 1 − 1 χ−1 s  
�����
∞
 
note that disc a  2  coincides with disc a  defined earlier 
similarly to above  we let
discmax n  k   = sup
m∈n
sup
a∈ 0 1 n×m disc a  k  
the following lemma is a consequence of corollary 3 5 of
doerr and srivastav  2003  and lemma 2 3 
lemma 2 6   doerr and srivastav  2003    for any n  k ∈ n 
discmax n  k  ≤ o √n  
furthermore  doerr and srivastav also proved the follow-
ing lower bound 5
lemma 2 7   doerr and srivastav  2003  theorem 5 2    for
any n  k ∈ n such that k ≥ 2  discmax n  k  ≥ ω 
�
n/k  
3
approximate fair division from
multi-color discrepancy
in this section  we derive generic upper and lower bounds for
the value ccd
k
based on the multi-color discrepancy bounds
discmax n  k   our results are stated formally below 
theorem 3 1  for any n  k ∈ n  we have
ccd
k  n  ≥ ⌈discmax n  k ⌉ 
5doerr and srivastav  2003  only stated their lower bound for
n such that a hadamard matrix of order n exists  however  as ex-
plained in our proof of proposition 2 5  this implies the same asymp-
totic bound for all n ∈ n 
theorem 3 2  for any n  k ∈ n  we have
ccd
k  n  ≤ 4 · ⌈discmax 2n  k ⌉ 
by the known bounds for discmax  lemmas 2 6 and 2 7  
the two results above yield theorem 1 3 
using the relationships between ccd
k   cef  and cprop estab-
lished in proposition 2 2  we get the following corollary 
corollary 3 3  for any k  n′  n1          nk ∈ n  we have
 a  cef n1          nk  ≤ 4 · ⌈discmax 2 n1   · · ·   nk   k ⌉ 
 b  cprop n1          nk  ≤ 4·⌈discmax 2 n1  · · · nk   k ⌉ 
 c  cef n′          n′  ≥ ⌈discmax n′  k ⌉  where there are k
copies of n′ on the left-hand side 
parts  a  and  b   together with the known upper bound
for discmax  lemma 2 6   give us the upper bounds in the-
orems 1 1 and 1 2  on the other hand  part  c  is not suffi-
cient for the lower bounds in these theorems yet  since the
above corollary does not apply to the  unbalanced groups 
case where some groups are small  e g   when n1 = · · · =
nk−1 = 1 and nk = n′  indeed  the lower bound parts of
theorems 1 1 and 1 2 will be handled in section 4 
3 1
lower bound
we prove theorem 3 1 via a simple reduction that views each
row of a matrix a as a vector of utilities for the goods  the
existence of a consensus 1/k-division up to a small number
of goods would imply a strong upper bound on the discrep-
ancy of a  this is formalized below  since the distribution of
agents into groups is irrelevant for consensus 1/k-division 
we use the notation aj and uj instead of a i j  and u i j  
proof of theorem 3 1  let ∆  = ⌈discmax n  k ⌉  note that
∆ − 1 < discmax n  k   thus  there exists m ∈ n and
a ∈  0  1 n×m such that disc a  k  > ∆ − 1  we define the
agents  utilities by uj ℓ  = aj ℓ for all j ∈  n  and ℓ ∈  m  
it suffices to show that there is no consensus 1/k-division up
to ∆ − 1 goods with respect to these utilities 
suppose for the sake of contradiction that there is a con-
sensus 1/k-division up to ∆ − 1 goods   a1          ak   let
χ    m  →  k  denote the coloring corresponding to this allo-
cation  i e   χ−1 s  = as 
consider any agent aj  since the allocation is a consensus
1/k-division up to ∆ − 1 goods and each good has value at
most 1 to each agent  the following holds for all i  s ∈  k  
∆ − 1 ≥ |uj ai  − uj as | 
 1 
fix any s ∈  k   for each j ∈  n   this inequality allows us to
bound the jth entry of a
� 1
k · 1 − 1 χ−1 s  
�
as
�����
�
a
�1
k · 1 − 1 χ−1 s  
��
j
����� =
����
uj g 
k
− uj as 
����
=
������
1
k
�
i∈ k 
 uj ai  − uj as  
������
≤ 1
k
�
i∈ k 
��uj ai  − uj as 
��
 1 
≤ ∆ − 1 
where the first inequality follows from the triangle inequality 
applying this for all j ∈  n   we have disc a  k  ≤ ∆−1 
contradicting our assumption that disc a  k  > ∆ − 1 
proceedings of the thirtieth    ijcai-21 
338
 3 2
upper bound
we next prove our upper bound  theorem 3 2   which turns
out to be more challenging than the lower bound  to demon-
strate this  let us consider using the  reverse  of the reduction
in the proof of theorem 3 1  specifically  suppose we create
one row for each agent corresponding to her utilities  the
discrepancy bound ensures that we can divide the goods into
k bundles so that each agent s utilities for the k bundles are
not too different  however  this does not translate into any
bound on the number of goods necessary in the relaxation of
any of the fairness notions  since it is possible that an agent
has a tiny utility for every good in some bundle 
to tackle this issue  we must also ensure that each agent has
some  large   i e   valuable  goods in every bundle  to this
end  we divide the set of goods  with respect to each agent 
into the set of large goods and the set of  small  goods  we
create one row as before  but only for the small goods  this is
to ensure that the utilities of the agent for the small goods do
not differ by much between bundles  additionally  we cre-
ate a row corresponding to the large goods  which ensures
that the agent has a non-trivial number of large goods in each
bundle  when choosing the size of the set of large goods ap-
propriately  this gives us the desired bound  we formalize this
intuition in the proof below 
proof of theorem 3 2  let t  = ⌈discmax 2n  k ⌉  for every
agent aj  let sj
large ⊆ g denote the set of l  = min m  3tk 
goods that the agent values the most  ties broken arbitrar-
ily   and let pj  = minℓ∈sj
large uj ℓ   we define yj as the
m-dimensional indicator vector of sj
large  i e   yj = 1 sj
large  
we also define zj as the utility vector of the goods outside of
sj
large  scaled by 1/pj  i e  
zj
ℓ =
�
uj ℓ /pj
if ℓ /∈ sj
large 
0
otherwise 
by our choice of sj
large and pj  we have zj ∈  0  1 m   we use
the convention 0/0 = 0  i e   zj is the all-zero vector when
pj = 0  
finally  we define our matrix a =
�
y1 · · · ynz1 · · · zn�t  
note that a ∈  0  1 2n×m  from the definition of discmax 
there exists a coloring χ    m  →  k  such that
����a
�1
k · 1 − 1 χ−1 i  
�����
∞
≤ t 
 2 
for all i ∈  k   we pick our allocation  a1          ak  accord-
ing to χ  that is  ai = χ−1 i  for all i ∈  k  
next  we argue that for every pair i  i′ ∈  k  and every
agent aj  there exists b ⊆ ai′ of size at most 4t such that
uj ai  ≥ uj ai′ \ b   this suffices to finish the proof  from
 2  and the definition of a  we have
t ≥
����
�
yj 
�1
k · 1 − 1 ai 
������ =
����
l
k − |ai ∩ sj
large|
����
and
t ≥
����
�
zj 
�1
k · 1 − 1 ai 
������
= 1
pj ·
����
1
k · uj g \ sj
large  − uj ai \ sj
large 
����  
rearranging these  we have
����
l
k − |ai ∩ sj
large|
���� ≤ t
 3 
and
����
1
k · uj g \ sj
large  − uj ai \ sj
large 
���� ≤ pj · t 
 4 
a similar argument on bundle ai′ implies
����
l
k − |ai′ ∩ sj
large|
���� ≤ t
 5 
and
����
1
k · uj g \ sj
large  − uj ai′ \ sj
large 
���� ≤ pj · t 
 6 
let b  = ai′ ∩ sj
large  by  5   we have |b| ≤ l/k   t ≤
4t  now  if m ≤ 3tk  then we have l = m and ai′ \b = ∅ 
thus  uj ai  ≥ uj ai′ \ b  trivially holds in this case 
next  consider the case m > 3tk  so l = 3tk  in this
case  we may bound uj ai  − uj ai′ \ b  as follows 
uj ai  − uj ai′ \ b 
= uj ai ∩ sj
large   
�
uj ai \ sj
large  − uj ai′ \ sj
large 
�
≥ pj · |ai ∩ sj
large|  
�
uj ai \ sj
large  − uj ai′ \ sj
large 
�
 3 
≥ pj l/k − t   
�
uj ai \ sj
large  − uj ai′ \ sj
large 
�
 4   6 
≥
pj l/k − t  − 2pj · t ≥ 0 
where the first inequality follows from our definition of pj
and the last inequality follows from l = 3tk  this con-
cludes the proof 
4
lower bounds from weighted discrepancy
in this section  we prove a lower bound on cprop for k groups
via weighted discrepancy 
theorem 4 1  for any n′  k ∈ n  we have
cprop 2n′  1          1  ≥ ⌈wdiscmax
1/k  n′ /k⌉ 
combined with proposition 2 2  this gives a similar lower
bound for cef  again  the left-hand side contains k − 1 1 s  
corollary 4 2  for any n′  k ∈ n  we have
cef 2n′  1          1  ≥ ⌈wdiscmax
1/k  n′ /k⌉ 
these two results  together with the lower bound on
wdiscmax
p
 proposition 2 5  and the observation that remov-
ing agents does not increase the value of cef or cprop  yield
the lower bound parts of theorems 1 1 and 1 2  more specif-
ically  we claim that for any n1          nk  we have
cef max n1          nk   1  1          1  ≤ cef n1          nk    7 
proceedings of the thirtieth    ijcai-21 
339
 to see why this claim holds  first note that due to symme-
try  we may assume that n1 = max n1          nk   note also
that if an allocation satisfies a fairness notion for a certain
instance  it still satisfies the same fairness notion when we ar-
bitrarily remove some agent s  from some group s   hence 
given any instance with group sizes n1  1          1  we may add
agents with arbitrary utilities so that the group sizes become
n1          nk and apply the bound for the latter case  this im-
plies  7   whereupon we can apply corollary 4 2 and propo-
sition 2 5 to derive theorem 1 1  a similar argument can be
used to derive theorem 1 2 from theorem 4 1 
the proof of theorem 4 1 can be found in the full ver-
sion of our paper  we describe here the intuition behind it 
we construct the utility functions of the agents so that if
 a1          ak  is proportional up to a small number of goods 
then x  = 1 a1  gives us a small 1/k-weighted discrepancy 
similarly to the proof of theorem 3 1  we start by creating
n′ agents in the first group where each agent s utilities corre-
spond to a row of a  this yields a lower bound on each entry
of a · 1 a1   to get an upper bound  we simply create a
 conjugate  of each of these agents in the first group  i e   the
conjugate utility of each good is simply 1 minus the original
utility  however  this construction alone is not sufficient—for
example  it is still possible to assign all goods to a1  to avoid
this  we create one agent in each of the remaining groups with
the same utility for all goods  this ensures that a1 has size
roughly m/k  which turns out to be sufficient for bounding
the 1/k-weighted discrepancy  using x  = 1 a1   
5
computational complexity
since efficient algorithms matching the bound in lemma 2 6
are known  bansal  2010  lovett and meka  2015 6 and all of
our upper bounds are obtained by polynomial-time reductions
to this bound  it immediately follows that given the goods
and the agents  utilities for them  we can efficiently find an
allocation matching the upper bounds in our main theorems
 theorems 1 1–1 3   in summary  we have 
corollary 5 1  there exists a randomized polynomial-time
algorithm that can compute a consensus 1/k-division  or an
envy-free/proportional allocation  up to o √n  goods 
in light of the above corollary  a natural question is whether
we can improve on this o √n  bound if we know that  say 
an unknown  fully fair  division exists for a given instance 
for example  provided that there is a consensus 1/k-division
in that instance  can we efficiently find an allocation that beats
the upper bounds in corollary 5 1 
a similar question has been asked in the context of dis-
crepancy theory  for the bound in lemma 2 3  the answer was
shown to be negative  charikar et al   2011   i e   even when
a has discrepancy zero  it is np-hard to find x achieving dis-
crepancy o √n   in this section  we extend this hardness to
the setting of fair division  as stated below 
theorem 5 2  for any constant k ∈ n \  1   there exists a
constant εk > 0 such that it is np-hard  given m goods and
6please refer to the full version of our paper for more details
 manurangsi and suksompong  2021  
k groups  each containing n′ agents with additive utilities  to
distinguish between the following two cases 
•  yes  there exists a consensus 1/k-division 
•  no  no allocation is proportional up to εk
√
n′ goods 
in other words  when k is constant  we cannot asymptoti-
cally improve upon the bound in corollary 5 1 even when we
are promised that a consensus 1/k-division exists  note that
since consensus 1/k-division is the strongest notion and pro-
portionality the weakest  see proposition 2 2   this theorem is
the  strongest possible  
6
conclusion and future work
in this paper  we have studied the allocation of indivisible
goods to groups of agents using the standard fairness no-
tions of envy-freeness  proportionality  and consensus 1/k-
division  we presented bounds on the optimal relaxations
of these notions that can be guaranteed for agents with ad-
ditive valuations  all of the bounds are asymptotically tight
when the number of groups is constant  our results imply
that relatively strong fairness guarantees can be provided for
all agents even when agents in the same group  who share
the same set of resources  have highly differing preferences 
moreover  we showed that computing allocations that im-
prove upon these bounds is np-hard even in instances where
such allocations are known to exist 
besides closing the gaps left by our work  an interesting
direction for future work is to consider agents with arbitrary
monotonic utilities  indeed  the techniques from discrepancy
theory that we used crucially rely on the additivity assump-
tion  so does the result of alon  1987  that established the
existence of a consensus 1/k-division for divisible goods 
even in the case of prime numbers k  where a consensus 1/k-
division can be guaranteed for non-additive utilities  filos-
ratsikas et al   2021  7 it is unclear whether such a division
can be rounded into a discrete allocation with a loss that is
bounded only in terms of n  beyond the setting of our paper 
one could also consider allocating a mixture of indivisible and
divisible goods  bei et al   2021  or allowing groups to have
different entitlements which can correspond to the group sizes
 chakraborty et al   2020  as well 
acknowledgments
this work was partially supported by an nus start-up grant 
we would like to thank paul goldberg  alexandros hollen-
der  and ayumi igarashi for interesting discussions and the
anonymous reviewers for valuable comments 
references
 aleksandrov and walsh  2018  martin
aleksandrov
and
toby
walsh  group envy freeness and group pareto efficiency in fair
division with indivisible items  in ki  pages 57–72  2018 
 alon and spencer  2000  noga alon and joel h  spencer 
the
probabilistic method  wiley  2nd edition  2000 
7see theorem 6 5 in their extended version  for k = 2  the ex-
istence of a consensus halving with non-additive utilities was shown
by simmons and su  2003  
proceedings of the thirtieth    ijcai-21 
340
  alon  1987  noga alon  splitting necklaces  advances in mathe-
matics  63 3  247–253  1987 
 aziz and rey  2020  haris aziz and simon rey 
almost group
envy-free allocation of indivisible goods and chores  in ijcai 
pages 39–45  2020 
 bansal  2010  nikhil bansal  constructive algorithms for discrep-
ancy minimization  in focs  pages 3–10  2010 
 bei et al   2021  xiaohui bei  zihao li  jinyan lu  shengxin liu 
and xinhang lu  fair division of mixed divisible and indivisible
goods  artificial intelligence  293 103436  2021 
 benabbou et al   2019  nawal benabbou  mithun chakraborty 
edith elkind  and yair zick  fairness towards groups of agents in
the allocation of indivisible items  in ijcai  pages 95–101  2019 
 berliant et al   1992  marcus berliant  william thomson  and
karl dunz  on the fair division of a heterogeneous commodity 
journal of mathematical economics  21 3  201–216  1992 
 bouveret et al   2016  sylvain bouveret  yann chevaleyre  and
nicolas maudet 
fair allocation of indivisible goods 
in fe-
lix brandt  vincent conitzer  ulle endriss  j erˆome lang  and
ariel d  procaccia  editors  handbook of computational social
choice  chapter 12  pages 284–310  cambridge university press 
2016 
 brams and taylor  1996  steven j  brams and alan d  taylor 
a procedure for divorce settlements 
mediation quarterly 
13 3  191–205  1996 
 chakraborty et al   2020  mithun chakraborty  ayumi igarashi 
warut suksompong  and yair zick  weighted envy-freeness in
indivisible item allocation  in aamas  pages 231–239  2020 
 charikar et al   2011  moses charikar  alantha newman  and
aleksandar nikolov  tight hardness results for minimizing dis-
crepancy  in soda  pages 1607–1614  2011 
 conitzer et al   2019  vincent conitzer  rupert freeman  nisarg
shah  and jennifer wortman vaughan  group fairness for the
allocation of indivisible goods  in aaai  pages 1853–1860  2019 
 deligkas et al   2021  argyrios deligkas  john fearnley  themis-
toklis melissourgos  and paul g  spirakis  computing exact solu-
tions of consensus halving and the borsuk-ulam theorem  jour-
nal of computer and system sciences  117 75–98  2021 
 doerr and srivastav  2003  benjamin doerr and anand srivastav 
multicolour discrepancies  combinatorics  probability and com-
puting  12 4  365–399  2003 
 filos-ratsikas and goldberg  2018  aris
filos-ratsikas
and
paul w  goldberg 
consensus halving is ppa-complete 
in
stoc  pages 51–64  2018 
 filos-ratsikas et al   2020  aris filos-ratsikas  alexandros hol-
lender  katerina sotiraki  and manolis zampetakis  consensus-
halving  does it ever get easier  in ec  pages 381–399  2020 
 filos-ratsikas et al   2021  aris filos-ratsikas  alexandros hol-
lender  katerina sotiraki  and manolis zampetakis  a topologi-
cal characterization of modulo-p arguments and implications for
necklace splitting  in soda  pages 2615–2634  2021  extended
version available as arxiv 2003 11974 
 ghodsi et al   2018  mohammad ghodsi  mohamad latifian  ar-
man mohammadi  sadra moradian  and masoud seddighin  rent
division among groups  in cocoa  pages 577–591  2018 
 goldberg et al   2020  paul w  goldberg  alexandros hollender 
ayumi igarashi  pasin manurangsi  and warut suksompong 
consensus halving for sets of items  in wine  pages 384–397 
2020 
 hobby and rice  1965  charles r  hobby and john r  rice 
a
moment problem in l1 approximation  proceedings of the amer-
ican mathematical society  16 4  665–670  1965 
 husseinov  2011  farhad husseinov  a theory of a heterogeneous
divisible commodity exchange economy  journal of mathemati-
cal economics  47 1  54–59  2011 
 kyropoulou et al   2020  maria kyropoulou  warut suksompong 
and alexandros a  voudouris  almost envy-freeness in group re-
source allocation  theoretical computer science  841 110–123 
2020 
 lipton et al   2004  richard
j 
lipton 
evangelos
markakis 
elchanan mossel  and amin saberi  on approximately fair al-
locations of indivisible goods  in ec  pages 125–131  2004 
 lov asz et al   1986  l aszl o lov asz  joel spencer  and katalin
vesztergombi 
discrepancy of set-systems and matrices 
eu-
ropean journal of combinatorics  7 2  151–160  1986 
 lovett and meka  2015  shachar lovett and raghu meka  con-
structive discrepancy minimization by walking on the edges 
siam journal on computing  44 5  1573–1582  2015 
 manurangsi and suksompong  2017  pasin manurangsi and warut
suksompong  asymptotic existence of fair divisions for groups 
mathematical social sciences  89 100–108  2017 
 manurangsi and suksompong  2021  pasin manurangsi and warut
suksompong 
almost envy-freeness for groups 
improved
bounds via discrepancy theory  corr  abs/2105 01609  2021 
 markakis  2017  evangelos markakis  approximation algorithms
and hardness results for fair division 
in ulle endriss  editor 
trends in computational social choice  chapter 12  pages 231–
247  ai access  2017 
 moulin  2003  herv e moulin  fair division and collective wel-
fare  mit press  2003 
 moulin  2019  herv e moulin  fair division in the internet age  an-
nual review of economics  11 407–441  2019 
 segal-halevi and nitzan  2019  erel segal-halevi and shmuel
nitzan  envy-free cake-cutting among families  social choice
and welfare  53 4  709–740  2019 
 segal-halevi and suksompong  2019  erel
segal-halevi
and
warut suksompong 
democratic fair allocation of indivisible
goods  artificial intelligence  277 103167  2019 
 simmons and su  2003  forest w  simmons and francis edward
su 
consensus-halving via theorems of borsuk-ulam and
tucker  mathematical social sciences  45 1  15–25  2003 
 spencer  1985  joel spencer 
six standard deviations suffice 
transactions of the american mathematical society  289 2  679–
706  1985 
 suksompong  2018  warut suksompong  approximate maximin
shares for groups of agents 
mathematical social sciences 
92 40–47  2018 
 thomson  2016  william thomson  introduction to the theory of
fair allocation  in felix brandt  vincent conitzer  ulle endriss 
j erˆome lang  and ariel d  procaccia  editors  handbook of com-
putational social choice  chapter 11  pages 261–283  cambridge
university press  2016 
 todo et al   2011  taiki todo  runcong li  xuemei hu  takayuki
mouri  atsushi iwasaki  and makoto yokoo  generalizing envy-
freeness toward group of agents  in ijcai  pages 386–392  2011 
proceedings of the thirtieth    ijcai-21 
341
 "
None,2021,https-www-ijcai-org-proceedings-2021-0048-pdf,Winner Determination and Strategic Control in Conditional Approval Voting,"Evangelos Markakis, Georgios Papasotiropoulos",None,https://www.ijcai.org/proceedings/2021/0048.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0048-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0048-pdf.pdf,"winner determination and strategic control in conditional approval voting
evangelos markakis and georgios papasotiropoulos
athens university of economics and business
 markakis  gpapasotiropoulos @aueb gr
abstract
our work focuses on a generalization of the clas-
sic minisum approval voting rule  introduced by
barrot and lang  2016   and referred to as con-
ditional minisum  cms   for multi-issue elections 
although the cms rule provides much higher lev-
els of expressiveness  this comes at the expense of
increased computational complexity  in this work 
we study further the issue of efficient algorithms
for cms  and we identify the condition of bounded
treewidth  of an appropriate graph that emerges
from the provided ballots   as the necessary and
sufficient condition for polynomial algorithms  un-
der common complexity assumptions  additionally
we investigate the complexity of problems related
to the strategic control of such elections by the pos-
sibility of adding or deleting either voters or alter-
natives  we exhibit that in most variants of these
problems  cms is resistant against control 
1
introduction
this work focuses on a voting rule for multi-issue elections
that couples approval voting with the possibility of express-
ing dependencies among issues  as a first example  imagine
a group of friends who have to decide on the menu of a buffet
for the party they are hosting  it is expected that their pref-
erences on certain dishes are conditioned on whether some
other  e g   complementary  dishes will be selected or not  we
can consider another example with conditional preferences 
taken from recommendation systems for online advertising 
suppose an ad management service needs to make a person-
alized selection of ads  to be shown on alice s favorite news
website  for each slot  or area  in the advertising region of
the site  there is a set of possible ads to choose from and the
overall goal is to maximize alice s satisfaction  the probabil-
ity of an ad to be clicked by her   if we think of the slots as
corresponding to issues  a recommendation could be made by
looking at the data from users  similar  to alice  voters   and
their clicking behavior  approvals   the voters have condi-
tional preferences  as the clicking probability is affected when
an ad appears in a nearby slot with a related one  e g  it is in-
creased for frequently bought together products  
it seems obvious in the examples above  that deciding in-
dependently for each issue would not be a wise choice  moti-
vated by these considerations  the work of  barrot and lang 
2016  introduced an expressive framework that handles con-
ditional ballots within the approval voting format  and de-
fined  among others  the conditional minisum  cms  voting
rule  cms can be thought of as a natural  intuitive general-
ization of the well known minisum rule in approval-based
elections  under preferential dependencies 
at the moment however  the power and limitations of cms
are still under-explored  and further studies are needed to ar-
rive at a better evaluation of this relatively new rule  first  it
has been shown that the higher level of expressiveness comes
at the price of increased computational complexity  although
the minisum rule is easy to implement in the standard  uncon-
ditional  setting  cms was proved to be intractable already by
 barrot and lang  2016   given this negative result  it be-
comes important to understand which properties can play a
crucial role on obtaining efficient algorithms  the subsequent
work of  markakis and papasotiropoulos  2020  made some
progress along this front  providing a sufficient condition for
fast algorithms  but this has been far from a complete under-
standing  second  we still know very little about the complex-
ity of controlling and/or manipulating a cms election  this
is a very prominent research agenda within computational so-
cial choice  and further results would provide more insights
on the benefits or drawbacks of conditional voting 
contribution 
our main goal is to investigate algorithmic
and complexity aspects of solving and controlling elections
under cms  more precisely  our results in section 3  provide
characterizations for the families of cms instances that can
be placed in p and fpt  the main insight gained out of this 
is that the condition of bounded treewidth  of an appropri-
ate graph  aggregating all the provided dependencies  serves
as the lynchpin between expressiveness of preferences and
efficiency of computation  these results also establish a con-
nection between winner determination under cms and a well
studied class of constraint satisfaction problems  which can
be of independent interest  moving on  in section 4  we ini-
tiate for cms the study of some standard notions of election
control  these problems concern the attempt by an external
agent to enforce a certain outcome by adding or deleting ei-
ther voters or alternatives in the election  our findings reveal
that cms is sufficiently resistant against such moves 
proceedings of the thirtieth    ijcai-21 
342
 related work
the works most related to ours are  barrot and lang  2016 
and  markakis and papasotiropoulos  2020   the former in-
troduced the rule we study  and provided computational hard-
ness results  along with other interesting properties  whereas
the latter focused on algorithms for special cases of the prob-
lem  for surveys on approval voting  we refer to  brams and
fishburn  2010  and  kilgour  2010   beyond approval vot-
ing  we point to the work of  chevaleyre et al   2008  for
the relation of similar solution concepts within ai and to the
enlightening survey of  lang and xia  2016   for an exposi-
tion of solution concepts  proposed as attempts for a tradeoff
between expressiveness and computational cost over combi-
natorial domains 
regarding election control  the versions that we consider
fall within the standard approaches that have been used for
studying the complexity of affecting election outcomes  for
an extensive study on this topic  we refer to  faliszewski and
rothe  2016   indicatively  the study of such problems with
adding or deleting voters or alternatives began with the semi-
nal paper of  bartholdi iii et al   1992  and some of the subse-
quent works are  among others   hemaspaandra et al   2007 
faliszewski et al   2011  liu et al   2009  
2
formal background
for the relevant definitions of our setting  we closely fol-
low the framework of  barrot and lang  2016   let i =
 i1          im  be a set of m issues  where each issue ij is as-
sociated with a finite domain dj of different alternatives  let
d = d1 ×d2 ×· · ·×dm be the set of all feasible outcomes 
we consider a set v =  1          n  of n voters who have
to reach a common decision for every issue in i  the vot-
ers can express dependencies among issues in the following
manner  we assume each voter i provides a directed graph
gi =  i  ei   referred to as her dependency graph  for an is-
sue ij  we denote by ni ij  the set of in-neighbors of the ver-
tex corresponding to ij in the dependency graph gi  for an
issue ij where the set of in-neighbors is non-empty  the opin-
ion of voter i on ij is dependent on the outcome of the issues
in ni ij   a useful quantity in the sequel is the maximum
in-degree for a voter i  which is ∆i = maxj∈ m  |ni ij |  
definition 1  a conditional approval ballot of a voter i over
the issues of i =  i1          im  is a pair bi = ⟨gi   aj  j ∈
 m  ⟩  where gi is the dependency graph of voter i  and for
each issue ij  aj is a set of conditional approval statements
 t   dj   for some t ∈ �
k∈ni ij  dk and some dj ∈ dj 
the rationale in definition 1 is that the set aj expresses
the combinations of values that make the voter satisfied with
respect to issue ij  we note that when ni ij  = ∅  voter
i can express a simple unconditional ballot for approving an
alternative d of issue ij  which for simplicity  will be denoted
as  d   we also stress that our setting is incomparable with
the semantics of the cp-nets framework  as already pointed
out by  barrot and lang  2016  
definition 2  the global dependency graph of a set of voters
is the undirected1 simple graph that emerges from ignoring
1defined as a directed graph in  markakis and papasotiropoulos 
the orientation of edges in the graph  i  �
i∈ n  ei  
let b =  b1          bn  denote the voters  conditional bal-
lots  an instance of a conditional approval election is called
a profile  given by a tuple  i  d  v  b   an outcome of the
election is a vector  s1  s2          sm  ∈ d  with sj ∈ dj  
definition 3  given an outcome s =  s1  s2          sm   we
say that voter i is dissatisfied  or disagrees  with issue ij  if
either ni ij  = ∅ and  sj  /∈ bj
i   or if the projection of s
on ni ij   say t  satisfies  t   sj  /∈ bj
i   where bj
i is the
restriction of the ballot bi on the issue ij  we denote as δi s 
the total number of issues from s that dissatisfy voter i 
for illustrative examples concerning the definitions  we
refer to  barrot and lang  2016  and  markakis and papa-
sotiropoulos  2020   we focus on the following voting rule
within the framework of conditional approval elections 
problem  conditional minisum  cms 
instance  a profile of a cms election  i  d  v  b  
output  an outcome that achieves mins∈d
�
i∈ n  δi s  
if the global dependency graph of an instance is empty  i e  
∆i = 0  ∀i ∈  n   then the election degenerates to uncondi-
tional minisum which is simply the classic minisum rule in
approval voting over multiple independent issues  in the se-
quel  we will make extensive use of the treewidth parameter
of a graph g  denoted as tw g   for the relevant definition 
we refer to  robertson and seymour  1986  or to any textbook
of parameterized complexity such as  cygan et al   2015   fi-
nally  we note that all missing proofs can be found in the full
version of this work 
3
winner determination of cms elections
the price we pay for the higher expressiveness of cms is its
increased complexity  as already established by the work that
introduced the rule  barrot and lang  2016   here  we focus
on understanding the properties that allow cms to be imple-
mented in polynomial time  for this  we stick to the non-
trivial case where ∆i ≤ 1 for every voter i  which is already
np-hard  and investigate what further restrictions can make
the problem tractable  more specifically  we utilize the global
dependency graph of an instance  defined in section 2  aggre-
gating all the dependencies of the voters into a single graph 
the role of the global dependency graph was highlighted in
 markakis and papasotiropoulos  2020   where an optimal al-
gorithm was described when the treewidth is at most 2  in
this section  we first provide a generalization of this result
for any constant treewidth  theorem 1   resolving one of the
open questions by  markakis and papasotiropoulos  2020  
but more importantly  we also show that this is tight  and we
cannot hope to go beyond constant treewdith  theorem 2 and
corollary 1   under standard complexity assumptions 
in our results  we make extensive use of constraint sat-
isfaction problems  csps   a prominent class of problems as
they can model numerous applications in ai  a csp instance
is described by a tuple  v  d  c   where v is the set of vari-
ables  d is the cartesian product of the domains of the vari-
ables  and c is a set of constraints  each constraint involves a
2020   but their results utilized its undirected version 
proceedings of the thirtieth    ijcai-21 
343
 subset of the variables  and is represented by all the combina-
tions of variables that make it satisfiable  we will pay partic-
ular attention to the so-called binary csps  where each con-
straint involves at most two variables  the decision problem
for a csp asks whether we can find an assignment to the vari-
ables of v so that all constraints of c are satisfied  whereas
a natural optimization version  freuder and wallace  1992  is
to minimize the number of unsatisfied constraints  when an-
alyzing csps  a useful concept in the literature is the primal
or gaifman graph of an instance  defined below 
definition 4  the primal  or gaifman  graph of a csp in-
stance is an undirected graph  whose vertices are the variables
of the instance and there is an edge between two vertices  if
and only if they co-appear in at least one constraint 
the proof of the following theorem is based on formulat-
ing our problem as minimizing the number of unsatisfied con-
straints in an appropriate binary csp instance  whose primal
graph has constant treewidth  for these classes of csps  one
can then use known results from  freuder  1990 2 or  koster
et al   2002  for solving them efficiently 
theorem 1  if the global dependency graph of a cms in-
stance with ∆i ≤ 1 for every voter i  has constant treewidth 
then the problem is optimally solvable in polynomial time 
even for arbitrary domain cardinality for each issue 
remark 1  theorem 1 does not seem to have any direct gen-
eralization to instances where ∆i ≥ 2 for some voter i  since
in that case the global dependency graph will not necessar-
ily coincide with the primal graph of the corresponding csp
 which is an essential part of the proof   tackling higher de-
grees is left as an open problem  on the other hand  theorem
1 can be generalized when there is a weight for each voter so
as to optimize the weighted sum of the dissatisfaction scores 
theorem 1 shows that ∆i ≤ 1 for each i  along with con-
stant treewidth on the global dependency graph form a suffi-
cient condition for polynomial time solvability  we argue that
such conditions are not overly restrictive for election rules 
instances with ∆i ≤ 1 can be thought of as a natural first-step
generalization of the unconditional approval voting case  by
adding at most one dependence per issue  constant treewidth
also provides an adequate degree of expressiveness and can
be encountered when the aggregate dependencies are not too
dense  graphs with low treewidth can arise when there is a
commonly accepted hierarchy between issues or when voters
have a high level of agreement on the type of dependencies in
combination with the fact that ∆i ≤ 1 for each voter i 
a natural question is whether we can solve other classes of
instances  containing graphs of non-constant treewidth  under
the assumption of ∆i ≤ 1 for each i  by focusing on other
parameters of the problem  quite surprisingly  it turns out that
the constant treewidth is essentially the only property that can
yield efficiency guarantees  to establish this claim  we first
show a  reverse  direction to theorem 1  that binary csps
can be reduced to cms  hence  together with theorem 1 
this means that cms is computationally equivalent to binary
2the original results in  freuder  1990  do not deal with the opti-
mization version  but as demonstrated in later works  e g   proposi-
tion 4 3 from  knop et al   2019    can be extended for this version 
csps  and thus to any other problem that is already known
to have this property  such as the partitioned subgraph
isomorphism problem  marx  2010   this reveals further
connections between cms and other combinatorial problems 
theorem 2  every binary csp with primal graph g  can be
reduced in polynomial time to a cms instance with ∆i ≤ 1
for every voter i  and with g as the global dependency graph 
proof  for convenience  we will work with the decision ver-
sion of csp asking for a solution that satisfies every con-
straint  let p be a binary csp instance  and without loss of
generality  assume that every constraint involves exactly two
variables  we construct a cms instance p ′  where the issues
correspond to the variables and the voters correspond to the
constraints of p  in particular  for every variable xj of the
csp instance  we add an issue ij and for every constraint we
add a voter  with the following preferences  let xj  xk be the
two variables involved in the constraint  we pick one of the
two variables  arbitrarily   say xk  and we set ik as the issue
that the voter cares about  conditioned on ij  we also set her
conditional ballot for issue ik in such a way  so that the voter
becomes satisfied precisely for all combinations of values for
xj and xk that make the constraint satisfied  the voter is also
satisfied unconditionally with every outcome for every other
issue of the produced instance  obviously  the dependency
graph of every voter has maximum in-degree equal to one 
as an example  suppose that a constraint is of the form
x1∨x2 and the variables x1  x2 have binary domain  then we
introduce a voter  and two issues i1  i2  if they have not been
introduced already by other constraints   and we can select i2
as being dependent on i1  the conditional ballot regarding
the satisfaction of the voter for i2 is  x1   x2    x1   x2  
 x1   x2   in addition  the voter approves unconditionally
every outcome of any issue other than i2 
to complete the reduction  we consider the decision ver-
sion of cms where we ask for an assignment with no dis-
satisfactions  i e   the instance p ′ has an affirmative solution
only when all voters are satisfied with all the issues  observe
that this is a polynomial time reduction  the conditional ballot
of each voter for her single issue of interest can be described
in o d2  time  where d is the maximum domain cardinality
of the csp variables   the following is quite obvious 
claim 1  the primal graph of csp instance p is identical to
the global dependency graph of the cms instance p ′ 
it remains to see that there exists a solution to p that sat-
isfies every constraint if and only if there exists a solution to
p ′ that satisfies every voter  which can be easily verified 
theorem 2 allows us to apply some known hardness results
on binary csps with large domain size  namely  grohe  2007 
grohe et al   2001   which imply that one cannot hope to have
an efficient algorithm for a class of cms instances  if the class
contains instances with non-constant treewidth  hence  the-
orem 1 is essentially tight  and this resolves the problem of
finding a characterization for instances that admit polynomial
time solutions for cms  subject to a standard computational
complexity assumption 
proceedings of the thirtieth    ijcai-21 
344
 corollary 1  let g be a recursively enumerable  e g   decid-
able  class of graphs  and let cms g  be the class of instances
with a global dependency graph that belongs to g  and with
∆i ≤ 1 for every voter i  assuming fpt̸= w 1   there is a
polynomial algorithm for cms g  if and only if every graph
in g has constant treewidth 
remark 2  if we strengthen the complexity assumption used 
from fpt̸=w 1  to the exponential time hypothesis  eth  
we can obtain an even stronger impossibility result  in par-
ticular  by exploiting the result of  marx  2010   and the re-
duction in the proof of theorem 2  we can show that under
eth  one cannot even hope for an algorithm on cms g  that
runs in time f g ||p||o tw g  /log tw g    where ||p|| is the
size of the cms instance and g ∈ g  this implies that the
o ntw g   algorithm from theorem 1 is best possible up to
an o log  tw g    factor in the exponent 
parameterized complexity of cms 
the algorithm used in
the proof of theorem 1  runs in time exponential in tw g  
where g is the global dependency graph and thus it places
cms in xp w r t the treewidth parameter  one can wonder
if anything more can be said concerning the fixed parame-
ter tractability of the problem  given the equivalence of our
problem with binary csps  we can use known results  samer
and szeider  2010  gottlob and szeider  2008   to extract
some further characterizations and obtain an almost complete
picture with respect to the most relevant parameters  on the
positive side  we can show that our problem is in fpt w r t 
the parameter  treewidth   domain size   on the negative
side  we cannot hope to prove fpt only w r t the treewidth
parameter  independent of the domain size  as stated below 
corollary 2  when ∆i ≤ 1 for every voter i  cms is in fpt
w r t the parameter tw   d  where tw is the treewidth of the
global dependency graph and d is the maximum domain size 
moreover  it is w 1 -hard w r t  tw and w r t  d 
4
strategic control of cms elections
in this section  we consider strategic aspects of cms and
study questions related to controlling an election of interde-
pendent issues  which falls under the broad and well studied
umbrella of influencing election outcomes in computational
social choice  suppose that there is an external agent  called
controller  who has a strong preference for a specific value
of some  or every  issue in a cms election  one of the in-
struments for enforcing a desirable value for the issue s  the
controller cares about  is by enabling new voters to participate
or respectively  by disabling some existing voters  which can
be done for example by changing the criteria for eligibility of
voters  e g   age  permanent residence  or even more special-
ized criteria in committee elections   furthermore  a different
instrument for the controller is to add more choices for the
issues under consideration or delete existing ones  towards
enforcing her will  we refer to  chen et al   2017  for related
examples  it is reasonable to assume that the controller does
not have unlimited power  and therefore  she is capable of
adding/deleting only a certain number of voters/alternatives 
each combination of control features gives rise to a differ-
ent control type  in this manner  we obtain 8 distinct algo-
rithmic problems that we study in this work  the formal def-
initions of which are presented in the following subsections 
these are adaptations to cms elections  of the original defi-
nitions provided in  bartholdi iii et al   1992   following the
terminology of  hemaspaandra et al   2007   we say that a
voting rule is vulnerable to a certain control type  if the cor-
responding problem is always solvable in polynomial time  if
the problem is c-hard for a complexity class c  we consider
the rule to be resistant to the specific control type  typically
c is the class np   in the cases where it is not possible for a
controller to affect the election towards fulfilling her will  we
say that the rule is immune to the corresponding control type 
as noted in  hemaspaandra et al   2009   the  dream case 
would be an efficiently computable voting rule which would
be either resistant or immune to all control types  hence 
given the results of section 3  we are mainly interested in
elections that satisfy the conditions identified there  for an
overview of the results of this section  we refer to table 1 
4 1
controlling voters
we start with the problems of adding or deleting voters for
enforcing a specific outcome either for a single issue or for
every issue of the election 
instance  a cms election  i  d  v  b   where v is the set
of registered voters  a set v ′ of yet unregistered voters with
v ∩ v ′ = ∅  for use only by cav   an integer quota q  a
distinguished alternative pj ∈ dj for a specific issue ij or
an outcome p ∈ d specifying an alternative for every issue 
problem cav-1  resp  cdv-1   does there exist a set v ′′ ⊆
v ′  resp  v ′′ ⊆ v    with |v ′′| ≤ q  such that pj is the
value of issue ij in every optimal cms solution of the profile
 i  d  v ∪ v ′′  b   resp  of the profile  i  d  v \ v ′′  b   
problem cav-all  resp  cdv-all   does there exist a set
v ′′ ⊆ v ′   resp  v ′′ ⊆ v   with |v ′′| ≤ q  such that p is the
unique optimal cms solution of the profile  i  d  v \v ′′  b 
 resp  of the profile  i  d  v \ v ′′  b   
remark 3  one has the option of either breaking ties in fa-
vor of the controller  if there are multiple optimal solutions
in cms  as in  davies et al   2011    or demand that the con-
troller s will is fulfilled in every optimal outcome  we focus
on the second case  as is also done in the seminal paper of
 bartholdi iii et al   1992   additionally  it is possible that
the controller has a strong opinion not just for a single or all
issues  but for a subset of issues  as a starting point  we have
chosen to consider the two  intuitively simpler  extremes 
we now present our results for these 4 problems  exhibiting
that it is not generally easy for a controller to enforce her will
in such elections  in fact  resistance to control by adding or
deleting voters can be established even for very simple forms
of elections  without even the presence of conditional ballots 
theorem 3  cav-all and cdv-all are np-hard even for
unconditional minisum and for binary domain in each issue 
theorem 3 may not be very surprising  since controlling all
issues appears to be a quite strict requirement  the next step
is to see whether such hardness results go through when the
controller wishes to control just a single issue  for uncondi-
tional minisum this is not the case  if we insist on a constant
proceedings of the thirtieth    ijcai-21 
345
 cdv
cav
cda
caa
∆ = 0
d = o 1 
∆ = 0
d = ω 1 
∆ = 0
d = o 1 
∆ = 0
d = ω 1 
∆ = 0
d = ω 1 
∆ = 1
d = o 1 
∆ = 1
d = ω n 
∆ = 0
d = ω 1 
∆ = 1
d = ω n 
∆ = 2
d = o 1 
all
r
r
r
r
v
 
r
i
i
i
1
v
r
v
r
v
v
r
i
r
r
table 1  results on controlling cms elections  r stands for resistant  v for vulnerable and i for immune  for a cms instance  we denote as
∆ the maximum in-degree of every voter s dependency graph  ∆ = maxi∈ n  ∆i   d the maximum domain size and n the number of voters 
domain size for the designated issue  the reason is that this
can be reduced to an fpt version of the set multi-cover 
proposition 1  implied by  bredereck et al   2020    cav-1
and cdv-1 can be solved in polynomial time for uncondi-
tional minisum if the domain size of each issue is constant 
as a consequence  any potential hardness result for cav-1
and cdv-1 would have to consider either non-constant do-
main or conditional ballots  indeed  it suffices to move to
non-constant domain size  to establish np-hardness 
theorem 4  cav-1 and cdv-1 are np-hard  even for un-
conditional minisum  but with non-constant domain size in at
least one issue 
we now have a complete picture for the unconditional set-
ting  the results of which  transfer to the conditional case too 
the status of cdv-1 and cav-1 for constant domain size in
the presence of conditional ballots  remains unresolved 
4 2
controlling alternatives
we now consider the analogous control problems  regarding
the addition or deletion of alternatives  instead of voters 
instance  a cms election  i  d  v  b   where d = d1 ×
· · ·×dm  and dk is the set of qualified alternatives of each
issue ik  a set d′
k of spoiler alternatives for each ik  for use
only by caa   an integer quota q  a distinguished alterna-
tive pj ∈ dj for a specific issue ij or an outcome p ∈ d
specifying an alternative for every issue 
problem caa-1  resp 
cda-1   does there exist a set
d′′ ⊆ ⊔k∈ m d′
k  resp  d′′ ⊂ ⊔k∈ m dk   with |d′′| ≤ q 
such that pj is the value of the issue ij in every optimal
cms solution of the profile where the domain of each issue
ik is enlarged by the alternatives in d′′ ∩d′
k  resp  reduced
by the alternatives in d′′ ∩ d′
k  
problem
cda-all 
does there exist a set d′′
⊂
⊔k∈ m dk  with |d′′| ≤ q  such that p is the unique op-
timal cms solution of the profile where the domain of each
issue ik is reduced by the alternatives in d′′ ∩ d′
k 
note  for cda-1 and cda-all  we also require that for
every k  |dk \ d′′| ≥ 1 
in the definitions above  we use ⊔ to denote the disjoint
union of sets  having in mind that we could consider alterna-
tives of different domains as distinct  even if they correspond
to the same values  e g  in boolean domains  
remark 4  we first note that we have not included caa-
all in the definitions as cms is trivially immune to adding
alternatives in order to enforce a qualified alternative in every
issue  concerning caa-1  we assume that the voters may ex-
press an opinion about any outcome of every issue  whether it
concerns a qualified or a spoiler alternative  additionally  an-
other way to define such problems would be to allow the con-
troller to completely delete or add issues  however  given the
existence of dependency graphs  erasing an issue can make
the preferences of a voter ill-defined  lastly  the constraint
|dk \d′′| ≥ 1  for cda-1 and cda-all  is to ensure that the
controller cannot eliminate all the alternatives of an issue 
it turns out that the picture differs significantly from the
problem of adding or removing voters 
proposition 2  cda-1 and cda-all can be solved in poly-
nomial time whereas caa-1 is immune  for unconditional
minisum  with arbitrary domain size 
as soon as we move however to instances with conditional
ballots  the problems do become hard  with the exception of
proposition 3   we start with the hardness of cda-all 
theorem 5  cda-all is np-hard  when ∆i ≤ 1 for every
voter i  and even when the treewidth of the global dependency
graph is at most one  but with non-constant domain size in at
least one issue 
next  we move to cda-1 and caa-1  when we allow a
large domain size  we show that they have a similar behavior 
and they are both resistant  the proof of theorem 6 below 
shows a connection with some natural problems on directed
graphs  that have been linked to election control in the past
for different voting rules  betzler and uhlmann  2009  
theorem 6  caa-1 and cda-1 are np-hard  when ∆i ≤ 1
for every voter i  and even when the treewidth of the global
dependency graph is at most one  but with non-constant do-
main in at least one issue 
proof  we will prove hardness for cda-1  the proof for caa-
1 is similar  using a reduction from the np-hard max out-
degree deletion  mod   betzler and uhlmann  2009  
instance  a directed graph g =  v  e   a distinguished
vertex p ∈ v and an integer k ≥ 1 
problem  does there exist v ′ ⊆ v with |v ′| ≤ k such that
p is the only vertex of maximum out-degree in g v \ v ′  
for s ⊆ v   we denote by degs u  the out-degree of vertex
u in a graph g =  v  e   when we count only outgoing edges
towards the vertices of s  let p =  g =  v  e   p  k  be an
instance of mod in a directed graph with n vertices and m
edges  we create a cda-1 instance  where we have one issue
ij for every vertex vj  j ∈  n  and an extra issue i0  hence
i =  i0  i1  i2          in   for j ∈  n   the domain of issue ij
is binary in the form dj =  dj  dj   the domain of i0  say
d0  contains  k   1  n − 1    1 alternatives  in particular  it
contains an alternative bp that corresponds to the designated
proceedings of the thirtieth    ijcai-21 
346
 vertex p ∈ v   and for every vertex v ∈ v \  p   there are
k   1 alternatives bℓ
v  for ℓ ∈  k   1   essentially  these are
identical k   1  copies  encoding the selection of v in i0  and
play a significant role in the reverse direction of the reduction 
as for the voters  there are two types of voters  edge voters
and vertex voters  there is one edge voter for every edge
 i  j  ∈ e  with a dependency graph having one edge from
ij to i0  and voting as follows 
• for the issue i0  she votes conditioned on ij for  dj   bi 
if i = p or otherwise for  dj   bℓ
i   ∀ℓ ∈  k   1  
• for all other issues she is satisfied with any outcome 
for every vertex other than p  we also have a block of l iden-
tical voters  where it suffices to take l = m   1  each voter
in the j-th block  with j ∈ v \  p  has a dependency graph
with 1 edge  from i0 to ij and votes as follows 
• for the issue ij  she is satisfied with the combinations
 bℓ
j   dj  for any ℓ  also  if the value of i0 differs from
bℓ
j  for any ℓ  she is satisfied with any value on ij  hence 
the only restriction is that when the value of i0 comes
from an alternative corresponding to vertex j  the voter
can be satisfied w r t  ij only by dj 
• for all other issues  she is satisfied with any outcome 
in total  we have m    n − 1 l voters  we also use k as
the quota parameter  and we suppose the controller wants to
enforce the outcome bp at issue i0  clearly  for every voter i 
∆i ≤ 1  and the global dependency graph is a star centered
on i0  the maximum domain cardinality is o kn  = o n2  
suppose there exists a set s of vertices in g of size at most
k  say wlog that s =  1          k  ⊆ v   whose deletion
leaves p as the only vertex of maximum out-degree  we now
choose to delete the corresponding alternatives  d1          dk 
from the issues  i1          ik   if we select bp for the issue i0 
then the total dissatisfaction score can be brought down to
m − degv \s p   by choosing dj for every issue ij where dj
has not been deleted  on the other hand  if we select for i0
some bℓ
j for any ℓ ∈  k   1   we need to consider two cases 
depending on j  if j ∈ v \ s  then by the same reason-
ing as before  the best we could achieve is a dissatisfaction
score equal to m − degv \s j   but since p has the maximum
out-degree  this would yield a worse solution  for the sec-
ond case  suppose j ∈ s  then dj has been deleted from ij 
hence  the j-th block of vertex voters will be dissatisfied w r t 
ij  and since l > m  this cannot yield an optimal solution 
to conclude  after the deletion of the selected alternatives  bp
has to be selected for i0 in any optimal solution 
for the reverse direction  suppose that there is a set d′′
of at most k alternatives  the deletion of which  forces bp
to be selected for i0 in every optimal solution  we claim
that the deleted alternatives must come from distinct issues
among i1          in  and they all correspond to some dj for
j ∈  n   it is now easy to observe that deleting from v the set
s formed by the vertices corresponding to these alternatives
in d′′  makes p the unique vertex of maximum out-degree
in the induced subgraph of g  if not  there is a vertex  say
v ∈ v \ s  with greater or equal out-degree  in that case  if
we select bℓ′
v for i0 for some arbitrary ℓ′  and dj for all issues
ij  for which dj has not been deleted  we will obtain a solu-
tion with at most the same dissatisfaction score as the one that
used bp  indeed  we will have fewer or equal dissatisfactions
from the edge voters w r t  i0  and also all the blocks of the
vertex voters will be satisfied which contradicts the fact that
bp was elected for i0 in every optimal solution 
let us now move to a constant domain size for cda-1 and
caa-1  here  the problems seem to behave differently 
proposition 3 
cda-1 can be solved in polynomial time 
when ∆i ≤ 1 for every voter i  the treewidth of the global
dependency graph is constant  and the domain size is also
constant for every issue 
hence  constant domain size makes a difference for cda-1
when we stick to the assumptions from section 3 on each ∆i
and on the treewidth  for caa-1  we are not yet aware if the
same result holds  but the proof arguments certainly do not
go through   however  we have established intractability  as
soon as we move to slightly richer instances with ∆i ≤ 2 
theorem 7  caa-1 is np-hard  when ∆i ≤ 2 for every voter
i  even when the treewidth of the global dependency graph is
at most one and even for binary domain size in every issue 
overall  we end the current section  concluding that cms is
computationally resistant in most of the variants of the control
problem considered 
5
conclusions
our work has mostly focused on the natural  first-step gener-
alization of the classic minisum rule into conditional voting 
i e   with ∆i ≤ 1 for every voter i  for this case  we con-
clude that cms provides a satisfactory tradeoff between ex-
pressiveness and efficiency under the assumption of bounded
treewidth  and at the same time exhibits sufficient resistance
to control in the considered settings 
there are still several interesting problems for future re-
search  algorithmic results for instances with even higher ex-
pressiveness  e g   with ∆i ≤ 2  seem more challenging  the
problem remains np-hard and we are not aware of any prop-
erties that could lead to optimal algorithms for special cases  
from a strategic point of view  some questions have been
left open for the models we considered  including also pa-
rameterized complexity aspects  more interestingly  one can
go further and study other strategic moves such as destruc-
tive versions of control or bribery aspects in a cms election 
along this spirit  cms was proven to be non-strategyproof by
 barrot and lang  2016   but the complexity of finding a ma-
nipulation has not been examined  lastly  an experimental
evaluation of the cms election rule would also be an interest-
ing pursuit  complementary to our theoretical analysis 
acknowledgements
this work has been supported by the hellenic foundation for
research and innovation  h f r i   under the  first call for
h f r i  research projects to support faculty members and
researchers and the procurement of high-cost research equip-
ment  grant  project number  hfri-fm17-3512  
proceedings of the thirtieth    ijcai-21 
347
 references
 barrot and lang  2016  nathana¨el barrot and j erˆome lang  con-
ditional and sequential approval voting on combinatorial do-
mains  in proceedings of the 25th international joint conference
on artificial intelligence  ijcai-16   pages 88–94  2016 
 bartholdi iii et al   1992  john bartholdi iii  craig tovey  and
michael trick  how hard is it to control an election 
mathe-
matical and computer modelling  16 8-9  27–40  1992 
 betzler and uhlmann  2009  nadja
betzler
and
johannes
uhlmann 
parameterized complexity of candidate control
in elections and related digraph problems  theoretical computer
science  410 52  5425–5442  2009 
 brams and fishburn  2010  steven j  brams and peter c  fishburn 
going from theory to practice  the mixed success of approval
voting  in handbook on approval voting  pages 19–37  springer 
2010 
 bredereck et al   2020  robert bredereck  piotr faliszewski  rolf
niedermeier  piotr skowron  and nimrod talmon  mixed integer
programming with convex/concave constraints  fixed-parameter
tractability and applications to multicovering and voting  theo-
retical computer science  pages 86–105  2020 
 chen et al   2017  jiehua chen  piotr faliszewski  rolf nieder-
meier  and nimrod talmon  elections with few voters  candidate
control can be easy  journal of artificial intelligence research 
60 937–1002  2017 
 chevaleyre et al   2008  yann chevaleyre  ulle endriss  j erˆome
lang  and nicolas maudet  preference handling in combinatorial
domains  from ai to social choice  ai magazine  29 4  37–37 
2008 
 cygan et al   2015  marek cygan  fedor fomin  łukasz kowa-
lik  daniel lokshtanov  d aniel marx  marcin pilipczuk  michał
pilipczuk  and saket saurabh 
parameterized algorithms 
springer  2015 
 davies et al   2011  jessica davies  george katsirelos  nina naro-
dytska  and toby walsh  complexity of and algorithms for borda
manipulation  in proceedings of the 25th aaai conference on
artificial intelligence  aaai-11   pages 657–662  2011 
 faliszewski and rothe  2016  piotr faliszewski and j¨org rothe 
control and bribery in voting  in handbook of computational so-
cial choice  pages 146–268  cambridge university press  2016 
 faliszewski et al   2011  piotr faliszewski  edith hemaspaandra 
and lane hemaspaandra  multimode control attacks on elections 
journal of artificial intelligence research  40 305–351  2011 
 freuder and wallace  1992  eugene freuder and richard wallace 
partial constraint satisfaction  artificial intelligence  58 1-3  21–
70  1992 
 freuder  1990  eugene freuder  complexity of k-tree structured
constraint satisfaction problems 
in proceedings of the 4th
aaai conference on artificial intelligence  aaai-90   pages 4–9 
1990 
 gottlob and szeider  2008  georg gottlob and stefan szeider 
fixed-parameter algorithms for artificial intelligence  constraint
satisfaction and database problems 
the computer journal 
51 3  303–325  2008 
 grohe et al   2001  martin grohe  thomas schwentick  and luc
segoufin 
when is the evaluation of conjunctive queries
tractable 
in proceedings of the 33rd symposium on the the-
ory of computing   stoc-01   pages 657–666  2001 
 grohe  2007  martin grohe  the complexity of homomorphism
and constraint satisfaction problems seen from the other side 
journal of the acm  54 1  1–24  2007 
 hemaspaandra et al   2007  edith hemaspaandra  lane hemas-
paandra  and j¨org rothe  anyone but him  the complexity of
precluding an alternative  artificial intelligence  171 5-6  255–
285  2007 
 hemaspaandra et al   2009  edith hemaspaandra  lane hemas-
paandra  and j¨org rothe  hybrid elections broaden complexity-
theoretic resistance to control  mathematical logic quarterly 
55 4  397–424  2009 
 kilgour  2010  marc kilgour  approval balloting for multi-winner
elections 
in handbook on approval voting  pages 105–124 
springer  2010 
 knop et al   2019  dusan
knop 
martin
kouteck y 
tom as
masar ık  and tom as toufar 
simplified algorithmic metathe-
orems beyond mso  treewidth and neighborhood diversity 
logical methods in computer science  15 4  12 1–12 32  2019 
 koster et al   2002  arie koster  stan van hoesel  and antoon
kolen  solving partial constraint satisfaction problems with tree
decomposition  networks  40 3  170–180  2002 
 lang and xia  2016  j erˆome lang and lirong xia 
voting in
combinatorial domains  in handbook of computational social
choice  pages 197–222  cambridge university press  2016 
 liu et al   2009  hong liu  haodi feng  daming zhu  and junfeng
luan  parameterized computational complexity of control prob-
lems in voting systems  theoretical computer science  410 27-
29  2746–2753  2009 
 markakis and papasotiropoulos  2020  evangelos markakis and
georgios papasotiropoulos 
computational aspects of condi-
tional minisum approval voting in elections with interdependent
issues  in proceedings of the 22nd international joint conference
on artificial intelligence  ijcai-20   pages 304–310  2020 
 marx  2010  d aniel marx  can you beat treewidth 
theory of
computing  6 85–112  2010 
 robertson and seymour  1986  neil robertson and paul seymour 
graph minors  ii  algorithmic aspects of tree-width  journal of
algorithms  7 3  309–322  1986 
 samer and szeider  2010  marko samer and stefan szeider  con-
straint satisfaction with bounded treewidth revisited  journal of
computer and system sciences  76 2  103–114  2010 
proceedings of the thirtieth    ijcai-21 
348
 "
None,2021,https-www-ijcai-org-proceedings-2021-0049-pdf,Majority Vote in Social Networks: Make Random Friends or Be Stubborn to Overpower Elites,"Charlotte Out, Ahad N. Zehmakan",None,https://www.ijcai.org/proceedings/2021/0049.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0049-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0049-pdf.pdf,"majority vote in social networks  make random friends or be stubborn to
overpower elites
charlotte out   ahad n  zehmakan
department of computer science  eth z¨urich
chaout@student ethz ch  ahadn zehmakan@gmail com
abstract
consider a graph g  representing a social network 
assume that initially each node is colored either
black or white  which corresponds to a positive or
negative opinion regarding a consumer product or
a technological innovation  in the majority model 
in each round all nodes simultaneously update their
color to the most frequent color among their con-
nections 
experiments on the graph data from the real world
social networks  sns  suggest that if all nodes in
an extremely small set of high-degree nodes  often
referred to as the elites  agree on a color  that color
becomes the dominant color at the end of the pro-
cess  we propose two countermeasures that can be
adopted by individual nodes relatively easily and
guarantee that the elites will not have this dispro-
portionate power to engineer the dominant output
color  the first countermeasure essentially requires
each node to make some new connections at ran-
dom while the second one demands the nodes to be
more reluctant towards changing their color  opin-
ion   we verify their effectiveness and correctness
both theoretically and experimentally 
we also investigate the majority model and a vari-
ant of it when the initial coloring is random on the
real world sns and several random graph models 
in particular  our results on the erd˝os-r enyi and
regular random graphs confirm or support several
theoretical findings or conjectures by the prior work
regarding the threshold behavior of the process 
finally  we provide theoretical and experimental
evidence for the existence of a poly-logarithmic
bound on the expected stabilization time of the ma-
jority model 
1
introduction
when facing a decision or forming an opinion about a topic
such as a consumer product  a technological innovation  or a
political event  humans often consult friends  family or oth-
ers in their close circle for advice  additionally  we often
consider the opinions of the figures whose opinions we value
in some way  for example  politicians we usually agree with 
celebrities whom we look up to  or well-established scientists 
in this way  an individual s opinion is influenced by the opin-
ions of the people around her  furthermore  due to the rise of
online social networking  opinions are formed and changed
at a higher pace  consequently  there has been a growing de-
mand for a quantitative understanding of the opinion forming
process 
recently  within the field of computer science  especially
computational social choice and algorithmic game theory 
there has been a rising interest in developing and studying
mathematical opinion diffusion models  which aim to mimic
the process of opinion forming in a society  at a high level
of abstraction  in these models one usually consider a graph
g and some initial coloring of the nodes  where each node
is colored either black or white  this graph is meant to rep-
resent a social network  in which the agents are modeled as
nodes and an edge between two nodes corresponds to a rela-
tion between the respective agents  e g  friendship  common
interests  or advice  the color of a node represents its opinion
on an innovation or a political party  etc  after initialization 
in each round a group of nodes update their color based on a
predefined rule 
plentiful instances of the aforementioned abstract model
have been introduced and studied  among them  the majority
model has attracted considerable attention  cf   auletta et al  
2015   in the majority model  for a graph g and an initial
coloring  in each round all nodes simultaneously update their
color to the most frequent color in their neighborhood  in
case of a tie  a node keeps its current color  we also consider
the  ψ1  ψ2 -majority model  for some ψ1  ψ2 > 1/2  here 
a black  resp  white  node changes its color if at least ψ1
 resp  ψ2  fraction of its neighbors hold the opposite color
from itself  we observe that this is the same as the majority
model for ψ1 = ψ2 = ψ for a ψ slightly larger than 1/2 
several different variants of the majority model have been
studied by prior work  cf   keller et al   2014    we will fo-
cus on the following two variants  assume that each node v
has an influence factor r v   here also each node chooses the
majority color  but it counts the color of a neighbor v  r v 
times  by default we assume that r v  = 1 for each node v 
otherwise it is mentioned explicitly  note that if all nodes
have influence factor one  we recover the majority model 
secondly  we consider the variant in which we assign a stub-
proceedings of the thirtieth    ijcai-21 
349
 bornness factor γ v  ∈  0  1  to each node v  then  a node
v changes its color if at least γ v  fraction of its neighbors
have the opposite color  we observe that if we assign a fixed
stubbornness factor γ to all nodes  this would coincide with
the  ψ1  ψ2 -majority model for ψ1 = ψ2 = γ 
all the updating rules that we study in this paper are de-
terministic  furthermore  for an n-node graph g  there are
2n possible colorings  therefore  after at most 2n rounds the
process reaches a cycle of colorings  the number of rounds
the process needs to reach the cycle and the length of the cy-
cle are called the stabilization time and period of the process 
we say a color  black or white  wins if more than half of the
nodes share that color in the final configuration 
moreover  a color takes over if all nodes share that color
in the final configuration 
we say a set of nodes form a
white/black coalition if they are all white/black  a node set s
is said to be a winning set  resp  dynamo  if black color wins
 resp  takes over  once nodes in s form a black coalition 
1 1
our contribution
question 1  what is the number of black nodes required for
the black color to win or take over  alternatively  more re-
alistically speaking  if a marketing campaign can convince
a group of individuals to adopt a new product  and the goal
is to trigger a large cascade of further adoptions building on
collective decision-making  which set of individuals should
it target and how large this set needs to be  when consider-
ing graphs of real world social networks  sns    avin et al  
2019  experimentally observed that in such graphs  if a small
set of nodes  e g  1  of nodes  with the highest degrees form
a black coalition and have an influence factor slightly larger
than the rest of nodes  the black color wins  such a small
set of high-degree nodes are meant to approximate the elites 
which are a relatively small and well-connected set of individ-
uals  i e   nodes  with substantial economic or social power 
cf   avin et al   2017  
several random graph models have been introduced to sim-
ulate the real world sns  arguably  one of the most well-
studied such graph models is the preferential attachment
 pa  random graph  barab asi and albert  1999   in contrast
to the real world sns   avin et al   2019  observed that in the
pa graphs  with comparable number of nodes and edges  a
small set of black nodes is not capable of enforcing the vic-
tory of the black color  unless they have extremely large in-
fluence factors  therefore  they suggested for future work
to propose graph models which not only retain well known
characteristics of the real world sns  but also support the ex-
istence of a small set of nodes with a significant dispropor-
tionate power in the majority model 
the fact is even though the pa model possesses some cru-
cial features of the real world sns  it also suffers from lack of
some fundamental properties such as a high clustering coef-
ficient  that is  two neighbors of a node are likely to be adja-
cent   cf   krioukov et al   2010   hence  the aforementioned
result by  avin et al   2019  is just another indication that the
pa model is not a decent choice to represent the sns  on
the other hand  hyperbolic random graph  hrg   krioukov
et al   2010  is known to possess all the desired fundamental
properties  including a high clustering coefficient  making it
an interesting and suitable model to consider  leading to our
first contribution 
contribution 1  our experiments on hrg matches the re-
sults for the real world sns  that is  almost the same number
of highest degree black nodes with a rather small influence
factor suffices for the black color to win   the parameters
of the hrg selected suitably to make it comparable to the
respective sn  see section 1 2  for more details  
given this disproportionate amount of controlling power
of the elites  a natural question that arises is whether one can
develop a counter measure to overpower them 
a proposed countermeasure ideally should not require sig-
nificant changes in the graph structure or the updating rule 
furthermore  it should be easy for the agents to implement 
e g  it should not require them to have a full knowledge of the
graph structure or memorize the history of the process 
contribution 2  we propose two countermeasures and sup-
port their effectiveness both experimentally and theoretically 
firstly  we show that if we require every agent to make a cer-
tain number of new connections at random  a small set of elite
nodes cannot control the output of the majority model any-
more  more formally  we prove that if we add a graph with
strong expansion properties on top of any graph  including a
real world sn  for the black color to win a significant num-
ber of nodes must be black initially  secondly  we show that
if each agent changes her color only if a  sufficiently  large
fraction of her neighbors hold a different color  no small set
of nodes can determine the output of the process  this is re-
alized by assigning a high stubbornness factor to each node 
furthermore  we demonstrate that our experiments support
these theoretical findings 
question 2  what is the probability that the black color wins
 or takes over  if we assume that initially each node is colored
black independently with some probability pb ∈  0  1  
it is known  cf   zehmakan  2020   that in the majority
model on  nearly  regular graphs with strong expansion prop-
erties  such as random regular graphs and erd˝os-r enyi ran-
dom graph  see section 1 2 for a formal definition   if pb is
 slightly  more  resp  less  than 1/2  then black  resp  white 
color takes over asymptotically almost surely   we say that
an event occurs asymptotically almost surely  a a s   if it hap-
pens with probability tending to 1 when we let the number of
nodes go to infinity  
contribution 3  we provide experimental results confirming
the existence of this threshold behavior in the erd˝os-r enyi
and regular random graphs  and show that this behavior is
also observed in the pa random graph  however  the majority
model turns out to exhibit a different behavior on real world
sns and hrg  that is  the black  resp  white  color might
not take over even when pb  resp  1 − pb  is significantly
larger than 1/2  however  we show that upon the addition of
a d-regular random graph for a reasonably large d we recover
the aforementioned threshold behavior 
we study the above question for the  ψ1  ψ2 -majority
model as well  we prove that for a dense erd˝os-r enyi ran-
dom graph  the process exhibits a threshold behavior with two
phase transitions   i  the white color takes over if pb < 1−ψ1
 ii  both colors will survive  i e   no color takes over  if
1 − ψ1 < pb < ψ2  iii  the black color takes over if ψ2 < pb
proceedings of the thirtieth    ijcai-21 
350
 a a s 
furthermore  our experiments suggest that such a
threshold behavior is also present in the pa random graph 
sparse regular random graphs  hrg  and the real world sns 
but for different threshold values 
as mentioned  the majority model on the erd˝os-r enyi ran-
dom graph gn q is well understood when pb is smaller or
larger than 1/2  what if we have pb = 1/2   benjamini et al  
2016  conjectured if q is  sufficiently  larger than 1/n  then
a a s  one of the two colors almost takes over  i e   all nodes
share the same color at the end  except a sub-linear number of
them    fountoulakis et al   2020  proved that the conjecture
is true when q is larger than 1/√n  but it has remained open
for q smaller than 1/√n 
contribution 4  we perform experiments whose results sup-
port this conjecture  more precisely  we observe that in the
majority model on gn q with pb = 1/2 if q = c/n for c ≥ 12 
one of the two colors almost takes over  however  if c ≤ 8 
the process reaches a configuration where almost half of the
nodes are black 
question 3 
what is the stabilization time and period of
the process 
for the majority model on a graph g =
 v  e    goles and olivos  1980  proved that the period
is always one or two 
furthermore using some algebraic
tools   poljak and turz ık  1986  showed that the stabiliza-
tion time is in o |e|   which
 frischknecht et al   2013 
proved to be tight  up to some poly-logarithmic factor  how-
ever  if we start from a random coloring  where each node is
black independently with probability pb  the probability that
an extremal coloring  for which the process takes a long time 
emerges is fairly small  hence  a natural question that arises
here is whether one can provide stronger bounds on the ex-
pected stabilization time  i e   the expected number of rounds
the process needs to reach a cycle of colorings from a random
initial coloring   it is widely believed that a poly-logarithmic
upper bound must exist  but this is proven only for some spe-
cial classes of graphs  cf   zehmakan  2020  
contribution 5  as our first evidence for a poly-logarithmic
upper bound  we prove that the expected stabilization time
of the majority model is at most log n when the underlying
graph is a cycle cn  furthermore  we experimentally inves-
tigate the expected stabilization time of the majority model
on different random graph models and real world sns and
our findings support the conjectured poly-logarithmic bound 
it is worth to stress that the process takes the longest at the
threshold value pb = 1/2 
we study the stabilization time of the  ψ1  ψ2 -majority
model too and  building on a potential function argument 
prove that it is also bounded by o |e|  when ψ1 = ψ2  for
the proof  we set a connection between the number of edges
whose endpoints have opposite colors in the initial coloring
and the number of rounds the process needs to end  as we
will explain  this technique might be useful to prove a poly-
logarithmic bound on the expected stabilization of the major-
ity and  ψ1  ψ2 -majority model 
1 2
preliminaries
graph definitions 
let g =  v  e  be an n-node graph 
for a node v ∈ v   n  v   =  u ∈ v    u  v  ∈ e  is the
neighborhood of v  for a set s ⊂ v   we define n  s   =
�
v∈s n  v  and ns  v   = n  v  ∩ s  moreover  d  v   =
|n  v  | is the degree of v in g and ds  v   = |ns  v  | 
furthermore  for two node sets s and s′  we define
e  s  s′   = |  v  u  ∈ s × s′    v  u  ∈ e | where s × s′
is the cartesian product of s and s′ 
note that whenever graph g is not clear from the con-
text  we add a superscript  e g  we write dg v   dg
s  v   and
eg s  s′  
random graphs 
let gn q denote the erd˝os-r enyi ran-
dom graph  which is the random graph on the set  1  · · ·   n  
where each edge is present independently with probability q 
we denote by gn d the d-regular random graph  which is the
random graph with a uniform distribution over all d-regular
graphs on n nodes 
models  for a graph g =  v  e   a coloring is a function
c   v →  b  w   where b and w represent black and white 
respectively  for a node v ∈ v   the set n c
a  v   =  u ∈
n  v    c  u  = a  includes the neighbors of v which have
color a ∈  b  w  in coloring c  assume that we are given
an initial coloring c0 on a graph g  in a model m  ct  v  
which is the color of node v in the t-th coloring for t ∈ n 
is determined based on a predefined updating rule  we are
mainly interested in the following two models  where ct  v 
is defined by a deterministic updating rule as a function of
ct−1  u  for u ∈ n  v  ∪  v  
majority model  in the majority model
ct v  =
�
ct−1 v 
if |n ct−1
b
 v | = |n ct−1
w
 v |
argmaxa∈ b w |n ct−1
a
 v |
otherwise
 
 ψ1  ψ2 -majority model  in the  ψ1  ψ2 -majority model
for some ψ1  ψ2 ∈  1/2  1 
ct v  =
�
�
�
�
�
w
if ct−1 v  = b ∧ |n ct−1
w
 v | ≥ ψ1d v 
b
if ct−1 v  = w ∧ |n ct−1
b
 v | ≥ ψ2d v 
ct−1 v 
otherwise
 
in these models  we define bt and wt for t ∈ n0 to be the
set of black and white nodes in ct 
experimental setup 
we run our experiments for the
graph data of the facebook  fb  and youtube  yt  sn
from  viswanath et al   2009  and  mislove et al   2007  and
twitter  tw  and slashdot  sd  graph data from  leskovec
and krevl  2014  furthermore  we focus on several random
graph models such as erd˝os-r enyi  er  random graph 
random regular graph  rrg   preferential attachment  pa 
random graph  and hyperbolic random graph  hrg   to
make our experiments on the random graph models and real
world sns comparable  we set the parameters of random
graphs in a way that they have the same number of nodes
and edges in expectation  for the generation of the rrg and
hrg  we rely on the  approximation  algorithms of  steger
and wormald  1999  and  staudt et al   2015  respectively 
and the implementations in  hagberg et al   2008   to gen-
erate hrg  in addition to the number of nodes and edges 
one needs to provide the exponent of the power-law degree
distribution β and the temperature t as the input parameters 
throughout this paper  we set β = 2 5 and t = 0 6  ex-
periments which required random choice of edges or colors
were executed 8 times and then the average output was con-
sidered  furthermore   several  experiments were carried out
proceedings of the thirtieth    ijcai-21 
351
 on an intel xeon e3 cpu  with 32 gb ram  and a linux
os 
1 3
prior works
opinion diffusion models  in the plethora of opinion diffu-
sion models  considerable attention has been devoted to the
study of different variants of the majority model  such as an
asynchronous updating rule  anagnostopoulos et al   2020  
various tie-breaking rules  schoenebeck and yu  2018   and
randomized updating rules  mossel et al   2013   even more
complex models such as the one considered in  ferraioli and
ventre  2017  which follows an averaging-based updating
rule  or the models in  faliszewski et al   2018  and  brill
et al   2016  can be seen as extensions of the majority model 
in the present paper  we consider variants of the major-
ity model previously studied by cf 
 avin et al   2019  and
 auletta et al   2017   furthermore  the  ψ1  ψ2 -majority
model  which is a generalization of the model studied in  bal-
ister et al   2010  
minimum size of a winning set  determining the mini-
mum size of a winning set and a dynamo has been considered
in various majority based models and for different classes
of graphs such as er  benjamini et al   2016   pa  avin et
al   2019   and lattice  balister et al   2010  
for general
graphs   berger  2001  proved that there exist arbitrarily large
graphs which have dynamos of constant size under the ma-
jority model and it was shown in  auletta et al   2018  that
every n-node graph has a dynamo of size at most n/2 under
the asynchronous variant 
random initial coloring  the majority model with a ran-
dom initial coloring has been investigated for different classes
of graphs such as hypercubes and preferential attachment
trees  cf   balister et al   2010   as stated  special attention
has been devoted to the study of er when each node is black
independently with probability pb = 1/2  cf   benjamini et
al   2016  
stabilization time and period   goles and olivos  1980 
proved that the period of the majority model is always one or
two  recently  it was shown by  chistikov et al   2020  that
it is pspace-complete to decide whether the period is one
or not for a given coloring of a directed graph  furthermore 
 poljak and turz ık  1986  proved that the stabilization time of
the majority model on a graph g =  v  e  is upper-bounded
by o |e|   stronger bounds are known for special classes
of graphs  for instance  for a d-regular graph with strong
expansion properties the stabilization time is in o logd n  
cf   zehmakan  2020  
2
power of elites and countermeasures
 avin et al   2019  observed that in real world sns  if a small
set  e g  1   of the elite nodes are provided with a constant
influence factor  e g  8   they are capable of determining the
outcome of the majority model  i e   they form a winning set 
in the pa random graphs with comparable parameters  in con-
trast  these authors showed that for a small set of elite nodes to
form a winning set  they must have an extremely large influ-
ence factor  as mentioned earlier  the pa random graph lacks
the presence of a high clustering coefficient cf   krioukov et
al   2010   we believe this is the source of such discrepancy 
on the other hand  hrg is known  krioukov et al   2010 
to possess all the aforementioned properties  justifying our
choice to investigate the majority model on hrg 
our experiments demonstrate that the size and influence
factor required for a set of elites to form a winning set is ap-
proximately the same in the real world sns and hrgs with
comparable parameters  this is depicted for yt sn in fig-
ure 1  left   and other sns are included in the full version of
this paper  figure 1  left  also covers pa  which was already
investigated by  avin et al   2019  
disproportionate power of elites  naturally  the question
arises how to prevent a small set of elite nodes from deter-
mining the outcome of the majority model  to this end  we
propose two countermeasures to overpower the elites  firstly 
we prove that if we add a sufficiently dense rrg on top of
any graph  in particular a sn  no small winning set will exist 
secondly  we show that if we assign a sufficiently large stub-
bornness factor to each node  no small set of elites can create
a winning set 
countermeasure 1  adding a rrg on top of a sn is es-
sentially the same as asking agents  nodes  to make a set of
connections at random  consider a small set s of elite nodes
who form a winning set in a sn  intuitively speaking  the
randomly added connections for each node are unlikely to be
chosen from set s  thus reducing the influencing power of the
elite nodes in s  we formally state our result in theorem 2 
of which the proof can be found in the full paper version 
theorem 2  let g1 =  v  e1  be an arbitrary graph with
average degree ¯d  g2 =  v  e2  be a d-regular graph and
z ⊂ v be an arbitrary set of nodes in g =  v  e1 ∪ e2 
with |z| = 0 05n and n = |v |  let g1 =  v  e1  be an
arbitrary graph with average degree ¯d and g2 =  v  e2 
be a d-regular graph  suppose that z ⊂ v is an arbitrary
set of nodes in g =  v  e1 ∪ e2  and |z| = 0 05n  where
n = |v |  consider the majority model on g  where b0 = z
and all nodes in z have influence factor r ≤ 10  while it is
1 for the rest of nodes   if σ g2  ≤ β and d = cr ¯d for a
suitable choice of constants c  β > 0  the white color wins 
corollary   friedman  2003  proved that for a random d-
regular graph gn d  σ  gn d  ≤ 2/
√
d a a s  when d ≥ 3 
this implies that the statement of theorem 2 holds a a s if
g2 = gn d for a sufficiently large d  therefore  if we add a
gn d on top of a sn  there is no winning set which includes
less than 5  of the nodes  recall that based on  avin et al  
2019  the real world sns usually allow winning sets of much
smaller size than 5   for example in yt sn  a set of highest
degree nodes of size 0 15   as we will discuss  our exper-
iments support even stronger bounds than the one given in
theorem 2  lastly  it is worth to mention that the constraint
r ≤ 10 can be relaxed  but cannot be lifted entirely because
if a set s of elites in a sn have extremely large influence fac-
tors  even after adding a complete graph on top of the sn  s
is a winning set 
countermeasure 2 
note that we consider the setting in
which initially a set of elites form a black coalition  and the
rest of nodes  or most of them  are white  hence intuitively
speaking  if most nodes become very reluctant to change their
proceedings of the thirtieth    ijcai-21 
352
 figure 1  the minimum size of a winning set of elite nodes whose
influence factor is r = 2x  while it is 1 for the rest of nodes   left  on
yt sn and hrg and pa with comparable parameters  and  right 
on fb sn and the graphs cm1 and cm2  corresponding to our
countermeasures applied to fb sn  cm1 is the union of fb sn
and a rrg with degree d = 2r ¯d  where ¯d is the average degree
of fb sn   cm2 denotes fb sn in which all nodes get assigned a
stubbornness factor γ = 1 − 1/2r 
color  i e   have a large stubbornness factor   one would ex-
pect most of the white nodes to keep their color unchanged 
we state this observation more formally in theorem 3  proven
in the full version of this paper 
theorem 3  consider a graph g =  v  e   let z ⊂ v
such that |z| < n/2 and dz v  ≤ fd v  for some f ∈  0  1 
and every v ∈ v \ z  consider the majority model where
all nodes in z have influence factor r ∈ n  if for each node
v ∈ v \ z the stubbornness factor γ v  >
r
r  1−f
f   then z is
not a winning set 
observe that the statement of theorem 3  in particular  is
true when z includes the nodes of highest degree and they all
have influence factor r  while it is 1 for the rest of nodes  
experiments of countermeasures 
the experimental re-
sults of both countermeasures applied to fb sn are depicted
in figure 1  right   which confirm their effectiveness   the
plots for other sns are given in the full version of the pa-
per  for instance  our experiments indicate that in fb sn an
elite set consisting of 0 4  of nodes with influence factor 16
form a winning set  but after applying countermeasure cm1
 adding a rrg  and cm2  assigning high stubbornness fac-
tor  an elite set of size 10  and 33   respectively  is required
to win  with the same influence factor 
3
random initial coloring
we experimentally investigate the majority and  ψ1  ψ2 -
majority model on various real world sns and random graph
models  where initially each node is black independently with
probability pb  we aim to determine the final fraction of black
nodes  i e   the number of black nodes in the final configura-
tion divided by the number of all nodes  for different values
of pb 
majority model with random coloring  our experimen-
tal results for the majority model on sd sn and several ran-
dom graph models with comparable parameters are depicted
in figure 2  left    the plots for other real world sns can
be found in the full version of the paper   we observe that
the majority model is a fair density classifier on er  rrg 
and pa  that is  for pb < 1/2  resp  pb > 1/2   the white
 resp  black  color takes over  this confirms some prior the-
oretical results  cf   zehmakan  2020   however for sd sn
and hrg  the white  resp  black  color might not take over
even when pb  resp  1−pb  is much smaller than 1/2  lastly 
we note that upon the addition of a rrg with the same aver-
age degree on top of sd sn  the aforementioned fair density
classification behavior emerges   see cm1 in figure 2  left  
uniform random coloring  in prior work  special atten-
tion has been devoted to the study of the majority model on
the erd˝os-r enyi random graph gn q for pb = 1/2  in par-
ticular   benjamini et al   2016  conjectured that if q is suffi-
ciently larger  resp  smaller  than 1/n  the process reaches an
almost monochromatic coloring  resp  an almost balanced
coloring  a a s 
in an almost monochromatic coloring  all
nodes share the same color  except a sub-linear number of
them  and in an almost balanced coloring the difference be-
tween the number of black and white nodes is sub-linear 
our experiments on gn q for n = 1000000 indicate that for
q ≥ 12/n  resp  q ≤ 8/n  the process reaches an almost
monochromatic coloring  resp  an almost balanced coloring  
hence  our results support the correctness of the conjecture 
 ψ1  ψ2 -majority model with random coloring 
we
prove that in the  ψ1  ψ2 -majority model on gn q a a s   for
q sufficiently larger than log n/n  which is the connectivity
threshold    i  the white color takes over if pb < 1 − ψ1
 ii  both colors will survive  i e   no color takes over  if
1 − ψ1 < pb < ψ2  iii  the black color takes over if ψ2 < pb 
the proof of this proposition can be found in the full version
of this paper  furthermore  we experimentally investigate the
 ψ1  ψ2 -majority model  for certain values of ψ1  ψ2  with a
random initial coloring on various real world sns and ran-
dom graph models with comparable parameters  our results
for tw sn and corresponding random graphs are depicted in
figure 2  right    similar plots are provided in the full ver-
sion of the paper for other real world sns   we observe that a
similar threshold behavior with two phase transitions is also
present in tw sn  pa  hrg  and rrg but the threshold val-
ues are different from 1 − ψ1 and ψ2 
4
stabilization time and period
stabilization in majority model  as discussed  prior work
has shown that the stabilization time and period of the ma-
jority model are bounded by o |e|  and 2  however  in the
random setting a poly-logarithmic bound on the expected sta-
bilization time is believed to exist  but only proven for a some
special classes of graphs   we provide evidence to support
this conjecture  firstly  we prove in theorem 4that the ex-
pected stabilization time of the majority model on a cycle cn
is at most log n  the proof of this theorem can be found in
the full version of the paper 
theorem 4  consider the majority model on a cycle cn  if
each node is initially black independently with probability pb 
then the process stabilizes in log n rounds a a s 
furthermore  we investigate the expected stabilization time
of the majority model on several real world sns and random
graph models  this is depicted for sd sn and random graphs
proceedings of the thirtieth    ijcai-21 
353
 figure 2  the final fraction of black nodes  left  in the majority
model with a random initial coloring for different values of pb on sd
sn  several random graphs with comparable parameters and cm1
 which corresponds to the union of sd sn and gn d for d = ¯d 
where ¯d is the average degree of sd sn    right  in the  ψ1  ψ2 -
majority model for ψ1 = 0 7 and ψ2 = 0 8 and different values of
pb on tw sn and random graphs pa  hrg and rrg with compa-
rable parameters 
with comparable parameters in figure 3  left    see the full
version of the paper for other sns   in our experiments on all
these graphs the process ends in less than 30 rounds  while
the number of edges is around m = 500000  thus  loosely
speaking  the expected stabilization time here seems to be
poly-logarithmic in m rather than linear  furthermore  we ob-
serve that adding a rrg on top of sd sn  similar to our first
countermeasure in section 2  speeds up the process  hence 
adding random edges not only helps the color with initial ma-
jority to win  but also makes this happen faster 
stabilization in  ψ1  ψ2 -majority model 
consider the
 ψ1  ψ2 -majority model  for ψ1 = ψ2  on a graph g =
 v  e  
building upon a potential function argument  we
prove in theorem 5 that the stabilization time and period of
the process are upper-bounded by 4m∗ and 2  respectively 
where m∗ denotes the number of bichromatic edges in the
initial coloring   recall that an edge is bichromatic if its end-
points have opposite colors   note that m∗ ≤ |e| and the  ψ 
ψ -majority model coincides with the majority model when
ψ is slightly larger than 1/2  thus  theorem 5  as a special
case  bounds the stabilization time of the majority model with
o |e|   previously proven by  poljak and turz ık  1986   the
main idea of our proof is to establish a relation between the
 ψ  ψ -majority model on g and a process called the periodic
majority model on a weighed graph h  which is constructed
from g  then  we argue that in this new process the summa-
tion of weights of bichromatic edges decreases in each round 
the proof is given in the full version of this paper 
theorem 5  consider the  ψ  ψ -majority model  for some
ψ ∈  1/2  1   on a graph g =  v  e   the stabilization
time is upper-bounded by 4m∗  where m∗ is the number of
bichromatic edges in the initial coloring  and the period is
always one or two 
furthermore  we experimentally analyze the expected sta-
bilization time of the  ψ1  ψ2 -majority model 
see fig-
ure 3  right  for our results on tw sn  and random graph
models with comparable parameters  and the full version of
this paper  for other real world sns  we observe that the ini-
figure 3  the expected stabilization time for different values of pb
in  left  the majority model on sd sn and random graphs with com-
parable parameters and cm1  which corresponds to the union of sd
sn and gn d for d = ¯d  where ¯d is the average degree of sd sn  
 right  the  ψ1  ψ2 -majority model  for ψ1 = 0 7 and ψ2 = 0 8 
on tw sn and pa  hrg and rrg with comparable parameters 
tial probabilities pb for which the process takes the longest
to stabilize  are identical to the empirically observed thresh-
old values depicted in figure 2  right   we note that this is
also the case in the majority model  as the stabilization time
peaks at pb = 1/2  visible in figure 3  left    at which also
the phase transition occurs  visible in figure 2  left   
5
conclusion
we showed that in the real world social networks  an ex-
tremely small set of high-degree nodes  i e   elites  can de-
termine the output of an opinion forming process  we de-
veloped two countermeasures which can be applied to over-
power such a small set of elite nodes  in general  motivated
from the study of effective marketing strategies  the problem
of finding a small set of agents whose opinion governs the fi-
nal dominant opinion has been extensively studied for various
models  however  the current understanding of the develop-
ment of countermeasure mechanisms to subdue such a small
group with disproportionate influencing power is limited  we
aspire this work to be a starting point for further investigation
of effective countermeasures for a large spectrum of models 
furthermore  we proved that the  ψ1  ψ2 -majority model
exhibits a threshold behavior with two phase transitions at
1 − ψ1 and ψ2 when the underlying graph is a dense erd˝os-
r enyi random graph  our experiments suggest that a similar
threshold behavior might exist for other classes of graphs  but
the threshold values are different from 1−ψ1 and ψ2  it would
be interesting to determine these values in the future work 
in addition  we provided several experimental and theoret-
ical evidence to support the widely believed conjecture of a
poly-logarithmic upper bound on the expected stabilization
time of the majority model  however  it remains open in its
full generality  for the  ψ1  ψ2 -majority model  for ψ1 = ψ2 
we proved that the stabilization time is bounded by 4 times
the number of bichromatic edges in the initial coloring  we
believe this can be an important milestone to settle the conjec-
ture  specifically  if one can prove that from a random color-
ing the process reaches a coloring with poly-logarithmically
many bichromatic edges in a poly-logarithmic number of
rounds in expectation  then our result yields the conjecture 
proceedings of the thirtieth    ijcai-21 
354
 references
 anagnostopoulos et al   2020  aris anagnostopoulos  luca
becchetti  emilio cruciani  francesco pasquale  and sara
rizzo  biased opinion dynamics  when the devil is in the
details  ijcai  pages 53–59  2020 
 auletta et al   2015  vincenzo auletta  ioannis caragiannis 
diodato ferraioli  clemente galdi  and giuseppe per-
siano 
minority becomes majority in social networks 
wine  pages 74–88  2015 
 auletta et al   2017  vincenzo auletta  ioannis caragiannis 
diodato ferraioli  clemente galdi  and giuseppe per-
siano  information retention in heterogeneous majority dy-
namics  wine  pages 30–43  2017 
 auletta et al   2018  vincenzo auletta  diodato ferraioli 
and gianluigi greco  reasoning about consensus when
opinions diffuse through majority dynamics 
in ijcai 
pages 49–55  2018 
 avin et al   2017  chen avin  zvi lotker  david peleg 
yvonne-anne pignolet  and itzik turkel  elites in social
networks  an axiomatic approach  netscix  pages 75–87 
2017 
 avin et al   2019  chen avin  zvi lotker  assaf mizrachi 
and david peleg  majority vote and monopolies in social
networks  icdcn  pages 342–351  2019 
 balister et al   2010  paul balister  b ela bollob as  j robert
johnson  and mark walters  random majority percolation 
random structures   algorithms  36 3  315–340  2010 
 barab asi and albert  1999  albert-l aszl o
barab asi
and
r eka albert  emergence of scaling in random networks 
science  286 5439  509–512  1999 
 benjamini et al   2016  itai benjamini  siu-on chan  ryan
o donnell  omer tamuz  and li-yang tan  convergence 
unanimity and disagreement in majority dynamics on uni-
modular graphs and random graphs  stochastic processes
and their applications  126 9  2719–2733  2016 
 berger  2001  eli berger  dynamic monopolies of constant
size  journal of combinatorial theory  series b  pages
191–200  2001 
 brill et al   2016  markus brill  edith elkind  ulle endriss 
umberto grandi  et al  pairwise diffusion of preference
rankings in social networks  ijcai  pages 130–136  2016 
 chistikov et al   2020  dmitry
chistikov 
grzegorz
lisowski  mike paterson  and paolo turrini 
con-
vergence of opinion diffusion is pspace-complete  aaai 
pages 7103–7110  2020 
 faliszewski et al   2018  piotr faliszewski  rica gonen 
martin kouteck y  and nimrod talmon  opinion diffusion
and campaigning on society graphs  ijcai  pages 219–
225  2018 
 ferraioli and ventre  2017  diodato ferraioli and carmine
ventre  social pressure in opinion games  ijcai  2017 
 fountoulakis et al   2020  nikolaos fountoulakis  mihyun
kang  and tam as makai  resolution of a conjecture on
majority dynamics  rapid stabilization in dense random
graphs 
random structures   algorithms  57 4  1134–
1156  2020 
 friedman  2003  joel friedman  a proof of alon s second
eigenvalue conjecture  stoc  pages 720–724  2003 
 frischknecht et al   2013  silvio
frischknecht 
barbara
keller  and roger wattenhofer  convergence in  social 
influence networks  disc  pages 433–446  2013 
 goles and olivos  1980  e  goles and j  olivos  periodic
behaviour of generalized threshold functions 
discrete
mathematics  30 2  187 – 189  1980 
 hagberg et al   2008  aric hagberg 
pieter swart 
and
daniel s chult  exploring network structure  dynamics 
and function using networkx  technical report  2008 
 keller et al   2014  barbara keller  david peleg  and roger
wattenhofer  how even tiny influence can have a big im-
pact  fun  pages 252–263  2014 
 krioukov et al   2010  dmitri krioukov 
fragkiskos pa-
padopoulos  maksim kitsak  amin vahdat  and mari an
bogun a 
hyperbolic geometry of complex networks 
physical review e  82 3  036106  2010 
 leskovec and krevl  2014  jure
leskovec
and
andrej
krevl 
snap datasets  stanford large network dataset
collection  http //snap stanford edu/data  june 2014 
 mislove et al   2007  alan mislove  massimiliano marcon 
krishna p  gummadi  peter druschel  and bobby bhat-
tacharjee 
measurement and analysis of online social
networks  imc  2007 
 mossel et al   2013  elchanan mossel  joe neeman  and
omer tamuz  majority dynamics and aggregation of infor-
mation in social networks  autonomous agents and multi-
agent systems  28 3  408–429  2013 
 poljak and turz ık  1986  svatopluk
poljak
and
daniel
turz ık 
on pre-periods of discrete influence systems 
discrete applied mathematics  13 1  33–39  1986 
 schoenebeck and yu  2018  grant schoenebeck and fang-
yi yu  consensus of interacting particle systems on erd¨os-
r enyi graphs  soda  pages 1945–1964  2018 
 staudt et al   2015  christian l  staudt  aleksejs sazonovs 
and henning meyerhenke 
networkit  a tool suite for
large-scale complex network analysis  2015 
 steger and wormald  1999  angelika
steger
and
nicholas c wormald  generating random regular graphs
quickly 
combinatorics  probability and computing 
8 04  377–396  1999 
 viswanath et al   2009  bimal viswanath  alan mislove 
meeyoung cha  and krishna p  gummadi  on the evo-
lution of user interaction in facebook  wosn  2009 
 zehmakan  2020  ahad n  zehmakan  opinion forming in
erd˝os–r enyi random graph and expanders  discrete ap-
plied mathematics  277 280 – 290  2020 
proceedings of the thirtieth    ijcai-21 
355
 "
None,2021,https-www-ijcai-org-proceedings-2021-0050-pdf,Mean Field Games Flock! The Reinforcement Learning Way,"Sarah Perrin, Mathieu Laurière, Julien Pérolat, Matthieu Geist, Romuald Élie, Olivier Pietquin",None,https://www.ijcai.org/proceedings/2021/0050.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0050-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0050-pdf.pdf,"mean field games flock  the reinforcement learning way
sarah perrin1   mathieu lauri ere2   julien p erolat3   matthieu geist4   romuald
 elie3 and olivier pietquin4
1univ  lille  cnrs  inria  centrale lille  umr 9189 cristal
2princeton university  orfe
3deepmind paris
4google research  brain team
sarah perrin@inria fr  lauriere@princeton edu   perolat  mfgeist  relie  pietquin @google com 
abstract
we present a method enabling a large number of
agents to learn how to flock 
this problem has
drawn a lot of interest but requires many structural
assumptions and is tractable only in small dimen-
sions 
we phrase this problem as a mean field
game  mfg   where each individual chooses its
own acceleration depending on the population be-
havior 
combining deep reinforcement learn-
ing  rl  and normalizing flows  nf   we obtain
a tractable solution requiring only very weak as-
sumptions  our algorithm finds a nash equilibrium
and the agents adapt their velocity to match the
neighboring flock s average one  we use fictitious
play and alternate   1  computing an approximate
best response with deep rl  and  2  estimating the
next population distribution with nf  we show nu-
merically that our algorithm can learn multi-group
or high-dimensional flocking with obstacles 
1
introduction
the term flocking describes the behavior of large populations
of birds that fly in compact groups with similar velocities 
often exhibiting elegant motion patterns in the sky  such be-
havior is pervasive in the animal realm  from fish to birds 
bees or ants  this intriguing property has been widely stud-
ied in the scientific literature  shaw  1975  reynolds  1987 
and its modeling finds applications in psychology  animation 
social science  or swarm robotics  one of the most popu-
lar approaches to model flocking was proposed in  cucker
and smale  2007  and allows predicting the evolution of each
agent s velocity from the speeds of its neighbors 
to go beyond pure description of population behaviours
and emphasize on the decentralized aspect of the underlying
decision making process  this model has been revisited to in-
tegrate an optimal control perspective  see e g   caponigro et
al   2013  bailo et al   2018   each agent controls its velocity
and hence its position by dynamically adapting its accelera-
tion so as to maximize a reward that depends on the others 
behavior  an important question is a proper understanding
of the nature of the equilibrium reached by the population
of agents  emphasizing how a consensus can be reached in a
group without centralized decisions  such question is often
studied using the notion of nash equilibrium and becomes
extremely complex when the number of agents grows 
a way to approximate nash equilibria in large games is to
study the limit case of an continuum of identical agents  in
which the local effect of each agent becomes negligible  this
is the basis of the mean field games  mfgs  paradigm intro-
duced in  lasry and lions  2007   mfgs have found numer-
ous applications from economics to energy production and
engineering  a canonical example is crowd motion modeling
in which pedestrians want to move while avoiding congestion
effects  in flocking  the purpose is different since the agents
intend to remain together as a group  but the mean-field ap-
proximation can still be used to mitigate the complexity 
however  finding an equilibrium in mfgs is computa-
tionally intractable when the state space exceeds a few di-
mensions  in traditional flocking models  each agent s state
is described by a position and a velocity  while the con-
trol is the acceleration  in terms of computational cost  this
typically rules out state-of-the-art numerical techniques for
mfgs based on finite difference schemes for partial differen-
tial equations  pdes   achdou and capuzzo-dolcetta  2010  
in addition  pdes are in general hard to solve when the ge-
ometry is complex and require full knowledge of the model 
for these reasons  reinforcement learning  rl  to learn
control strategies for mfgs has recently gained in popular-
ity  guo et al   2019  elie et al   2020  perrin et al   2020  
combined with deep neural nets  rl has been used success-
fully to tackle problems which are too complex to be solved
by exact methods  silver et al   2018  or to address learn-
ing in multi-agent systems  lanctot et al   2017   particu-
larly relevant in our context  are works providing techniques
to compute an optimal policy  haarnoja et al   2018  lilli-
crap et al   2016  and methods to approximate probability dis-
tributions in high dimension  rezende and mohamed  2015 
kobyzev et al   2020  
our main contributions are   1  we cast the flocking prob-
lem into a mfg and propose variations which allow multi-
group flocking as well as flocking in high dimension with
complex topologies   2  we introduce the flock n rl algo-
rithm that builds upon the fictitious play paradigm and in-
volves deep neural networks and rl to solve the model-free
flocking mfg  and  3  we illustrate our approach on several
numerical examples and evaluate the solution with approxi-
proceedings of the thirtieth    ijcai-21 
356
 mate performance matrix and exploitability 
2
background
three main formalisms will be combined  flocking  mean
field games  mfg   reinforcement learning  rl   ez
stands for the expectation w r t  the random variable z 
2 1
the model of flocking
to model a flocking behaviour  we consider the following
system of n agents derived in a discrete time setting in
 nourian et al   2011  from cucker-smale flocking modeling 
each agent i has a position and a velocity  each in dimension
d and denoted respectively by xi and vi  we assume that it
can control its velocity by choosing the acceleration  denoted
by ui  the dynamics of agent i ∈  1          n  is 
xi
t 1 = xi
t   vi
t∆t 
vi
t 1 = vi
t   ui
t∆t   ϵi
t 1 
where ∆t is the time step and ϵi
t is a random variable playing
the role of a random disturbance  we assume that each agent
is optimizing for a flocking criterion f that is underlying to
the flocking behaviour  for agent i at time t  f is of the form 
f i
t = f xi
t  vi
t  ui
t  µn
t   
 1 
where the interactions with other agents are only through
the empirical distribution of states and velocities denoted by 
µn
t = 1
n
�n
j=1 δ xj
t vj
t   
we focus on criteria incorporating a term of the form 
f flock
β
 x  v  u  µ  = -
����
�
r2d
 v − v′ 
 1   ∥x − x′∥2 β dµ x′  v′ 
����
2
   2 
where β ≥ 0 is a parameter and  x  v  u  µ  ∈ rd×rd×rd×
p rd × rd   with p e  denoting the set of probability mea-
sures on a set e  this criterion incentivises agents to align
their velocities  especially if they are close to each other  note
that β parameterizes the level of interactions between agents
and strongly impacts the flocking behavior  if β = 0  each
agent tries to align its velocity with all the other agents of the
population irrespective of their positions  whereas the larger
β > 0  the more importance is given to its closest neighbors
 in terms of position  
in the n-agent case  for agent i  it becomes 
f flock i
β t
= −
������
1
n
n
�
j=1
 vi
t − vj
t  
 1   ∥xi
t − xj
t∥2 β
������
2
 
 3 
the actual criterion will typically include other terms  for in-
stance to discourage agents from using a very large accelera-
tion  or to encourage them to be close to a specific position 
we provide such examples in sec  4 
since the agents may be considered as selfish  they try to
maximize their own criterion  and may have conflicting goals
 e g  different desired velocities   we consider nash equi-
librium as a notion of solution to this problem and the in-
dividual criterion can be seen as the payoff for each agent 
the total payoff of agent i given the other agents  strate-
gies u−i =  u1          ui−1  ui 1          un  is  f i
u−i ui  =
exi
t vi
t
� �
t≥0 γtf i
t
�
  with f i
t defined eq   1   in this context 
a nash equilibrium is a strategy profile  ˆu1  ˆu2          ˆun  such
that there s no profitable unilateral deviation  i e   for every
i = 1          n  for every control ui  f i
ˆu−i ˆui  ≥ f i
ˆu−i ui  
2 2
mean field games
an mfg describes a game for a continuum of identical agents
and is fully characterized by the dynamics and the payoff
function of a representative agent  more precisely  denoting
by µt the state distribution of the population  and by ξt ∈ rℓ
and αt ∈ rk the state and the control of an infinitesimal
agent  the dynamics of the infinitesimal agent is given by
ξt 1 = ξt   b ξt  αt  µt    σϵt 1 
 4 
where b   rℓ × rk × p rℓ  → rℓ is a drift  or transition 
function  σ is a ℓ × ℓ matrix and ϵt 1 is a noise term taking
values in rℓ  we assume that the sequence of noises  ϵt t≥0
is i i d   e g  gaussian   the objective of each infinitesi-
mal agent is to maximize its total expected payoff  defined
given a flow of distributions µ =  µt t≥0 and a strategy α
 i e   a stochastic process adapted to the filtration generated by
 ϵt t≥0  as  jµ α  = eξt αt
� �
t≥0 γtϕ ξt  αt  µt 
�
  where
γ ∈  0  1  is a discount factor and ϕ   rℓ×rk×p rℓ  → rℓ
is an instantaneous payoff function  since this payoff de-
pends on the population s state distribution  and since the
other agents would also aim to maximize their payoff  a nat-
ural approach is to generalize the notion of nash equilibrium
to this framework  a mean field  nash  equilibrium is de-
fined as a pair  ˆµ  ˆα  =  ˆµt  ˆαt t≥0 of a flow of distributions
and strategies such that the following two conditions are sat-
isfied  ˆα is a best response against ˆµ  optimality  and ˆµ is the
distribution generated by ˆα  consistency   i e  
1  ˆα maximizes α �→ jˆµ α  
2  for every t ≥ 0  ˆµt is the distribution of ξt when it fol-
lows the dynamics  4  with  αt  µt  replaced by  ˆαt  ˆµt  
finding a mean field equilibrium thus amounts to finding a
fixed point in the space of  flows of  probability distributions 
the existence of equilibria can be proven through classical
fixed point theorems  carmona and delarue  2018   in most
mean field games considered in the literature  the equilib-
rium is unique  which can be proved using either a strict con-
traction argument or the so-called lasry-lions monotonic-
ity condition  lasry and lions  2007   computing solutions
to mfgs is a challenging task  even when the state is in
small dimension  due to the coupling between the optimal-
ity and the consistency conditions  this coupling typically
implies that one needs to solve a forward-backward system
where the forward equation describes the evolution of the
distribution and the backward equation characterizes the op-
timal control  one can not be solved prior to the other one 
which leads to numerical difficulties  the basic approach 
which consists in iteratively solving each equation  works
only in very restrictive settings and is otherwise subject to
cycles  a method which does not suffer from this limitation
is fictitious play  summarized in alg  1  it consists in com-
puting the best response against a weighted average of past
proceedings of the thirtieth    ijcai-21 
357
 algorithm 1  generic fictitious play in mfgs
input   mfg =  ξ  ϕ  µ0   # of iterations j  
1 define ¯µ0 = µ0 for j = 1          j do
2
1  set best response αj = arg maxα j¯µj−1 α  and
let ¯αj be the average of  αi i=0     j
3
2  set µj = γ-stationary distribution induced by αj
4
3  set ¯µj = j−1
j ¯µj−1   1
j µj
5 return ¯αj  ¯µj
distributions instead of just the last distribution  this algo-
rithm has been shown to converge for more general mfgs 
state-of-the-art numerical methods for mfgs based on par-
tial differential equations can solve such problems with a high
precision when the state is in small dimension and the ge-
ometry is elementary  achdou and capuzzo-dolcetta  2010 
carlini and silva  2014   more recently  numerical methods
based on machine learning tools have been developed  car-
mona and lauri ere  2019  ruthotto et al   2020   these tech-
niques rely on the full knowledge of the model and are re-
stricted to classes of quite simple mfgs 
2 3
reinforcement learning
the reinforcement learning  rl  paradigm is the machine
learning answer to the optimal control problem  it aims at
learning an optimal policy for an agent that interacts in an
environment composed of states  by performing actions  for-
mally  the problem is framed under the markov decision pro-
cesses  mdp  framework  an mdp is a tuple  s  a  p  r  γ 
where s is a state space  a is an action space  p   s × a →
p s  is a transition kernel  r   s × a → r is a reward
function and γ is a discount factor  see eq   5    using ac-
tion a when the current state is s leads to a new state dis-
tributed according to p s  a  and produces a reward r s  a  
a policy π   s → p a   s �→ π ·|s  provides a distribu-
tion over actions for each state  rl aims at learning a policy
π∗ which maximizes the total return defined as the expected
 discounted  sum of future rewards 
r π  = eat st 1
� �
t≥0
γtr st  at 
�
 
 5 
with at ∼ π ·|st  and st 1 ∼ p ·|st  at   note that if the
dynamics  p and r  is known to the agent  the problem can
be solved using e g  dynamic programming  most of the
time  these quantities are unknown and rl is required  a
plethora of algorithms exist to address the rl problem  yet 
we need to focus on methods that allow continuous action
spaces as we want to control accelerations  one category of
such algorithms is based on the policy gradient  pg  theo-
rem  sutton et al   1999  and makes use of the gradient as-
cent principle  π ← π   α ∂r π 
∂π   where α is a learning
rate  yet  pg methods are known to be high-variance be-
cause they use monte carlo rollouts to estimate the gradi-
ent  a vast literature thus addresses the variance reduction
problem  most of the time  it involves an hybrid architecture 
namely actor-critic  which relies on both a representation
of the policy and of the so-called state-action value function
 s  a  �→ qπ s  a   qπ s  a  is the total return conditioned on
starting in state s and using action a before using policy π for
subsequent time steps  it can be estimated by bootstrapping 
using the markov property  through the bellman equations 
most recent implementations rely on deep neural networks to
approximate π and q  e g   haarnoja et al   2018   
3
our approach
in this section  we put together the pieces of the puzzle to
numerically solve the flocking model  based on a mean-field
approximation  we first recast the flocking model as an mfg
with decentralized decision making  for which we propose a
numerical method relying on rl and deep neural networks 
3 1
flocking as an mfg
mean field limit 
we go back to the model of flocking
introduced in sec  2 1  when the number of agents grows to
infinity  the empirical distribution µn
t is expected to converge
towards the law µt of  xt  vt   which represents the position
and velocity of an infinitesimal agent and have dynamics 
xt 1 = xt   vt∆t 
vt 1 = vt   ut∆t   ϵt 1 
this problem can be viewed as an instance of the mfg frame-
work discussed in sec  2 2  by taking the state to be the
position-velocity pair and the action to be the acceleration 
i e   the dimensions are ℓ = 2d  k = d  and ξ =  x  v   α = u 
to accommodate for the degeneracy of the noise as only the
velocities are disturbed  we take σ =
�
0d
0d
0d
1d
�
where 1d is
the d-dimensional identity matrix 
the counterpart of the notion of n-agent nash equilib-
rium is an mfg equilibrium as described in sec  2 2  we
focus here on equilibria which are stationary in time 
in
other words  the goal is to find a pair  ˆµ  ˆu  where ˆµ ∈
p rℓ × rℓ  is a position-velocity distribution and ˆu   rℓ ×
rℓ �→ rℓ is a feedback function to determine the accel-
eration given the position and velocity  such that   1  ˆµ is
an invariant position-velocity distribution if the whole pop-
ulation uses the acceleration given by ˆu  and  2  ˆu maxi-
mizes the rewards when the agent s initial position-velocity
distribution is ˆµ and the population distribution is ˆµ at ev-
ery time step  in mathematical terms  ˆu maximizes jˆµ u  =
ext vt ut
� �
t≥0 γtϕ xt  vt  ut  ˆµ 
�
  where  xt  vt t≥0 is the
trajectory of an infinitesimal agent who starts with distribu-
tion ˆµ at time t = 0 and is controlled by the acceleration
 ut t≥0  as the payoff function ϕ we use f flock
β
from eq   2  
moreover  the consistency condition rewrites as  ˆµ is the sta-
tionary distribution of  xt  vt t≥0 if controlled by  ˆut t≥0 
theoretical analysis 
the analysis of mfg with flocking
effects is challenging due to the unusual structure of the dy-
namics and the payoff  which encourages gathering of the
population  this is running counter to the classical lasry-
lions monotonicity condition  lasry and lions  2007   which
typically penalizes the agents for being too close to each
other  however  existence and uniqueness have been proved
in some cases  if β = 0  every agent has the same influence
over the representative agent and it is possible to show that
proceedings of the thirtieth    ijcai-21 
358
 algorithm 2  flock n rl
input   mfg =   x  v   f flock
β
  µ0   # of iterations j
1 define ¯µ0 = µ0 for j = 1          j do
2
1  set best response πj = arg max
π
j¯µj−1 π  with
sac and let ¯πj be the average of  π0          πj 
3
2  using a normalizing flow  compute µj =
γ-stationary distribution induced by πj
4
3  using a normalizing flow and samples from
 µ0          µj−1   estimate ¯µj
5 return ¯πj  ¯µj
the problem reduces to a linear-quadratic setting  th 2 in
 nourian et al   2011  shows that a mean-consensus in ve-
locity is reached asymptotically with individual asymptotic
variance σ2
2   if β > 0   nourian et al   2011  shows that if the
mf problem admits a unique solution  then there exists an ϵn
nash equilibrium for the n agents problem and
lim
n→ ∞ ϵn =
0  existence has also been proved when β > 0 in  carmona
and delarue  2018  section 4 7 3   with a slight modification
of the payoff  namely considering  with ϕ a bounded func-
tion  rt = −ϕ
����
�
r2d
 vt−v′ 
 1 ∥xt−x′∥2 
β µt dx′  dv′ 
���
2�
 
3 2
the flock n rl algorithm
we propose flock n rl  a deep rl version of the fictitious
play algorithm for mfgs  elie et al   2020  adapted to flock-
ing  we consider a γ-discounted setting with continuous state
and action spaces and we adapt alg  2 from its original tab-
ular formulation  perrin et al   2020   it alternates 3 steps 
 1  estimation of a best response  using deep rl  against the
mean distribution ¯µj−1  which is fixed during the process   2 
estimation  with normalizing flows  kobyzev et al   2020  
of the new induced distribution from trajectories generated by
the previous policy  and  3  update of the mean distribution
¯µj 
computing the best response with sac
the first step in the loop of alg  2 is the computation of a
best response against ¯µj  in fact  the problem boils down to
solving an mdp in which ¯µj enters as a parameter  following
the notation introduced in sec  2 3  we take the state and ac-
tion spaces to be respectively s = r2d  for position-velocity
pairs  and a = rd  for accelerations   letting s =  x  v 
and a = u  the reward is   x  v  u  =  s  a  �→ r s  a  =
f x  v  u  ¯µj   which depends on the given distribution ¯µj 
remember that r is the reward function of the mdp while f
is the optimization criterion in the flocking model 
as we set ourselves in continuous state and action spaces
and in possibly high dimensions  we need an algorithm that
scales  we choose to use soft actor critic  sac   haarnoja
et al   2018   an off-policy actor-critic deep rl algorithm
using entropy regularization  sac is trained to maximize a
trade-off between expected return and entropy  which allows
to keep enough exploration during the training  it is designed
to work on continuous action spaces  which makes it suited
for acceleration controlled problems such as flocking 
the best response is computed against ¯µj  the fixed aver-
age distribution at step j of flock n rl  sac maximizes the
reward which is a variant of f flock i
β t
from eq   3   it needs
samples from ¯µj in order to compute the positions and ve-
locities of the fixed population  note that  in order to mea-
sure more easily the progress during the learning at step j 
we sample n agents from ¯µj at the beginning of step 1  i e 
we do not sample new agents from ¯µj every time we need to
compute the reward   during the learning  at the beginning of
each episode  we sample a starting state s0 ∼ ¯µj 
in the experiments  we will not need ¯πj but only the as-
sociated reward  see the exploitability metric in sec  4   to
this end  it is enough to keep in memory the past policies
 π0          πj  and simply average the induced rewards 
normalizing flow for distribution embedding
we choose to represent the different distributions using a gen-
erative model because the continuous state space prevents us
from using a tabular representation  furthermore  even if we
could choose to discretize the state space  we would need a
huge amount of data points to estimate the distribution using
methods such as kernel density estimators  in dimension 6
 which is the dimension of our state space with 3-dimensional
positions and velocities   such methods already suffer from
the curse of dimensionality 
thus  we choose to estimate the second step of alg  2 us-
ing a normalizing flow  nf   rezende and mohamed  2015 
kobyzev et al   2020   which is a type of generative model 
different from generative adversarial networks  gan  or
variational autoencoders  vae   a flow-based generative
model is constructed by a sequence of invertible transforma-
tions and allows efficient sampling and distribution approxi-
mation  unlike gans and vaes  the model explicitly learns
the data distribution and therefore the loss function simply
identifies to the negative log-likelihood  an nf transforms a
simple distribution  e g  gaussian  into a complex one by ap-
plying a sequence of invertible transformations  in particular 
a single transformation function f of noise z can be written
as x = f z  where z ∼ h z   here  h z  is the noise distri-
bution and will often be in practice a normal distribution 
using the change of variable theorem  the probability
density of x under the flow can be written as  p x  =
h f −1 x  
���det
�
∂f −1
∂x
����   we thus obtain the probability dis-
tribution of the final target variable  in practice  the trans-
formations f and f −1 can be approximated by neural net-
works  thus  given a dataset of observations  in our case
rollouts from the current best response   the flow is trained
by maximizing the total log likelihood �
n log p x n   
computation of ¯µj
due to the above discussion on the difficulty to represent the
distribution in continuous space and high dimension  the third
step  line 4 of alg  2  can not be implemented easily  we
represent every µj as a generative model  so we can not  av-
erage  the normalizing flows corresponding to  µi i=1     j in
a straightforward way but we can sample data points x ∼ µi
for each i = 1          j  to have access to ¯µj  we keep in mem-
ory every model µj  j ∈  1          j  and  in order to sam-
ple points according to ¯µj for a fixed j  we sample points
proceedings of the thirtieth    ijcai-21 
359
 from µi  i ∈  1          j   with probability 1/j  these points
are then used to learn the distribution ¯µj with an nf  as it is
needed both for the reward and to sample the starting state of
an agent during the process of learning a best response policy 
4
experiments
environment 
we implemented the environment as a cus-
tom openai gym environment to benefit from the power-
ful gym framework and use the algorithms available in sta-
ble baselines  hill et al   2018   we define a state s ∈ s
as s =  x  v  where x and v are respectively the vectors
of positions and velocities  each coordinate xi of the posi-
tion can take any continuous value in the d-dimensional box
xi ∈  −100   100   while the velocities are also continuous
and clipped vi ∈  −1  1   the state space for the positions is a
torus  meaning that an agent reaching the box limit reappears
at the other side of the box  we chose this setting to allow the
agents to perfectly align their velocities  except for the effect
of the noise   as we look for a stationary solution 
at the beginning of each iteration j of fictitious play  we
initialize a new gym environment with the current mean dis-
tribution ¯µj  in order to compute the best response 
model - normalizing flows 
to model distributions  we
use neural spline flows  nsf  with a coupling layer  durkan
et al   2019   more details about how coupling layers and
nsf work can be found in the appendix 
model
-
sac 
to
compute
the
best
response
at
each flock n rl iteration 
we use soft actor critic
 sac   haarnoja et al   2018   but other pg algorithms would
work   sac is an off-policy algorithm which  as mentioned
above  uses the key idea of regularization  instead of con-
sidering the objective to simply be the sum of rewards  an
entropy term is added to encourage sufficient randomization
of the policy and thus address the exploration-exploitation
trade-off 
to be specific  in our setting  given a popula-
tion distribution µ  the objective is to maximize  jµ π  =
e st ut 
�� ∞
t=0 γtr xt  vt  ut  µt    δh π ·|st  
�
  where h
denotes the entropy and δ ≥ 0 is a weight 
to implement the optimization  the sac algorithm follows
the philosophy of actor-critic by training parameterized q-
function and policy  to help convergence  the authors of sac
also train a parameterized value function v   in practice  the
three functions are often approximated by neural networks 
in comparison to other successful methods such as trust
region policy optimization  trpo   schulman et al   2015 
or asynchronous actor-critic agents  a3c   sac is ex-
pected to be more efficient in terms of number of samples re-
quired to learn the policy thanks to the use of a replay buffer
in the spirit of methods such as deep deterministic policy
gradient  ddpg   lillicrap et al   2016  
metrics 
an issue with studying our flocking model is
the absence of a gold standard  especially  we can not com-
pute the exact exploitability  perrin et al   2020  of a pol-
icy against a given distribution since we can not compute
the exact best response 
the exploitability measures how
much an agent can gain by replacing its policy π with a
best response π′  when the rest of the population plays π 
φ π   = max
π′ j µ0  π′  µπ  − j µ0  π  µπ   if φ ¯πj  → 0
as j increases  fp approaches a nash equilibrium  to cope
with these issues  we introduce the following ways to mea-
sure progress of the algorithm 
• performance matrix 
we build the matrix m of per-
formance of learned policies versus estimated distri-
butions 
the entry mi j on the i-th row and the j-
th column is the total γ-discounted sum of rewards 
mi j = e
��t
t=0 γtrt i | s0 ∼ ¯µi−1  ut ∼ πj  |st 
�
 
where rt i = r st  ut  ¯µi−1   obtained with πj against
¯µi−1  the diagonal term mj j corresponds to the value
of the best response computed at iteration j 
• approximate exploitability 
we do not have access to
the exact best response due to the model-free approach
and the continuous spaces  however  we can approxi-
mate the first term of φ ¯π  directly in the flock n rl al-
gorithm with sac  the second term  j µ0  ¯π  µ¯π   can
be approximated by replacing ¯π with the average over
past policies  i e   the policy sampled uniformly from the
set  π0          πj   at step j  the approximate exploitabil-
ity is ej = mj j −
1
j−1
�j−1
k=1 mj k  to smoothen the
exploitability  we take the best response over the last 5
policies and use a moving average over 10 points  please
note that only relative values are important as it depends
on the scale of the reward 
a 4-dimensional example 
we illustrate in a four dimen-
sional setting  i e  two-dimensional positions and velocities 
how the agents learn to adopt similar velocities by controlling
their acceleration  we focus on the role of β in the flocking
effect  we consider noise ϵi
t ∼ n 0  ∆t  and the following
reward  ri
t = f flock i
β t
− ∥ui
t∥2
2   ∥vi
t∥∞ − min ∥xi
2 t ± 50∥  
where xi
2 t stands for the second coordinate of the i-th agent s
position at time t  the last term attracts the agents  positions
towards one of two lines corresponding to the second coordi-
nate of x being either −50 or  50  we added a term regard-
ing the norm of the velocity to prevent agents from stopping 
here we take ∥vi
t∥∞ = max |vi
1 t|  |vi
2 t|   hence  a possible
equilibrium is with two groups of agents  one for each line 
when β = 0  the term f flock i
β t
encourages agent i to have the
same velocity vector as the rest of the whole population  at
equilibrium  the agents in the two groups should thus move in
the same direction  to the left or to the right  in order to stay
on the two lines of x s   on the other hand  when β > 0 is
large enough  e g  β = 100   agent i gives more importance
to its neighbors when choosing its control and it tries to have
a velocity similar to the agents that are position-wise close to 
this allows the emergence of two groups moving in different
directions  one group moves towards the left  overall negative
velocity  and the other group moves towards the right  overall
positive velocity  
this is confirmed by fig  1  in the experiment  we set the
initial velocities perpendicular to the desired ones to illustrate
the robustness of the algorithm  we observe that the approxi-
mate exploitability globally decreases  in the case β = 0  we
experimentally verified that there is always a global consen-
proceedings of the thirtieth    ijcai-21 
360
  a  initial positions and velocities
 b  at convergence
 c  performance matrix
 d  approximate exploitability
figure 1  multi-group flocking with noise and β = 100 
sus  i e   only one line or two lines but moving in the same
direction 
scaling to 6 dimensions and non-smooth topology 
we
now present an example with arbitrary obstacles  and thus
non-smooth topology  in dimension 6  position and velocity
in dimension 3  which would be very hard to address with
classical numerical methods  in this setting  we have multi-
ple columns that the agents are trying to avoid  the reward
has the following form  ri
t = f flock i
β t
− ∥ui
t∥2
2   ∥vi
t∥∞ −
min ∥xi
2 t∥  − c ∗ 1obs  if an agent hits an obstacle  it gets
a negative reward and bounces on it like a snooker ball  af-
ter a few iterations  the agents finally find their way through
the obstacles  this situation can model birds trying to fly in
a city with tall buildings  in our experiments  we noticed that
different random seeds lead to different solutions  this is not
surprising as there are a lot of paths that the agents can take to
avoid the obstacles and still maximizing the reward function 
the exploitability decreases quicker than in the previous ex-
periment  we believe that this is because agents find a way
through the obstacles in the first iterations 
5
related work
numerical methods for flocking models 
most work us-
ing flocking models focus on the dynamical aspect without
optimization  to the best of our knowledge  the only existing
numerical approach to tackle a mfg with flocking effects is
in  carmona and delarue  2018  section 4 7 3   but it is re-
stricted to a very special and simpler type of rewards 
learning in mfgs 
mfgs have attracted a surge of inter-
est in the rl community as a possible way to remediate the
scalability issues encountered in marl when the number of
agents is large  perolat et al   2018    guo et al   2019  com-
 a  initial positions and velocities
 b  at convergence
 c  performance matrix
 d  approximate exploitability
figure 2  flocking with noise and many obstacles 
bined a fixed-point method with q-learning  but the conver-
gence is ensured only under very restrictive lipschitz condi-
tions and the method can be applied efficiently only to finite-
state models   subramanian and mahajan  2019  solve mfg
using a gradient-type approach 
the idea of using fp in
mfgs has been introduced in  cardaliaguet and hadikhan-
loo  2017   assuming the agent can compute perfectly the best
response   elie et al   2020  perrin et al   2020  combined fp
with rl methods  however  the numerical techniques used
therein do not scale to higher dimensions 
6
conclusion
in this work we introduced flock n rl  a new numerical
approach which allows solving mfgs with flocking effects
where the agents reach a consensus in a decentralized fash-
ion  flock n rl combines fictitious play with deep neural
networks and reinforcement learning techniques  normaliz-
ing flows and soft actor-critic   we illustrated the method on
challenging examples  for which no solution was previously
known  in the absence of existing benchmark  we demon-
strated the success of the method using a new kind of ap-
proximate exploitability 
thanks to the efficient represen-
tation of the distribution and to the model-free computation
of a best response  the techniques developed here could be
used to solve other acceleration controlled mfgs  achdou et
al   2020  or  more generally  other high-dimensional mfgs 
last  the flexibility of rl  which does not require a perfect
knowledge of the model  allow us to tackle mfgs with com-
plex topologies  such as boundary conditions or obstacles  
which is a difficult problem for traditional methods based on
partial differential equations 
proceedings of the thirtieth    ijcai-21 
361
 references
 achdou and capuzzo-dolcetta  2010  yves
achdou
and
italo capuzzo-dolcetta 
mean field games  numerical
methods  siam j  numer  anal   2010 
 achdou et al   2020  yves achdou  paola mannucci  clau-
dio marchi  and nicoletta tchou  deterministic mean field
games with control on the acceleration  nodea  2020 
 bailo et al   2018  rafael bailo  mattia bongini  jos e a
carrillo  and dante kalise  optimal consensus control of
the cucker-smale model  ifac  2018 
 caponigro et al   2013  marco caponigro  massimo for-
nasier  benedetto piccoli  and emmanuel tr elat  sparse
stabilization and optimal control of the cucker-smale
model  mathematical control and related fields  2013 
 cardaliaguet and hadikhanloo  2017  pierre
cardaliaguet
and saeed hadikhanloo  learning in mean field games 
the fictitious play  esaim cont  optim  calc  var   2017 
 carlini and silva  2014  elisabetta carlini and francisco j 
silva  a fully discrete semi-lagrangian scheme for a first
order mean field game problem  siam j  numer  anal  
2014 
 carmona and delarue  2018  ren e carmona and franc¸ois
delarue 
probabilistic theory of mean field games with
applications  i  2018 
 carmona and lauri ere  2019  ren e carmona and mathieu
lauri ere  convergence analysis of machine learning al-
gorithms for the numerical solution of mean field control
and games  ii - the finite horizon case   under review at
annals of applied probability   2019 
 cucker and smale  2007  felipe cucker and steve smale 
emergent behavior in flocks  ieee transactions on au-
tomatic control  2007 
 durkan et al   2019  conor durkan  artur bekasov  iain
murray  and george papamakarios  neural spline flows 
in proc  of neurips  2019 
 elie et al   2020  romuald elie  julien perolat  mathieu
lauri ere  matthieu geist  and olivier pietquin 
on the
convergence of model free learning in mean field games 
in proc  of aaai  2020 
 guo et al   2019  xin guo  anran hu  renyuan xu  and
junzi zhang 
learning mean-field games 
in proc  of
neurips  2019 
 haarnoja et al   2018  tuomas
haarnoja 
aurick
zhou 
pieter abbeel  and sergey levine 
soft actor-critic 
off-policy maximum entropy deep reinforcement learning
with a stochastic actor  corr  abs/1801 01290  2018 
 hill et al   2018  ashley hill  antonin raffin  maximilian
ernestus  adam gleave  anssi kanervisto  rene traore 
prafulla dhariwal  christopher hesse  oleg klimov  alex
nichol  matthias plappert  alec radford  john schulman 
szymon sidor  and yuhuai wu  stable baselines  https 
//github com/hill-a/stable-baselines  2018 
 kobyzev et al   2020  ivan kobyzev  simon prince  and
marcus brubaker  normalizing flows  an introduction and
review of current methods  pami  2020 
 lanctot et al   2017  marc lanctot  vinicius zambaldi  au-
drunas gruslys  angeliki lazaridou  karl tuyls  julien
perolat  david silver  and thore graepel  a unified game-
theoretic approach to multiagent reinforcement learning 
in proc  of neurips  2017 
 lasry and lions  2007  jean-michel
lasry
and
pierre-
louis lions  mean field games  jpn  j  math   2007 
 lillicrap et al   2016  timothy p lillicrap  jonathan j hunt 
alexander pritzel  nicolas heess  tom erez  yuval tassa 
david silver  and daan wierstra  continuous control with
deep reinforcement learning  in proc  of iclr  2016 
 nourian et al   2011  mojtaba nourian  peter e caines  and
roland p malham e 
mean field analysis of controlled
cucker-smale type flocking  linear analysis and pertur-
bation equations  ifac  2011 
 perolat et al   2018  julien perolat  bilal piot  and olivier
pietquin  actor-critic fictitious play in simultaneous move
multistage games  in proc  of aistats  2018 
 perrin et al   2020  sarah perrin  julien p erolat  mathieu
lauri ere  matthieu geist  romuald elie  and olivier
pietquin  fictitious play for mean field games  contin-
uous time analysis and applications  in proc  of neurips 
2020 
 reynolds  1987  craig w reynolds 
flocks  herds and
schools  a distributed behavioral model  in proc  of sig-
graph  1987 
 rezende and mohamed  2015  danilo rezende and shakir
mohamed  variational inference with normalizing flows 
in proc  of icml  2015 
 ruthotto et al   2020  lars
ruthotto 
stanley
j
osher 
wuchen li  levon nurbekyan  and samy wu fung  a
machine learning framework for solving high-dimensional
mean field game and control problems  pnas  2020 
 schulman et al   2015  john
schulman 
sergey
levine 
philipp moritz  michael i  jordan  and pieter abbeel  trust
region policy optimization  corr  abs/1502 05477  2015 
 shaw  1975  e shaw 
naturalist at large-fish in schools 
natural history  1975 
 silver et al   2018  david silver  thomas hubert  julian
schrittwieser  ioannis antonoglou  matthew lai  arthur
guez  marc lanctot  laurent sifre  dharshan kumaran 
thore graepel  timothy lillicrap  karen simonyan  and
demis hassabis  a general reinforcement learning algo-
rithm that masters chess  shogi  and go through self-play 
science  2018 
 subramanian and mahajan  2019  jayakumar subramanian
and aditya mahajan  reinforcement learning in stationary
mean-field games  in proc  of aamas  2019 
 sutton et al   1999  r  s  sutton  d  mcallester  s  singh 
and y  mansour  policy gradient methods for reinforce-
ment learning with function approximation  in proc  of
neurips  mit press  1999 
proceedings of the thirtieth    ijcai-21 
362
 "
None,2021,https-www-ijcai-org-proceedings-2021-0051-pdf,Data-Driven Methods for Balancing Fairness and Efficiency in Ride-Pooling,"Naveen Raman, Sanket Shah, John Dickerson",None,https://www.ijcai.org/proceedings/2021/0051.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0051-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0051-pdf.pdf,
None,2021,https-www-ijcai-org-proceedings-2021-0052-pdf,Shortlisting Rules and Incentives in an End-to-End Model for Participatory Budgeting,"Simon Rey, Ulle Endriss, Ronald de Haan",None,https://www.ijcai.org/proceedings/2021/0052.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0052-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0052-pdf.pdf,"shortlisting rules and incentives in an end-to-end model
for participatory budgeting
simon rey∗   ulle endriss and ronald de haan
institute for logic  language and computation 
university of amsterdam
 s j rey  u endriss  r dehaan @uva nl
abstract
we introduce an end-to-end model for participatory
budgeting grounded in social choice theory  our
model accounts for the interplay between the two
stages commonly encountered in real-life partici-
patory budgeting  in the first stage participants pro-
pose projects to be shortlisted  while in the second
stage they vote on which of the shortlisted projects
should be funded  prior work of a formal nature has
focused on analysing the second stage only  we in-
troduce several shortlisting rules for the first stage
and analyse them in both normative and algorith-
mic terms  our main focus is on the incentives of
participants to engage in strategic behaviour during
the first stage  in which they need to reason about
how their proposals will impact the range of strate-
gies available to everyone in the second stage 
1
introduction
participatory budgeting  pb  is a loosely defined range of
mechanisms designed to improve the involvement of ordi-
nary citizens in public spending decisions  cabannes  2004  
it is usually organised as a two-stage process  in the first
stage  participants are invited to propose projects  a selec-
tion of which are put on a shortlist 
then  in the second
stage  everyone can vote on the shortlisted projects to decide
which of them should receive funding  shah  2007   these
are problems of social choice with a clear algorithmic compo-
nent  brandt et al   2016  aziz and shah  2020   prior formal
work—in particular in the ai and the economics   com-
putation communities—has concentrated almost exclusively
on the second stage  aziz et al   2018  benade et al   2017 
fluschnik et al   2019  fain et al   2016  goel et al   2019 
jain et al   2020  rey et al   2020  talmon and faliszewski 
2019   in this paper  we instead propose an end-to-end model
of pb that accounts for both stages  by studying this model 
we aim at better understanding real-life processes 
our contribution  beyond the formulation of the model it-
self  is twofold  first  we propose and analyse several short-
listing rules for the first stage  second  we analyse the in-
centives of engaging in strategic manipulation when making
∗contact author
proposals during the first stage—in view of how these affect
the second stage  let us briefly discuss both contributions 
during the first stage  the shortlisting stage  participants
can propose projects  e g   planting a tree   it is often seen as
desirable to significantly reduce the number of proposals en-
tering the second stage  for instance  if we look at the pb ex-
ercises in lisbon  around 30  of the projects were shortlisted
 allegretti and antunes  2014   in toronto   this number was
as low as 10   murray  2019   an important objective at this
point is diversity  inspired by the thiele rules for committee
elections  janson  2016   we study diversity w r t  proposers 
by minimising the number of participants without shortlisted
proposals  secondly  inspired by clustering algorithms  jain
and dubes  1988   we also explore diversity w r t  the short-
list  by avoiding selecting too many similar projects 
during the second stage  the allocation stage  participants
vote on the shortlisted projects to decide which of them to
fund—subject to a given budget limit  since the shortlisting
stage determines the  input  for this stage  there is signifi-
cant interaction between the two  which motivates the study
of end-to-end models that can account for such effects  our
focus is on participants who strategise during the shortlisting
stage to affect the set of shortlisted projects that people can
vote for during the allocation stage  to this end  we introduce
the notion of first-stage strategyproofness and analyse how it
depends on both the information available to participants and
the choice of aggregation rules used during the two stages 
related work  most prior research of a formal nature regard-
ing pb has focused on the allocation stage only  topics are
ranging from concrete rules  talmon and faliszewski  2019  
to strategic behaviour  goel et al   2019   or proportionality
 aziz et al   2018   much of this work takes inspiration from
the literature on multiwinner voting  faliszewski et al   2017  
exploiting the fact that electing a committee of k representa-
tives is isomorphic to selecting projects when each project
costs 1 dollar and the budget limit is k dollars 
we are not aware of any formal work regarding the short-
listing stage in pb  note that in multiwinner voting the term
 shortlisting  is used in two different senses  either to empha-
sise that choosing a set of k candidates is but a first step in
making a final decision  faliszewski et al   2017   or to re-
fer to the problem of electing a set of variable size  kilgour 
2016  faliszewski et al   2020  lackner and maly  2021  
only the latter is formally related to shortlisting for pb  but
proceedings of the thirtieth    ijcai-21 
370
 does not involve costs or a budget limit   note that its connec-
tions to clustering techniques have already been developed
 lackner and maly  2021  
paper outline  we develop our end-to-end model for pb in
section 2  then  section 3 is dedicated to shortlisting rules
and section 4 to first-stage strategyproofness 
2
the model
in this section  we introduce the two stages of our model for
pb and fix our assumptions regarding agent preferences 
2 1
basic notation and terminology
let p =  p1          pm  be the  finite  set of all conceivable
projects  the cost of each project is given by c   p → n  the
total cost of any set p ⊆ p is written c p  = �
p∈p c p  
the budget limit is denoted by b ∈ n  for every project p ∈
p  we assume w l o g  that c p  ≤ b  the set of agents par-
ticipating in the pb exercise is denoted by n =  1          n  
we shall make use of the following generic procedure to
choose a  best  subset  fitting the budget  of a given set of
projects in view of a given ranking of those projects 
definition 1  greedy selection   for a set p ⊆ p of projects
and a strict linear order ≫ on p  the greedy selection pro-
cedure returns the set of projects greed p  ≫  defined as
follows  projects are examined following ≫  a project p ∈ p
is selected iff the total cost of the selected projects does not
exceed b  the next project  if any  is then considered 
we are going to require a means for breaking ties  both be-
tween alternative projects and between alternative sets of
projects  for any p ⊆ p  let idx p  =  i ∈ n | pi ∈ p 
be the set of indices of the projects in p  the canonical tie-
breaking rule t returns t p  = pi with i = min idx p  
for any nonempty set p ⊆ p  we also use t to transform
weak orders on projects into strict orders  take any weak or-
der ≥ on p  then for every indifference class p ⊆ p of ≥ 
we break ties as follows  p = t p  is the first project  then
comes t p \  p    and so forth  overloading notation  we
denote by t ≥  the strict order thus obtained  finally  we
extend t to nonempty sets p ⊆ 2p of sets of projects in a
lexicographic manner  t p  is the unique set p ∈ p such
that t  p \p ′  ∪  p ′ \p   ∈ p for all p ′ ∈ p\  p   thus 
we require that  amongst all the projects on which p and p ′
differ  the one with the lowest index must belong to p 
2 2
the shortlisting stage
in the first stage  agents are asked to propose projects  a
shortlisting instance is a tuple ⟨p  c  b⟩  because of bounded
rationality  an agent may not be able to conceive of all the
projects she would approve of if only she were aware of them 
we denote by ci ⊆ p the set of projects that agent i can
conceive of—her awareness set—and we call the vector c =
 c1          cn  the awareness profile  agent i knows the cost
of the projects in ci as well as the budget limit b 
we denote by pi ⊆ ci the set of projects agent i ∈ n
chooses to actually propose  and we call the resulting vector
p =  p1          pn  a shortlisting profile  we use  p −i  p ′
i 
to denote the profile we obtain when  starting from profile p  
agent i changes her proposal to p ′
i 
a shortlisting rule r maps any given shortlisting instance
i = ⟨p  c  b⟩ and shortlisting profile p to a shortlist  i e   a
set r i  p   ⊆ � p = p1 ∪ · · · ∪ pn of shortlisted projects 
2 3
the allocation stage
in the second stage  agents vote on the shortlisted projects to
decide which ones should get funded  an allocation instance
is a tuple ⟨p  c  b⟩  where p ⊆ p is the set of shortlisted
projects  contrary to the shortlisting stage  the agents now
know about all the projects they can vote for  they vote by
submitting approval ballots  denoted by ai ⊆ p for each i ∈
n  giving rise to a profile a =  a1          an   the approval
score of a project p in profile a is na
p = | i ∈ n | p ∈ ai | 
moreover  we define the weak order ≥a
app on p by stipulating
that p ≥a
app p′ holds iff na
p ≥ na
p′ 
for a given instance i  the goal is to choose a budget al-
location a ⊆ p  it is feasible if c a  ≤ b and a i  is the
set of feasible budget allocations  moreover  a ∈ a i  is
exhaustive if there exists no p ∈ p \ a s t  c a ∪  p   ≤ b
and aex  i  is the set of exhaustive budget allocations in i 
an allocation rule f maps any given allocation instance i
and profile a to a feasible budget allocation f i  a  ∈ a i  
two well-known  polynomial-time  allocation rules try to
maximise the approval score of their output  either greedily
 goel et al   2019  or exactly  talmon and faliszewski  2019  
definition 2  greedy-approval rule   the greedy-approval
rule f returns  for any given allocation instance i
=
⟨p  c  b⟩ and profile a  the following budget allocation 
f i  a  = greed
�
p  t
�
≥a
app
��
definition 3  approval-maximising rule   the approval-
maximising rule f returns  for any given allocation instance
i =⟨p  c  b⟩ and profile a  the following budget allocation 
f i  a  = t
�
�argmax
a∈a i 
�
p∈a
na
p
�
�
we say that an allocation rule f is exhaustive if  for all in-
stances i and all profiles a  we have f i  a  ∈ aex  i  
we furthermore say that f is unanimous if  for every instance
i = ⟨p  c  b⟩ and every profile of the form a =  a          a 
with a ∈ a i   we have f i  a  ⊇ a  we will at one point
in the paper need the following strengthening of unanimity 
definition 4  strong unanimity   an allocation rule f is
strongly unanimous if  for every allocation instance i =
⟨p  c  b⟩  every agent i ∈ n  every feasible set a ∈ a i  
and every profile a with |a| ≥ 3 and ai′ = a for all agents
i′ ∈ n \  i   we have f i  a  ⊇ a 
observe that both of the rules defined above are exhaustive
and strongly unanimous  and thus also unanimous  
2 4
agent preferences
suppose agent i ∈ n has preferences over all individual
projects in p expressed as a strict linear order ▷i  even
though she might not be aware of ▷i in full   for p ⊆ p 
we denote by ▷i|p the restriction of ▷i to p  moreover 
amongst the projects in p  agent i has an ideal set topi p 
proceedings of the thirtieth    ijcai-21 
371
 of projects  assumed to be determined by the greedy selec-
tion procedure  topi p  = greed p  ▷i|p  
this ap-
proach will permit us to model what constitutes a truthful
vote by an agent for varying shortlists p  we call the vector
top p  =  top1 p           topn p   the ideal profile given p 
we make use of two already introduced preference models
that an agent can use to derive preference relations from her
ideal set  goel et al   2019  talmon and faliszewski  2019  
for any ideal set p ⊆ p  we denote by ⪰p the induced weak
preference relation and by ≻p its strict part  for any two
budget allocations a and a′  under the overlap preference
model we have a ⪰p a′ if and only if |a ∩ p| ≥ |a′ ∩ p| 
while under the cost preference model we have a ⪰p a′ if
and only if c a ∩ p  ≥ c a′ ∩ p  
finally  for any preference relation ⪰ and any family of
budget allocations p ⊆ 2p  we use best ⪰  p  to denote the
set of budget allocations that are undominated in p w r t  ⪰ 
3
shortlisting rules
we are not aware of any shortlisting rules introduced in the
literature for pb  in the following  we propose several 
the first of these is what arguably is the simplest of all
rules  the nomination rule  where every agent acts as a nomi-
nator  i e   someone whose proposals are always all accepted 
definition 5  nomination rule   the nomination rule r re-
turns  for every shortlisting instance i = ⟨p  c  b⟩ and short-
listing profile p   the shortlist r i  p   = � p  
although very natural  the nomination shortlisting rule is not
effective in reducing the number of projects 
3 1
equal-representation shortlisting rules
since the budget limit is not a hard constraint at the short-
listing stage  we might want to try to ensure that every par-
ticipant has their say  building on this idea  we introduce
the k-equal-representation shortlisting rules—inspired by the
thiele rules for multiwinner voting  janson  2016 —where k
indicates an upper bound on the total cost of the shortlist 
definition 6  k-equal-representation shortlisting rules   let
k ∈ n  the k-equal-representation shortlisting rule r re-
turns  for any given shortlisting instance i = ⟨p  c  b⟩ and
profile p =  p1          pn   the following shortlist 
r i  p   = t
�
�
�argmax
p ⊆� p
c p  ≤kb
�
i∈n
|pi∩p |
�
ℓ=0
1
nℓ
�
�
�
the weight 1/n in the rule ensures that the rule will always
select  if possible  a project proposed by the agents with the
smallest number of thus-far-selected projects 
while intuitively attractive  computing shortlists under this
rule is a computationally demanding task 
proposition 1  for any k ∈ n  computing the outcome of the
k-equal-representation shortlisting rule is np-hard 
proof  note that for any k′ ∈ n  if all projects have cost b/k′ 
computing the outcome of the k-equal-representation short-
listing rule amounts to finding a committee of size k′ with a
thiele voting rule with weights  1  1/n  1/n2         in a multi-
winner election  janson  2016   interestingly  the reduction
showing that the well-known rule of proportional approval
voting  pav  is np-hard  aziz et al   2015  works for all
thiele rules with decreasing weights  since this is the case
here  the reduction applies as well and shows np-hardness
for the k-equal-representation rule 
3 2
median-based shortlisting rules
one criterion frequently used for excluding projects in prac-
tice is the similarity between them  based on this intuition 
we introduce a family of shortlisting rules that cluster the
projects and only select representatives of each cluster 
we call distance any metric over p 
for a distance δ 
the geometric median of p ⊆ p is defined as med p  =
t argminp⋆∈p
�
p′∈p δ p⋆  p′    a partition of p  denoted
by v =  v1          vp   is a  k  ℓ -vorono¨ı partition w r t  δ if
�
vj∈v c med vj   ≤ kb and for every distinct vj  vj′ ∈ v
and every p ∈ vj  we have 
• δ p  med vj   ≤ δ p  med vj′    i e   every project is
in the cluster of its closest geometric median  and
• δ p  med vj   ≤ ℓ  i e   every project is within dis-
tance ℓ of the geometric median of its cluster 
let vδ k ℓ p  be the set of all  k  ℓ -vorono¨ı partitions of p 
definition 7  k-median shortlisting rules   let k ∈ n  the
k-median shortlisting rule r w r t  distance δ returns  for any
shortlisting instance i and profile p   the following shortlist 
r i  p   = t
�
�
�
v ∈vδ k ℓ⋆ � p  
 med vj  | vj ∈ v  
�
�
here ℓ⋆ is the smallest ℓ such that vδ k ℓ � p   ̸= ∅ 
note that we chose to minimise ℓ in our definition  one could
similarly try to minimise k  or both ℓ and k  instead 
for most natural choices of δ  computing outcomes for the
k-median shortlisting rule will be np-hard  for instance  for
the euclidean distance  our formulation coincides with the k-
median problem  known to be np-hard  kariv and hakimi 
1979   still  known results on approximation algorithms and
fixed-parameter tractability can be exploited here 
3 3
end-to-end example
let us now clarify our whole setting with an example 
example 1  consider a shortlisting instance i = ⟨p  c  b⟩
with projects p =  p1        p10   cost c p  = 1 for every
project p ∈ p  and a budget limit of b = 3  now consider
five agents with the following characteristics 
preference order
awareness set
agent 1
p1 ▷ p4 ▷ p5 ▷ p10 ▷      
 p1  p4  p5  p10 
agent 2
p1 ▷ p2 ▷ p6 ▷ p4 ▷      
 p2  p6 
agent 3
p1 ▷ p2 ▷ p7 ▷ p4 ▷      
 p2  p7 
agent 4
p1 ▷ p3 ▷ p8 ▷ p5 ▷      
 p3  p8 
agent 5
p1 ▷ p3 ▷ p9 ▷ p5 ▷      
 p3  p9 
at the shortlisting stage  if agents are truthful they will all
submit their ideal set w r t  their awareness set  leading to the
proceedings of the thirtieth    ijcai-21 
372
 profile
  p1  p4  p5    p2  p6    p2  p7    p3  p8    p3  p9   
the outcome would be p\ p10  for the nomination rule  and
 p1  p2  p3  p4  p6  p7  for the 2-equal-representation rule 
suppose the shortlist is p = p \  p10   all agents now be-
come aware of all the shortlisted projects  the truthful profile
for the allocation stage would then be a =   p1  p4  p5  
 p1  p2  p6    p1  p2  p7    p1  p3  p8    p1  p3  p9    both
the greedy-approval and the approval-maximising allocation
rules would select the budget allocation a =  p1  p2  p3   △
3 4
axioms for shortlisting rules
we now present several basic axioms for shortlisting rules 
the first one  non-wastefulness  stipulates that it should be
possible to exhaust the budget in the allocation stage 
definition 8  non-wastefulness   a shortlisting rule r is
non-wasteful if  for every shortlisting instance i = ⟨p  c  b⟩
and profile p   either c r i  p    ≥ b or r i  p   = � p  
the second axiom we put forward here encodes the idea that
every agent should be represented by the outcome 
definition 9  representation efficiency   for shortlisting in-
stance i = ⟨p  c  b⟩ and a shortlisting profile p   a short-
list p ⊆ p is representatively dominated if there exists a set
p′ ⊆ p with c p′  ≤ c p   and |p′ ∩ pi| ≥ |p ∩ pi| for all
i ∈ n  with a strict inequality for at least one agent 
a shortlisting rule r is representatively efficient if its out-
come is never representatively dominated 
let us now see how our shortlisting rules perform w r t  these
axioms  the proof of the next result is immediate 
fact 2  the nomination shortlisting rule is both non-wasteful
and representatively efficient 
proposition 3  for k ≥ 2  the k-equal-representation short-
listing rule r is non-wasteful 
for k ≥ 1  the k-equal-
representation shortlisting rule is representatively efficient 
proof  first  assume that there exists a k ≥ 2 such that r is
wasteful  then there must exist i = ⟨p  c  b⟩ and p such
that c r i  p    < b and r i  p   ̸= � p   there exists then
a project p ∈ � p \ r i  p   such that the representation
score of the set r i  p   ∪  p  is higher than that of r i  p   
moreover  since c p  ≤ b  we have c r i  p   ∪  p   ≤
2b ≤ kb  hence  r i  p   ∪  p  would have been returned
by r  yielding a contradiction 
the fact that  for every k ≥ 1  the k-equal-representation
shortlisting rule is representatively efficient is immediate
from the choice of the weight 1/n in definition 6 
proposition 4  for k ≥ 2  the k-median shortlisting rule
is non-wasteful  but there exists no k ∈ n such that the k-
median shortlisting rule is representatively efficient 
proof  the proof that  for k ≥ 2  the k-median shortlisting
rule is non-wasteful is similar to the corresponding part of the
proof of proposition 3  indeed  for no shortlisting instance i
and profile p   can there be a p ∈ � p \ r i  p   such that
c r i  p   ∪  p   ≤ kb  since selecting this p would lead to
a smaller within-cluster distance 
finally  a k-median shortlisting rule is not efficiently rep-
resentative  since the agents are not taken into account 
4
first-stage strategyproofness
we now turn to the analysis of strategic interaction during the
shortlisting stage  the central challenge here is that we need
to account for agents who  during the first stage  reason about
what will happen during the second stage 
let us first discuss the information available to a manipu-
lator  in the classical voting framework  zwicker  2016   it is
assumed that the manipulator has access to all the other bal-
lots before submitting her own  in our setting  when consid-
ering a manipulator choosing which proposal to submit dur-
ing the first stage  the same assumption is reasonable w r t 
the proposals about to be submitted by the other agents dur-
ing the first stage—but not w r t  the ballots the other agents
are going to submit during the second stage  after the short-
list will have been determined  indeed  the set of actions for
the second stage depends on the proposal of the manipulator
in the first stage  we explore three possibilities  in the first
two cases  a manipulator in the first stage is unsure what will
happen during the second stage  but assumes that either the
worst scenario will be realised  pessimistic manipulation  or
the best one  optimistic manipulation   in the third case  she
knows the other agents  true preferences and trusts they will
vote accordingly  anticipative manipulation  
let us fix some further notation  for a given allocation rule
f  allocation instance i = ⟨p  c  b⟩  profile a  and agent i ∈
n  let a⋆
i  i  a  f  be defined as the ballot t best ≻topi p 
   f i   a−i  a′
i   | a′
i ⊆ p     the best response of i to
a  when clear from the context  we omit i  a  and/or f 
also recall that every agent i ∈ n can determine an ideal
set topi p  for any given set p  which induces a preference
relation ⪰topi p  on budget allocations 
definition 10  successful manipulation   let r be a short-
listing rule  f an allocation rule  i1 = ⟨p  c  b⟩ a short-
listing instance  p a shortlisting profile  and p ′
i ⊆ p an
alternative proposal for agent i ∈ n  consider the short-
lists p = r i1  p   and p′ = r i1   p −i  p ′
i    determining
the allocation instances i2 = ⟨p  c  b⟩ and i′
2 = ⟨p′  c  b⟩ 
and abbreviate f i2   a−i  a⋆
i  i2  a    as f ⋆ i2  a  and
f i′
2   a′
−i  a⋆
i  i′
2  a′    as f ⋆ i′
2  a′   for any two ap-
proval profiles a on p and a′ on p′  then we say that 
• p ′
i is a successful pessimistic manipulation if  for all
profiles a on p and a′ on p′  it is the case that
f ⋆ i′
2  a′  ⪰topi p∪p′  f ⋆ i2  a   with a strict pref-
erence for at least one pair  a  a′  
• p ′
i is a successful optimistic manipulation if  for at least
one profile a on p and one profile a′ on p′  it is the
case that f ⋆ i′
2  a′  ≻topi p∪p′  f ⋆ i2  a  
• p ′
i is a successful anticipative manipulation if  for the
two profiles a = top p  and a′ = top p′   it is the
case that f ⋆ i′
2  a′  ≻topi p∪p′  f ⋆ i2  a  
thus  a pessimist is pessimistic w r t  the advantages she can
gain from manipulating  assuming the best if she is truthful
and the worst otherwise  for optimists it is the other way
around  finally  an anticipative manipulator knows every-
one s preferences on both p and p′ and uses them to pre-
dict their votes for the second stage  note that this definition
works under both the overlap and the cost preference model 
proceedings of the thirtieth    ijcai-21 
373
 what information is available
to the manipulator i ∈ n 
only her own
awareness set ci
r-fssp
ci and the proposals
of the other agents
u-fssp
what is the manipulator
anticipating for the allocation stage 
the worst
the best
the others to
behave truthfully
r-fssp-p
r-fssp-o
r-fssp-a
u-fssp-p
u-fssp-o
u-fssp-a
figure 1  taxonomy of first-stage strategyproofness concepts
we are looking for rules that do not allow for successful
manipulation  i e   that are first-stage strategyproof  fssp  
we distinguish two cases  either the manipulator is restricted
to her awareness set  r-fssp  or she can also propose any of
the projects proposed by others  unrestricted  u-fssp  
definition 11  fssp   for a given preference model  a pair
⟨r  f⟩ consisting of a shortlisting and an allocation rule
is r-fssp w r t  a given type of manipulation  if for every
shortlisting instance ⟨p  c  b⟩  every awareness profile c =
 c1          cn   every shortlisting profile p =  p1          pn 
where pi′ ⊆ ci′ for all i′ ∈ n  and every agent i ∈ n  there
is no p ′
i ⊆ ci such that submitting p ′
i instead of topi ci  is
a successful manipulation for i 
in case p ′
i ⊆ ci ∪ � p and we consider topi ci ∪ � p  
instead of topi ci   we say that ⟨r  f⟩ is u-fssp 
thus  under u  agents are assumed to first gain access to ev-
eryone s proposals and then decide whether or not to vote
truthfully 
we are going to use fssp-p to denote fssp
w r t  pessimistic manipulation attempts  fssp-o for opti-
mistic  and fssp-a for anticipative manipulation  a sim-
plified overview is given in figure 1 
the following result summarises how the different notions
introduced relate to each other  where x implying x′ means
that any pair ⟨r  f⟩ satisfying x also satisfies x′ 
proposition 5  the following implications hold for both the
overlap preference model and the cost preference model 
• r-fssp-o implies r-fssp-a and r-fssp-p 
• u-fssp-o implies u-fssp-a and u-fssp-p 
• r-fssp implies u-fssp for all types of manipulation 
proof  to see that the last of these claims is true  observe
that u-fssp is a special case of r-fssp  namely when the
manipulator can conceive of all the proposed projects  i e  
when ci = � p  1 the other claims are immediate 
all results in this section hold for both preference models  so
we will not explicitly specify any preference model 
1this may be counter-intuitive at first  but as explained at the end
of section 4 1  u-fssp does not imply r-fssp 
4 1
awareness-restricted manipulation
we start by proving an impossibility theorem stating that 
when manipulators are restricted to their awareness sets  no
pair of reasonable rules can be first-stage strategyproof 
theorem 6  every pair ⟨r  f⟩ of a non-wasteful shortlist-
ing rule r and an exhaustive allocation rule f is neither r-
fssp-p nor r-fssp-a  and thus also not r-fssp-o  
proof  we provide a proof for r-fssp-p  but the same proof
also goes through for r-fssp-a  the claim for r-fssp-o
then follows from proposition 5 
let i = ⟨p  c  b⟩ be the shortlisting instance with p =
 p1  p2   c p1  = c p2  = 1  and b = 1 
suppose
there are two agents  with p2 ▷1 p1 and c1 =  p1  and
p1 ▷2 p2 and c2 =  p2   i e   each agent is aware only
of the project they like less  the truthful shortlisting pro-
file is p =   p1    p2    since r is non-wasteful  we have
|r i  p  | ≥ 1  we distinguish three cases for r i  p   
in case r i  p   =  p1   whichever way the agents vote in
the allocation stage  as f is exhaustive  the final budget allo-
cation must be  p1   if agent 1 manipulates by not proposing
any project for the shortlist   p2  will get shortlisted  since r
is non-wasteful  in that case   p2  will also be the final bud-
get allocation  since f is exhaustive  it is clear that for either
preference model  agent 1 prefers  p2  over  p1   so agent 1
has an incentive to pessimistically manipulate 
the case of r i  p   =  p2  is symmetric to the previous
one  except that now agent 2 can manipulate 
finally  consider the case r i  p   =  p1  p2   w l o g  
suppose the final budget allocation is  p1  in case both agents
vote truthfully  then  just as in the first case  agent 1 has an
incentive to submit an empty set of proposals instead  as that
guarantees a final budget allocation of  p2  
note that the scenario used in the proof shows that strate-
gyproofness under u does not imply strategyproofness under
r  indeed  under u no agent would have an incentive to ma-
nipulate in this scenario  as they would have all the informa-
tion they need to submit an optimal truthful proposal 
4 2
unrestricted manipulation
for the case of u  let us start with the nomination rule  we
first prove that it is immune to pessimistic manipulation when
used with a strongly unanimous allocation rule 
proposition 7  for every allocation rule f that is exhaus-
tive and strongly unanimous  the pair ⟨r  f⟩  where r is the
nomination rule  is u-fssp-p 
proof  let i = ⟨p  c  b⟩ be a shortlisting instance  and p
the truthful shortlisting profile  consider an agent i ∈ n 
let pi = topi ci ∪ � p    from definition 5  we know
that if i submits p ′
i instead of pi  the shortlist will become
p ′
i ∪  �
i′∈n \ i  pi′   since now weakly fewer projects from
topi ci∪� p   are shortlisted  none of the budget allocations
newly reachable will be strictly better for i  moreover  strong
unanimity entails that for every exhaustive budget allocation
a  there is a profile realising it  namely  the one where every
agent except i submits a  this directly implies that i cannot
be better off by pessimistically manipulating 
proceedings of the thirtieth    ijcai-21 
374
 on the other hand  we can show that the nomination shortlist-
ing rule paired with either one of the allocation rules defined
in section 2 3 is not u-fssp-a  and thus not u-fssp-o  
example 2  recall example 1  where for both the greedy-
approval and the approval-maximising rule the outcome was
a
=
 p1  p2  p3  
suppose now that agent 1 submits
 p4  p5  p10  instead of  p1  p4  p5  in the shortlisting stage 
the shortlist then becomes p = p \  p1   in the second
stage  all agents now approve of their second  third  and
fourth most preferred projects  leading to the budget alloca-
tion  p2  p4  p5   it is clear that under both of our preference
models  this is better than a for agent 1 
△
unfortunately  also the other shortlisting rules we defined turn
out to not be first-stage strategyproof 
proposition 8  for all k ∈ n  the pair ⟨r  f⟩  where r is
the k-equal-representation shortlisting rule and f is a unan-
imous allocation rule  is neither u-fssp-p nor u-fssp-o 
proof  we first prove the claim for k = 1 and then explain
how to generalise to any k ∈ n  let i = ⟨p  c  b⟩ be a short-
listing instance with p =  p1        p4   c p2  = 2  c p  = 1
for all p ∈ p \  p2   and b = 2  consider this scenario 
preference order
awareness set
agent 1
p3 ▷ p4 ▷ p2 ▷ p1
 p1  p2  p3  p4 
agent 2
p1 ▷ p2 ▷ p3 ▷ p4
 p1  p2 
agent 3
p2 ▷ p1 ▷ p3 ▷ p4
 p2 
consider the 1-equal-representation shortlisting rule  under
the truthful profile p =   p3  p4    p1  p2    p2    the short-
list would be p =  p2   note that p ∩ top1 � p   = ∅  as-
sume now that agent 1 submits  p1  p3  instead of  p3  p4  
then the outcome of the first stage becomes p′ =  p1  p3  
it is clear that every a′ ∈ a ⟨p′  c  b⟩  is weakly preferred
by agent 1 to every a ∈ a ⟨p  c  b⟩  and some are strictly
preferred  the ones in which p3 appears   since the allocation
rule is unanimous  all these budget allocations can be reached
 when every agent submit the budget allocation  so agent 1 s
manipulation is pessimistically successful 
to generalise to k > 1  add 3 k − 1  agents in groups of
3  each group can conceive and approve of two new projects 
it is easy to check that all the new projects will always be
shortlisted  so we are back to the scenario above 
proposition 9  for all k ∈ n  the pair ⟨r  f⟩  where r is the
k-median shortlisting rule based on the euclidean distance
over r2 and f is a unanimous allocation rule  is neither u-
fssp-p nor u-fssp-o 
proof  we first prove the claim for k = 1 and then explain
how to generalise it to all k ∈ n  consider the shortlisting
instance i = ⟨p  c  b⟩ with p =  p1          p6   all projects
have cost 1  and b = 3  suppose the distance δ is the usual
distance in the plane  with the projects as in the figure below 
•
p1
•
p2
•
p3
•
p4
• p5
• p6
• p7
2
2
2
2/
√
3
√
17
4
4
1
1
consider two agents such that p1 ▷1 p2 ▷1 p3 ▷1       and
c1 =  p1  p2  p3  p5   and p4 ▷2 p6 ▷2 p7 ▷2       and c2 =
 p4  p6  p7   the truthful profile is  c1 \  p5   c2  which
will lead to the clusters  p1  p2  p3  p4    p5   and  p6  for
the 1-median shortlisting rule  the set of shortlisted projects
then is p =  p4  p6  p7   note that p ∩ top1 p  = ∅ 
now assume that agent 1 submits  p1  p2  p5   then there
will be the clusters  p1    p2  p4   and  p5  p6  p7  
the
shortlist would then be p′ =  p1  p2  p5   for the same rea-
son as in the proof of proposition 8  since f is unanimous 
agent 1 s manipulation is pessimistically successful 
to extend this to all k > 1  add k − 1 agents  all knowing
and approving of three new projects of cost 1  all the new
projects are placed uniformly on a circle with centre p4 and
a radius large enough so that all new projects will be in their
own cluster  then all the new projects will be shortlisted and
we are back to the original case for k = 1 
note that the previous statement can be generalised to other
distances  in particular  it holds for any surjective distance 
to conclude this section  note that the proofs of proposi-
tions 8 and 9 do not extend to u-fssp-a as that notion is
about a specific profile for which we have no relevant infor-
mation  however  the following facts hold for u-fssp-a 
fact 10  for no k ∈ n is the pair ⟨r  f⟩ u-fssp-a  when r
is the k-equal-representation shortlisting rule and f is either
the greedy-approval or the approval-maximising rule 
fact 11  for no k ∈ n is the pair ⟨r  f⟩ u-fssp-a  when r
is the k-median shortlisting rule and f is either the greedy-
approval or the approval-maximising rule 
the counterexample used in the proof of proposition 9 also
works for fact 11  that of proposition 8 can be made to work
for fact 10 by slightly changing the agent preferences  mak-
ing p1 and p3 the most preferred projects of many agents  
5
conclusion
to account for the fact that real-life pb is a two-stage process 
we have initiated the study of pb encompassing not only the
allocation stage but also the shortlisting stage preceding it 
this has prompted several proposals for concrete shortlist-
ing rules  and allowed us to analyse the incentives of agents
to manipulate the shortlisting stage  in view of how their ac-
tions affect the ultimate outcome during the allocation stage 
our results suggest that it is hard to devise sensible shortlist-
ing rules that incentivise the citizens to truthfully propose the
projects they would like to see achieved 
this paper is a first step towards the principled investiga-
tion of the full pb process  there are still many other features
deserving attention  for instance  it would be interesting to
consider other allocation rules  not only based on approval
scores  e g   proportional rules  aziz et al   2018   more gen-
erally  other types of interaction between the two stages can
be investigated  such as devising allocation rules that take into
account not only the outcome of the shortlisting stage but also
the shortlisting profile itself  to enforce some kind of fairness
across the two stages  this leads to the idea of defining and
studying single rules for the whole process instead of taking
the composition of a shortlisting and an allocation rule 
proceedings of the thirtieth    ijcai-21 
375
 references
 allegretti and antunes  2014  giovanni allegretti and sofia
antunes  the lisbon participatory budget  results and
perspectives on an experience in slow but continuous
transformation  field actions science reports  2014  spe-
cial issue 11 
 aziz and shah  2020  haris aziz and nisarg shah 
par-
ticipatory budgeting  models and approaches 
in path-
ways between social science and computational social
science  theories  methods and interpretations  springer-
verlag  2020 
 aziz et al   2015  haris aziz  serge gaspers  joachim gud-
mundsson  simon mackenzie  nicholas mattei  and toby
walsh  computational aspects of multi-winner approval
voting  in proceedings of the 14th international confer-
ence on autonomous agents and multiagent systems  aa-
mas   pages 107–115  2015 
 aziz et al   2018  haris  aziz  barton e  lee  and nimrod
talmon  proportionally representative participatory bud-
geting  axioms and algorithms  in proceedings of the 17th
international conference on autonomous agents and mul-
tiagent systems  aamas   pages 23–31  2018 
 benade et al   2017  gerdus
benade 
swaprava
nath 
ariel d  procaccia  and nisarg shah  preference elicita-
tion for participatory budgeting 
in proceedings of the
31st aaai conference on artificial intelligence  aaai  
pages 376–382  2017 
 brandt et al   2016  felix brandt  vincent conitzer  ulle
endriss  j erˆome lang  and ariel d  procaccia  editors 
handbook of computational social choice  cambridge
university press  2016 
 cabannes  2004  yves cabannes  participatory budgeting 
a significant contribution to participatory democracy  en-
vironment and urbanization  16 1  27–46  2004 
 fain et al   2016  brandon fain  ashish goel  and kamesh
munagala  the core of the participatory budgeting prob-
lem  in proceedings of the 12th international workshop on
internet and network economics  wine   pages 384–399 
springer-verlag  2016 
 faliszewski et al   2017  piotr faliszewski  piotr skowron 
arkadii slinko  and nimrod talmon  multiwinner voting 
a new challenge for social choice theory  in ulle endriss 
editor  trends in computational social choice  ai access 
2017  chapter 2 
 faliszewski et al   2020  piotr faliszewski  arkadii slinko 
and nimrod talmon 
multiwinner rules with variable
number of winners  in proceedings of the 24th european
conference on artificial intelligence  ecai   pages 67–74 
ios press  2020 
 fluschnik et al   2019  till
fluschnik 
piotr
skowron 
mervin triphaus  and kai wilker 
fair knapsack 
in
proceedings of the 33rd aaai conference on artificial
intelligence  aaai   pages 1941–1948  2019 
 goel et al   2019  ashish goel  anilesh k  krishnaswamy 
sukolsak sakshuwong  and tanja aitamurto 
knap-
sack voting  voting mechanisms for participatory budget-
ing  acm transaction on economics and computation 
7 2  8 1–8 27  2019 
 jain and dubes  1988  anil k  jain and richard c  dubes 
algorithms for clustering data  prentice-hall  1988 
 jain et al   2020  pallavi jain  krzysztof sornat  and nim-
rod talmon  participatory budgeting with project interac-
tions  in proceedings of the 29th international joint con-
ference on artificial intelligence  ijcai   pages 386–392 
2020 
 janson  2016  svante janson  phragm en s and thiele s elec-
tion methods  arxiv preprint arxiv 1611 08826  2016 
 kariv and hakimi  1979  oded kariv and s  louis hakimi 
an algorithmic approach to network location problems  ii 
the p-medians  siam journal on applied mathematics 
37 3  539–560  1979 
 kilgour  2016  d  marc kilgour  approval elections with
a variable number of winners 
theory and decision 
81 2  199–211  2016 
 lackner and maly  2021  martin lackner and jan maly 
approval-based shortlisting  in proceedings of the 20th
international conference on autonomous agents and mul-
tiagent systems  aamas   2021 
 murray  2019  chris murray 
toronto s participatory
budgeting pilot evaluation 
city manager s report  city
of toronto  2019 
available at https //www toronto ca/
legdocs/mmis/2019/bu/bgrd/backgroundfile-124370 pdf
 accessed on 6 july 2020  
 rey et al   2020  simon rey  ulle endriss  and ronald
de haan  designing participatory budgeting mechanisms
grounded in judgment aggregation  in proceedings of the
17th international conference on principles of knowledge
representation and reasoning  kr   2020 
 shah  2007  anwar shah  editor  participatory budgeting 
public sector governance and accountability series  the
world bank  washington  dc  2007 
 talmon and faliszewski  2019  nimrod talmon and piotr
faliszewski  a framework for approval-based budgeting
methods  in proceedings of the 33rd aaai conference on
artificial intelligence  aaai   pages 2181–2188  2019 
 zwicker  2016  william s  zwicker  introduction to the the-
ory of voting  in felix brandt  vincent conitzer  ulle en-
driss  j erˆome lang  and ariel d  procaccia  editors  hand-
book of computational social choice  cambridge univer-
sity press  2016  chapter 2 
proceedings of the thirtieth    ijcai-21 
376
 "
None,2021,https-www-ijcai-org-proceedings-2021-0053-pdf,Matchings with Group Fairness Constraints: Online and Offline Algorithms,"Govind S. Sankar, Anand Louis, Meghana Nasre, Prajakta Nimbhorkar",None,https://www.ijcai.org/proceedings/2021/0053.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0053-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0053-pdf.pdf,"matchings with group fairness constraints  online and offline algorithms
govind s  sankar1   anand louis∗2   meghana nasre∗1 and prajakta nimbhorkar∗3 4
1indian institute of technology madras  chennai
2indian institute of science  bangalore
3chennai mathematical institute  chennai
4umi relax
govindbose@gmail com  anandl@iisc ac in  meghana@cse iitm ac in  prajakta@cmi ac in
abstract
we consider the problem of assigning items to
platforms in the presence of group fairness con-
straints  in the input  each item belongs to cer-
tain categories  called classes in this paper  each
platform specifies the group fairness constraints
through an upper bound on the number of items it
can serve from each class  additionally  each plat-
form also has an upper bound on the total number
of items it can serve  the goal is to assign items to
platforms so as to maximize the number of items
assigned while satisfying the upper bounds of each
class  this problem models several important real-
world problems like ad-auctions  scheduling  re-
source allocations  school choice etc  we show
that if the classes are arbitrary  then the problem is
np-hard and has a strong inapproximability  we
consider the problem in both online and offline
settings under natural restrictions on the classes 
under these restrictions  the problem continues to
remain np-hard but admits approximation algo-
rithms with small approximation factors  we also
implement some of the algorithms  our experi-
ments show that the algorithms work well in prac-
tice both in terms of efficiency and the number of
items that get assigned to some platform 
1
introduction
graph matching is a fundamental problem in graph theory
and theoretical computer science that has been studied ex-
tensively over the years  computing the maximum match-
ing in bipartite graphs  both in the online and the offline
setting is an important building block in many applications
in allocation problems such as ad-auctions  mehta  2013 
mehta et al   2007   scheduling  mckeown et al   1999   re-
source allocation  halabian et al   2012   school choice  ab-
dulkadiroglu and s¨onmez  2003  etc  since the notation used
in these various problems differ  we use the general terms
items and platforms to refer to the two parts of the bipartite
graph  in practice  items may be classified based on different
properties and hence may belong to certain groups or classes 
∗these three authors contributed equally 
modeling the allocation problems as a vanilla matching prob-
lem seeks to optimize the cost of the solution alone and may
inadvertently be  unfair  to some classes of items  necessi-
tated by the need to be fair and unbiased towards any group of
items in the input  there has been a lot of recent work study-
ing algorithms for various problems augmented with fairness
constraints  such as  celis et al   2018  kay et al   2015 
costello et al   2016  bolukbasi et al   2016   
in this paper  we enforce group fairness through con-
straints that place an upper bound on the number of items
that can be matched from a particular class to a platform  we
note that group fairness constraints usually involve both up-
per and lower bounds  this is incompatible with the practical
applications that we have in mind  namely ad-allocation and
course allocation problems  for this reason  we focus only on
upper bounds  we formally define the problem as follows 
classified maximum matching  cmm  
we have a set a
of items and a set p of platforms  and these sets form the two
parts of a bipartite graph  the presence of an edge  a  p  in-
dicates that item a can be matched to platform p  let n p 
denote the neighborhood of p  each platform p has a collec-
tion of classes cp ⊆ 2n p   i e   each item in n p  may be-
long to some of the classes in cp  each class c ∈ cp has an
associated quota qc
p denoting the maximum number of items
from c that can be assigned to p  in addition  each platform p
has a quota qp  which is an upper bound on the total number
of items it can serve  our goal is to compute an assignment
of items to platforms so as to maximize the number of items
assigned  while satisfying all the quotas 
classes allow platforms to specify group fairness con-
straints – for instance the classes can be seen as properties
or categories and the quotas impose the constraints that not
too many items from one category are assigned to a plat-
form  these types of fairness constraints have been stud-
ied in many practical applications  in  abdulkadiroglu and
s¨onmez  2003   the authors address the school choice prob-
lem where fairness constraints are imposed to achieve racial 
ethnic  and gender balance  in the assignment of medical
residents to hospitals in japanese residency matching pro-
gram  jrmp   regional quotas are introduced to ensure fair-
ness amongst urban and rural hospitals  kamada and kojima 
2012  kamada and kojima  2015   huang  huang  2010  mo-
tivates classifications from the perspective of enabling diver-
proceedings of the thirtieth    ijcai-21 
377
 sity in academic hiring  apart from matchings  group fairness
constraints have also been studied for many other problems
like the knapsack problem  patel et al   2021   and clustering
problems  bera et al   2019   to name a few 
some recent pre-prints have discussed fairness in matching
problems  soriano and bonchi  garc ıa-soriano and bonchi 
2020  study a different notion of individual fairness that they
call maxmin-fairness  their goal is to output a solution such
that the satisfaction of one agent cannot be improved without
making another agent worse-off  ma and xu  ma and xu 
2020  measure fairness by the ratio of expected number of
agents matched from a particular group to the expected num-
ber of agents from that group and their goal is to maximize
the minimum of this ratio over all groups  basu et al   basu
et al   2020  also measure fairness based on metrics involving
the ratio of agents across groups and the utility they provide 
while qualitatively similar  our constraints can be seen as be-
ing orthogonal to such notions of fairness 
in different applications  the fairness constraints can have
a different structure  in  kamada and kojima  2012  kamada
and kojima  2015   each hospital belongs to exactly one re-
gion  hence fairness constraints partition the set of hospitals 
on the other hand  in the school choice problem in  abdulka-
diroglu and s¨onmez  2003   a student belongs to multiple
constraints  the structure of the constraints crucially affects
the computational complexity of finding a fair allocation 
this has been illustrated in the context of bipartite match-
ings where one or both sides of the bipartition express prefer-
ences over the other side  huang  huang  2010  and fleiner
and kamiyama  fleiner and kamiyama  2012   address the
cmm problem when both sides of the bipartition have prefer-
ences over each other and the notion of optimality is stability 
whereas  nasre et al   2019  study the cmm problem under
the optimality criteria of rank-maximality and popularity  in
all these cases  it has been shown that the cmm problem can
be efficiently solved if the constraints have a laminar1 struc-
ture  and is np-hard in general  nasre et al   2019   such a
restriction has been considered before in the literature  such
as in the hospital-resident problem  kamada and kojima 
2012  or the college admissions problem  bir o et al   2010 
goto et al   2016   however  a finer relation between the
structure of the class constraints and the computational ef-
ficiency has not received much attention in literature  in this
paper  we address this issue by focusing on a quantification of
non-laminarity in the classes and its effect on computational
efficiency  we strengthen the hardness results in  nasre et
al   2019  and obtain new approximation algorithms for the
cmm problem in the offline setting 
next  we turn our attention to the online version of the
problem  online matching problems have numerous practical
applications  such as in ad-allocations  mehta et al   2007  
resource allocation  devanur et al   2011   etc  see  mehta 
2013  for a survey on online bipartite matchings  fairness
has also been studied in online settings such as online learn-
ing  gillen et al   2018  or ride-hailing platforms  s¨uhr et al  
2019    fairness  in another form has been considered pre-
1a family c of subsets of a set s is laminar if  for every pair of
sets x  y ∈ c  either x ⊆ y or y ⊆ x or x ∩ y = ∅ 
viously in the online literature  for example  the  frequency
caps  mentioned in  feldman et al   2009  places a restriction
on the total number of ads that are shown to the same user  or
users from a particular demographic  we study some natural
online versions of the cmm problem  we first show that one
of our approximation algorithms for the offline non-laminar
case also works as an online algorithm  regardless of the in-
put model  for the setting where we restrict classes to be
laminar  we show that existing algorithms for online bipartite
matching carry over to our setting 
1 1
models
we study cmm problem in various settings  in practice  as-
signing an item a to a platform p may generate a revenue 
which can be modelled as the weight of the edge  a  p   in
such a case the goal of the weighted cmm problem is to com-
pute an assignment of items to platforms so as to maximize
the total weight of edges in the matching  while satisfying the
quotas of all the classes  we now formally define our models 
model 1  many-to-one   this is the setting described earlier 
in this setting  items can match to at most one platform 
model 2  many-to-many   this is a more general setting in
which items may be matched to multiple platforms  in addi-
tion to the classes of platforms  each item i also has a collec-
tion of classes ci ⊆ 2n i   i e   each platform in n i  belongs
to some of the classes in ci  and the items also have quotas
for their classes  this model arises in scenarios like course
allocation  where students may be allotted multiple courses
subject to various restrictions  courses may have restrictions
over the number of students allotted to it from each depart-
ment or from each batch 
in the setting of online matchings  the platforms are avail-
able offline and the items arrive online  when an item a ∈ a
arrives online  its neighbours in p  and the classes that it par-
ticipates in are revealed  it must be immediately decided if
we match a to some platform and any edges matched cannot
be unmatched later  in the literature  the order in which the
items arrive has been studied in various models  in the adver-
sarial model  the items can arrive in an arbitrary order  we
study a natural online arrival model for the items  called the
random input model  see  mehta  2013  for a survey of other
work on such models 
model 3  random input   in this setting  there is an underly-
ing graph g =  a∪p  e   the vertices of a arrive according
to a permutation chosen uniformly at random 
1 2
our results
in most applications  an item typically belongs to small num-
ber of classes  hence we first study this setting  for example 
 abdulkadiroglu and s¨onmez  2003  discusses the boston
student assignment mechanism which divides students into
two categories based on whether they already have a sibling
in the school and whether they are within walking distance to
the school  similarly  in a faculty hiring scenario  the number
of classes  which would correspond to specializations  is in-
dependent of the number of applicants  for the scenario when
there are constant number of classes we show the following
result 
proceedings of the thirtieth    ijcai-21 
378
 theorem
1
 informal
version
of
theorem
6  
the
cmm problem can be solved in polynomial time if there is a
constant number of platforms  each with a constant number
of classes  this leads to a 1
2-approximation algorithm for an
arbitrary number of platforms  each with a constant number
of classes 
now we turn to a more general setting where the number of
classes is arbitrary and exploit the structural relation amongst
the classes  we know from  nasre et al   2019  that when
the classes of every platform form exactly one laminar family
then the cmm problem is solvable in polynomial time  we
prove the following theorem 
theorem 2  there is a polynomial-time algorithm achieving
an approximation ratio of
1
∆ 1 for the many-to-one setting
 model 1  where each item belongs to at most ∆ laminar fam-
ilies of classes per platform  this generalizes to the weighted
many-to-many setting  model 2  where for each edge  a  p  
the classes of a and p that contain  a  p  can be partitioned
into ∆   1 laminar families 
the above result is applicable in scenarios like ad-
allocation where the number of classes can be arbitrary  but
any ad belongs to a few of them  complementing this  we also
obtain hardness results for computing the optimal cmm 
proposition 1 
 i  cmm cannot be approximated to a fac-
tor of nϵ−1 for any ϵ > 0 unless p = np  where
n = |a|  even when there is a single platform and all
edge weights are one 
 ii  when there is a single platform  and additionally  each
item appears in at most ∆ classes  the problem is np-
hard to approximate within a factor o
�
log2 ∆
∆
�
 
the proof of proposition 1 follows from a reduction from
the maximum independent set problem 
in the online setting  we first remark that our algorithm
from theorem 2 works as an online algorithm in the un-
weighted case  even when the input is adversarially chosen 
theorem 3  there is a polynomial-time online algorithm
achieving  in any input model  a competitive ratio of
1
∆ 1
for the many-to-one setting  model 1  where each item be-
longs to at most ∆ laminar families of classes per platform 
the algorithm extends to the many-to-many setting  model 2 
where the classes of a and p containing each edge  a  p  can
be partitioned into ∆   1 laminar families 
having achieved a competitive ratio that is close to the
lower bound  from proposition 1  ii    we consider the case
where classes are restricted to be laminar 
we consider
the random order input model  model 3  and show that a
simple greedy algorithm from the literature also works for
cmm and that it achieves the same competitive ratio  we
use the technique of randomized dual fitting which has been
used to analyse competitive ratios in works such as  devanur
et al   2013  huang et al   2018  
theorem 4  there is a polynomial-time algorithm achieving
a competitive ratio of 1 − 1
e for cmm with laminar classes
in the random input model 
1 3
implications for other problems
although the cmm problem is modelled as a matching of
items to platforms  we show that the classes capture problems
which are well studied and are of independent interest 
maximum independent set on hypergraphs 
given a
hypergraph h =  v  e   and a function f   e → z   com-
pute the largest set of vertices s such that for every e ∈ e 
|s ∩ e| ≤ f e   we note that when f e  = 1 for each
edge e  this is the problem of computing the strong maximum
independent set and when f e  = |e| − 1  this is the weak
maximum independent set problem 
these problems are
well-studied for bounded-degree hypergraphs   halld orsson
and losievskaja  2009  describe algorithms achieving factors
of
1
∆ and
5
∆ 3 for the strong and weak cases respectively 
where ∆ denotes the maximum degree of a vertex in h 
for the weak independent set  this was further improved to
o
�
log ∆
∆ log log ∆
�
in  agnarsson et al   2013   however  to the
best of our knowledge  there is no known approximation al-
gorithm for the case when f e  is an arbitrary value – we call
this the generalized maximum independent set on
hypergraphs  we state our approximation result for indepen-
dent sets on hypergraphs below  which is a consequence of
theorem 2 
proposition 2  there is a polynomial time
1
∆ approxima-
tion algorithm for the problem of computing a generalized
maximum independent set on hypergraphs with maxi-
mum degree ∆ 
for the case when average degree of the vertices is ∆  we
get the following 
theorem 5  there is a
r
4∆ approximation algorithm for the
generalized independent set where r = op t
n
and ∆ denotes
the average degree of a vertex 
for the cmm problem  this implies an op t
4∆n approxima-
tion algorithm when we only have an upper bound on the av-
erage number of laminar families of classes an item belongs
to  and there is only one platform 
ranking and group fairness 
in an apparently different
model  celis et al   celis et al   2018  consider ranking n
items from a universe of m items  where n ≪ m  items
are assigned properties  and upper quotas for the number of
items from any property in the top k ranks  when items have
at most ∆ properties each  they give a
1
∆ 2 approximation
while allowing constraints to be violated by a factor of 2  this
problem can be reduced to the cmm problem and our algo-
rithm from theorem 2 achieves the same approximation fac-
tor without violating any class constraints  we leave the re-
duction to the full version of this paper  sankar et al   2021  
simultaneous matchings 
kutz et al   kutz et al   2008 
study the problem called simultaneous matchings which is
defined as follows  given a bipartite graph g =  x ∪ d  e 
and a collection f ⊆ 2x  find the largest solution m ⊆ e
such that ∀ c ∈ f  m ∩ c ×d  is a matching  this problem
can be reduced to the cmm problem where every vertex d in
d has constraints f  excluding vertices to which d has no
edge   and each class has quota 1  the approximation factor
proceedings of the thirtieth    ijcai-21 
379
 in  kutz et al   2008  is better but the constraints are signifi-
cantly more restricted than ours 
2
offline approximation algorithms
in light of the strong inapproximability result for the general
cmm problem  proposition 1   we describe approximation
algorithms for some special cases 
2 1
proof of theorem 2
in this section  we consider the case when  for each platform p
and item a  the classes containing a can be partitioned into at
most ∆ laminar families  we first present a 1
∆-approximation
algorithm for the case when there is only one platform  this
algorithm also generalizes the maximum independent set in
hypergraphs  proposition 2   we extend this algorithm to a
1
∆ 1-approximation algorithm for the case with multiple plat-
forms and even to the many-to-many setting 
let g =  a∪ p   e  be an instance of the cmm problem
with a single platform p and a family of classes c with the
above restriction 
reduction to the generalized maximum indepen-
dent set problem  we construct an instance h =  v  eh 
by setting v =  vi | ai ∈ a  and eh =  ec | c ∈ c  
and f ec  = q c   we call a set s ⊆ v feasible if for every
e ∈ e   |s ∩ e| ≤ f e   we call a set s ⊆ v maximal if s is
feasible and s ∪  v  is not feasible for every v ∈ v \ s  our
algorithm is a simple greedy algorithm  output a maximal set
of vertices  to prove the approximation  we use the following
lemma  see the full version of this paper for the proof 
lemma 1  consider a set s ⊆ v and a set b ⊆ v \ s
such that s ∪ b is a maximal set of vertices  then for every
feasible set c such that s ⊆ c and c ∩ b = ∅  we have
|c| ≤ |s|   ∆|b| 
let alg denote any maximal independent set of h and
opt be the optimal independent set  in the above lemma 
set s = alg ∩ opt  b = alg \ opt  c = opt  the
lemma implies |opt| ≤ ∆|alg|  this proves proposi-
tion 2  we note that this also gives us a
1
∆-approximation
for the cmm problem in the single platform case when ev-
ery item belongs to at most ∆ laminar families of the plat-
form  it is also easy to see that this algorithm runs in time
o |v ||eh|   for every vertex  we add it if it does not exceed
the quota of any edge it belongs to 
multiple platforms 
we can use the previous result to ob-
tain a
1
∆ 1 approximation for the multiple platforms case via
a simple o |e| -time reduction to the single platform case 
for every edge  a  p   make a new item ea p  replace all the
platforms by a single dummy platform  since classes are sub-
sets of the neighbourhood sets of items or platforms  they can
also be seen as subsets of edges of the graph  these natu-
rally form classes over the items ea p  this combined with
the result for the single platform case gives an o |e| · |c| 
algorithm for the multiple platform case where |c| is the total
number of classes  establishing theorem 2 
remark 1  weights on items   we remark that the same anal-
ysis goes through even if items have weights and the goal is
to compute a maximum weight matching  the algorithm sim-
ply keeps matching the highest weight item that can feasibly
match to the platform 
2 2
constant number of classes
we can also prove theorem 2 via the following general state-
ment combined with proposition 2  we leave the proof to the
full version of this paper  sankar et al   2021   we will also
need this to prove theorem 1 
lemma 2  given a polynomial-time α-approximation al-
gorithm for the many-to-one matching problem with a
single platform  we can obtain a polynomial-time
α
1 α-
approximation for the matching problem with multiple plat-
forms 
theorem 6  formal version of theorem 1   the cmm prob-
lem can be represented as an ip with 2∆ variables if there is
only one platform with ∆ classes  this can be solved in time
o 22∆poly n    and also gives rise to a 1
2-approximation
in time o 22∆poly n   for multiple platforms  each with ∆
classes of items 
sketch  for an instance with ∆ classes  every item can be
represented by a ∆-bit incidence vector of the classes it be-
longs to  this partitions the items into 2∆ types  our ilp
has one variable for each type  the runtime is obtained via
 lenstra  1983   theorem 1 follows by setting ∆ = o 1   in
practice  there exist integer program heuristics that are faster
 for example  see  fischetti et al   2005    for arbitrarily large
number of platforms  each with a constant number of classes 
we can use this with lemma 2 to get a 1
2-approximation 
2 3
bounded average degree
we extend the result from the previous section for a single
platform to the case when the average number of laminar
families of classes an item belongs to is bounded by ∆  we
state it in terms of generalized maximum independent
sethere  now consider the case where the hypergraph h
constructed above has only bounded average degree of ∆ 
proof of theorem 5  since the average degree is ∆  for any
f  there cannot be more than n
f vertices of degree more than
f∆  suppose we estimate r and set f = 2
r  we call a vertex
low degree if its degree is at most f∆  otherwise the vertex
is high degree  then the number of low degree vertices is
≥ n
�
1 − r
2
�
  in the graph induced by the low degree ver-
tices  the size of the optimal independent set is at least op t
2
 
since at most op t
2
vertices of high degree  we use our
1
∆
approximation algorithm on the graph induced by the low de-
gree vertices  since this graph has maximum degree ≤ 2∆
r  
the size of the independent set has size ≥ r·op t
4∆
 
thus  our approximation ratio is at least
r
4∆  we finally
need to estimate r  we guess a value of opt from 1 to n and
run the above procedure for each of the guesses  amongst all
the solutions that we obtain  we pick the one with the highest
cardinality  this is guaranteed to do at least as well as the
case when we picked the correct value of opt 
proceedings of the thirtieth    ijcai-21 
380
 3
online algorithms
the online algorithm for theorem 3 is essentially the same
as the one in proposition 2 and works even for an arbitrary
input model  whenever an item arrives online  we match it to
a platform such that the matching remains feasible  if there
is no such platform  we leave it unmatched  the output is a
maximal set  which by proposition 2  gives us the required
competitive ratio  however  we point out that this only works
for the unweighted version 
we now look at an  easier  version of cmm where the
classes form a laminar family  this version is known to have
an efficient offline algorithm  via the construction of a sim-
ple flow network  a similar construction is used to compute
the rank-maximal matching in  nasre et al   2019   in this
setting  we look at the many-to-many cmm model  model
2  and assume an input model where the item set arrives in
a uniformly random permutation  model 3   for the sake of
the analysis  we assume that a random variable yi picked uni-
formly at random from  0  1  for every item ai  and the items
arrive in the increasing order of yi  therefore the random vec-
tor ⃗y  =  y1  y2          yn  fully describes the order of arrival of
the items  we use ⃗y−i to represent the vector after removing
yi from ⃗y  we use the following greedy algorithm  and ana-
lyze its competitive ratio  in expectation   keep an arbitrary 
fixed ranking of all the platforms in p  when an item arrives
online  match it to as many platforms as possible  picking the
highest ranked ones 
sketch of theorem 4  we use a linear programming relax-
ation of our problem to analyze our algorithm  we set the pri-
mal values according to the output of our algorithm  thereby
ensuring the feasibility of the primal solution  now we need
to construct an appropriate dual solution  we use the follow-
ing folklore fact about the well-known method of dual fitting
in designing algorithms  this technique is used in  devanur
et al   2013  huang et al   2018  among others 
in the primal lp  we have a variable xij = 1 ⇐⇒ item
ai is matched to platform pj  we also have constraints for
both the item and platform classes  in the dual lp  we have
variables corresponding to constraints in the primal lp  we
describe the lp formally in the full version of this paper 
fact 1  folklore   suppose we can set the dual variables such
that the primal objective is equal to the dual objective  and the
dual constraints of the form α ≥ 1 instead satisfy e α  ≥ f 
then  our algorithm has a competitive ratio f in expectation 
now  we set the dual variables so that the dual con-
straints have a lower bound of f 
the following is the
key lemma in analyzing how the algorithm behaves depend-
ing on ⃗y  although it is inspired by  devanur et al   2013 
huang et al   2018  goel and mehta  2008   our many-to-
many model  model 2  is more complicated in that moving
one vertex up the ranking can cause more changes to the
matching because an item can match to multiple platforms 
even apart from the platform classes  we must take care of
item classes as well  to that end  we use the following lemma 
lemma 3  for any i  j such that j ̸= i  if an item aj is
matched to some platforms at yi = 1  then it cannot be un-
matched from any platform at yi = θ ∈  0  1  due to an item
class 
once we have the lemma  we show theorem 4 the follow-
ing way  let α ≥ 1 be such a dual constraint  we want to
show that e  α  ≥ f or equivalently  ey−i  eyi  α   ≥ f  we
look at the inner expectation  we fix y−i and vary yi from 0
to 1  and show using dual-fitting arguments and lemma 3 that
e  α  ≥
�
1 − 1
e
�
  from fact 1  this proves theorem 4 
4
experiments
in this section  we present the experimental evaluation of our
offline algorithms from theorem 1 and theorem 2  we use a
total of seven datasets which we categorize as real-world and
synthetic datasets  the three real-world datasets are sourced
from an elective allocation process at an educational institu-
tion  the four synthetic datasets are generated as described
below  all experiments were run on a laptop running on a
64-bit windows 10 home edition  and equipped with an in-
tel core i7-7500u cpu @2 7ghz and 12gb of ram  for
solving integer programs  we used ibm ilog cplex op-
timization studio 20 1 through its python api  all code was
written to run on python 3 8 
real-world datasets 
we use data from three course-
registration periods at an educational institution  each dataset
has around 100 courses and 2000 students  the students and
the courses correspond to items and platforms respectively in
our model  the edges represent the courses that a student
is interested in  the students are partitioned into 13 depart-
ments  majors  as well as 5 batches  1st year–5th year   each
course has an overall quota denoting the maximum number of
students that can be allotted to it  for each course  we intro-
duce a quota for each department and a quota for each batch 
each course belongs to one of two categories  and each stu-
dent can be matched to at most one course of each category 
the goal is to maximize the number of edges selected subject
to these constraints  this can be immediately viewed as an
instance of cmm 
synthetic datasets 
modelled on the real-world datasets 
we synthetically generate large instances and compare the
performance of our algorithms to the optimal algorithm im-
plemented using a matching integer linear program  the
synthetic datasets are generated as follows  datasets labelled
 large  have 500 courses  and 20 departments with 10 000
students in each department  the datasets labelled  small 
have 300 courses  and 20 departments with 2 000 students
in each department  the students have a degree that is cho-
sen uniformly at random between 3 and 10 in the  dense 
datasets and between 3 and 5 in the  sparse  datasets  stu-
dents choose their courses randomly based on a non-uniform
probability distribution  this distribution is defined by as-
signing a random  popularity  value to each course  we ob-
serve this feature in the real-world dataset  where all courses
are not equally popular  we also experiment without this fea-
ture  and obtain similar results 
proceedings of the thirtieth    ijcai-21 
381
 dataset
1
2-approx
∆-approx
opt
real-1
1871 5  0 92 
1899 8  0 93 
2035  1 
real-2
1988 6  0 92 
2014 0  0 93 
2170  1 
real-3
1938 6  0 92 
1936 7  0 92 
2107  1 
table 1  comparison of  average  solution values on the real-world
datasets  relative values are in parentheses 
dataset
1
2-approx
∆-approx
opt
real-1
0 39  1 23 
0 11  4 29 
0 48  1 
real-2
0 43  1 03 
0 11  3 89 
0 44  1 
real-3
0 33  1 23 
0 10  3 90 
0 40  1 
table 2  comparison of  average  running-times in seconds on the
real-world datasets  relative speedups are in parentheses 
we compare our performance and running-time with the
optimal solution obtained by solving the standard match-
ing ilp augmented with the constraints for each class  all
running-times include the time taken for file i/o  the solu-
tion values and running-times were averaged over 10 runs 
though our algorithms are deterministic  these implementa-
tions utilize some randomness because of the use of hash-
tables  observe that since we have two laminar families of
classes  theorem 1 and theorem 2 provide theoretical guar-
antees of only 1
2 and 1
3 respectively  however  the perfor-
mance of the algorithms on both real-world and random data
are close to optimal 
all our tables provide absolute val-
ues of the solution value and running-time of the algorithm
from theorem 1  column 1
2-approx  and algorithm from the-
orem 2  column ∆-approx   as well as the relative value or
relative speedup in comparison to that of the matching ilp
 column opt  
4 1
observations
tables 1  2 provide the solution values and running times for
real-world instances and tables 3  4 provide the same for the
synthetic datasets  in both these datasets  both of our algo-
rithms output solutions with value at least 90  of the opti-
mum value  this seems to suggest that both real-world or
random settings are  easier  than the worst-case instances for
our algorithms  furthermore  we believe that the significantly
improved running-time more than makes up for loss of 10 
in the output value  the biggest speedups are observed in
the  large  datasets  where our algorithms achieve speedups
of 15× and 30× respectively  this is expected because the
ilp takes time exponential in the size of the graph 
5
conclusion
in this paper we gave approximation algorithms for the cmm
problem in various offline and online settings 
improv-
ing these approximation factors or showing matching lower
bounds are natural open questions 
there are existing al-
gorithms that break the 1 − 1/e barrier for online bipartite
matching without group fairness constraints such as  feld-
man et al   2009   obtaining similar bounds for online cmm
dataset
1
2-approx
∆-approx
opt
large-
dense
239552
 0 97 
239566 4  0 97 
247537  1 
large-
sparse
212600 1
 0 97 
211885 1  0 97 
218622  1 
small-
sparse
72676 4
 0 93 
72821 5  0 93 
78279  1 
small-
dense
75887 7
 0 95 
76133 4  0 95 
79827  1 
table 3  comparison of  average  solution values in the synthetic
datasets  relative values are in parentheses 
dataset
1
2-approx
∆-approx
opt
large-dense
5 68  14 41 
2 90  28 21 
81 99  1 
large-sparse
4 67  15 14 
2 19  32 19 
70 73  1 
small-sparse
1 55  3 00 
0 46  10 07 
4 68  1 
small-dense
1 73  5 39 
0 58  16 14 
9 37  1 
table 4  comparison of  average  running-times in seconds in the
synthetic datasets  relative speedups are in parentheses 
is also an interesting open problem 
acknowledgements
we acknowledge some initial discussions with ajay saju ja-
cob  we are grateful to the anonymous reviewers for their
comments 
al was supported in part by serb award
ecr/2017/003296 and a pratiksha trust young investigator
award  mn and pn are supported in part by serb award
crg/2019/004757 
references
 abdulkadiroglu and s¨onmez  2003  atila
abdulkadiroglu
and t  s¨onmez  school choice  a mechanism design ap-
proach  am  econ  rev   93 3  729–747  2003 
 agnarsson et al   2013  geir
agnarsson 
magn us
m 
halld orsson  and elena losievskaja 
sdp-based al-
gorithms for maximum independent set problems on
hypergraphs  theor  comput  sc   470 1–9  2013 
 basu et al   2020  kinjal basu  cyrus diciccio  heloise
logan  and noureddine el karoui 
a framework for
fairness in two-sided marketplaces 
arxiv preprint
arxiv 2006 12756  2020 
 bera et al   2019  suman bera 
deeparnab chakrabarty 
nicolas flores  and maryam negahbani  fair algorithms
for clustering  in neurips  pages 4955–4966  2019 
 bir o et al   2010  p eter bir o  tam as fleiner  robert w  irv-
ing  and david f  manlove  the college admissions prob-
lem with lower and common quotas  theor  comput  sc  
411 34-36  3136–3153  2010 
 bolukbasi et al   2016  tolga bolukbasi  kai-wei chang 
james zou  venkatesh saligrama  and adam kalai  man
is to computer programmer as woman is to homemaker 
proceedings of the thirtieth    ijcai-21 
382
 debiasing word embeddings  in nips  page 4356–4364 
2016 
 celis et al   2018  l  elisa celis  damian straszak  and
nisheeth k  vishnoi  ranking with fairness constraints 
in icalp  volume 107  pages 28 1–28 15  2018 
 costello et al   2016  matthew costello  james hawdon 
thomas ratliff  and tyler grantham 
who views on-
line extremism  individual attributes leading to exposure 
comput  hum  behav   63 311–320  2016 
 devanur et al   2011  nikhil r  devanur  kamal jain  bala-
subramanian sivan  and christopher a  wilkens  near op-
timal online algorithms and fast approximation algorithms
for resource allocation problems 
in ec  pages 29–38 
2011 
 devanur et al   2013  nikhil r  devanur  kamal jain  and
robert d  kleinberg 
randomized primal-dual analysis
of ranking for online bipartite matching  in soda  pages
101–107  2013 
 feldman et al   2009  jon feldman  aranyak mehta  va-
hab s  mirrokni  and s  muthukrishnan  online stochastic
matching  beating 1-1/e  in focs  pages 117–126  2009 
 fischetti et al   2005  matteo fischetti  fred glover  and
andrea lodi 
the feasibility pump 
math  program  
104 1  91–104  2005 
 fleiner and kamiyama  2012  tam as fleiner and naoyuki
kamiyama  a matroid approach to stable matchings with
lower quotas  in soda  pages 135–142  2012 
 garc ıa-soriano and bonchi  2020  david
garc ıa-soriano
and francesco bonchi  fair-by-design matching  data
min  knowl  disc   pages 1–45  2020 
 gillen et al   2018  stephen
gillen 
christopher
jung 
michael kearns  and aaron roth  online learning with
an unknown fairness metric  in nips  pages 2605–2614 
2018 
 goel and mehta  2008  gagan goel and aranyak mehta 
online budgeted matching in random input models with
applications to adwords  in soda  pages 982–991  2008 
 goto et al   2016  masahiro goto  atsushi iwasaki  yujiro
kawasaki  ryoji kurata  yosuke yasuda  and makoto
yokoo  strategyproof matching with regional minimum
and maximum quotas  artif  intell   235 40–57  2016 
 halabian et al   2012  hassan
halabian 
ioannis
lam-
badaris 
and chung-horng lung 
optimal server
assignment in multi-server parallel queueing systems with
random connectivities and random service failures 
in
icc  pages 1219–1224  2012 
 halld orsson and losievskaja  2009  magn us
m 
halld orsson
and
elena
losievskaja 
independent
sets in bounded-degree hypergraphs 
discrete appl 
math   157 8  1773–1786  2009 
 huang et al   2018  zhiyi huang  ning kang  zhihao gavin
tang  xiaowei wu  yuhao zhang  and xue zhu  how to
match when all vertices arrive online  in stoc  pages 17–
29  2018 
 huang  2010  chien-chung huang 
classified stable
matching  in soda  pages 1235–1253  2010 
 kamada and kojima  2012  yuichiro kamada and fuhito
kojima 
stability and strategy-proofness for matching
with constraints  a problem in the japanese medical match
and its solution  am  econ  rev   102 3  366–70  2012 
 kamada and kojima  2015  yuichiro kamada and fuhito
kojima 
efficient matching under distributional con-
straints 
theory and applications 
am  econ  rev  
105 1  67–99  2015 
 kay et al   2015  matthew kay  cynthia matuszek  and
sean a  munson 
unequal representation and gender
stereotypes in image search results for occupations 
in
chi  pages 3819–3828  2015 
 kutz et al   2008  martin kutz  khaled elbassioni  irit ka-
triel  and meena mahajan 
simultaneous matchings 
hardness and approximation  j  comput  and syst  sc  
74 5  884–897  2008 
 lenstra  1983  h  w  lenstra  integer programming with a
fixed number of variables  math  oper  res   8 4  538–
548  1983 
 ma and xu  2020  will ma and pan xu  group-level fair-
ness maximization in online bipartite matching 
arxiv
preprint arxiv 2011 13908  2020 
 mckeown et al   1999  nick
mckeown 
venkat
anan-
tharam  and jean walrand  achieving 100  throughput
in an input-queued switch  ieee t  comm   47 8  1260–
1267  1999 
 mehta et al   2007  aranyak mehta  amin saberi  umesh
vazirani  and vijay vazirani  adwords and generalized
online matching  j  acm  54 5  22–es  2007 
 mehta  2013  aranyak mehta  online matching and ad allo-
cation  foundations and trends® in theoretical computer
science  8 4  265–368  2013 
 nasre et al   2019  meghana nasre  prajakta nimbhorkar 
and nada pulath  classified rank-maximal matchings and
popular matchings – algorithms and hardness 
in wg 
pages 244–257  2019 
 patel et al   2021  deval patel  arindam khan  and anand
louis  group fairness for knapsack problems  in aamas 
page 1001–1009  2021 
 sankar et al   2021  govind
s 
sankar 
anand
louis 
meghana nasre  and prajakta nimbhorkar 
matchings
with group fairness constraints  online and offline algo-
rithms  arxiv preprint arxiv 2105 09522  2021 
 s¨uhr et al   2019  tom s¨uhr  asia j  biega  meike zehlike 
krishna p  gummadi  and abhijnan chakraborty  two-
sided fairness for repeated matchings in two-sided mar-
kets  a case study of a ride-hailing platform  in kdd 
pages 3082–3092  2019 
proceedings of the thirtieth    ijcai-21 
383
 "
None,2021,https-www-ijcai-org-proceedings-2021-0054-pdf,Stochastic Market Games,"Kyrill Schmid, Lenz Belzner, Robert Müller, Johannes Tochtermann, Claudia Linnhoff-Popien",None,https://www.ijcai.org/proceedings/2021/0054.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0054-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0054-pdf.pdf,
None,2021,https-www-ijcai-org-proceedings-2021-0055-pdf,Tango: Declarative Semantics for Multiagent Communication Protocols,"Munindar P. Singh, Samuel H. Christie V.",None,https://www.ijcai.org/proceedings/2021/0055.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0055-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0055-pdf.pdf,"tango: declarative semantics for multiagent communication protocols
munindar p. singh1 and samuel h. christie v1,2
1department of computer science, north carolina state university, raleigh, nc 27695, usa
2school of computing and communications, lancaster university, lancaster la1 4wa, uk
mpsingh@ncsu.edu, schrist@ncsu.edu
abstract
to build a decentralized multiagent system whose
member agents are not coupled to each other’s deci-
sion making requires a flexible communication pro-
tocol. information-based protocol languages cap-
ture a protocol in terms of causality and integrity
constraints based on the information exchanged by
the agents. thus, they enable highly flexible enact-
ments in which the agents proceed asynchronously
and messages may be arbitrarily reordered. how-
ever, the existing semantics for such languages can
produce a large number of protocol enactments,
which makes verification of a protocol property in-
tractable. this paper formulates a protocol seman-
tics declaratively via inference rules that determine
when a message emission or reception becomes en-
abled during an enactment, and its effect on the lo-
cal state of an agent. this representation enables
heuristics for determining when alternative exten-
sions of a current enactment would be equivalent,
thereby helping produce parsimonious models and
yielding improved protocol verification methods.
1
introduction
we consider a decentralized multiagent system in which
autonomous agents communicate through message passing.
such multiagent systems find natural application in settings
such as commerce and the internet of things where multiple
parties interoperate autonomously with minimal coupling.
a crucial challenge is to specify, verify, and implement
multiagent systems in terms of high-level concepts such as
norms and other organizational constructs [g¨unay et al.,
2015; jiang et al., 2015; el menshawy et al., 2011]. however,
in a decentralized setting, the high-level concepts can become
entwined with details of message flow. in this context, a data-
driven approach [montali et al., 2014] can unite meanings
with operations and processing [de masellis et al., 2017].
we adopt bspl (the blindingly simple protocol language)
[singh, 2011], which precisely expresses the information to
be exchanged between agents. thus, it yields enactments as
flexible as possible given causal and integrity constraints that
naturally encode meanings [chopra et al., 2020]. however,
the current bspl semantics [singh, 2012] and its variants
buyer
seller
po
ship
pay
(a) shipment first
buyer
seller
po
pay
ship
(b) payment first
buyer
seller
po
pay
ship
(c) concurrent
figure 1: some possible equivalent enactments of purchase.
produce a combinatorial explosion of enactments, which ex-
acerbates the complexity of formal verification.
let us describe the problem and solution informally. an
enactment (of a protocol) is what may happen when it is
instantiated—which messages are sent and received in what
order by what participant. consider a purchase protocol. a
role buyer sends po (a purchase order specifying item and
price) to a role seller, who responds to po with ship (of
that item). buyer sends pay of price in po. notice that ship
and pay are independent but each depends on po. figure 1
shows some enactments of purchase for a single transaction.
to capture decentralization, each enactment is modeled as
a vector of histories, one history per role [singh, 2012]. we
term two enactments equivalent if they reflect the “same” in-
formation and decision making at each role. representing
multiple equivalent enactments does not enhance the protocol
properties verified but exacerbates verification complexity.
a protocol may produce multiple equivalent enactments
for three main reasons. one, flexibility. figure 1’s enactments
differ only with respect to the ordering of pay and ship—
precisely the ordering that is irrelevant in the protocol. from
buyer’s perspective, po must precede ship and pay but their
order of occurrence is irrelevant. from seller’s perspective,
po must precede ship but how ship and pay are ordered is ir-
relevant. two, the infrastructure. for example, under fifo,
seller would observe po before pay, but either order is ac-
ceptable without fifo. three, the architecture. specifically,
decentralization means there is no central controller that can
force an agent to observe messages in a particular order.
to verify the correctness of a protocol, one would check
properties such as liveness and safety by generating a model
proceedings of the thirtieth   (ijcai-21)
391
 "
None,2021,https-www-ijcai-org-proceedings-2021-0056-pdf,Vitality Indices are Equivalent to Induced Game-Theoretic Centralities,Oskar Skibski,None,https://www.ijcai.org/proceedings/2021/0056.pdf,data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0056-pdf.pdf,../vikus-viewer/data/fulltext/pdf/2021/https-www-ijcai-org-proceedings-2021-0056-pdf.pdf,
